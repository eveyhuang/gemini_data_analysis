{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96095aed",
   "metadata": {},
   "source": [
    "### Extract outcome variables from excel sheret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f6a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d68160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'team_id': 'SLU1', 'funded_status': 0, 'members': ['Smadar Naoz', 'Keith Hawkins', 'Daniel Huber']}, {'team_id': 'SLU2', 'funded_status': 0, 'members': ['Andrew Vanderburg', 'Paul Robertson']}, {'team_id': 'SLU3', 'funded_status': 0, 'members': ['Eliza Kempton', 'Mathieu Lapotre', 'Laura Schaefer']}, {'team_id': 'SLU4', 'funded_status': 0, 'members': ['Stephanie Olson', 'Meredith MacGregor', 'Nathaniel Gabor']}, {'team_id': 'SLU5', 'funded_status': 0, 'members': ['Tyler Robinson', 'Liming Li']}, {'team_id': 'SLU6', 'funded_status': 0, 'members': ['Gregory Fournier', 'Gongjie Li']}, {'team_id': 'SLU7', 'funded_status': 1, 'members': ['Stilianos Louca', 'Gregory Fournier']}, {'team_id': 'SLU8', 'funded_status': 0, 'members': ['Laura Barge', 'Andro Rios']}, {'team_id': 'SLU9', 'funded_status': 0, 'members': ['Leslie Rogers', 'Ke Zhang']}, {'team_id': 'SLU10', 'funded_status': 1, 'members': ['Laura Schaefer', 'Meredith MacGregor', 'Aaron Engelhart']}, {'team_id': 'SLU11', 'funded_status': 0, 'members': ['Edward Schwieterman', 'Kimberly Lau', 'Betül Kaçar']}, {'team_id': 'SLU12', 'funded_status': 0, 'members': ['Morgan Raven', 'Trinity Hamilton', 'Simon Darroch']}, {'team_id': 'SLU13', 'funded_status': 0, 'members': ['Tyler Robinson', 'Noah Planavsky']}, {'team_id': 'SLU14', 'funded_status': 1, 'members': ['Marc Neveu', 'Ziming Yang']}, {'team_id': 'SLU15', 'funded_status': 1, 'members': ['Noah Planavsky', 'Rika Anderson']}, {'team_id': 'SLU16', 'funded_status': 1, 'members': ['Smadar Naoz', 'Jennifer Glass', 'Edwin Kite']}, {'team_id': 'SLU17', 'funded_status': 0, 'members': ['Eliza Kempton', 'Joseph Levy']}, {'team_id': 'SLU18', 'funded_status': 0, 'members': ['Amanda Stockton', 'Aaron Engelhart', 'Christopher Hamilton']}, {'team_id': 'SLU19', 'funded_status': 0, 'members': ['Keith Hawkins', 'Solange Duhamel']}, {'team_id': 'SLU20', 'funded_status': 0, 'members': ['Ziming Yang', 'Gongjie Li']}, {'team_id': 'SLU21', 'funded_status': 0, 'members': ['Jeffrey Marlow', 'Solange Duhamel', 'Christopher Hamilton']}, {'team_id': 'SLU22', 'funded_status': 0, 'members': ['Liming Li', 'Nicolas Cowan']}, {'team_id': 'SLU23', 'funded_status': 0, 'members': ['Mathieu Lapotre', 'Joseph Levy']}, {'team_id': 'SLU24', 'funded_status': 1, 'members': ['Edwin Kite', 'Christopher Reinhard', 'Stilianos Louca']}, {'team_id': 'SLU25', 'funded_status': 1, 'members': ['Laura Barge', 'Jeffrey Marlow']}, {'team_id': 'SLU26', 'funded_status': 1, 'members': ['Kimberly Lau', 'Bradford Foley', 'Stephanie Olson']}]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "csv_file_path = \"/Users/eveyhuang/Documents/NICO/gemini_code/data/2021SLU/SLU_teams_2021.xlsx\"\n",
    "df = pd.read_excel(csv_file_path)\n",
    "\n",
    "# Process the data\n",
    "teams_data = []\n",
    "for index, row in df.iterrows():\n",
    "    team_id = row['team_id']\n",
    "    funded_status = 1 if row['funding_status'] == 'funded' else 0\n",
    "    team_members = row['team_members'].split(', ')\n",
    "    \n",
    "    team_info = {\n",
    "        \"team_id\": team_id,\n",
    "        \"funded_status\": funded_status,\n",
    "        \"members\": team_members\n",
    "    }\n",
    "    teams_data.append(team_info)\n",
    "\n",
    "output_file_path = '/Users/eveyhuang/Documents/NICO/gemini_code/data/2021SLU/2021SLU_outcome.json'\n",
    "\n",
    "# Save the teams_data to a JSON file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(teams_data, json_file, indent=4)\n",
    "\n",
    "# Output the result\n",
    "print(teams_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15bc8e",
   "metadata": {},
   "source": [
    "### merge data for each session in output into data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa2cfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def add_times(time1, time2):\n",
    "    \n",
    "    # Split the time strings into hours and minutes\n",
    "    hours1, minutes1 = map(int, time1.split(':'))\n",
    "    hours2, minutes2 = map(int, time2.split(':'))\n",
    "    \n",
    "    # Add the hours and minutes separately\n",
    "    total_hours = hours1 + hours2\n",
    "    total_minutes = minutes1 + minutes2\n",
    "    \n",
    "    # If total minutes are 60 or more, convert to hours\n",
    "    if total_minutes >= 60:\n",
    "        total_hours += total_minutes // 60\n",
    "        total_minutes = total_minutes % 60\n",
    "    \n",
    "    #print(f\"adding {time1} and {time2} result is {total_hours:02}:{total_minutes:02}\")\n",
    "    # Format the result as \"HH:MM\"\n",
    "    return f\"{total_hours:02}:{total_minutes:02}\"\n",
    "\n",
    "def normalize_name(full_string):\n",
    "    \"\"\"\n",
    "    Extracts just the name from various formats of name strings.\n",
    "    \n",
    "    Args:\n",
    "        full_string: String containing name and additional information\n",
    "        \n",
    "    Returns:\n",
    "        String containing just the name\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove common titles\n",
    "    full_string = re.sub(r'^(Dr\\.?|Prof\\.?|Professor|Mr\\.?|Ms\\.?|Mrs\\.?)\\s+', '', full_string, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove everything after common separators\n",
    "    for separator in [' (', '-', ',']:\n",
    "        if separator in full_string:\n",
    "            full_string = full_string.split(separator)[0]\n",
    "    \n",
    "    # Clean up any remaining whitespace\n",
    "    name = full_string.strip()\n",
    "    \n",
    "    name = name.replace('.', '')\n",
    "    # Handle cases where institution is connected with a hyphen without space\n",
    "    parts = name.split('-')\n",
    "    if len(parts) > 1:\n",
    "        # Check if the part after hyphen contains \"University\" or similar institutional words\n",
    "        if any(word in parts[-1].lower() for word in ['university', 'college', 'institute', 'school', 'u of']):\n",
    "            name = parts[0].strip()\n",
    "    \n",
    "    return name\n",
    "\n",
    "def split_name(name):\n",
    "    \"\"\"Split a name into first and last (handles middle names by joining all but last as first).\"\"\"\n",
    "    parts = name.strip().split()\n",
    "    if len(parts) == 1:\n",
    "        return parts[0], \"\"\n",
    "    return \" \".join(parts[:-1]), parts[-1]\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def find_matching_name(name, correct_names, last_name_threshold=0.9, first_name_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Fuzzy match names, requiring a strong match on last name and a looser match on first name.\n",
    "    \"\"\"\n",
    "    name_first, name_last = split_name(name.lower())\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for correct_name in correct_names:\n",
    "        correct_first, correct_last = split_name(correct_name.lower())\n",
    "        # Compare last names\n",
    "        last_ratio = SequenceMatcher(None, name_last, correct_last).ratio()\n",
    "        if last_ratio >= last_name_threshold:\n",
    "            # Compare first names\n",
    "            first_ratio = SequenceMatcher(None, name_first, correct_first).ratio()\n",
    "            # Use average or weighted score for ranking\n",
    "            score = (last_ratio + first_ratio) / 2\n",
    "            if first_ratio >= first_name_threshold and score > best_score:\n",
    "                best_score = score\n",
    "                best_match = correct_name\n",
    "\n",
    "    if best_match:\n",
    "        return best_match, best_score\n",
    "    return None, 0\n",
    "\n",
    "# Example usage with more complex cases:\n",
    "def find_and_correct_name(name, correct_names, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Wrapper function that provides more detailed output about name matching.\n",
    "    \n",
    "    Args:\n",
    "        name: String containing the potentially misspelled name\n",
    "        correct_names: List of correctly spelled names\n",
    "        threshold: Float between 0 and 1, minimum similarity ratio to consider a match\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing matching information\n",
    "    \"\"\"\n",
    "    name = normalize_name(name)\n",
    "    match, ratio = find_matching_name(name, correct_names, threshold)\n",
    "    result = {\n",
    "        \"input_name\": name,\n",
    "        \"matched_name\": match,\n",
    "        \"similarity\": round(ratio, 3),\n",
    "        \"is_match\": ratio >= threshold\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7f4bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE conf name here \n",
    "conf_name = '2021MND'\n",
    "\n",
    "conference_dir = f'data/{conf_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167f90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/2021MZT/output_2021_09_30_MZT_S6, unmatched names: {'Matt Erdman', 'Sandra Laney', 'Troy Clavell Sutton', 'Pilar Fernandez'}\n",
      "outputs/2021MZT/output_2021_09_30_MZT_S7, unmatched names: {'Andrew Feig', 'Daren Ginete', 'Guillaume Bastille', 'Salvador Almagro', 'Hannah Frank Tulane', 'Mike Wimberly', 'Bethany McGregor USDA ARS', 'Richard Wiener', 'adela', 'Rebecca Garabed', 'Gonzalo Vazquez', 'Linda Detwiler'}\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S3, unmatched names: {'Peter Dorhout', 'Andrew Feig', 'Becky Smith', 'Chuck Lewis', 'Daren Ginete', 'Pilar Fernandez', 'A Ali Yanik', 'Prashant Singh', 'Beth Lautner', 'Richard Wiener', 'Christine K Johnson', 'Peter Dornhout', 'Rebecca Garabed', 'Linda Detwiler'}\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S4, unmatched names: {'Andrew Feig', 'Chuck Lewis', 'Pilar Fernandez', 'Joyce Jose Penn State', 'Adela Detwiler', 'Angela Arenas TAMU', 'Rebecca Garabed'}\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S5, unmatched names: set()\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S2, unmatched names: {'Troy Sutton', 'Katia Koelle', 'Guillaume Bastille', 'Adela', 'adela', 'Mike Wimberly', 'Amy Hartman', 'Linda Detwiler'}\n",
      "outputs/2021MZT/output_2021_09_30_MZT_S2, unmatched names: {'Andrew Feig', 'Guillaume Bastille', 'Bethany McGregor USDA ARS', 'Mike Wimberly', 'Gonzalo Vazquez'}\n",
      "outputs/2021MZT/output_2021_09_30_MZT_S5, unmatched names: {'Matt Erdman', 'Chuck Lewis', 'Troy Clavell Sutton', 'Pilar Fernandez'}\n",
      "outputs/2021MZT/output_2021_09_30_MZT_S4, unmatched names: {'Curt Horvath', 'Chang Yanling', 'Chang', 'Prashant Singh', 'Sandra Laney', 'Paola Boggiatto ARS/USDA'}\n",
      "outputs/2021MZT/output_2021_09_30_MZT_S3, unmatched names: {'Peter Dorhout', 'Diego Huet', 'Arenas', 'William Witola', 'Wilfred van der Donk', 'Erik Procko', 'Richard Wiener', 'Wilfred van der Donk UIUC/HHMI'}\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S9, unmatched names: {'Peter Dorhout', 'Andrew Feig', 'Becky Smith', 'Curt Horvath', 'A Ali Yanik', 'Wilfred van der Donk', 'Beth Lautner', 'Christine K Johnson', 'Silvia Ronco', 'Gonzalo Vazquez'}\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S7, unmatched names: {'Amy Vincent', 'Chuck Lewis', 'Paola Boggiatto ARS', 'Pilar Fernandez', 'Colin Basler', 'Erik Procko', 'Mike Wimberly', 'Amy Hartman'}\n",
      "Error processing file outputs/2021MZT/output_2021_10_01_MZT_S1/B1.1_Zoom_Meeting_Room_1_2021_10_01_11_04_18/all_B1.1_Zoom_Meeting_Room_1_2021_10_01_11_04_18.json: []\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S1, unmatched names: {'Heather Walden', 'Diego Huet', 'Amy Vincent', 'Pilar Fernandez', 'William Witola'}\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S8, unmatched names: {'Andrew Feig', 'Angela Arenas TAMU', 'Adela', 'Curt Horvath', 'Matt Erdman', 'Chang', 'adela'}\n",
      "outputs/2021MZT/output_2021_10_01_MZT_S11, unmatched names: {'William Witola', 'Joyce Jose Penn State', 'Wilfred van der Donk'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "with open(f'data/{conf_name}/{conf_name}_outcome.json') as f:\n",
    "    teams_data = json.load(f)\n",
    "\n",
    "team_data_names = set()\n",
    "\n",
    "for team in teams_data:\n",
    "    members = team['members']\n",
    "    for name in members:\n",
    "        team_data_names.add(name)\n",
    "\n",
    "\n",
    "def normalize_keys(entry):\n",
    "    normalized = {}\n",
    "    for key, value in entry.items():\n",
    "        normalized[key.replace(' ', '_')] = value\n",
    "    return normalized\n",
    "\n",
    "# merge data from output folders \n",
    "def merge_json_files(directory):\n",
    "    merged_data = []\n",
    "    all_speakers = []\n",
    "    speaking_length = 0\n",
    "    last_end_time = \"00:00\"\n",
    "    unmatch_names = set()\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.startswith(\"all\") and file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    for entry in data:\n",
    "                        entry = normalize_keys(entry)\n",
    "                        \n",
    "                        \n",
    "                        match_name_result = find_and_correct_name(entry['speaker'], team_data_names)\n",
    "                        if match_name_result['is_match']:\n",
    "                            entry['speaker'] = match_name_result['matched_name']\n",
    "                        else:\n",
    "                            entry['speaker'] = match_name_result['input_name']\n",
    "                            unmatch_names.add(entry['speaker'])\n",
    "                        all_speakers.append(entry['speaker'])\n",
    "                        speaking_length += int(entry['speaking_duration'])\n",
    "                        entry['start_time'] = add_times(entry['start_time'], last_end_time)\n",
    "                        entry['end_time'] = add_times(entry['end_time'], last_end_time)\n",
    "                            \n",
    "                        merged_data.append(entry)\n",
    "                    try:    \n",
    "                        last_end_time = max(entry['end_time'] for entry in data)\n",
    "                    except ValueError:\n",
    "                        print(f\"Error processing file {file_path}: {data}\")\n",
    "                        continue\n",
    "                    \n",
    "    unique_speakers = set(all_speakers)   \n",
    "    print(f\"{directory}, unmatched names: {unmatch_names}\")             \n",
    "    return merged_data, list(unique_speakers), speaking_length\n",
    "\n",
    "gemini_output_dir = f'outputs/{conf_name}'\n",
    "output_dir = f'data/{conf_name}'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "     os.makedirs(output_dir)\n",
    "\n",
    "for folder in os.listdir(gemini_output_dir):\n",
    "     if folder.startswith(\"output\"):\n",
    "          folder_path = os.path.join(gemini_output_dir, folder)\n",
    "          merged_data, all_speaker, speaking_length = merge_json_files(folder_path)\n",
    "          \n",
    "          result = {\n",
    "                \"all_speakers\": all_speaker,\n",
    "                \"total_speaking_length\": speaking_length,\n",
    "                \"all_data\": merged_data,     \n",
    "          }\n",
    "          \n",
    "          output_file_name = folder.replace(\"output_\", \"\").strip()\n",
    "          output_file_path = os.path.join(output_dir, f\"{output_file_name}.json\")\n",
    "          \n",
    "          with open(output_file_path, 'w') as f:\n",
    "                json.dump(result, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36ec47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read outcome.json to get team information (match each person to their team and funding status)\n",
    "\n",
    "outcome_file = os.path.join(conference_dir, f'{conf_name}_outcome.json')\n",
    "with open(outcome_file, 'r') as f:\n",
    "    outcome_data = json.load(f)\n",
    "\n",
    "# Create a mapping of normalized full names to their team IDs\n",
    "name_to_teams = defaultdict(list)  # Changed to defaultdict to store multiple teams per person\n",
    "for proposal in outcome_data:\n",
    "    team_id = proposal.get('team_id', '')\n",
    "    member_names = proposal.get('members', [])\n",
    "    funded_status = proposal.get('funded_status', None)\n",
    "    \n",
    "    if member_names:\n",
    "        for name in member_names:\n",
    "            \n",
    "            name_to_teams[name].append({\n",
    "                'team_id': team_id,\n",
    "                'full_name': name,\n",
    "                'funded_status': funded_status\n",
    "            })\n",
    "\n",
    "\n",
    "with open(f'data/{conf_name}/{conf_name}_person_to_team.json', 'w') as f:\n",
    "    data = json.dump(name_to_teams, f, indent=4)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8eaa5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 2021MND_person_to_team.json because it doesn't contain 'all_speakers'\n",
      "Skipping 2021MND_session_outcomes.json because it doesn't contain 'all_speakers'\n",
      "Names in outcome.json not identified in any session (could be due to different spellings or typos):\n",
      "Yang-Yu Liu\n",
      "People in sessions who never joined any team:\n",
      "Anne Hultgren\n",
      "Jia Li Zhu\n",
      "Leah Pyter\n",
      "Chris Whitlatch\n",
      "Camille Carole Habousha\n",
      "Joel Bango Kote\n",
      "Chris Whtibey\n",
      "Richard Wiener\n",
      "Jeff Bleich\n",
      "Barbara Bendlin\n",
      "Michael Coleman\n",
      "Andrew Walker R\n",
      "Sarah Mckachern\n",
      "Jill Sean McEachern\n",
      "Jia Li\n",
      "Robert Bryant Jr\n",
      "Robert Isaacson Jr\n",
      "Jeff Thompson\n",
      "Xiao\n",
      "Wendy Bahr\n",
      "Michael D Coleman\n",
      "Sarah MacEachern\n",
      "Laura Ellen Eisen\n",
      "Jeff Brian Norman\n",
      "Judith Eisen\n",
      "Leanne Debra Opheim Stoltze\n",
      "Kallol Mondal\n",
      "Ali Keshavarziian\n",
      "Carol F Huseboe\n",
      "David Bryman\n",
      "Emily Balskus\n",
      "Cesar de la Fuente UPenn\n",
      "Jarrad Horowitz\n",
      "William Zuercher\n",
      "Jell Barone\n",
      "Carl Bryan Agee\n",
      "Chris Whidbey\n",
      "Wesling Meng\n",
      "Xun Zhang\n",
      "Cesar de la Fuente U Penn\n",
      "Joel Bryan Bornstein\n",
      "Stephanie Rosener\n",
      "Haike Qi\n",
      "Sarkis Mazmanian\n",
      "Jeff Brian Marcum\n",
      "Maria Garami\n",
      "Robin Michelle Voigt\n",
      "Noah Palm\n",
      "William Zuckerberg\n",
      "Juli Barre\n",
      "Raffi Maya Levi\n",
      "Helene Gerasimo\n",
      "Xun Wang\n",
      "LaureAnne O'Bryan\n",
      "Robert Bryan\n",
      "Lisa Ryno\n",
      "Jeff Balser\n",
      "Jeff Levenson\n",
      "Gillian Zuberberg\n",
      "Xin Zhang\n",
      "Joel Weizman\n",
      "Jill Panzer Codding\n",
      "Emily Baleikus\n",
      "Robert Bryan Jr\n",
      "Chris Windey\n",
      "Jiali Ping\n",
      "Unidentified speaker\n",
      "Gillian Zybertberg\n",
      "Laurel Beckett\n",
      "Jeff Dongga\n",
      "Leanne Joan Dube\n",
      "George Weinstock\n",
      "Melanie Gareau\n",
      "Aida Ebrahimi\n",
      "Xu Zhang\n",
      "Sandra Laney\n",
      "Yael Kiselman\n",
      "Robin Michelle\n",
      "Joel Pfu\n",
      "Unknown speaker\n",
      "Stephanie Culina\n",
      "John-Paul Yu\n",
      "Jali Zilberberg\n",
      "Jinha Choi\n",
      "Aisla Ibrahimi\n",
      "Mayana Keynan\n",
      "Carl Bryan Bates\n",
      "Stephanie Grainger McOgga\n",
      "botB1\n",
      "Daren Ginete\n",
      "Laura Eisen\n",
      "Silvia Ronco RC4SA\n",
      "Jeff Brian Thurman\n",
      "Joel Zylberberg\n",
      "Xin Qi\n",
      "Joel Bornstein\n",
      "Silvia Rossbach\n",
      "Andrew\n",
      "Bishakha Mona\n",
      "Richard Morimoto\n",
      "Abhishek Shrivastava ASU\n",
      "Ali Keshavarzan\n",
      "Jae Seungh\n",
      "Wang Ying\n",
      "Shawroulla Hatoum\n",
      "Robert Frymier Jr\n",
      "Alexandra Bedford\n",
      "Jeff Bryan Kottkamp\n",
      "Wingjin Zhang\n",
      "Emily Balakus\n",
      "Arida Ebrahimi\n",
      "Jeff Errington\n",
      "Silvia Ronco\n",
      "Leah Pyter OSU\n",
      "All Bryan Bayles\n",
      "Andrew Feig\n",
      "Liang Song\n",
      "Lee Berg\n",
      "Rosa Krajmalnik\n",
      "Paul Hsu\n",
      "Jeff Brian Harman\n",
      "Will Thompson\n",
      "Jae Sung Kim\n",
      "Joel P Fhu\n",
      "Tanisia Chung\n",
      "Sheryl Hozier\n",
      "Jae\n",
      "Jill Panzer Godager\n",
      "Yang\n",
      "Laura Elias\n",
      "Abigail Levy\n",
      "Courtney Robinson\n",
      "Alda Ebrahimi\n",
      "Ashley Harris\n",
      "Michael D Cullinan\n",
      "Ali Keshavarzian\n",
      "Jeff Stine\n",
      "Sarah McEachran\n",
      "Melanie Gareau UC Davis\n",
      "Michael O'Bananu Coleman\n",
      "Chris Whitbey\n",
      "Melanie Garami\n",
      "JP Bryson\n",
      "Sarah Mackachern\n",
      "Ashley Marie Gorey\n",
      "Jill Marburger\n",
      "All\n",
      "Leslie Eisen\n",
      "Robin Voigt\n",
      "William Zuberbierg\n",
      "Lauren O'Connell\n",
      "Jeff Miller\n",
      "Jill Sarah MacEachern\n",
      "Stephanie M Goggin\n",
      "Cesar de la Fuente Ureña\n",
      "Lisa Ryne\n",
      "Kai Iwi\n",
      "Melanie Garces\n",
      "Alexandra Basford\n",
      "Jae Hwan Song\n",
      "Cesar de la Fuente\n",
      "Ali Keshavarazian\n",
      "Jeff Thomas\n",
      "Unidentified Speaker\n",
      "Andrew Ferg\n",
      "Jial Rongge Xue\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "with open(f'data/{conf_name}/{conf_name}_person_to_team.json', 'r') as f:\n",
    "    name_to_teams = json.load(f)\n",
    "    \n",
    "all_sessions = OrderedDict()\n",
    "\n",
    "# Process each JSON file in the directory\n",
    "for filename in os.listdir(conference_dir):\n",
    "    if filename.endswith('.json') and filename != f'{conf_name}_outcome.json':\n",
    "        file_path = os.path.join(conference_dir, filename)\n",
    "        \n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if \"all_speakers\" in data:\n",
    "            # Create an ordered dictionary for this session\n",
    "            session_data = OrderedDict()\n",
    "            session_data[\"all_speakers\"] = data[\"all_speakers\"]\n",
    "            \n",
    "            # Find teams present in this session\n",
    "            teams_in_session = defaultdict(list)\n",
    "            for name in data[\"all_speakers\"]:\n",
    "                \n",
    "                if name in name_to_teams:\n",
    "                    # Add person to all their teams\n",
    "                    for team_info in name_to_teams[name]:\n",
    "                        teams_in_session[team_info['team_id']].append({\n",
    "                            'name': team_info['full_name'],\n",
    "                            'funded_status': team_info['funded_status'],\n",
    "                            'team_id': team_info['team_id']\n",
    "                        })\n",
    "                \n",
    "            \n",
    "            # Add team information to session data, only including teams with at least 2 members\n",
    "            if teams_in_session:\n",
    "                session_data[\"teams\"] = OrderedDict()\n",
    "                for team_id, team_info in teams_in_session.items():\n",
    "                    if len(team_info) >= 2:  # Only include teams with 2 or more members\n",
    "                        session_data[\"teams\"][team_id] = {\n",
    "                            \"members\": [member['name'] for member in team_info],\n",
    "                            \"funded_status\": team_info[0]['funded_status'] if team_info else None\n",
    "                        }\n",
    "            \n",
    "            # Add to the main dictionary using the filename (without .json) as the key\n",
    "            session_name = os.path.splitext(filename)[0]\n",
    "            all_sessions[session_name] = session_data\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(f\"Skipping {filename} because it doesn't contain 'all_speakers'\")\n",
    "\n",
    "\n",
    "seen_names = set()\n",
    "for session_data in all_sessions.values():\n",
    "    if \"all_speakers\" in session_data:\n",
    "        seen_names.update(session_data[\"all_speakers\"])\n",
    "\n",
    "# Step 2: Find unmatched names\n",
    "unmatched_names = set(name_to_teams.keys()) - seen_names\n",
    "\n",
    "# Step 3: Print them\n",
    "print(\"Names in outcome.json not identified in any session (could be due to different spellings or typos):\")\n",
    "for name in unmatched_names:\n",
    "    print(name)\n",
    "    \n",
    "all_sessions['missing_names'] = list(unmatched_names)\n",
    "# Step 2: Find people not in any team\n",
    "not_in_any_team = seen_names - set(name_to_teams.keys())\n",
    "\n",
    "# Step 3: Print them\n",
    "print(\"People in sessions who never joined any team:\")\n",
    "for name in not_in_any_team:\n",
    "    print(name)\n",
    "\n",
    "all_sessions['people_not_in_any_team'] = list(set(not_in_any_team))\n",
    "with open(f'data/{conf_name}/{conf_name}_session_outcomes.json', 'w') as f:\n",
    "    data = json.dump(all_sessions, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
