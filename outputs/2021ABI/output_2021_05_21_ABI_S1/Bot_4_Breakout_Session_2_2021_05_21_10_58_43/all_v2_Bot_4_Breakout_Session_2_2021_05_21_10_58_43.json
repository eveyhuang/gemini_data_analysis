[
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:35-00:36",
        "transcript": "30 seconds.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the OBS software interface. The interface displays multiple windows, including the video feed of Brian Pogue, audio mixer controls, scene transitions, and recording controls. [low confidence]",
        "start_time": "00:35",
        "end_time": "00:36",
        "annotations": {
            "process management": "The utterance '30 seconds' directly relates to managing the meeting's time, aligning with the definition of process management which includes managing meeting flow and time."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:51-01:18",
        "transcript": "Okay, well while we're finishing that up, why don't we just do the 30 second intro to each other. Um, so I'm I'll start. I'm Brian Pogue, I'm at Dartmouth College. I've worked here for 25 years in different types of imaging technologies, optical imaging technologies in medicine. Um, mostly macroscopic imaging, so I I call myself an anti-microscopist. Um, I mostly work on things that you can see.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:51",
        "end_time": "01:18",
        "annotations": {
            "process management": "Brian suggests initiating a 30-second introduction session, which is an activity to manage the meeting's flow and structure.",
            "assign task": "Brian assigns himself the task of starting the introductions, taking responsibility for an action item.",
            "signal expertise": "Brian explicitly states his extensive experience and qualifications in different types of imaging technologies, further elaborating on his focus on macroscopic imaging and clarifying his work on visible things."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:21-01:22",
        "transcript": "Um, so why don't we go to Carolyn?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:21",
        "end_time": "01:22",
        "annotations": {
            "encourage participation": "The speaker invites Carolyn to speak, which directly aligns with encouraging participation by inviting someone to contribute their ideas or information."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "01:23-01:46",
        "transcript": "Hi, I'm Carolyn Bayer. I'm an assistant professor at Tulane University. Um, my research is in photoacoustic imaging, um, with some contrast ultrasound thrown in and um, I primarily focus on preeclampsia, um, and studying vascular development and remodeling of the placenta.",
        "speaking duration": 23,
        "nods_others": 1,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:23",
        "end_time": "01:46",
        "annotations": {
            "signal expertise": "Carolyn explicitly states her academic position as an assistant professor at Tulane University and details her research focus in photoacoustic imaging and preeclampsia, thereby signaling her qualifications and area of knowledge."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:46-01:50",
        "transcript": "Okay and next I'll just go by my screen, Katherine.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:46",
        "end_time": "01:50",
        "annotations": {
            "process management": "Brian Pogue manages the meeting flow by directing the next speaker in the round of introductions, explicitly stating his method of going 'by my screen' to maintain structure."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "01:52-02:18",
        "transcript": "Hi, I'm Katherine White. I'm an assistant professor at the University of Notre Dame and my lab sits at the interface of cancer cell biology and chemical biology. We develop new optogenetic tools that allow us to manipulate pH in space and time to better understand how spatial temporal pH dynamics regulate single cell behaviors and how this promotes um, uh, tumor genesis in in cancer development.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:52",
        "end_time": "02:18",
        "annotations": [
            {
                "Code Name": "signal expertise",
                "Explanation": "Katherine explicitly states her academic position, the interdisciplinary focus of her lab, and the specific research tools they develop to understand cancer development, thereby signaling her qualifications and area of expertise."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:21-02:22",
        "transcript": "Okay and Shannon.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:21",
        "end_time": "02:22",
        "annotations": {
            "process management": "Brian Pogue manages the meeting flow by directing the next speaker, Shannon, to continue the round of introductions."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "02:23-02:46",
        "transcript": "I'm an assistant professor at University of Georgia in computer science and biology. Um, and my lab revolves mostly around building computer vision machine learning tools for modeling spatial temporal changes in cellular systems in response to some kind of stimulus. Um, so I'm really excited about this discussion.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:23",
        "end_time": "02:46",
        "annotations": {
            "signal expertise": "Shannon explicitly states her academic position and details her lab's focus on building computer vision and machine learning tools, thereby signaling her qualifications and areas of knowledge.",
            "supportive response": "Shannon expresses a positive evaluation and enthusiasm for the ongoing discussion, indicating a supportive stance towards the collaborative activity."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:46-02:47",
        "transcript": "Great. Okay and Brian.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:46",
        "end_time": "02:47",
        "annotations": [
            {
                "Code Name": "supportive response",
                "Explanation": "Brian expresses positive evaluation ('Great') of the previous speaker's introduction."
            },
            {
                "Code Name": "encourage participation",
                "Explanation": "Brian invites the next group member, Brian, to speak, encouraging his contribution to the introductions."
            }
        ]
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "02:50-03:14",
        "transcript": "Everybody, I'm a physicist at Northeastern University. You can call me Bry to differentiate me from Brian Pogue. Um, and I work on photo medicine and um, cancer imaging and the imaging component is micro endoscopy, so miniature laser scanning microscopes to go inside the body and image with cellular resolution and we think a lot about multi photon.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 25.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:50",
        "end_time": "03:14",
        "annotations": {
            "signal expertise": "Bryan explicitly states his profession as a physicist and details his specific research areas, including photo medicine, cancer imaging, micro endoscopy, and multi-photon imaging, thereby signaling his expertise."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:15-03:22",
        "transcript": "And for full disclosure, Brian and Brian do we we do collaborate through a P1, so we're kind of breaking the rules here, but anyway.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:15",
        "end_time": "03:22",
        "annotations": {
            "signal expertise": "Brian Pogue explicitly states that he and Bryan Spring collaborate through a P1 grant, which signals their established expertise and qualifications in a relevant research area.",
            "express humor": "Brian Pogue makes a lighthearted, humorous remark by stating that their pre-existing collaboration is 'kind of breaking the rules here'."
        }
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "03:23-03:24",
        "transcript": "We'll keep it a secret.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:23",
        "end_time": "03:24",
        "annotations": {
            "express humor": "Bryan Spring's statement 'We'll keep it a secret' is a lighthearted, playful response to Brian Pogue's preceding comment about them 'breaking the rules' by collaborating, indicating a humorous remark."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:26-03:27",
        "transcript": "Uh, Sue.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:26",
        "end_time": "03:27",
        "annotations": {
            "process management": "Brian is managing the meeting flow by calling on Sue to take her turn in the ongoing sequence of introductions."
        }
    },
    {
        "speaker": "Seu Sim",
        "timestamp": "03:28-03:53",
        "transcript": "Hello everyone. I'm an assistant professor at UC Irvine chemistry department and I'm actually a self material chemist, so I make materials with living bacterial cells. So I want to arrange bacterial communities in three-dimensional order, so this is a good topic and I want to see how people, you know, think about the big challenge issue of temporal imaging.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 20.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:28",
        "end_time": "03:53",
        "annotations": {
            "signal expertise": "Seu Sim explicitly states her professional role as an assistant professor and her specific area of expertise as a self-material chemist who makes materials with living bacterial cells, signaling her qualifications.",
            "encourage participation": "Seu Sim invites other group members to share their thoughts on the 'big challenge issue of temporal imaging,' thereby encouraging their participation."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:53-03:55",
        "transcript": "Great. Okay and Larry.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:53",
        "end_time": "03:55",
        "annotations": {
            "supportive response": "Brian Pogue expresses positive evaluation for the previous speaker's contribution by saying 'Great. Okay'.",
            "encourage participation": "Brian Pogue invites Larry to contribute by calling his name, prompting him to introduce himself."
        }
    },
    {
        "speaker": "Larry Cheng",
        "timestamp": "03:56-04:33",
        "transcript": "Good morning everyone. Uh my name is Larry. I'm also professor at Penn State University. Uh our focus in the group has been mostly on the deformable multi modality sensors for the medical application. And our uh interest with spatial imaging uh primarily related to the threshold uh photo acoustic imaging on the membrane for the imaging of the whole cortex layer and to a particular address issue with the skull and we are really happy to see how different modality will be able to combine for the enhanced spatial temporal resolution.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:56",
        "end_time": "04:33",
        "annotations": {
            "signal expertise": "Larry explicitly states his group's focus on deformable multi-modality sensors for medical applications and their interest in spatial imaging, particularly photoacoustic imaging for cortex and skull issues, demonstrating their relevant expertise."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:33-04:35",
        "transcript": "Great. Okay and Josh.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:33",
        "end_time": "04:35",
        "annotations": {
            "encourage participation": "Brian Pogue explicitly invites Josh to speak by saying \"and Josh,\" which prompts him to contribute his introduction to the group."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:36-05:06",
        "transcript": "Everybody, my name is Josh Brake. I'm an assistant professor at Harvey Mudd College about 30 miles outside Los Angeles. And uh the focus of my group is on uh deep tissue imaging using optical wavefront shaping, trying to use scattered light to see deeper into tissue. And also a little bit of work in computational microscopy with a particular um uh edge looking at how we can use that for education and teaching optics. Um, I'm really looking forward to conversation with you all today.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the OBS software interface. The interface displays multiple windows, including the video feed of Josh Brake, audio mixer controls, scene transitions, and recording controls. [low confidence]",
        "start_time": "04:36",
        "end_time": "05:06",
        "annotations": {
            "signal expertise": "Josh explicitly states his name, affiliation, and the specific research and teaching focuses of his group, thereby establishing his qualifications and areas of expertise relevant to the meeting."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:07-05:10",
        "transcript": "Great. And uh Katie.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:07",
        "end_time": "05:10",
        "annotations": {
            "supportive response": "Brian Pogue expresses positive evaluation ('Great') in response to the previous speaker's introduction.",
            "process management": "Brian Pogue manages the meeting flow by calling on the next participant ('Katie') to continue the round of introductions."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "05:11-05:45",
        "transcript": "Hi, I'm Katie Keenan. I'm from the National Institute of Standards and Technology in Boulder, Colorado. Uh and I work on quantitative MRI and how we can um validate some quantitative properties and you can measure information about what the protons are doing and that gives you uh the ideas, it gives you information about the state of the tissue. Um, but we're also moving into low field MRI applications.",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:11",
        "end_time": "05:45",
        "annotations": {
            "signal expertise": "Katy Keenan explicitly states her name, affiliation, and details her work on quantitative MRI, including validating properties and moving into low field MRI applications, which clearly communicates her relevant qualifications and background to the group."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "05:45-05:46",
        "transcript": "Cool.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:45",
        "end_time": "05:46",
        "annotations": {
            "supportive response": "The utterance 'Cool.' expresses a positive evaluation or agreement, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:46-05:50",
        "transcript": "Yeah, I love that topic. That's that's a nice one.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:46",
        "end_time": "05:50",
        "annotations": {
            "supportive response": "Brian Pogue expresses positive evaluation for Katy Keenan's previously mentioned topic on quantitative MRI and low field MRI by stating \"I love that topic\" and \"That's a nice one\"."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:50-06:03",
        "transcript": "Uh, Nina. Hi, I'm Nina Cardoza. I'm director for grants and operations at the Chan Zuckerberg Initiative and I am an observer.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:50",
        "end_time": "06:03",
        "annotations": {
            "encourage participation": "Brian Pogue explicitly invites Nina to speak by calling her name, encouraging her to participate in the introductions.",
            "signal expertise": "Nina explicitly states her professional role and her status as an observer, which clarifies her qualifications and the nature of her contribution to the meeting."
        }
    },
    {
        "speaker": "Nina Cardoza",
        "timestamp": "06:03-06:04",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:03",
        "end_time": "06:04",
        "annotations": {
            "supportive response": "The utterance \"Okay\" serves as a minimal affirmative response, acknowledging the previous speaker's \"Okay\" and signaling the completion of the self-introduction."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:05-06:06",
        "transcript": "And got bot for too, but I don't know what that is.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:05",
        "end_time": "06:06",
        "annotations": {
            "identify knowledge gap": "The speaker explicitly states 'I don't know what that is,' indicating a lack of familiarity or knowledge regarding 'bot for too'."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:06-06:07",
        "transcript": "Um, okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:06",
        "end_time": "06:07",
        "annotations": {
            "process management": "Brian Pogue uses \"Um, okay\" to signal the completion of the introductions and transition the meeting to the next phase, which is a form of managing the meeting flow."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:07-06:11",
        "transcript": "So where should we start?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:07",
        "end_time": "06:11",
        "annotations": {
            "process management": "The utterance 'So where should we start?' is an attempt to manage the meeting's flow by initiating the next phase of discussion after introductions."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:11-06:15",
        "transcript": "Any initial thoughts?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:11",
        "end_time": "06:15",
        "annotations": {
            "encourage participation": "The speaker invites the group to contribute their initial thoughts, opinions, or ideas, which aligns with encouraging participation by inviting others to share their input."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:15-06:17",
        "transcript": "Or questions?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:15",
        "end_time": "06:17",
        "annotations": {
            "encourage participation": "Brian Pogue invites the group to contribute by asking if they have any questions, thereby encouraging their participation in the discussion."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:17-06:20",
        "transcript": "Wait, I have more questions than thoughts I think at this time.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:17",
        "end_time": "06:20",
        "annotations": {
            "identify knowledge gap": "Brian explicitly states he has 'more questions than thoughts,' indicating a current lack of clear ideas or understanding that needs to be addressed through inquiry before he can contribute concrete thoughts."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:20-06:23",
        "transcript": "Any any big questions that we shouldn't try to answer as a group?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:20",
        "end_time": "06:23",
        "annotations": {
            "encourage participation": "Brian Pogue invites the group to contribute their thoughts or questions by asking \"Any any big questions that we shouldn't try to answer as a group?\", which encourages their participation in the discussion."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "06:26-06:30",
        "transcript": "I'm just curious how people do this right now.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:26",
        "end_time": "06:30",
        "annotations": {
            "ask question": "The utterance \"I'm just curious how people do this right now\" is a direct request for information from other team members regarding current practices, aligning with the definition of asking a question."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "06:30-06:35",
        "transcript": "Um, how folks here image across spatial and temporal domains?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:30",
        "end_time": "06:35",
        "annotations": {
            "ask question": "The utterance is a direct request for information from other team members about their methods for imaging across spatial and temporal domains, which aligns with the definition of asking a question."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:37-06:39",
        "transcript": "Yeah, what are the things that work?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:37",
        "end_time": "06:39",
        "annotations": {
            "utterance": "Brian Pogue: Yeah, what are the things that work?",
            "annotations": [
                {
                    "code_name": "ask question",
                    "explanation": "Brian asks for information about what methods or approaches are currently effective, which is a request for information from other team members."
                }
            ]
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:39-06:40",
        "transcript": "What are the success stories, you know?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:39",
        "end_time": "06:40",
        "annotations": {
            "ask question": "Brian asks for information about 'success stories' in imaging across spatial and temporal domains, directly requesting examples of what works from the group."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:41-06:42",
        "transcript": "Any any ideas?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:41",
        "end_time": "06:42",
        "annotations": {
            "encourage participation": "Brian Pogue explicitly invites the group to contribute their ideas by asking \"Any any ideas?\", which serves to open the floor for discussion."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "06:55-07:17",
        "transcript": "One question I had when I looked at this is when we do work in MRI, we do a lot of under sampling uh and I don't know how much of that is done on the microscopy side. So we we do a lot of under sampling and then, you know, clever recon to try to find the information that you lost with your under sampling.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:55",
        "end_time": "07:17",
        "annotations": {
            "ask question": "Katy asks \"I don't know how much of that is done on the microscopy side,\" requesting information about the application of under sampling in microscopy.",
            "develop idea": "Katy elaborates on the concept of under sampling by explaining the subsequent step of \"clever recon\" to recover lost information, building upon the initial mention of under sampling."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "07:17-07:21",
        "transcript": "So can anyone tell me what you guys what happens on the microscopy side?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:17",
        "end_time": "07:21",
        "annotations": {
            "ask question": "Katy explicitly requests information from the group about practices in microscopy by asking \"can anyone tell me what you guys what happens on the microscopy side?\""
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:22-07:26",
        "transcript": "And by under sampling just to define that so you under sample in frequency space or something?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:22",
        "end_time": "07:26",
        "annotations": {
            "ask question": "Brian Pogue asks for clarification on the term 'under sampling' that was just mentioned by Katy Keenan, seeking to define it or confirm his understanding."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "07:27-07:37",
        "transcript": "Yes, exactly. So in MRI we acquire in frequency space or K space and then we typically do a 4A transform to image space, but a lot of AI is replacing the 4A transform.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:27",
        "end_time": "07:37",
        "annotations": [
            {
                "Code Name": "supportive response",
                "Explanation": "Katy Keenan expresses agreement with Brian Pogue's clarification by saying 'Yes, exactly', validating his understanding of 'under sampling'."
            },
            {
                "Code Name": "develop idea",
                "Explanation": "Katy Keenan elaborates on the concept of under sampling in MRI by explaining the acquisition process in frequency space and the role of 4A transform and AI in image reconstruction."
            }
        ]
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "07:37-08:24",
        "transcript": "Um, and then you can do under sampling by acquiring less data and also by uh using more sensors essentially. So we have parallel coils but just increasing the number of sensors you have. So that's a common strategy that we use across imaging modalities.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:37",
        "end_time": "08:24",
        "annotations": {
            "develop idea": "Katy elaborates on the concept of under sampling by explaining methods such as acquiring less data and using more sensors, providing the example of parallel coils, and stating that this is a common strategy across imaging modalities."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "00:00-00:22",
        "transcript": "are we setting up our experiment to ensure we're not missing something important and how can we ensure after the fact that our our collected data which we um uh that our collected data is representative of of the biology in terms of potential heterogeneity which is certainly important for cancer.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:00",
        "end_time": "10:22",
        "annotations": [
            {
                "Code Name": "ask question",
                "Explanation": "Katharine asks a question about how the experiment is being set up to ensure no important information is missed."
            },
            {
                "Code Name": "ask question",
                "Explanation": "Katharine asks a question about how to ensure the collected data is representative of the biology, particularly concerning heterogeneity in cancer."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:23-00:36",
        "transcript": "Actually as you were talking I just realized I made a catastrophic mistake which is we do not have a scribe yet. So,",
        "speaking duration": 13,
        "nods_others": 1,
        "smile_self": 23,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:23",
        "end_time": "10:36",
        "annotations": {
            "process management": "The speaker identifies a missing scribe, which is an explicit recognition of an oversight in managing the meeting's structure and organization."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:36-00:48",
        "transcript": "would love to be a scribe. Not it. Nobody? Otherwise I'm going to have to randomly choose somebody.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 58,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:36",
        "end_time": "10:48",
        "annotations": {
            "express humor": "Brian uses sarcasm and a playful phrase to humorously decline the role of scribe.",
            "encourage participation": "Brian asks 'Nobody?' to invite a volunteer for the scribe role.",
            "process management": "Brian states he will randomly choose someone, indicating a method for managing the assignment of the scribe role."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "00:49-00:55",
        "transcript": "I was a scribe in my first breakout group. So I I eliminate myself from running.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 17,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:49",
        "end_time": "10:55",
        "annotations": [
            {
                "Code Name": "None",
                "Explanation": "This sentence provides context about a past role but does not directly align with any of the defined interaction codes."
            },
            {
                "Code Name": "process management",
                "Explanation": "This sentence directly contributes to managing the group activity of finding a scribe by explicitly removing the speaker from consideration for the role, which is part of organizing group activities."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:55-01:04",
        "transcript": "Shannon gets a free pass. Um okay. Um Alright. How do you Oh, Josh?",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 22,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:55",
        "end_time": "11:04",
        "annotations": {
            "annotations": [
                {
                    "sentence": "Shannon gets a free pass.",
                    "code_name": "process management",
                    "explanation": "Brian is managing the process of assigning a scribe by excusing Shannon from the task, which falls under organizing group activities."
                },
                {
                    "sentence": "Um okay.",
                    "code_name": "None",
                    "explanation": "This is a filler phrase and does not align with any specific code in the codebook."
                },
                {
                    "sentence": "Um Alright.",
                    "code_name": "None",
                    "explanation": "This is a filler phrase and does not align with any specific code in the codebook."
                },
                {
                    "sentence": "How do you Oh, Josh?",
                    "code_name": "encourage participation",
                    "explanation": "Brian directly invites Josh to contribute his thoughts or ideas by calling on him."
                }
            ]
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "01:04-01:07",
        "transcript": "I was going to say I don't mind I don't mind taking notes. I don't mind scribing.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:04",
        "end_time": "11:07",
        "annotations": {
            "process management": "Josh volunteers to take notes and scribe, which directly addresses the need for a scribe and contributes to managing the meeting's organization and flow."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:07-01:11",
        "transcript": "Okay, awesome, awesome.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:07",
        "end_time": "11:11",
        "annotations": {
            "supportive response": "Brian Pogue expresses strong positive evaluation and agreement with Josh's offer to take notes by saying 'Okay, awesome, awesome.'"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:11-01:22",
        "transcript": "I was taking notes myself and I realized which I compulsively do because I never retained anything unless I write it down. Uh, but uh you're right then. Okay.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 18,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:11",
        "end_time": "11:22",
        "annotations": {
            "None": "Brian shares a personal anecdote about his note-taking habits and the reason behind them, which does not align with any of the defined codes.",
            "supportive response": "Brian expresses agreement and acceptance of Josh's offer to scribe by stating 'you're right then. Okay.', thereby validating his contribution."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:22-01:36",
        "transcript": "So what do we think about that? So in the microscopy world, you know, this is where it's done a lot, right? In the microscopy world, high spatial, high temporal sampling, you know, a lot of success stories, right?",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:22",
        "end_time": "11:36",
        "annotations": [
            {
                "Code Name": "ask question",
                "Explanation": "Brian asks the group for their thoughts and opinions on the preceding discussion about sampling in microscopy."
            },
            {
                "Code Name": "ask question",
                "Explanation": "Brian asks for confirmation on his statement that high sampling is commonly practiced in the microscopy field."
            },
            {
                "Code Name": "ask question",
                "Explanation": "Brian seeks confirmation from the group regarding the prevalence of success stories related to high spatial and temporal sampling in microscopy."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:36-01:38",
        "transcript": "But as you say, there's limits.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:36",
        "end_time": "11:38",
        "annotations": {
            "acknowledge contribution": "Brian Pogue verbally recognizes Katy Keenan's prior input about the limitations of under-sampling by stating \"as you say, there's limits,\" without explicitly agreeing or expanding on the idea."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "01:39-02:33",
        "transcript": "Yeah, there's also a problem frequently that you're collecting more data than you need to study the biology and then that's just data that you have to process and analyze and and so for for us on the experimental side it's always a question of well how how much do we need, how fast do we need, how how good does our spatial resolution need to be in order to to capture what we're looking what we're interested in in terms of the biology and sometimes that can be hard to determine a priori as you go into an experiment, um, but comes from after this analysis of this high density data, you realize that oh we're actually not seeing, you know, the dynamics at the scale that we were expecting or we're actually able to, you know, densify our data by eliminating or by",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 11,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:39",
        "end_time": "12:33",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Katharine elaborates on the challenges of data collection in microscopy, explaining that collecting excessive data leads to processing burdens and that determining the optimal amount, speed, and spatial resolution of data is a difficult question for experimentalists to answer a priori."
            }
        ]
    },
    {
        "speaker": "Katharine White",
        "timestamp": "02:33-02:33",
        "transcript": "uh",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:33",
        "end_time": "12:33",
        "annotations": {
            "None": "The utterance consists only of a filler word 'uh' and does not convey any substantive meaning that aligns with the provided codes."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:34-02:37",
        "transcript": "you got to have the same density, right? So yeah.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:34",
        "end_time": "12:37",
        "annotations": {
            "ask question": "Brian asks for confirmation or clarification on the necessity of maintaining the same data density, directly following up on Katharine's discussion about data collection and density, which aligns with requesting information or clarification on a prior statement."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:38-02:42",
        "transcript": "especially as you get in as you say get into very high sampling and you can.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:38",
        "end_time": "12:42",
        "annotations": {
            "develop idea": "The speaker elaborates on the existing idea of 'very high sampling' in microscopy, building upon the previous discussion about data collection and its implications."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "02:42-03:16",
        "transcript": "Yeah, yeah, so like, you know, we're interested in actin cytoskeleton remodeling which occurs on a two minute time scale, but the actual particle dynamics are on a much faster time scale. So if we do 25 millisecond collection, we're left with all of this data for a two minute experiment that not all of it is useful, not all of it is, you know, significant from one one part to the next in terms of of even identifying particle movement or real dynamics particularly as we sorry.",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 12,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:42",
        "end_time": "13:16",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Katharine elaborates on the challenges of data collection in microscopy by providing an example of biological processes occurring at different time scales and explaining how collecting data at a very fast rate for a slower process results in a large amount of non-useful data."
            }
        ]
    },
    {
        "speaker": "Andrew Ferg",
        "timestamp": "03:18-03:30",
        "transcript": "If you think about the computational space that the QMMM folks have dealt with this problem quite effectively. So how would you think about bringing in their insights into the data collection realm.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a person with a desert background. The person is speaking about computational space and data collection.",
        "start_time": "13:18",
        "end_time": "13:30",
        "annotations": {
            "propose new idea": "The speaker introduces the new idea of considering how QMMM (Quantum Mechanics/Molecular Mechanics) folks have effectively dealt with a similar problem, suggesting a new source of insight for the current discussion.",
            "ask question": "The speaker asks the group for their thoughts on how to apply the insights from QMMM to the data collection realm, seeking information and ideas."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "03:30-04:15",
        "transcript": "Yeah, I would have I would have no idea in terms of that. We at our at our level we're kind of struggling even from from kind of trying to find off the shelf analyses that we can that we can use to kind of mine our data and my lab is not computationally heavy. We're definitely more on the protein biosensor tool development application side and so it can be definitely daunting for graduate students and even postdocs who haven't don't have experience in in those areas to kind of delve into these to these areas and so that's one one case that I that I struggle with as a as a mentor to to get my students all um uh",
        "speaking duration": 45,
        "nods_others": 0,
        "smile_self": 13,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:30",
        "end_time": "14:15",
        "annotations": {
            "identify knowledge gap": "Katharine explicitly states her lack of knowledge regarding the previous suggestion and explains that her lab struggles with computational analyses because they are not computationally heavy, indicating a gap in their expertise and resources."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:15-04:22",
        "transcript": "Is there a need for tools? Is there a need for sort of canned tools there to help microscopists?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:15",
        "end_time": "14:22",
        "annotations": {
            "ask question": "Brian asks the group if there is a need for tools, specifically 'canned tools,' to assist microscopists, seeking information and opinions from the team following a discussion about computational struggles."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "04:23-04:25",
        "transcript": "I mean, I think so.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:23",
        "end_time": "14:25",
        "annotations": {
            "supportive response": "Katharine expresses agreement with Brian Pogue's suggestion that there is a need for canned tools to help microscopists, without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:26-04:32",
        "transcript": "Is it one of the beautiful things about microscopy is there's all kinds of open source tools available, right?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:26",
        "end_time": "14:32",
        "annotations": {
            "ask question": "The speaker asks a question to confirm the availability of open-source tools in microscopy, seeking information or clarification from the group."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "04:33-04:56",
        "transcript": "Yeah, but how how well those work off the off the shelf uh can can vary quite significantly even in terms of like parameter setting, what does this parameter mean? And because it's open source it's not, you know, the annotation of that is not always consistent. So you can have",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:33",
        "end_time": "14:56",
        "annotations": [
            {
                "Code Name": "critical response",
                "Explanation": "Katharine questions the effectiveness and ease of use of 'off-the-shelf' open-source tools, specifically regarding parameter setting, which challenges the prior positive framing of such tools."
            },
            {
                "Code Name": "develop idea",
                "Explanation": "Katharine elaborates on the reason for the variability and difficulty of open-source tools by explaining that their annotation is often inconsistent due to their open-source nature."
            }
        ]
    },
    {
        "speaker": "Katharine White",
        "timestamp": "04:56-05:11",
        "transcript": "for example, membrane dynamics trackers on GitHub, a reasonable paper, but you know, the paper is on version one, this version 4.0 and there's all these new parameters and so it can become difficult and you obviously don't want to be retreading like redesigning new stuff and we certainly don't want to be redesigning new stuff if there's stuff out there that has been shown to beautifully work in a paper, but in terms of of application for a lot of my students they struggle trying to trying to kind of take these these",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:56",
        "end_time": "15:11",
        "annotations": {
            "identify knowledge gap": {
                "explanation": "Katharine highlights a practical challenge for her students in using existing open-source tools, explaining that discrepancies between paper versions and software versions, along with new parameters, make it difficult to apply these resources effectively, indicating a gap in skill or familiarity."
            }
        }
    },
    {
        "speaker": "Andrew Ferg",
        "timestamp": "05:11-05:12",
        "transcript": "So",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:11",
        "end_time": "15:12",
        "annotations": [
            {
                "code_name": "None",
                "explanation": "The utterance 'So' is an incomplete thought and does not convey enough explicit content to be categorized under any of the provided codes."
            }
        ]
    },
    {
        "speaker": "Katharine White",
        "timestamp": "05:12-05:37",
        "transcript": "very awesome, very powerful already developed systems off the shelf. So.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:12",
        "end_time": "15:37",
        "annotations": {
            "supportive response": "Katharine expresses a positive evaluation of the \"already developed systems off the shelf,\" which were previously discussed as \"open source tools\" by Brian Pogue, thereby validating their quality."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:37-05:52",
        "transcript": "So we we talked a little bit about MR now microscopy are there other techniques or success stories across spatial and temporal domains that people want to chime in on?",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:37",
        "end_time": "15:52",
        "annotations": {
            "encourage participation": "Brian invites the group to contribute by asking if there are other techniques or success stories across spatial and temporal domains that people want to chime in on, encouraging their input."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "05:52-06:11",
        "transcript": "I mean I I do photostic imaging and that kind of often it's seen as something that kind of slows those dimensions so we have certainly not the spatial resolution of optical techniques.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:52",
        "end_time": "16:11",
        "annotations": {
            "identify knowledge gap": "Carolyn explicitly recognizes a limitation in photoacoustic imaging, stating that it lacks the spatial resolution of optical techniques, which identifies a gap in the capabilities of her domain."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "06:11-06:25",
        "transcript": "Um but still have good spatial resolution and it's generally seen as real time or close to real time. Um, so again, not fast enough to see some of the fast cellular molecular dynamics, but",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:11",
        "end_time": "16:25",
        "annotations": {
            "develop idea": "Carolyn elaborates on the capabilities of photoacoustic imaging by clarifying its good spatial resolution and real-time temporal characteristics.",
            "identify knowledge gap": "Carolyn explicitly recognizes a limitation of photoacoustic imaging, stating it is not fast enough to observe certain cellular molecular dynamics."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "06:25-06:27",
        "transcript": "again, sort of splitting the middle.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:25",
        "end_time": "16:27",
        "annotations": {
            "develop idea": "This utterance elaborates on the characteristics of photoacoustic imaging, clarifying its position as a compromise between different imaging modalities in terms of spatial and temporal resolution."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "06:27-06:36",
        "transcript": "Um, I also had a question, what is QMM? Because I tried to Google it real quick and that there in the 60 second question generation, but",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:27",
        "end_time": "16:36",
        "annotations": [
            {
                "Code Name": "ask question",
                "Explanation": "Carolyn explicitly asks for clarification on 'QMM', which was a prior statement by another group member, demonstrating a request for information."
            },
            {
                "Code Name": "None",
                "Explanation": "This sentence provides context for the preceding question by explaining that the speaker attempted to find the information independently but could not quickly, and does not fit any specific code."
            }
        ]
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "06:36-06:39",
        "transcript": "maybe there's someone else like me who doesn't actually know what that is.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:36",
        "end_time": "16:39",
        "annotations": {
            "identify knowledge gap": "This utterance explicitly recognizes Carolyn's own lack of knowledge regarding 'QMM' by stating 'doesn't actually know what that is', aligning with the definition of identifying a knowledge gap."
        }
    },
    {
        "speaker": "Andrew Ferg",
        "timestamp": "06:40-07:12",
        "transcript": "So speaking in acronyms. Uh QM is quantum mechanics. MM is molecular mechanics and so it's it's the way that the computational dynamicists move between the femto second vibrational time scales and the um uh microsecond uh and and up from the from the pico to millisecond ranges.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a person with a desert background. The person is explaining the acronyms QM and MM.",
        "start_time": "16:40",
        "end_time": "17:12",
        "annotations": {
            "develop idea": "Andrew explains that QM stands for quantum mechanics and MM for molecular mechanics, elaborating on how computational dynamicists use these to bridge different time scales, which clarifies the previously mentioned acronym QMM."
        }
    },
    {
        "speaker": "Andrew Ferg",
        "timestamp": "07:12-07:12",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a person with a desert background. The person is explaining the acronyms QM and MM.",
        "start_time": "17:12",
        "end_time": "17:12",
        "annotations": [
            {
                "code_name": "None",
                "explanation": "The utterance 'Okay.' is a generic discourse marker that does not explicitly fit any of the provided codes without inferring intent or stretching the definitions beyond what is explicitly observed."
            }
        ]
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:14-07:21",
        "transcript": "Oh, so it's like how do we have a molecular dynamic situation for image simulation for imaging data. That's kind of the analogy you're drawing.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:14",
        "end_time": "17:21",
        "annotations": {
            "ask question": "Shannon is asking for clarification and confirmation of the analogy Andrew is drawing between QMMM and image simulation for imaging data, which seeks information on a prior statement."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:21-07:24",
        "transcript": "Like a multi scale approach kind of like.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:21",
        "end_time": "17:24",
        "annotations": {
            "ask question": "The speaker rephrases the concept of QMMM as a 'multi scale approach' and uses 'kind of like' to implicitly ask for confirmation or clarification from other team members regarding his understanding of the previously discussed idea."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:24-07:28",
        "transcript": "Huh. Okay. I I I get that a little more now.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:24",
        "end_time": "17:28",
        "annotations": {
            "supportive response": "The speaker expresses that they now understand the concept better, which serves as a positive evaluation of the preceding explanation provided by other group members."
        }
    },
    {
        "speaker": "Andrew Ferg",
        "timestamp": "07:28-07:58",
        "transcript": "Yeah, so they have ways that they computationally choose um we're going to run 100 pico seconds at a molecular dynamic scale and then they're going to run some femto a couple femto seconds of quantum mechanics at super high resolution. And so it it shifts it keep the computationally it keeps shifting the time scales in a in a structured manner to get the information across the time domains.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a person with a desert background. The person is explaining the acronyms QM and MM.",
        "start_time": "17:28",
        "end_time": "17:58",
        "annotations": {
            "develop idea": "Andrew is elaborating on the QMMM concept by providing a detailed example of how it computationally shifts between different time scales (pico seconds for molecular dynamics and femto seconds for quantum mechanics) to gather information across time domains."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:59-08:01",
        "transcript": "Interesting. Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:59",
        "end_time": "18:01",
        "annotations": {
            "supportive response": "Brian expresses positive evaluation and agreement with Andrew's explanation of QMMM, without adding new content."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "08:03-08:08",
        "transcript": "Do they always do it in a structured manner or do they sometimes randomize it?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:03",
        "end_time": "18:08",
        "annotations": {
            "ask question": "Katy asks for clarification on whether the computational approach discussed is always structured or sometimes randomized, seeking information about a prior statement."
        }
    },
    {
        "speaker": "Andrew Ferg",
        "timestamp": "08:09-08:14",
        "transcript": "Um, depends on the implementation. It can it can certainly be done in sort of a Monte Carloish uh approach.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a person with a desert background. The person is explaining the acronyms QM and MM.",
        "start_time": "18:09",
        "end_time": "18:14",
        "annotations": {
            "develop idea": "Andrew Ferg elaborates on the implementation of QMMM by explaining that it can be done in a randomized, Monte Carlo-like approach, which expands on the previous discussion about how this computational method operates."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "00:08-00:34",
        "transcript": "So I guess a couple a couple things that came to mind for me was thinking about specifying regions of interest in some larger volume and then bouncing between those to sample them. I also wonder what it would look like tying into this it it feels to me that the computation like we were hard to translate that directly to imaging because if you don't if you sample at a low resolution, you don't you're missing in some sense.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:08",
        "end_time": "20:34",
        "annotations": {
            "propose new idea": "Josh proposes a new approach for data collection by suggesting specifying regions of interest in a larger volume and sampling between them.",
            "critical response": "Josh expresses a critical concern about directly translating computational methods to imaging, highlighting that low-resolution sampling in imaging results in missing information."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "00:34-01:42",
        "transcript": "So I wonder if there if there's a hybrid modality where you have a front end which is maximally performant in space and time and obviously you can't have your cake and eat it too, so you have to make a choice about which of those you want to optimize and that still maybe a hard choice to make. But let's say you pick that out and then you're you're taking all of the system, you know, performance you can possibly muster and then in between that layer before you actually save the data, you have something that can run at quasi real time show you, okay, this is important or not based on this highest quality data we can get and then only storing, you know, because this is something that we talked about yesterday as well with super resolution and light sheet. I mean, just the amount of data get",
        "speaking duration": 68,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:34",
        "end_time": "21:42",
        "annotations": [
            {
                "code_name": "propose new idea",
                "explanation": "Josh proposes a new 'hybrid modality' approach for imaging that aims for maximal performance in space and time, acknowledging the inherent trade-offs."
            },
            {
                "code_name": "develop idea",
                "explanation": "Josh elaborates on the proposed hybrid modality by suggesting a real-time processing layer that determines data importance before storage, building on the concept of optimizing data collection."
            },
            {
                "code_name": "develop idea",
                "explanation": "This fragment continues to develop the idea by implicitly referencing the large amount of data generated, which the proposed real-time processing layer aims to address."
            }
        ]
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "01:42-02:13",
        "transcript": "and then what are you going to do? So that's uh practical something but it seems to me that that you can't you you really play a risky game if you do some do too much down sampling in your collection all the way out to the you know, your imaging because you might miss something. It's like anything else. If you alias the signal, it's done that is not you can't go can't go back. I mean, maybe you can. Maybe that's an open question, but at least conventionally we think you can't go back.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0.06,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:42",
        "end_time": "22:13",
        "annotations": [
            {
                "Code Name": "critical response",
                "Explanation": "Josh expresses a negative evaluation of excessive downsampling, stating it's a 'risky game' because it could lead to missing important information."
            },
            {
                "Code Name": "develop idea",
                "Explanation": "Josh elaborates on the critical response by providing reasoning that aliasing a signal due to downsampling is conventionally irreversible, meaning the lost information cannot be recovered."
            }
        ]
    },
    {
        "speaker": "Katharine White",
        "timestamp": "02:13-02:14",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:13",
        "end_time": "22:14",
        "annotations": {
            "supportive response": "Katharine White's 'Yeah' expresses agreement with Josh Brake's preceding point about the risks of downsampling in imaging, without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:16-02:25",
        "transcript": "Does anybody have any um examples where temporal and spatial sampling are critical? Um that's what I'm sort of scratching my brain about is trying to figure out",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:16",
        "end_time": "22:25",
        "annotations": {
            "ask question": "The speaker asks the group for examples where temporal and spatial sampling are critical, seeking information from other team members.",
            "identify knowledge gap": "The speaker explicitly states they are 'scratching my brain about' and 'trying to figure out' examples, indicating a personal lack of understanding or knowledge on the topic."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:28-02:35",
        "transcript": "good examples where you really do need high temporal and spatial sampling to solve some kind of problem.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:28",
        "end_time": "22:35",
        "annotations": {
            "ask question": "Brian asks the group to provide examples where high temporal and spatial sampling are critical, requesting information from other team members."
        }
    },
    {
        "speaker": "Larry Cheng",
        "timestamp": "02:36-03:50",
        "transcript": "So here just try to um tiny in response to uh the application also Carolyn has mentioned in photoacoustic. And since we have been increasingly applying this on the human scalp uh for the long term and um continuous monitoring of this brain signal for um at least the free moving bodies. And if we don't have a high spatial resolution, we won't be able to get into the for example cortex layer and then to understand the language uh cognition aging and a lot of the other logical mechanisms. And if we miss the temporal resolution and some of those process may happen at least within a second or a few seconds and uh for example, some people have been talking about uh FMRI functional MRI and that has been super high spatial resolution but it takes uh um really limited um uh time and also be uh confined into the space. So in that sense, I think it's quite important to achieve a combined or balanced spatial temporal resolution.",
        "speaking duration": 74,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:36",
        "end_time": "23:50",
        "annotations": {
            "acknowledge contribution": "Larry acknowledges Carolyn's previous mention of photoacoustic imaging, recognizing her input.",
            "develop idea": "Larry develops the idea by elaborating on the application of photoacoustic imaging for brain signal monitoring, explaining the necessity of high spatial resolution for understanding biological mechanisms, and further detailing the importance of temporal resolution with an fMRI example.",
            "clarify goal": "Larry defines a key objective for the group, stating the importance of achieving a combined or balanced spatial and temporal resolution."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:50-04:06",
        "transcript": "Yeah. Yeah, and I've heard that argument a lot but but the transition between FMRI and functional near infrared spectroscopy you can get fast sampling with functional near infrared and but you get much much better spatial sampling with functional MRI.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:50",
        "end_time": "24:06",
        "annotations": {
            "annotations": [
                {
                    "sentence": "Yeah.",
                    "code_name": "supportive response",
                    "explanation": "Brian expresses agreement with the previous speaker's point by saying 'Yeah'."
                },
                {
                    "sentence": "Yeah, and I've heard that argument a lot but but the transition between FMRI and functional near infrared spectroscopy you can get fast sampling with functional near infrared and but you get much much better spatial sampling with functional MRI.",
                    "code_name": "develop idea",
                    "explanation": "Brian elaborates on the discussion about spatial and temporal resolution by comparing FMRI and functional near infrared spectroscopy, building upon the prior argument."
                }
            ]
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:06-04:07",
        "transcript": "That's right.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:06",
        "end_time": "24:07",
        "annotations": {
            "supportive response": "The utterance \"That's right\" expresses agreement with the previous speaker's statement without adding new content, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:07-04:10",
        "transcript": "Are there other examples we should think about?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:07",
        "end_time": "24:10",
        "annotations": {
            "annotations": [
                {
                    "Code Name": "encourage participation",
                    "Explanation": "Brian Pogue explicitly invites the group to contribute additional examples related to the discussion topic by asking an open-ended question."
                }
            ]
        }
    },
    {
        "speaker": "Seu Sim",
        "timestamp": "04:32-05:10",
        "transcript": "I'm so I I'm thinking this problem in a very small scale. for example, super resolution just like really good spatial resolution but you have to fix it and then you have to use a specific buffer that's not compatible with biological system that to like switching up and down. And I'm I don't know if it's possible but some sort of a molecular system where it's just like inherently unstable.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0.03,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:32",
        "end_time": "25:10",
        "annotations": [
            {
                "Code Name": "critical response",
                "Explanation": "The speaker highlights significant limitations of super-resolution techniques, such as the need to fix samples and use incompatible buffers, which negatively evaluates their applicability for biological systems."
            },
            {
                "Code Name": "identify knowledge gap",
                "Explanation": "The speaker explicitly states uncertainty (\"I don't know if it's possible\") regarding the feasibility of working with inherently unstable molecular systems, indicating a recognized challenge or lack of knowledge."
            }
        ]
    },
    {
        "speaker": "Seu Sim",
        "timestamp": "05:10-05:22",
        "transcript": "So you just install that for marker to allow you know, super resolution imaging but not having to sacrifice, you know, endogenous dynamics of biomolecules and I'm not really sure if it's possible but I want to know if you have thought about it.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.17,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:10",
        "end_time": "25:22",
        "annotations": [
            {
                "Code Name": "ask question",
                "Explanation": "Seu Sim asks the group for their thoughts on the feasibility of using a marker for super-resolution imaging without sacrificing biomolecule dynamics, indicating their own uncertainty about its possibility."
            }
        ]
    },
    {
        "speaker": "Katharine White",
        "timestamp": "05:22-05:23",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:22",
        "end_time": "25:23",
        "annotations": {
            "utterance": "Katharine White: Yeah.",
            "annotations": [
                {
                    "Code Name": "supportive response",
                    "Explanation": "The utterance 'Yeah' expresses agreement or validation with the preceding statement from Seu Sim, without adding new content."
                }
            ]
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "05:23-05:57",
        "transcript": "So I totally agree with you. I think this is a a critical area that we need to be thinking about on the super resolution optical side as well. I mean, I always say this to my students, but if you think about it, we really do have like a complete parts list of what exists inside cells.",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:23",
        "end_time": "25:57",
        "annotations": {
            "annotations": [
                {
                    "sentence": "So I totally agree with you.",
                    "code_name": "supportive response",
                    "explanation": "This sentence expresses direct agreement with the previous speaker's statement, aligning with the definition of expressing agreement or validation."
                },
                {
                    "sentence": "I think this is a a critical area that we need to be thinking about on the super resolution optical side as well.",
                    "code_name": "develop idea",
                    "explanation": "This sentence expands on the previous discussion about super-resolution imaging by emphasizing its critical importance as an area for further consideration."
                },
                {
                    "sentence": "I mean, I always say this to my students, but if you think about it, we really do have like a complete parts list of what exists inside cells.",
                    "code_name": "develop idea",
                    "explanation": "This sentence elaborates on the context of the discussion by providing a foundational perspective on the existing knowledge of cellular components, which informs the challenges of imaging."
                }
            ]
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "05:57-06:16",
        "transcript": "We have genomes, we have, you know, some parts of that are unannotated or still mysterious to us, but we have a pretty good sense of of proteins of RNA of molecules, but we don't really have a sense of how they're interacting in time.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:57",
        "end_time": "26:16",
        "annotations": {
            "identify knowledge gap": "The speaker explicitly states that while there is a good understanding of biomolecules, there is a lack of knowledge regarding how they interact in time, highlighting a gap in current understanding."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "06:16-07:14",
        "transcript": "And this is where spatial and temporal methods and spatial and temporal approaches at the molecular scale are so important. We've got this whole parts list, but we don't know who is where, what and when and why, how they're interacting, why they're interacting and how that might be different in disease state versus normal state.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:16",
        "end_time": "27:14",
        "annotations": {
            "identify knowledge gap": "Katharine explicitly recognizes a group knowledge gap by stating that despite having a 'parts list' of cellular components, they lack understanding of how these components interact in time and space, and how these interactions differ in disease versus normal states, highlighting the importance of methods that address this."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "07:14-07:43",
        "transcript": "And so for all of those questions, how they're interacting what why when as well as disease versus normal, you maybe have different approaches or different constraints on on the need for temporal versus spatial resolution. So um but that that um that question of of how do you set up your experiment or how do you set up your acquisition to to capture the biology, to capture these dynamics, which I think, you know, in the next 15, 20 years is going to be where a lot of uh at least molecular scale uh microscopy is is focused. So",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:14",
        "end_time": "27:43",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Katharine is expanding on the complexity of capturing biological dynamics by explaining how different research questions (interaction, disease state) impose varying constraints on temporal versus spatial resolution needs."
            },
            {
                "Code Name": "clarify goal",
                "Explanation": "Katharine is defining a critical objective for the field, specifically how to design experiments and acquisitions to effectively capture biological dynamics, which she identifies as a future focus for molecular scale microscopy."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:44-07:44",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:44",
        "end_time": "27:44",
        "annotations": {
            "supportive response": "Brian Pogue's 'Yeah' expresses agreement with Katharine White's preceding statement about the critical importance of spatial and temporal methods at the molecular scale."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:44-07:56",
        "transcript": "So just to follow on that, I think one of the other important things is that for a lot of for a lot of this, we don't really know in disease whether the interactions, the partners are changing,",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:44",
        "end_time": "27:56",
        "annotations": {
            "identify knowledge gap": "The speaker explicitly states a lack of knowledge by saying, \"we don't really know in disease whether the interactions, the partners are changing,\" highlighting an area where understanding is currently missing."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "07:57-08:15",
        "transcript": "And just to oh sorry, just to follow on that, I think one of the other important things is that for a lot of for a lot of this, we don't really know in disease whether the interactions, the partners are changing,",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:57",
        "end_time": "28:15",
        "annotations": {
            "identify knowledge gap": "The speaker explicitly states a lack of current understanding by saying 'we don't really know in disease whether the interactions, the partners are changing', which directly recognizes a knowledge gap for the group."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "08:15-08:57",
        "transcript": "whether the length or time of interaction, the spatial organization of an interaction happening inside the cell is changing. And and so frequently we don't know whether spatial resolution or temporal resolution is going to be a priori is going to be the most important for for these comparative analyses. So it",
        "speaking duration": 42,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:15",
        "end_time": "28:57",
        "annotations": {
            "annotations": [
                {
                    "sentence": "whether the length or time of interaction, the spatial organization of an interaction happening inside the cell is changing.",
                    "code": {
                        "Code Name": "identify knowledge gap",
                        "Explanation": "Katharine explicitly states uncertainty about whether the length, time, or spatial organization of intracellular interactions is changing, indicating a knowledge gap."
                    }
                },
                {
                    "sentence": "And and so frequently we don't know whether spatial resolution or temporal resolution is going to be a priori is going to be the most important for for these comparative analyses. So it ",
                    "code": {
                        "Code Name": "identify knowledge gap",
                        "Explanation": "Katharine highlights a frequent lack of knowledge regarding whether spatial or temporal resolution is more important for comparative analyses, identifying a specific knowledge gap."
                    }
                }
            ]
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:58-09:15",
        "transcript": "So sort of just macroscopically we've kind of discussed there's a lot of really cool needs and applications in microscopy. And then on the macroscopic scale, we've discussed, you know, uh MRI and functional optical measurements to brain. Um",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:58",
        "end_time": "29:15",
        "annotations": {
            "summarize conversation": "The speaker summarizes the group's previous discussions, covering both the needs and applications in microscopy and the macroscopic scale measurements like MRI and functional optical measurements to the brain."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:00-00:14",
        "transcript": "So is there anything that doesn't work? Like uh like in my mind I'm again I'm it's a lot of things I'd like to say I don't do and CT is one of them. CT is useless, you know, it gives you great images but it's really insensitive to molecules, you know.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:14",
        "annotations": {
            "ask question": "Brian asks \"is there anything that doesn't work?\" to request information about techniques or approaches that are not effective.",
            "critical response": "Brian provides a negative evaluation of CT by stating it is \"useless\" due to its insensitivity to molecules."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:14-00:27",
        "transcript": "Um is that fair to say? All right, I'm just going to say it. So that's off the list, you know, but but what we're interested in microscopy tools.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 31,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:14",
        "end_time": "30:27",
        "annotations": [
            {
                "sentence": "Um is that fair to say?",
                "annotations": [
                    {
                        "Code Name": "ask question",
                        "Explanation": "Brian asks for validation from the group regarding his prior statement about CT being useless, seeking their agreement or disagreement."
                    }
                ]
            },
            {
                "sentence": "All right, I'm just going to say it.",
                "annotations": [
                    {
                        "Code Name": "None",
                        "Explanation": "This phrase is a conversational lead-in or declaration of intent that does not align with any specific code in the provided codebook."
                    }
                ]
            },
            {
                "sentence": "So that's off the list, you know, but but what we're interested in microscopy tools.",
                "annotations": [
                    {
                        "Code Name": "process management",
                        "Explanation": "Brian explicitly removes CT from the discussion's focus and redirects the group's attention to microscopy tools, thereby managing the meeting's flow and topic."
                    }
                ]
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:27-00:34",
        "transcript": "Uh MR tools, macroscopic optical tools, are there other tools we're forgetting?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:27",
        "end_time": "30:34",
        "annotations": {
            "ask question": "The speaker asks if the group is forgetting any other tools, which is a direct request for information from other team members about additional relevant tools."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:34-00:38",
        "transcript": "I mean there's no I guess there's no nuclear medicine people here so we're just not going to talk about it.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:34",
        "end_time": "30:38",
        "annotations": {
            "express humor": "The speaker uses a lighthearted, slightly sarcastic tone to dismiss the topic of nuclear medicine due to the absence of experts, which serves as a humorous remark."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:38-00:54",
        "transcript": "I don't know, but I'm really intrigued by what Andrew mentioned about orthogonal measurements, you know, where you use one measurement to help the other measurement. Um what do you think of that?",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:38",
        "end_time": "30:54",
        "annotations": {
            "acknowledge contribution": "Brian Pogue explicitly states his intrigue and refers to Andrew's previously mentioned idea about orthogonal measurements, thereby recognizing Andrew's input.",
            "encourage participation": "Brian Pogue directly asks the group 'what do you think of that?', inviting team members to contribute their opinions and ideas on the discussed topic."
        }
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "00:54-01:00",
        "transcript": "Has that happened yet in image guided surgery Brian, you know, with some of these systems.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:54",
        "end_time": "31:00",
        "annotations": {
            "ask question": "Bryan is requesting information from Brian Pogue about whether the concept of orthogonal measurements has been applied in image-guided surgery, seeking clarification on a prior statement or idea."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:01-01:13",
        "transcript": "There's certainly a lot of um yeah, I mean using one system to guide the other one, right? So tracking system guiding an imaging system.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:01",
        "end_time": "31:13",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Brian elaborates on the concept of using one system to guide another by providing a concrete example of a tracking system guiding an imaging system."
            }
        ]
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "01:13-01:25",
        "transcript": "I keep thinking of MRI or pet, something guiding a microscopic tool or photoacoustic tool to a location to get higher imaging space. Yeah.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:13",
        "end_time": "31:25",
        "annotations": {
            "utterances": [
                {
                    "sentence": "I keep thinking of MRI or pet, something guiding a microscopic tool or photoacoustic tool to a location to get higher imaging space.",
                    "annotations": [
                        {
                            "code_name": "propose new idea",
                            "explanation": "Bryan introduces a new, specific approach for combining imaging modalities by suggesting the use of MRI or PET to guide microscopic or photoacoustic tools for enhanced imaging space."
                        }
                    ]
                },
                {
                    "sentence": "Yeah.",
                    "annotations": [
                        {
                            "code_name": "supportive response",
                            "explanation": "The utterance 'Yeah' expresses general agreement or validation with the ongoing discussion about combining different measurement techniques."
                        }
                    ]
                }
            ]
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:26-01:43",
        "transcript": "And you know, most of the world is pushing MR, right? Trying to get faster and faster MR so that you can do MR guidance um you know on a time scale that matters.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:26",
        "end_time": "31:43",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "This sentence elaborates on the ongoing efforts to improve MR technology by making it faster, explaining that this development is driven by the need for MR guidance on a relevant time scale, thus building upon the discussion of imaging capabilities."
            }
        ]
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "01:44-02:55",
        "transcript": "Is there something um uh like at the MR scale that would inform where you want to sample with something like microscopy or the photoacoustic uh but we sometimes look at ask the converse and we don't have any solutions but um so like when a change happens in a cell can could we possibly see it in MR, right? So there's so many cells in a single foxel that we have. Um and so like how many changes would have to happen in order for me to see something or um what would have to happen and because so uh we have a um an animal system that we don't have a lot of competition for and so we've been slowly working on a project to just leave a sample of cells in there, but that's kind of, you know, I don't have much knowledge of what I want to do with that system uh or what the microscopy should be, but I mean we could run, you know, laser fibers in.",
        "speaking duration": 71,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:44",
        "end_time": "32:55",
        "annotations": {
            "ask question": "Katy asks if MR scale information can guide microscopy/photoacoustic sampling and if cellular changes are visible in MR, requesting information from the group.",
            "develop idea": "Katy elaborates on the challenge of detecting cellular changes with MR by explaining the high density of cells within a single MR voxel.",
            "identify knowledge gap": "Katy explicitly states a lack of knowledge regarding how to proceed with their animal system and what microscopy approach should be used."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "02:55-03:10",
        "transcript": "Um and probe with something else probably I have enough space. I think I can keep it warm enough to leave it there for a little bit. Uh but I don't really know what questions I should be at like how to look for something interesting.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:55",
        "end_time": "33:10",
        "annotations": [
            {
                "Code Name": "identify knowledge gap",
                "Explanation": "Katy explicitly states a lack of knowledge regarding what questions she should be asking or how to look for something interesting within her experimental system, indicating a gap in her understanding of research direction."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:11-03:16",
        "transcript": "Sounds like you need a MR compatible multi spectral endoscope.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:11",
        "end_time": "33:16",
        "annotations": {
            "offer feedback": "Brian suggests an 'MR compatible multi spectral endoscope' as a specific tool to help Katy address her stated problem of not knowing how to find interesting information within her MR system."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "03:16-03:17",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:16",
        "end_time": "33:17",
        "annotations": {
            "supportive response": "Katy Keenan's 'Yeah' expresses agreement with Brian Pogue's preceding suggestion about needing an MR compatible multi spectral endoscope."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:19-03:21",
        "transcript": "Perfect combination.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:19",
        "end_time": "33:21",
        "annotations": {
            "supportive response": "The speaker expresses a positive evaluation of the previously discussed idea of an 'MR compatible multi spectral endoscope' as a 'perfect combination', indicating agreement and validation."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "03:21-04:32",
        "transcript": "I think um what had occurred to me listening to Josh and Katherine and and Katie as well that um you know we were talking about the how to that we're producing more data than you're actually using. Um and I wonder if there would be a machine learning approach to identify rather than identifying pathology but identify what is data requiring it. So if there was some signature that would identify data whether that's just variation above noise.",
        "speaking duration": 71,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:21",
        "end_time": "34:32",
        "annotations": {
            "summarize conversation": "Carolyn references the group's prior discussion about producing more data than is actually used, summarizing a previously discussed challenge.",
            "propose new idea": "Carolyn proposes a new machine learning approach to identify 'data requiring it' rather than just pathology, suggesting a novel solution to the data overload problem.",
            "develop idea": "Carolyn elaborates on her proposed machine learning approach by suggesting it could identify a 'signature' in the data, such as variation above noise, to determine what data is useful."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:33-05:17",
        "transcript": "That that makes me think about like adaptive uh people refresh screens, right? Like LCDs. So like your iPhone, right? I mean it's similar to the these ideas in computer architecture too where they'll use little cores and big cores. So you have your power hungry cores and then your efficiency cores because your battery life matters and you know, okay, when somebody opens up I don't know what the, you know, Fortnite, whatever the kids are playing these days right on their phone and you need the graphics processor, you fire that up time to be able to use it, but then otherwise when you're just reading an article, you don't care about refreshing the screen at 120 frames a second, it's costly. So it's like that idea but in the opposite, the opposite way.",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:33",
        "end_time": "35:17",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Josh expands on the concept of adaptive data identification by drawing an analogy to adaptive refresh screens and big/little cores in computer architecture, illustrating how systems can dynamically adjust performance based on the importance or need of the data."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:17-06:11",
        "transcript": "Yeah, you know, in in the camera world, I'm I sort of work in the optical cameras world, you know, all the there's a huge push on putting an FPGA processor on board the camera. So field programmable gate array so that you can so you're not just streaming data to your hard drive but you can process it on the camera uh prior to streaming it to your hard drive and and you know, you could look for signatures or do data reduction or what we do is noise removal prior to streaming the data off so that you get more productive data.",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:17",
        "end_time": "36:11",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Brian elaborates on a current trend in the optical cameras world, describing the push to integrate FPGA processors into cameras."
            },
            {
                "Code Name": "develop idea",
                "Explanation": "Brian further develops the idea by explaining how FPGA processors enable on-camera data processing, reduction, and noise removal to yield more productive data."
            }
        ]
    },
    {
        "speaker": "Seu Sim",
        "timestamp": "06:12-06:16",
        "transcript": "I'm not exactly a pro person but I'm interested in designing molecules.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:12",
        "end_time": "36:16",
        "annotations": [
            {
                "Code Name": "identify knowledge gap",
                "Explanation": "Seu Sim explicitly states 'I'm not exactly a pro person,' indicating a self-identified lack of expertise or familiarity with the previously discussed technical aspects."
            },
            {
                "Code Name": "signal expertise",
                "Explanation": "Seu Sim states their interest in 'designing molecules,' which explicitly signals their area of expertise and qualifications relevant to the scientific collaboration."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:17-06:22",
        "transcript": "Okay, okay. Well we'd be nowhere without somebody who did designing molecules, right? So that's good.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:22",
        "annotations": {
            "supportive response": "The speaker expresses validation and positive evaluation of the previous speaker's contribution by acknowledging the importance of designing molecules and concluding with a positive affirmation."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:27-06:34",
        "transcript": "Um is there a way is there a part of this about the probe that's important?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:27",
        "end_time": "36:34",
        "annotations": {
            "ask question": "Brian asks if the 'probe' is an important part of the discussion, requesting information or clarification from the group regarding its relevance to the ongoing conversation about imaging and molecular systems."
        }
    },
    {
        "speaker": "Seu Sim",
        "timestamp": "06:35-07:55",
        "transcript": "So you know, in in terms of so I think this brought up in our, you know, yesterday's conversation about intracellular processes and I was caught up with this thought that if we can know so in force and microscope, we need to label whatever we are looking at and it could be force and proteins which is more common approach. But as a pro person here, I like the idea of installing, you know, really high functioning synthetic probes because they have just sometimes they have better, you know, physical properties, they don't photobleach as well and we can design it to look at the longer wavelengths and multiplex in a specific way. So then it brought up to a question, can we label biomolecules of interest in a known density so that our spatial temporal imaging or, you know, interaction partner seeking that can be relevant to, you know, disease, you know, how can we, you know, design a system that is experimentally addressable? For example, if we label everything in the system is going to be super bright and it might not give you that resolution either time or space to look at the processes that you want to look at. So from the chemistry perspective, my question is, can we design a way to, you know, label the molecule that we want in a very defined density we want to target the specific temporal and spatial resolution.",
        "speaking duration": 80,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:35",
        "end_time": "37:55",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "The speaker elaborates on the existing idea of intracellular processes and the common approach of labeling in microscopy, providing context for the subsequent discussion."
            },
            {
                "Code Name": "propose new idea",
                "Explanation": "The speaker introduces the new idea of using high-functioning synthetic probes and explains their superior physical properties and design capabilities for specific wavelengths and multiplexing."
            },
            {
                "Code Name": "ask question",
                "Explanation": "The speaker poses a question about the feasibility of labeling biomolecules of interest in a known density and designing an experimentally addressable system for spatial-temporal imaging relevant to disease."
            },
            {
                "Code Name": "develop idea",
                "Explanation": "The speaker elaborates on the challenge of labeling density by providing a hypothetical example where over-labeling could hinder resolution in spatial and temporal imaging."
            },
            {
                "Code Name": "ask question",
                "Explanation": "The speaker rephrases their core question from a chemistry perspective, asking how to design a labeling method with a very defined density to target specific temporal and spatial resolution."
            }
        ]
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "07:55-07:57",
        "transcript": "You consider that stimulated emission depletion stead.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:55",
        "end_time": "37:57",
        "annotations": {
            "offer feedback": "Bryan suggests 'stimulated emission depletion (STED)' as a specific technique to consider, providing a suggestion for how to address Seu Sim's preceding question about designing molecules for defined density and spatial-temporal resolution."
        }
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "07:57-08:01",
        "transcript": "Super resolution technique. Um.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:57",
        "end_time": "38:01",
        "annotations": {
            "develop idea": "The speaker elaborates on the concept of super resolution by explicitly naming 'stimulated emission depletion (STED)' as a 'super resolution technique,' building upon the previous discussion about super resolution imaging."
        }
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "08:01-08:03",
        "transcript": "I think that that can be used on live samples, I think.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:01",
        "end_time": "38:03",
        "annotations": {
            "develop idea": "Bryan develops the idea of stimulated emission depletion (STED) as a super-resolution technique by clarifying that it can be used on live samples, which is relevant to the discussion about maintaining endogenous dynamics."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:03-08:03",
        "transcript": "It's you know.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:03",
        "end_time": "38:03",
        "annotations": {
            "sentence1": {
                "Code Name": "None",
                "Explanation": "The utterance is incomplete and does not explicitly convey content that aligns with any of the provided codes."
            }
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:44-09:03",
        "transcript": "Yeah, the thing that came to my mind was sort of palm and storm microscopy, right? Where you've got probes that have you actually use the temporal nature of the probe to identify where it's coming from and then gives you this high resolution.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:44",
        "end_time": "39:03",
        "annotations": {
            "develop idea": "Brian elaborates on the discussion of super-resolution techniques by introducing PALM and STORM microscopy as examples and explaining how they utilize the temporal nature of probes to achieve high resolution."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "09:03-09:04",
        "transcript": "ability to image uh.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:03",
        "end_time": "39:04",
        "annotations": {
            "develop idea": "This utterance completes the previous sentence, elaborating on how the temporal nature of probes in palm and storm microscopy provides high resolution imaging ability."
        }
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "00:01-00:03",
        "transcript": "Yes.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:01",
        "end_time": "40:03",
        "annotations": {
            "supportive response": "Bryan Spring expresses agreement with Brian Pogue's previous statement about PALM and STORM microscopy by saying 'Yes', without adding new content."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "00:04-00:12",
        "transcript": "Yes, that definitely has a temporal issue if you're looking at molecular scale dynamics, but",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:04",
        "end_time": "40:12",
        "annotations": {
            "develop idea": "Katharine elaborates on the existing idea of super-resolution microscopy by specifying a 'temporal issue' when these techniques are applied to molecular scale dynamics, thus building upon the discussion of their characteristics."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "00:14-00:53",
        "transcript": "I think another problem with a lot of these fluorescent protein based approaches, which I think Sue was try was uh getting at is that, you know, they're relatively dim, they're also not as photostable. And so the anything that you want to extend, if you want to have the flexibility within your system to extend temporarily or to acquire more data within a spatial region, need to be as bright and as um as photostable as possible for for your labeling method.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:14",
        "end_time": "40:53",
        "annotations": {
            "critical response": "Katharine White provides a negative evaluation of fluorescent protein-based approaches by stating their limitations, specifically that they are 'relatively dim' and 'not as photostable'.",
            "offer feedback": "Katharine White suggests an improvement for labeling methods, stating that for extended temporal or spatial data acquisition, the labeling method 'need to be as bright and as photostable as possible'."
        }
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "00:54-00:55",
        "transcript": "That's an issue.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:54",
        "end_time": "40:55",
        "annotations": {
            "critical response": "Bryan's utterance provides a negative evaluation by confirming the problematic nature of the limitations of fluorescent protein-based approaches, as previously described by Katharine White."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "00:55-00:56",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:55",
        "end_time": "40:56",
        "annotations": {
            "supportive response": "The utterance 'Yeah' expresses agreement with the previous speaker's statement without adding new content, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "00:58-01:41",
        "transcript": "But I I I think that getting kind of coming back to this conversation to come on some stuff we were discussing earlier in terms of thinking about how you could do multimodal imaging to identify a larger spatial or a longer temporal scale to when to start acquiring or when to to switch to a higher resolution imaging approach or a higher resolution acquisition approach, be that spatial or temporal. I think is a really interesting, interesting idea and I think Josh and and Carolyn were both kind of commenting on this. And I and I that just I think it's a really interesting idea. I'm not sure how to do it. I'm not a hardware person.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:58",
        "end_time": "41:41",
        "annotations": {
            "develop idea": "The speaker elaborates on the existing idea of using multimodal imaging to adaptively switch between different spatial and temporal resolutions for data acquisition.",
            "supportive response": "The speaker expresses positive evaluation of the discussed idea, stating it is 'really interesting,' and acknowledges that Josh and Carolyn also commented on it.",
            "identify knowledge gap": "The speaker explicitly states a lack of knowledge regarding how to implement the idea and clarifies that this is due to not being a 'hardware person.'"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:42-01:47",
        "transcript": "Yeah, I guess in in the microscopy hardware world, people are combining different techniques in the same objective, right?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:42",
        "end_time": "41:47",
        "annotations": {
            "ask question": "Brian Pogue asks for confirmation on his understanding that people in the microscopy hardware world are combining different techniques in the same objective, seeking clarification on a point related to the ongoing discussion about multimodal imaging."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "01:48-02:35",
        "transcript": "Yeah, yeah, and it's I think in the next five to 10 years that's going to be moving forward a lot, but you know, the in, you know, if we take a look at like light sheet microscopy over the last five to 10 years, that's gotten used used all over biology now, but one of the issues is that you see something in in the light sheet or you see something at this kind of organismal or kind of millimeter to 1 millimeter to 20 millimeter scale and then identifying which areas or which regions are important or significant or that you might want to go into more spatial um higher spatial resolution approach takes a ton of data analysis to get to, particularly for dynamics that might not be as globally visible on the light sheet scale is like a developing zebrafish embryo or developing drosophila embryo, which are beautiful morphogenically, but if if you're interested in potentially like um manipulating or controlling or or studying in a on a single cell scale.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:48",
        "end_time": "42:35",
        "annotations": {
            "develop idea": "Katharine elaborates on the challenges of light sheet microscopy, explaining that while it is widely used, identifying specific regions for higher spatial resolution analysis requires extensive data analysis, particularly for dynamics not globally visible, using examples like developing zebrafish and drosophila embryos."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "02:35-02:36",
        "transcript": "That can get a little tricky.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:35",
        "end_time": "42:36",
        "annotations": {
            "critical response": "The speaker states that identifying important regions for higher spatial resolution from light sheet data 'can get a little tricky,' indicating a challenge or difficulty with the discussed approach."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "02:36-02:36",
        "transcript": "Or on a subcellular scale to look at like for the cells that are moving versus not, are there what are their lysosomes doing? What are their Golgi doing? These kind of uh scaling is is difficult.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:36",
        "end_time": "42:36",
        "annotations": {
            "ask question": "Katharine asks what lysosomes and Golgi are doing at a subcellular scale, seeking information about their activities.",
            "identify knowledge gap": "Katharine explicitly states that scaling to observe these subcellular processes is difficult, recognizing a challenge or limitation in current approaches."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:13-03:24",
        "transcript": "Um, should we um, I don't Josh, you're our scribe. I'm just thinking, should we be um trying to put some hierarchy to our notes or what what do you think?",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 9.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:13",
        "end_time": "43:24",
        "annotations": {
            "process management": "Brian Pogue asks the scribe, Josh, whether they should try to put some hierarchy to the notes, which is an explicit question about managing the structure and organization of the meeting's output."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:25-03:29",
        "transcript": "Yeah, I think that's I don't know, when is our, when are we done with this session?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:25",
        "end_time": "43:29",
        "annotations": {
            "process management": "Josh asks about the session's end time, which is a direct inquiry related to managing the meeting's duration and flow."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:29-03:32",
        "transcript": "I think we still have half an hour, I think.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:29",
        "end_time": "43:32",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by stating the remaining time, which aligns with the definition of process management."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:32-03:47",
        "transcript": "Okay. I'm just wondering if maybe we could put like a super structure to our notes and then try to fill in from there because I've heard things about MR, about microscopy, uh hybrid imaging, photoacoustic.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:32",
        "end_time": "43:47",
        "annotations": {
            "process management": "Brian suggests creating a 'super structure' for the notes and filling them in, which is a method for organizing the group's activities and the meeting's structure."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:49-03:55",
        "transcript": "we could make sort of large categories. I don't know, what do you people think? How should we, how should we try to document this?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:49",
        "end_time": "43:55",
        "annotations": [
            {
                "Code Name": "process management",
                "Explanation": "Josh suggests making large categories, which is a way to structure and organize the group's notes and activities."
            },
            {
                "Code Name": "encourage participation",
                "Explanation": "Josh directly asks 'what do you people think?', inviting other team members to contribute their ideas."
            },
            {
                "Code Name": "ask question",
                "Explanation": "Josh asks 'How should we, how should we try to document this?', requesting information or suggestions from the group on the documentation approach."
            }
        ]
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "04:04-04:07",
        "transcript": "Is there a way is there a way that we can all see it?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:04",
        "end_time": "44:07",
        "annotations": {
            "process management": "Shannon asks about a method for all participants to view the meeting notes, which is a logistical aspect of organizing group activities and managing the meeting's information flow."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:08-04:13",
        "transcript": "Yeah, guess Josh, you could share your screen if we wanted and that way we could kind of",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:08",
        "end_time": "44:13",
        "annotations": [
            {
                "Code Name": "process management",
                "Explanation": "The speaker suggests Josh share his screen to allow the group to collectively view the notes, which is an action to organize group activities and manage the meeting flow."
            }
        ]
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:14-04:24",
        "transcript": "Why don't why don't I I'll throw it in a Google Doc and then I can just share that with everybody and you can see it that way. I think that'll be easier because there's just a lot of scrolling of the random things I've jotted down. So.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:14",
        "end_time": "44:24",
        "annotations": [
            {
                "Code Name": "process management",
                "Explanation": "Josh suggests using a Google Doc to share the notes, which is a method for organizing and managing the group's shared information."
            },
            {
                "Code Name": "develop idea",
                "Explanation": "Josh elaborates on his suggestion by explaining that a Google Doc would be easier due to the current disorganized state of his jotted notes."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:25-04:26",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:25",
        "end_time": "44:26",
        "annotations": {
            "supportive response": "Brian's 'Yeah' expresses agreement with Josh's statement about the ease of sharing notes via a Google Doc, validating his contribution without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:26-04:34",
        "transcript": "Okay. Oh, that's right. We have to put it in a separate Google Docs so we don't overwhelm the system right away.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:26",
        "end_time": "44:34",
        "annotations": [
            {
                "Code Name": "supportive response",
                "Explanation": "Brian expresses agreement or acknowledgment of Josh's suggestion to use a Google Doc for notes."
            },
            {
                "Code Name": "supportive response",
                "Explanation": "Brian acknowledges a point, indicating agreement or realization, which serves as a supportive response to the ongoing discussion about note-taking."
            },
            {
                "Code Name": "process management",
                "Explanation": "Brian discusses the logistical decision to use a separate Google Doc for notes to manage the system, which falls under organizing group activities."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:35-05:01",
        "transcript": "Okay. Um, but so what are the broad categories people think of? We've discussed MR, optical. I mean, I hate to think of it this way, but as separate imaging modalities, um is there a different way to categorize what we've discussed?",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:35",
        "end_time": "45:01",
        "annotations": [
            {
                "Code Name": "process management",
                "Explanation": "The speaker is managing the meeting flow by asking the group to think about broad categories and alternative ways to categorize what has been discussed, aiming to structure their notes and discussion."
            },
            {
                "Code Name": "ask question",
                "Explanation": "The speaker asks direct questions to the group, such as 'what are the broad categories people think of?' and 'is there a different way to categorize what we've discussed?', requesting information from other team members."
            },
            {
                "Code Name": "summarize conversation",
                "Explanation": "The speaker briefly summarizes prior discussion points by stating 'We've discussed MR, optical,' indicating topics already covered by the group."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:01-05:03",
        "transcript": "And we also talked about algorithms for",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:01",
        "end_time": "45:03",
        "annotations": {
            "summarize conversation": "The speaker explicitly refers to a topic, 'algorithms for', that has been previously discussed by the group, indicating a summary of past conversation."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:03-05:07",
        "transcript": "um machine learning algorithms to identify useful data sets.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:03",
        "end_time": "45:07",
        "annotations": {
            "summarize conversation": "The speaker is listing a topic, 'machine learning algorithms to identify useful data sets,' that was previously discussed by the group, which aligns with the definition of summarizing the conversation."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:07-05:11",
        "transcript": "Maybe hardware approaches to identify.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:07",
        "end_time": "45:11",
        "annotations": {
            "propose new idea": "Brian suggests 'hardware approaches' as a new category or type of solution to consider for identifying useful data, which introduces a new dimension to the ongoing discussion about categorizing methods."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "05:11-05:12",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:11",
        "end_time": "45:12",
        "annotations": {
            "supportive response": "The utterance \"Yeah\" expresses agreement or validation with the immediately preceding statement by Brian Pogue, without adding new content, which aligns with the definition of a supportive response."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "05:17-05:42",
        "transcript": "I think you asked a question in the beginning um about sort of what our measurement is, what our output is. Are we interested in molecular scale, cellular scale, physiological scale, anatomical scale? Like that might what scale you're interested imaging might",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:17",
        "end_time": "45:42",
        "annotations": [
            {
                "Code Name": "acknowledge contribution",
                "Explanation": "Carolyn acknowledges Brian's earlier question about the nature of their measurements and outputs, recognizing his prior input."
            },
            {
                "Code Name": "clarify goal",
                "Explanation": "Carolyn asks about the specific scales of interest (molecular, cellular, physiological, anatomical) to clarify the group's objectives for imaging."
            },
            {
                "Code Name": "None",
                "Explanation": "The final part of the utterance is an incomplete sentence and does not convey a distinct action or meaning that aligns with any of the provided codes."
            }
        ]
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "05:42-05:47",
        "transcript": "I shouldn't say scale, but what what mechanism you're interested in imaging, right?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:42",
        "end_time": "45:47",
        "annotations": {
            "clarify goal": "Carolyn seeks to clarify the group's objective by asking what specific imaging mechanisms are of interest, refining her previous statement about 'scale'."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:48-05:48",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:48",
        "end_time": "45:48",
        "annotations": {
            "utterance": "Brian Pogue: Yeah. ",
            "annotations": [
                {
                    "Code Name": "supportive response",
                    "Explanation": "Brian Pogue's 'Yeah' expresses agreement with Carolyn Bayer's clarification regarding the mechanism of interest in imaging."
                }
            ]
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "06:06-06:15",
        "transcript": "Here's the this is just a link of that brain dump. I've just been trying to jot down stuff as people have been talking. So uh feel free to scan through that.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "46:06",
        "end_time": "46:15",
        "annotations": {
            "process management": "Josh is managing the meeting's documentation by sharing the link to the notes he has been taking and inviting the group to review them, which organizes group activities related to information flow."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "06:15-06:25",
        "transcript": "Um I bolded so one thing one major theme that came up for me that's really connected to the second question about borrowing from QN and MM uh methods.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "46:15",
        "end_time": "46:25",
        "annotations": {
            "summarize conversation": "Josh identifies a \"major theme\" that emerged from the discussion, explicitly connecting it to the previously discussed \"QN and MM methods,\" which summarizes a key point from the conversation."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "06:25-06:39",
        "transcript": "is how can we think about techniques that are used in simulation and translate those into experimental measurements? Um so this idea like Brian, you mentioned about um thinking about like mesh structures and how you can like at a level of hierarchy you can zoom in and you refine your measurement where it's necessary but not other places.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "46:25",
        "end_time": "46:39",
        "annotations": {
            "ask question": "The speaker asks how to conceptualize the translation of simulation techniques into experimental measurements, seeking a method or approach.",
            "develop idea": "The speaker elaborates on the idea of translating simulation techniques by referencing Brian's prior mention of mesh structures and the concept of hierarchically refining measurements where necessary."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:08-07:08",
        "transcript": "So,",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:08",
        "end_time": "47:08",
        "annotations": [
            {
                "sentence": "So,",
                "code_name": "None",
                "explanation": "The utterance 'So,' is a discourse marker or conversational filler that does not explicitly convey information or interaction type defined by the provided codebook categories."
            }
        ]
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:08-07:10",
        "transcript": "I'm I'm glad you came back to this.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:08",
        "end_time": "47:10",
        "annotations": {
            "supportive response": "Shannon expresses positive evaluation by stating 'I'm glad you came back to this', validating Brian's action of revisiting a previous topic without adding new content."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:10-07:11",
        "transcript": "I had",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:10",
        "end_time": "47:11",
        "annotations": {}
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:11-07:12",
        "transcript": "some",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:11",
        "end_time": "47:12",
        "annotations": [
            {
                "code_name": "None",
                "explanation": "The utterance 'some' is an incomplete thought and does not convey enough information to be categorized under any of the provided codes."
            }
        ]
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:12-07:13",
        "transcript": "ideas, but",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:12",
        "end_time": "47:13",
        "annotations": {
            "propose new idea": "Shannon indicates an intent to introduce new ideas or suggestions by stating 'I had some ideas' in response to a discussion point, even though the utterance is cut off."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:13-07:14",
        "transcript": "discussion kind of moved on.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:13",
        "end_time": "47:14",
        "annotations": {
            "process management": "This code applies because the utterance comments on the flow of the meeting by noting that the discussion has shifted from a previous topic."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:14-07:15",
        "transcript": "Um,",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:14",
        "end_time": "47:15",
        "annotations": {
            "annotations": [
                {
                    "sentence": "Um,",
                    "codes": [
                        {
                            "code_name": "None",
                            "explanation": "The utterance 'Um,' is a filler word and does not convey any content relevant to the provided codebook categories."
                        }
                    ]
                }
            ]
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:15-07:20",
        "transcript": "my understanding of molecular dynamics is a little bit limited because I don't really do it.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:15",
        "end_time": "47:20",
        "annotations": {
            "identify knowledge gap": "Shannon explicitly states a lack of familiarity with molecular dynamics by saying \"my understanding of molecular dynamics is a little bit limited because I don't really do it.\""
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:20-07:21",
        "transcript": "Um,",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:20",
        "end_time": "47:21",
        "annotations": [
            {
                "sentence": "Um,",
                "Code Name": "None",
                "Explanation": "The utterance 'Um,' is a filler word and does not convey any substantive meaning that aligns with the provided codes."
            }
        ]
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:21-08:01",
        "transcript": "but as far as I understand it, you are essentially simulating more or less F equals MA for every single atom and every molecule that you're interested in. And in that way you have all the knobs at your disposal. You can go at whatever resolution you want. Um, and with imaging, at least in sort of, you know, the live setting that we have,",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "47:21",
        "end_time": "48:01",
        "annotations": {
            "develop idea": "Shannon elaborates on their understanding of molecular dynamics by explaining its simulation process and the control it offers over resolution, then begins to contrast this with live imaging."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "08:01-08:24",
        "transcript": "it's not quite the same in that you're rather than having control over the entire system at every single time point and the decision coming down to figuring out how to cut out data. You are instead observing a system.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "48:01",
        "end_time": "48:24",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "This utterance develops the ongoing discussion by elaborating on the fundamental difference between molecular dynamics simulation and live imaging, explaining that imaging involves observing a system without the same level of control over the entire system or the ability to cut out data as in simulation."
            }
        ]
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "08:24-08:40",
        "transcript": "And you're sort of limited by issues of acquisition like we talked about or issues of size or scale um or what your equipment is able to gather at a certain resolution.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "48:24",
        "end_time": "48:40",
        "annotations": {
            "identify knowledge gap": "Shannon explicitly recognizes limitations in current imaging capabilities, specifically regarding issues of acquisition, size, scale, and equipment's ability to gather data at certain resolutions, indicating a gap in current resources or methods."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "08:40-08:42",
        "transcript": "Um, and so, yeah,",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "48:40",
        "end_time": "48:42",
        "annotations": {
            "supportive response": "Shannon Quinn uses \"yeah\" as a minimal verbal affirmation, indicating agreement or validation with the preceding discussion about the limitations and challenges in imaging."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "08:42-08:57",
        "transcript": "from my understanding it's it's not an exact mapping from the sort of simulation space where we started at very high resolution and it's an issue of what we cut out versus this imaging space where we're observing a system and we're kind of limited from the getgo by whatever acquisition method we're using and whatever analysis pipeline we're using.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "48:42",
        "end_time": "48:57",
        "annotations": {
            "develop idea": "Shannon elaborates on the analogy between simulation and imaging by explaining that imaging is limited by acquisition methods and analysis pipelines, unlike simulation where one has full control over resolution and data."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:57-08:57",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The speaker shared a link to a Google Doc in the chat.",
        "start_time": "48:57",
        "end_time": "48:57",
        "annotations": {
            "acknowledge contribution": "The speaker uses \"Okay\" to verbally recognize Shannon Quinn's preceding explanation about molecular dynamics and imaging, without adding new content or explicitly agreeing."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "00:00-00:59",
        "transcript": "of is and where you should be looking at what time and how how closely you should be doing it. So I think you you need the you need the simulation, like thinking even if you had this kind of QMM paradigm where you are simulating and you can tune it, I think if you have that kind of model for a system, then as the microscopist, you can decide, okay, I know that these time scales are important for this particular part of the system and so I'm going to you know, and and then thinking just just practically as the engineer, I'm going to have the system running at top performance and then I'm going to have some middleman grabbing all that raw data, the middleman has to be fast enough, maybe we use an FPGA or something on board to decide what to keep or what not to keep and kind of put a reasonable reasonable format.",
        "speaking duration": 59,
        "nods_others": 3,
        "smile_self": 10,
        "smile_other": 20,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:59",
        "annotations": {
            "propose new idea": "Josh proposes a new approach to manage imaging data by suggesting the use of simulation models (like QMM) to guide sampling decisions and implementing on-board processing (e.g., with an FPGA) to filter and store only relevant high-quality data."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "01:00-01:16",
        "transcript": "So I think there's this like like like anything, you have to have a model and then based on that decide how we're going to what makes sense in term efficient data capture because we have limitations in terms of imaging system performance.",
        "speaking duration": 16,
        "nods_others": 1,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:00",
        "end_time": "51:16",
        "annotations": {
            "develop idea": "Josh elaborates on the discussion about efficient data capture by proposing that having a model is essential to decide how to capture data efficiently, given the limitations of imaging system performance."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:19-01:21",
        "transcript": "Yeah, yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:19",
        "end_time": "51:21",
        "annotations": {
            "supportive response": "The speaker expresses agreement with the preceding statement by saying 'Yeah, yeah.', which aligns with the definition of a supportive response."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:25-01:35",
        "transcript": "Yeah, I'm a big fan of just a priori knowing what signals you want to measure and you know, applications, but um,",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:25",
        "end_time": "51:35",
        "annotations": {
            "clarify goal": "Brian Pogue emphasizes the importance of \"a priori knowing what signals you want to measure and applications,\" which defines the objectives and expectations for the group's work."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:36-01:41",
        "transcript": "Okay, um, how should we summarize that?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:36",
        "end_time": "51:41",
        "annotations": {
            "process management": "The speaker asks the group how they should summarize the discussion, which is an attempt to manage the meeting's flow and organize the group's output."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:47-01:54",
        "transcript": "Everybody's got the Google Doc there. We should probably try, oh yeah, you've got takeaways at the bottom there, right?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:47",
        "end_time": "51:54",
        "annotations": {
            "process management": "Brian is managing the meeting flow by confirming that everyone has access to the shared Google Doc and suggesting they utilize the 'takeaways' section to structure their notes."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:03-02:17",
        "transcript": "What are the key things um that we should put in the takeaways. Um, maybe Katherine, you could help with the microscopy piece.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:03",
        "end_time": "52:17",
        "annotations": {
            "clarify goal": "Brian asks the group to define what key information should be included in the takeaways, clarifying the objective for the summary.",
            "encourage participation": "Brian invites Katherine to contribute her expertise on the microscopy aspect of the discussion."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "02:20-02:22",
        "transcript": "Yeah, sure.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:20",
        "end_time": "52:22",
        "annotations": {
            "supportive response": "Katharine expresses agreement and willingness to help with the microscopy piece, indicating a positive response to Brian's request."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:28-02:33",
        "transcript": "Maybe Katie, you could try some of the MR stuff.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:28",
        "end_time": "52:33",
        "annotations": {
            "assign task": "Brian Pogue assigns Katie the responsibility of summarizing the MR-related discussion points, which is an action item for a group member."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:33-02:42",
        "transcript": "You guys wanted to sort of log into the Google Doc and maybe help transcribe a little bit. We can we can all type at the same time, which is pretty cool.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:33",
        "end_time": "52:42",
        "annotations": [
            {
                "Code Name": "assign task",
                "Explanation": "Brian Pogue assigns the task of logging into the Google Doc and helping transcribe to the group members, which is a specific action item for the meeting."
            },
            {
                "Code Name": "supportive response",
                "Explanation": "Brian Pogue expresses a positive evaluation of the collaborative capability of the Google Doc by stating that everyone can type at the same time, calling it 'pretty cool'."
            }
        ]
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "02:42-02:43",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:42",
        "end_time": "52:43",
        "annotations": {
            "supportive response": "Josh's 'Yeah' expresses agreement with Brian Pogue's statement about the Google Doc and its takeaways."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:28-03:51",
        "transcript": "I don't know I don't know much about this, but the the the phrase that jumped to my mind is this uh like um sensor fusion ideas, right? So from kind of electrical engineering again a little bit out of my field, but thinking about how you synthesize information from different pieces and put them to put them together.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:28",
        "end_time": "53:51",
        "annotations": [
            {
                "Code Name": "propose new idea",
                "Explanation": "Josh introduces the new concept of 'sensor fusion ideas' as a phrase that came to his mind, which has not been explicitly discussed in this phrasing before."
            },
            {
                "Code Name": "develop idea",
                "Explanation": "Josh elaborates on the 'sensor fusion' idea by explaining it as synthesizing information from different pieces and putting them together."
            }
        ]
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:51-04:08",
        "transcript": "I'm not sure exactly how that the what uh Bri was saying earlier about image guided surgery, again something that I'm not super familiar with, but that strikes me as the right kind of approach, like um,",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:51",
        "end_time": "54:08",
        "annotations": {
            "identify knowledge gap": "Josh explicitly states his lack of familiarity with image-guided surgery, indicating 'I'm not sure exactly how that... again something that I'm not super familiar with'.",
            "supportive response": "Josh expresses a positive evaluation of the discussed approach, stating that it 'strikes me as the right kind of approach'."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:08-04:34",
        "transcript": "Yeah, computational um I mean this is certainly a big paradigm in surgical guidance world is computation computationally combining data from different modalities to help guide imaging and therapy. Um, where you might have just a static structure image guiding your temporal treatment or temporal acquisition.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:08",
        "end_time": "54:34",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Brian elaborates on the concept of computationally combining data from different modalities, specifically in the context of surgical guidance, by explaining how a static structure image can guide temporal treatment or acquisition."
            }
        ]
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "04:37-04:43",
        "transcript": "What what would that look like in this case, right? I'm having I guess I'm trouble visualizing.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:37",
        "end_time": "54:43",
        "annotations": {
            "ask question": "Shannon asks for clarification on how computationally combining data from different modalities would look in this specific case.",
            "identify knowledge gap": "Shannon explicitly states difficulty in visualizing the concept, indicating a lack of understanding."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:43-04:43",
        "transcript": "Uh.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:43",
        "end_time": "54:43",
        "annotations": {
            "None": "The utterance 'Uh.' is a non-lexical filler and does not convey a specific communicative function or content that aligns with any of the provided codes."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "04:45-05:06",
        "transcript": "So you have data that's perhaps, you know, high spatial resolution or high temporal resolution and you want to use another data set or metadata set or something to improve the resolution of your data that is lacking.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:45",
        "end_time": "55:06",
        "annotations": {
            "ask question": "Shannon is seeking clarification on a prior statement by rephrasing her understanding of how different data sets or modalities could be combined to improve resolution, implicitly asking for confirmation."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:06-05:06",
        "transcript": "Yeah, so.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:06",
        "end_time": "55:06",
        "annotations": {
            "utterance": "Brian Pogue: Yeah, so.",
            "annotations": [
                {
                    "Code Name": "supportive response",
                    "Explanation": "The utterance 'Yeah, so.' expresses agreement with the preceding statement from Shannon Quinn, fitting the definition of a supportive response as it acknowledges without adding new content."
                }
            ]
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:07-05:26",
        "transcript": "Some concrete ones that we discussed are like using an MR scan, for example, to which is pretty stat can be pretty static and then using optical measurements of dynamics to to add temporal behavior to the sort of static structure that you might get with an MR.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:07",
        "end_time": "55:26",
        "annotations": {
            "develop idea": "The speaker elaborates on the previously discussed concept of combining different imaging modalities by providing a concrete example of using MR scans with optical measurements to add temporal behavior to static structural data."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "05:26-05:26",
        "transcript": "Oh, I see.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:26",
        "end_time": "55:26",
        "annotations": {
            "acknowledge contribution": "Shannon's utterance \"Oh, I see\" verbally recognizes and indicates understanding of Brian's preceding explanation of how different modalities can be combined."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "05:26-05:31",
        "transcript": "This uh just connected with me something that Katherine was saying earlier too about how",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:26",
        "end_time": "55:31",
        "annotations": {
            "acknowledge contribution": "Josh acknowledges Katherine's previous input by stating that something just connected with what she was saying earlier, recognizing her contribution to the discussion."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "05:31-06:55",
        "transcript": "all the different there's all these open source tools that are available and a lot of times you're just like playing with knobs. There's no it would be interesting to explore what it would look like to have a framework to try to maybe standardize some I mean standardization is a is kind of a nightmare to try to do that, but I wonder if there's at least if there's some value in establishing best practices so that people can reuse these algorithms and things um more successfully across different applications and labs and organisms and everything.",
        "speaking duration": 84,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:31",
        "end_time": "56:55",
        "annotations": {
            "critical response": "Josh provides a negative evaluation of the current state of open-source tools, stating that users are often 'just like playing with knobs' due to a lack of standardization.",
            "propose new idea": "Josh suggests exploring a framework for standardization and establishing best practices to enable more successful reuse of algorithms across different applications and labs."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "06:57-07:45",
        "transcript": "I think I think that this is a really good point and something that we run into a lot when we're trying to do three-dimensional reconstruction quantification of of voxels. So if you're you know, if you're trying to do this on a membrane label or like you have a membrane label, it needs to be really continuous for most softwares to to fit it, but you can see in the DIC, there's like in the uh bright field, you can see the edge of the cell, you can see the nuclear envelope, uh but if you don't have a good nuclear membrane label, it's really difficult for a lot of these these softwares to to combine those two, which a person can see by eye and could potentially hand draw a million of these things, but it's really, really difficult to combine these two. So I just want to emphasize what what Josh suggested is a a really good point, I think.",
        "speaking duration": 48,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:57",
        "end_time": "57:45",
        "annotations": {
            "supportive response": "Katharine expresses agreement with Josh's previous point, stating it is a \"really good point\" and something they \"run into a lot,\" and then reiterates this agreement at the end of the utterance.",
            "develop idea": "Katharine elaborates on the challenges of 3D reconstruction and quantification with existing software, explaining how issues with membrane labels and combining different imaging data make it difficult to fit and combine information that a human can easily see."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:46-07:47",
        "transcript": "Mhm.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:46",
        "end_time": "57:47",
        "annotations": {
            "supportive response": "The utterance \"Mhm.\" expresses agreement or acknowledgment of the previous speaker's point without adding new content, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:47-07:48",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:47",
        "end_time": "57:48",
        "annotations": {
            "process management": "The utterance 'Okay' serves as a simple transition, acknowledging the previous statement and signaling readiness to move to the next part of the discussion, which helps manage the meeting flow."
        }
    },
    {
        "speaker": "Katharine White-Notre Dame",
        "timestamp": "00:00-00:09",
        "transcript": "or your data is going to fit one mode versus another or one analysis versus another and that's something that I think would be an awesome resource but I don't know how we get",
        "speaking duration": 9,
        "nods_others": 1,
        "smile_self": 33,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:00",
        "end_time": "60:09",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "This sentence elaborates on the challenges of data analysis, specifically how data might not fit different analytical modes, building on previous discussions about software limitations and data combination."
            },
            {
                "Code Name": "supportive response",
                "Explanation": "This expresses a positive evaluation of the idea of establishing best practices or a framework for standardizing tools, which was previously suggested by Josh."
            },
            {
                "Code Name": "identify knowledge gap",
                "Explanation": "This explicitly states a lack of knowledge regarding the process or method to achieve the desired resource or standardization."
            }
        ]
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "00:10-00:10",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:10",
        "end_time": "60:10",
        "annotations": {
            "supportive response": "The utterance 'Yeah' expresses agreement with the previous speaker's statement, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Katharine White-Notre Dame",
        "timestamp": "00:10-00:23",
        "transcript": "how we get people to to rerun data through their analyses if it's not publishable or how we get people to establish or or develop these these depositories.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 38,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:10",
        "end_time": "60:23",
        "annotations": {
            "identify knowledge gap": "The speaker explicitly recognizes a systemic gap in the scientific community regarding incentives and infrastructure, questioning how to motivate people to rerun data for non-publishable analyses and how to establish or develop necessary data depositories."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "00:23-00:59",
        "transcript": "Yeah, so why why don't we we've got we're a little bit ahead here. We why don't we I'm going to try to push us a little bit and if we can all look at the Google Doc, you know, and really I would say try to think of all this list laundry list of stuff we've talked about, what would really be impactful? You know, like what what's the most important thing to do, to work on? I'd love to get people's thoughts on, you know, what really excites them and what they think would be the most impactful thing.",
        "speaking duration": 36,
        "nods_others": 1,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:23",
        "end_time": "60:59",
        "annotations": {
            "process management": "Brian manages the meeting flow by noting they are \"a little bit ahead\" and suggesting the group \"push\" to look at the Google Doc and focus on impactful ideas.",
            "clarify goal": "Brian seeks to define the group's objectives by asking \"what's the most important thing to do, to work on.\"",
            "encourage participation": "Brian invites \"people's thoughts\" on what excites them and what they think would be the most impactful thing, encouraging group contribution."
        }
    },
    {
        "speaker": "Katharine White-Notre Dame",
        "timestamp": "01:01-01:56",
        "transcript": "I feel like I've been talking a lot but I can start. Um, on my end it's this kind of question of how do you adjust your acquisition so that you're reducing the density of your data or after the fact, how do you analyze your data with these kind of coarse versus finer analyses? Because, you know, you could go to Janelia and get time on this super awesome microscope and they'll give you 10 terabytes of data at the end of it, but it and then analyzing it is your problem and and trying to mine that data is your problem and that takes tons of time um if if you're if you're not sure either because of a machine learning approach or because of an experimental observation if you're not sure where the timing matters or where the spatial and temporal kind of scale fits for your for your behavior or for your proteins of interest. So",
        "speaking duration": 55,
        "nods_others": 1,
        "smile_self": 20,
        "smile_other": 2,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:01",
        "end_time": "61:56",
        "annotations": {
            "ask question": "Katharine asks how to adjust data acquisition to reduce density or how to analyze data with coarse versus finer analyses, seeking information from the group.",
            "develop idea": "Katharine elaborates on the challenge of high-density data by providing an example of acquiring 10 terabytes of data and explaining the difficulty of analyzing it without clear understanding of relevant temporal and spatial scales."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "01:56-02:01",
        "transcript": "So approaches to reducing data volume and capturing data.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:56",
        "end_time": "62:01",
        "annotations": {
            "summarize conversation": "The speaker summarizes the preceding discussion about approaches to reducing data volume and efficiently capturing data, which was a key point raised by the previous speaker."
        }
    },
    {
        "speaker": "Katharine White-Notre Dame",
        "timestamp": "02:01-02:39",
        "transcript": "Yeah, either either as as it's being captured, I think as as Josh and and I think Shannon as well were kind of discussing this a little earlier, um, or after the fact in terms of how how to um how to determine like through other imaging approaches by combining imaging modality analysis like we were talking about um fluorescence and and DIC um or fluorescence and and wide field imaging um to to densify uh your need for spatial and potentially temporal acquisition.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:01",
        "end_time": "62:39",
        "annotations": {
            "develop idea": "Katharine elaborates on how to reduce data volume and optimize data capture by combining different imaging modalities (fluorescence, DIC, wide field imaging) to determine the necessary spatial and temporal acquisition, building on earlier discussions."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "02:39-02:40",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:39",
        "end_time": "62:40",
        "annotations": {
            "acknowledge contribution": "Brian Pogue's 'Okay' verbally recognizes Katharine White's preceding input about approaches to reducing data volume and capturing data, indicating he has heard and registered her contribution."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "02:40-03:01",
        "transcript": "Other other people, um, we just try to go around the group and say, you know, the one topic or area that they think, you know, they maybe it's just something that you feel like you could work on or maybe but ideally have the biggest impact. Anybody else?",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:40",
        "end_time": "63:01",
        "annotations": [
            {
                "Code Name": "encourage participation",
                "Explanation": "Brian explicitly invites other group members to share their thoughts on impactful topics or areas they could work on, directly encouraging their participation in the discussion."
            }
        ]
    },
    {
        "speaker": "Carolyn Bayer/Tulane (she/her)",
        "timestamp": "03:01-03:59",
        "transcript": "Yeah, I'll chime in. So I I definitely think um if if we're thinking about multimodal integrations, you know, then it definitely becomes a question of being able to identify in real time what's data so that you can determine which multimodal imaging system with different temporal and spatial resolution you want to use. Um, I think one thing though that's confusing me a little bit or you know still a mystery is that I don't I don't know how to make it into sort of a systematic approach, meaning like um you know I'm used to sort of comparatively thinking about all of the different imaging modalities, but how do we make this an approach which can which can be equally applied to microscopy and and and image guided surgery? You know, like how do we that's that's where I'm still haven't quite",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 5,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:01",
        "end_time": "63:59",
        "annotations": {
            "supportive response": "The speaker expresses readiness to contribute to the discussion by saying \"Yeah, I'll chime in.\"",
            "develop idea": "The speaker elaborates on the concept of multimodal integrations by discussing the challenge of real-time data identification for selecting appropriate imaging systems based on temporal and spatial resolution.",
            "identify knowledge gap": "The speaker explicitly states confusion and a lack of understanding about how to create a systematic approach applicable across different imaging modalities like microscopy and image-guided surgery."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "03:59-04:01",
        "transcript": "Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:59",
        "end_time": "64:01",
        "annotations": {
            "supportive response": "The utterance 'Yeah.' expresses agreement or validation with the previous speaker's statement, indicating a positive evaluation of their contribution."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "04:01-04:10",
        "transcript": "I don't think it necessarily has to be, you know, uh it would be great if there was some some super string theory for how to do this or something, you know, that",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 22,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:01",
        "end_time": "64:10",
        "annotations": {
            "express humor": "Brian uses the exaggerated analogy of a \"super string theory\" to humorously comment on the difficulty of finding a single, universally applicable systematic approach for integrating different imaging modalities."
        }
    },
    {
        "speaker": "Carolyn Bayer/Tulane (she/her)",
        "timestamp": "04:11-04:13",
        "transcript": "Clearly there must be.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:11",
        "end_time": "64:13",
        "annotations": {
            "supportive response": "Carolyn's statement 'Clearly there must be.' expresses agreement and validation with Brian's preceding comment about the desirability of a 'super string theory' or systematic approach for integrating imaging modalities."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "04:13-04:16",
        "transcript": "Um",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:13",
        "end_time": "64:16",
        "annotations": [
            {
                "code_name": "None",
                "explanation": "The utterance 'Um' is a filler word and does not convey any explicit content that aligns with the provided codes."
            }
        ]
    },
    {
        "speaker": "Josh Brake-Harvey Mudd College",
        "timestamp": "04:17-05:00",
        "transcript": "Well you can get you can get farther than you might think with general physical approaches thinking from a systems level in terms of imaging like an imaging system in general where you go black boxes and the same physics applies in a lot okay, different physics but same underlying uh physical properties or uh strategies like trading off longer acquisition time for better noise performance and this kind of thing. So you know, I I I guess there's maybe there's a middle a happy middle ground to.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 12,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:17",
        "end_time": "65:00",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Josh elaborates on the idea of a systematic approach for imaging by explaining how general physical principles and systems-level thinking can be applied across different imaging modalities, such as trading acquisition time for noise performance, and concludes by suggesting a 'happy middle ground' for these approaches."
            }
        ]
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "05:00-05:01",
        "transcript": "Mhm.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:00",
        "end_time": "65:01",
        "annotations": {
            "supportive response": "The utterance \"Mhm\" expresses agreement or validation with the previous speaker's point about finding a happy middle ground in imaging system strategies."
        }
    },
    {
        "speaker": "Silvia Ronco RCS4",
        "timestamp": "05:01-05:04",
        "transcript": "Brian, um there's 10 minutes left.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:01",
        "end_time": "65:04",
        "annotations": {
            "process management": "The utterance 'there's 10 minutes left' directly manages the meeting flow by indicating the remaining time, aligning with the definition of managing meeting time."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "05:04-05:05",
        "transcript": "We do. We're we're we're we're trying to prioritize it now, I think.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:04",
        "end_time": "65:05",
        "annotations": {
            "process management": {
                "Code Name": "process management",
                "Explanation": "The speaker acknowledges the remaining time and states the group's current activity of prioritizing the discussion, which is a direct action to manage the meeting's flow and focus within the time constraints."
            }
        }
    },
    {
        "speaker": "Silvia Ronco RCS4",
        "timestamp": "05:05-05:06",
        "transcript": "Okay, thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:05",
        "end_time": "65:06",
        "annotations": {
            "supportive response": "The utterance 'Okay, thank you' expresses positive evaluation and acknowledgment of the previous speaker's statement regarding the meeting's progress and time management, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Silvia Ronco RCS4",
        "timestamp": "05:06-05:06",
        "transcript": "Just a reminder.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:06",
        "end_time": "65:06",
        "annotations": {
            "process management": "This utterance serves as a reminder about the remaining meeting time, which falls under managing the meeting flow and structure."
        }
    },
    {
        "speaker": "Silvia Ronco RCS4",
        "timestamp": "05:06-05:07",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:06",
        "end_time": "65:07",
        "annotations": {
            "process management": "This utterance serves as a brief confirmation or acknowledgement of the time reminder, indicating the management of the meeting flow."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "05:07-05:07",
        "transcript": "Yeah, great.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:07",
        "end_time": "65:07",
        "annotations": {
            "supportive response": "The utterance 'Yeah, great.' expresses agreement and positive evaluation of a prior statement or contribution."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "05:07-05:57",
        "transcript": "Because that actually um Josh, you know, we should think about, you know, prioritizing that list, right? And part of this is sort of going through and seeing what people think are the biggest impact, I think. Um Any others?",
        "speaking duration": 50,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:07",
        "end_time": "65:57",
        "annotations": {
            "process management": "Brian suggests prioritizing the discussed list and identifying the biggest impact items, which is a way of managing the meeting's structure and organizing group activities.",
            "encourage participation": "Brian explicitly asks 'Any others?' to invite further contributions from the group members."
        }
    },
    {
        "speaker": "Bryan Spring | Northeastern U",
        "timestamp": "05:57-06:00",
        "transcript": "Let's mention that I think say you brought this up but making super resolution work for live cells I think is a",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:57",
        "end_time": "66:00",
        "annotations": {
            "propose new idea": "Bryan proposes 'making super resolution work for live cells' as a new impactful area to focus on, in response to the facilitator's request for the most important things to work on."
        }
    },
    {
        "speaker": "Bryan Spring | Northeastern U",
        "timestamp": "06:00-06:01",
        "transcript": "fascinating topic and direction.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:00",
        "end_time": "66:01",
        "annotations": {
            "supportive response": "Bryan expresses a positive evaluation by calling the topic and direction 'fascinating', indicating agreement or validation of a previously discussed point."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "06:01-06:01",
        "transcript": "Mhm.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:01",
        "end_time": "66:01",
        "annotations": {
            "supportive response": "The utterance 'Mhm.' expresses agreement or acknowledgment of the previous speaker's statement without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "06:01-06:01",
        "transcript": "Mhm.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:01",
        "end_time": "66:01",
        "annotations": {
            "supportive response": "The utterance \"Mhm.\" serves as a minimal verbal affirmation, expressing validation or implicit agreement with the previous speaker's statement without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue-DARTMOUTH",
        "timestamp": "06:01-06:01",
        "transcript": "Mhm.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:01",
        "end_time": "66:01",
        "annotations": {
            "supportive response": "The utterance \"Mhm.\" expresses agreement or validation with the preceding statement, without adding new content."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "00:00-00:12",
        "transcript": "of how we think about integrating across biological scales from the molecular to the cell to the tissue and I thought that was a a really good point.",
        "speaking duration": 12,
        "nods_others": 3,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:00",
        "end_time": "70:12",
        "annotations": [
            {
                "Code Name": "develop idea",
                "Explanation": "Katharine elaborates on the concept of integrating across different biological scales, from molecular to tissue, building upon previous discussions about multi-scale approaches."
            },
            {
                "Code Name": "supportive response",
                "Explanation": "Katharine expresses positive evaluation by stating 'that was a really good point,' indicating agreement or validation of a prior contribution."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:12-00:13",
        "transcript": "Oh yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:12",
        "end_time": "70:13",
        "annotations": {
            "supportive response": "Brian expresses agreement with Katharine's previous statement about integrating across biological scales, indicating validation of her contribution without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:15-00:16",
        "transcript": "So cross.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:15",
        "end_time": "70:16",
        "annotations": {
            "summarize conversation": "The utterance 'So cross.' concisely summarizes the preceding discussion point about integrating across biological scales, distilling the core idea into a single word."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "00:16-00:18",
        "transcript": "Thank you, that's that's a much better way of wording it. Thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:16",
        "end_time": "70:18",
        "annotations": {
            "supportive response": "Shannon expresses gratitude and positive evaluation for Katharine's rephrasing of a previous point, indicating agreement and validation of her contribution."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:18-00:18",
        "transcript": "[laughter]",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:18",
        "end_time": "70:18",
        "annotations": {
            "express humor": "The utterance explicitly indicates laughter, which aligns with the definition of expressing humor."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:21-00:22",
        "transcript": "So you mean spatial scales, right?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:21",
        "end_time": "70:22",
        "annotations": {
            "ask question": "Brian asks for clarification on Shannon's previous statement about 'biological scales' by asking 'So you mean spatial scales, right?', which seeks to confirm the intended meaning."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "00:23-01:13",
        "transcript": "Yeah, so like for example to kind of put you were asking for something more concrete in that area. So to put a concrete thing on it like we study pH dynamics at the single scale, but then that is communicated at a tissue scale as the cells change their behavior and talk to their neighbors through signaling we don't really understand. So we'd like to capture that dynamics and build up at the molecular scale within a single cell and then how that is then communicated to neighboring cells within a larger 2D environment and then eventually 3D tissue.",
        "speaking duration": 50,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:23",
        "end_time": "71:13",
        "annotations": {
            "acknowledge contribution": "Katharine acknowledges Brian's prior request for a concrete example, recognizing his input.",
            "develop idea": "Katharine elaborates on the concept of integrating across biological scales by providing a specific example of pH dynamics and cell communication.",
            "clarify goal": "Katharine defines her group's objective to capture and build understanding of dynamics from the molecular to the 3D tissue scale."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "01:13-01:17",
        "transcript": "tissue level effect uh has approaches across a lot of different biology.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:13",
        "end_time": "71:17",
        "annotations": {
            "develop idea": "Katharine White elaborates on the concept of integrating across biological scales by stating that tissue-level effects have approaches across a lot of different biology, building upon her previous explanation of pH dynamics from molecular to tissue scales."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "01:18-01:18",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:18",
        "end_time": "71:18",
        "annotations": {
            "supportive response": "Katharine White's 'Yeah' expresses agreement with Brian Pogue's clarification about spatial scales, indicating validation of his understanding."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:21-01:21",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:21",
        "end_time": "71:21",
        "annotations": {
            "acknowledge contribution": "The utterance 'Okay.' verbally recognizes Katharine White's preceding input without expressing agreement or expanding on it."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "01:22-01:26",
        "transcript": "It feels like an opportunity for some of the orthogonal imaging approaches also.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:22",
        "end_time": "71:26",
        "annotations": {
            "develop idea": "Katy Keenan expands on the existing idea of orthogonal imaging approaches by suggesting they present an opportunity for integrating across biological scales, thereby elaborating on their potential utility."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "01:27-01:28",
        "transcript": "Exactly, yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:27",
        "end_time": "71:28",
        "annotations": {
            "supportive response": "Katharine White's utterance \"Exactly, yeah\" expresses clear agreement with Katy Keenan's preceding statement about orthogonal imaging approaches, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:33-01:35",
        "transcript": "So what would we actually do?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:33",
        "end_time": "71:35",
        "annotations": {
            "ask question": "The utterance \"So what would we actually do?\" is a direct question asking the group for concrete actions or next steps, which aligns with requesting information or clarification from team members."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:37-01:47",
        "transcript": "I feel like we're really good at defining problems here, but we're maybe it's the engineer in me, but I I feel like we're a little bit lighter on the solutions, you know.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:37",
        "end_time": "71:47",
        "annotations": {
            "critical response": "Brian provides a negative evaluation of the group's progress, stating that while they are good at defining problems, they are \"lighter on the solutions,\" indicating a perceived lack of solution generation."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "01:48-02:56",
        "transcript": "Well, I think we actually have problems and then solutions to potentially address it. So like the labeling density problem is solved by either uh our first takeaway, so how do you simulate so that you know what your labeling density needs to be for a certain behavior, certain spatial or temporal resolution. And then collecting more data than you need, that kind of goes to this computational approach as a as a potential solution and then cross the scales of biology, multimodal imaging would potentially allow you to monitor something in the seconds to minutes time scale using a very high resolution approach and then potentially shift on the minutes to hours time scale to a single cell or a single area of a tissue and then ideally whole organism kind of thing on the days to whatever time scale.",
        "speaking duration": 68,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:48",
        "end_time": "72:56",
        "annotations": {
            "summarize conversation": "The speaker summarizes the discussion by noting that the group has identified both problems and potential solutions.",
            "develop idea": "The speaker elaborates on solutions by suggesting simulation for optimal labeling density, proposing computational approaches for data management, and detailing how multimodal imaging can integrate across various biological and temporal scales."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "02:56-02:57",
        "transcript": "Um yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "72:56",
        "end_time": "72:57",
        "annotations": {
            "supportive response": "The utterance 'Um yeah' expresses agreement and validation with the immediately preceding statement about cross-scale integration and multimodal imaging as a solution."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "02:58-03:11",
        "transcript": "So yeah, I would just say, you know, we've got what four minutes left, but if anybody wants to type in, make sure that solutions are typed in here as well as the problems. Uh feel free to, you know, put stuff down.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "72:58",
        "end_time": "73:11",
        "annotations": {
            "process management": "Brian explicitly states the remaining time left in the meeting and directs the group to ensure solutions and problems are typed into the shared document, managing the meeting's output.",
            "encourage participation": "Brian invites group members to contribute their thoughts and ideas by telling them to 'feel free to... put stuff down' in the document."
        }
    },
    {
        "speaker": "Bryan Spring",
        "timestamp": "03:12-03:23",
        "transcript": "Sounds like summarizing or creating it talking about infrastructure needed to combine orthogonal imaging modalities a lot of.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:12",
        "end_time": "73:23",
        "annotations": {
            "summarize conversation": "The utterance summarizes previous discussions by reflecting on the need for infrastructure to combine orthogonal imaging modalities, which has been a recurring theme in the conversation."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:33-03:35",
        "transcript": "Is there anything missing on this that we covered?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:33",
        "end_time": "73:35",
        "annotations": {
            "ask question": "The speaker asks the group if anything has been missed from the discussion, which is a direct request for information about the completeness of the covered topics."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "03:39-04:03",
        "transcript": "Yeah, I mean this is kind of a solution, this isn't something missing, sorry, but I feel like a way to approach this might be to identify the imaging modality that currently does the best job of scaling both time and space optimizing some sort of data analysis.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:39",
        "end_time": "74:03",
        "annotations": {
            "propose new idea": "Carolyn suggests a new approach to the problem by proposing to \"identify the imaging modality that currently does the best job of scaling both time and space optimizing some sort of data analysis,\" which is a new solution to the challenge."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "04:03-04:33",
        "transcript": "And um method of moving between those time and space skills and then integrating orthogonal or multimodal where you would then you know, so demonstrate it sort of on on the small scale on a single imaging system.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:03",
        "end_time": "74:33",
        "annotations": [
            {
                "Code Name": "offer feedback",
                "Explanation": "Carolyn provides a specific suggestion for approaching multimodal integration by proposing a method of moving between time and space scales and demonstrating it on a small scale within a single imaging system."
            }
        ]
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:33-04:33",
        "transcript": "Mhm.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:33",
        "end_time": "74:33",
        "annotations": [
            {
                "Code Name": "supportive response",
                "Explanation": "The utterance 'Mhm' serves as a minimal verbal cue expressing agreement or validation of the preceding speaker's contribution without adding new content."
            }
        ]
    },
    {
        "speaker": "Katharine White",
        "timestamp": "04:44-04:54",
        "transcript": "Yeah, I think I captured what Carolyn was saying. So if you want to double check that that was uh similar to what you're saying it's underneath the multimodal.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:44",
        "end_time": "74:54",
        "annotations": {
            "annotations": [
                {
                    "sentence": "Yeah, I think I captured what Carolyn was saying.",
                    "code_name": "supportive response",
                    "explanation": "Katharine expresses agreement and validates her understanding of Carolyn's previous contribution without adding new content."
                },
                {
                    "sentence": "So if you want to double check that that was uh similar to what you're saying it's underneath the multimodal.",
                    "code_name": "process management",
                    "explanation": "Katharine manages the documentation process by inviting Carolyn to verify the accuracy of the notes in the shared document, which relates to organizing group activities."
                }
            ]
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "04:54-04:54",
        "transcript": "And maybe you can clean that up.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:54",
        "end_time": "74:54",
        "annotations": {
            "assign task": "Katharine assigns the task of refining the notes in the shared document, stating 'you can clean that up,' which is an action item for the scribe or another group member."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "05:02-05:03",
        "transcript": "Some wild editing going on here.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:02",
        "end_time": "75:03",
        "annotations": {
            "express humor": "The speaker makes a lighthearted comment about the active, simultaneous editing occurring in the shared document, which serves as a form of humor."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "06:47-06:51",
        "transcript": "Looks like we're we're closing in like 20 seconds. Am I reporting out for us? Is that the plan? I'll just copy and paste.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:47",
        "end_time": "76:51",
        "annotations": {
            "annotations": [
                {
                    "sentence": "Looks like we're we're closing in like 20 seconds.",
                    "code_name": "process management",
                    "explanation": "The speaker manages the meeting flow by explicitly stating the remaining time for the session."
                },
                {
                    "sentence": "Am I reporting out for us?",
                    "code_name": "ask question",
                    "explanation": "The speaker requests clarification about a potential role or responsibility for the group's output."
                },
                {
                    "sentence": "Is that the plan?",
                    "code_name": "ask question",
                    "explanation": "The speaker seeks confirmation regarding the group's agreed-upon course of action for reporting out."
                },
                {
                    "sentence": "I'll just copy and paste.",
                    "code_name": "assign task",
                    "explanation": "The speaker self-assigns the action item of copying and pasting the notes for the report-out."
                }
            ]
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:51-06:51",
        "transcript": "You got it.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:51",
        "end_time": "76:51",
        "annotations": {
            "confirm decision": "Brian Pogue's utterance 'You got it' explicitly confirms the plan for Josh to report out, which was proposed in the preceding turn, thereby confirming a course of action."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "06:51-06:52",
        "transcript": "We believe in you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:51",
        "end_time": "76:52",
        "annotations": {
            "supportive response": "Carolyn expresses validation and encouragement to Josh, who is about to report out for the group, which aligns with expressing positive evaluation for another group member's contribution."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "06:53-06:53",
        "transcript": "All right.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:53",
        "end_time": "76:53",
        "annotations": {
            "supportive response": "Josh's utterance 'All right' serves as a supportive response, indicating his agreement and readiness to take on the task of reporting out, following Brian's confirmation and Carolyn's encouragement."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "06:53-06:54",
        "transcript": "Shipping me off.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:53",
        "end_time": "76:54",
        "annotations": {
            "express humor": "Josh Brake makes a lighthearted comment, 'Shipping me off,' in response to being assigned the task of reporting out, which aligns with expressing humor."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "06:54-06:59",
        "transcript": "I may throw somebody else under the bus. Watch out. I know who you are.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:54",
        "end_time": "76:59",
        "annotations": {
            "express humor": "Josh makes a joke about potentially implicating someone else during the report-out, using playful threats like 'Watch out. I know who you are,' which aligns with expressing humor."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "06:59-07:00",
        "transcript": "At least three seconds.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:59",
        "end_time": "77:00",
        "annotations": {
            "express humor": "This utterance is a brief, lighthearted remark that follows a humorous comment from Josh, contributing to the playful atmosphere at the end of the meeting."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "07:00-07:01",
        "transcript": "At least for a second.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "77:00",
        "end_time": "77:01",
        "annotations": {
            "express humor": "The utterance \"At least for a second\" is a brief, lighthearted comment that plays on the preceding remark about the remaining time, contributing to a humorous exchange as the session concludes."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:02-07:04",
        "transcript": "You got to make sense of all this, you know.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "77:02",
        "end_time": "77:04",
        "annotations": {
            "process management": "Brian directs the scribe to organize and make coherent the discussion points for the report-out, which falls under managing the structure and organization of the group's activities."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "07:04-07:06",
        "transcript": "All right, I'll do my best folks.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "77:04",
        "end_time": "77:06",
        "annotations": {
            "None": "The utterance expresses Josh Brake's acceptance of the assigned task and his commitment to perform it well, which does not align with any of the provided codes."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:06-07:06",
        "transcript": "Make us look good.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "77:06",
        "end_time": "77:06",
        "annotations": {
            "express humor": "Brian Pogue's comment \"Make us look good\" is a lighthearted, informal instruction to Josh, who is about to report out for the group, indicating a playful tone rather than a serious demand, especially following previous banter."
        }
    },
    {
        "speaker": "Katharine White",
        "timestamp": "07:06-07:06",
        "transcript": "Good luck.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "77:06",
        "end_time": "77:06",
        "annotations": {
            "supportive response": "The utterance 'Good luck' expresses positive support and encouragement to Josh as he prepares to report out, aligning with the definition of a supportive response."
        }
    },
    {
        "speaker": "Larry Cheng",
        "timestamp": "07:07-07:07",
        "transcript": "I'll do what I can.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "77:07",
        "end_time": "77:07",
        "annotations": {
            "supportive response": "Larry's statement 'I'll do what I can' expresses a general willingness to contribute positively to the group's effort, particularly in the context of the upcoming report out, aligning with expressing validation or positive evaluation for the group's collective task."
        }
    }
]