[
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:00-00:16",
        "transcript": "more discussion. I am sure that there are other topics of discussion that will come up that might fall off that list of key points. Um, maybe Richard who's on on in our room can um make a comment. Are we supposed to put those other ideas into the parking lot or just keep them ourselves or record them somewhere else?",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:00",
        "end_time": "00:16",
        "annotations": {
            "ask question": "The speaker asks for clarification on how to handle additional ideas.",
            "encourage participation": "The speaker invites Richard to make a comment.",
            "process management": "The speaker is managing the discussion process by questioning how to handle additional topics."
        }
    },
    {
        "speaker": "Richard Weisman",
        "timestamp": "00:17-00:36",
        "transcript": "And either of those things you can do. If you think they're really valuable to put in the parking lot, please do. You can keep them for yourselves. I suggest Josh take some notes on the side, which he can share with people, and then you at the very end of the meeting you added it into the key points uh for the discussion. And just have a lot of fun in the discussion.",
        "speaking duration": 19,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the logo of Research Corporation for Science Advancement. The logo is a blue figure eight with the text \"RESEARCH CORPORATION for SCIENCE ADVANCEMENT\" below it. The screen remains static throughout the segment.",
        "start_time": "00:17",
        "end_time": "00:36",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting how to handle additional ideas that come up during the discussion.",
            "assign task": "The speaker assigns a specific task to Josh, suggesting that he take notes on the side and share them with others."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:36-00:43",
        "transcript": "Okay, sounds perfect. Okay, does anyone have any questions before we take our minute to think?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 29.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:36",
        "end_time": "00:43",
        "annotations": {
            "encourage participation": "Inviting others to share questions or thoughts before proceeding"
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "00:43-00:56",
        "transcript": "Uh, I have a quick logistic question. So the slide is uh is called Psi log ABI meeting slides. And then where are we supposed to put our names? Is it slide 16 session one?",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 23.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:43",
        "end_time": "00:56",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification about where to put their names in the slides, which is a direct question to the group."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "00:57-01:00",
        "transcript": "I already copied and pasted all of our names in there, so we're good on names.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 33.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:57",
        "end_time": "01:00",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:00-01:02",
        "transcript": "Okay. It's slide 22.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:00",
        "end_time": "01:02",
        "annotations": {
            "process management": "Kristen Maitland is providing a clarification regarding the slide number, which helps manage their discussion materials and meeting flow."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "01:03-01:06",
        "transcript": "Uh slide 22. Okay, perfect. Thank you.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:03",
        "end_time": "01:06",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging Kristen Maitland's and Josh Brake's input.",
            "supportive response": "The utterance indicates agreement and satisfaction with the information provided."
        }
    },
    {
        "speaker": "Richard Weisman",
        "timestamp": "01:06-01:13",
        "transcript": "And I'll be jumping in and out through through a few rooms. So if I leave, uh don't worry about it and I'll be quiet the rest of the way.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 14.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the logo of Research Corporation for Science Advancement. The logo is a blue figure eight with the text \"RESEARCH CORPORATION for SCIENCE ADVANCEMENT\" below it. The screen remains static throughout the segment.",
        "start_time": "01:06",
        "end_time": "01:13",
        "annotations": {
            "process management": "This code applies because the utterance manages meeting flow by informing the group about Richard's movement and participation level for the rest of the meeting."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:13-01:15",
        "transcript": "Okay. Thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:13",
        "end_time": "01:15",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes another group member's input."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:15-02:30",
        "transcript": "Okay, so I'm going to set a timer for one minute for you each to think about your topic related to uh super resolution methods. We were given two kind of prompt questions, but I think you have other ideas and other questions that you might want to ask. So I'll just we'll have one minute of silence for thinking.",
        "speaking duration": 75,
        "nods_others": 0,
        "smile_self": 1.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:15",
        "end_time": "02:30",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by setting a timer for a minute of silence for thinking.",
            "clarify goal": "The speaker is defining or clarifying the goal of the thinking time, which is related to super resolution methods and possibly addressing prompt questions."
        }
    },
    {
        "speaker": "bot1",
        "timestamp": "02:31-02:36",
        "transcript": "So both three, I don't I don't have you assigned. I need so I don't know how to put you in.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:31",
        "end_time": "02:36",
        "annotations": {
            "ask question": "The speaker is requesting clarification or guidance on how to proceed with assignments.",
            "process management": "The speaker is dealing with the logistics of managing the group or task assignments."
        }
    },
    {
        "speaker": "bot1",
        "timestamp": "02:37-02:40",
        "transcript": "You don't have me, you don't see me in there in the room?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:37",
        "end_time": "02:40",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification about their presence in a shared document or room."
        }
    },
    {
        "speaker": "bot1",
        "timestamp": "02:40-02:46",
        "transcript": "I don't see you as an assigned. I don't know why.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:40",
        "end_time": "02:46",
        "annotations": {
            "identify gap": "The speaker identifies a gap in their knowledge or in the system regarding the assignment status of a person."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:46-03:12",
        "transcript": "Okay. That is strange. Do you I mean, um so one thing I'll say is that I'll just ask if anyone would want like to start the conversation. Um I'm going to try and keep an eye out on if there is someone that is not contributing and I will call on you at a certain point just to make sure we hear from everyone. Um and I do ask that you be respectful of other people's time and so um if you do feel like you're contributing quite a bit, that's excellent, but maybe make sure that everyone has a chance to speak.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 15.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:46",
        "end_time": "03:12",
        "annotations": {
            "process management": "Kristen Maitland is managing the meeting flow by indicating she will ensure everyone has a chance to speak and be respectful of others' time.",
            "encourage participation": "Kristen Maitland is encouraging all members to participate by offering to call on those who haven't contributed and asking if anyone wants to start the conversation."
        }
    },
    {
        "speaker": "bot1",
        "timestamp": "03:12-03:17",
        "transcript": "Okay, so who would like to get started?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 40.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:12",
        "end_time": "03:17",
        "annotations": {
            "encourage participation": "The speaker is inviting others to contribute their thoughts or ideas.",
            "process management": "The speaker is managing the flow of the discussion by initiating the start of contributions."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "03:17-04:46",
        "transcript": "I can get started on one of the topics. Uh I really like the second question, how can we mitigate or utilize multiple scattering when we transition this technique to invivo applications? I think there are two ways to think about it. So if we are talking about like traditional super resolution techniques like in optics, uh multiple scattering is the enemy because they scramble your light. So the first way to think about it is how can we gate these multiple scattering? How can we reject them so that we can only get ballistic photons that carry the truly valuable information. And then so I guess one direction along this way is to think how can we more efficiently uh select these ballistic photons. And then a second direction, a second perspective on this is how do we use multiple scattering to get more information? Because these ballistic photons decay exponentially as you go deeper into the tissue. Uh so if we can use the but multiple scattering uh process looks random, but it's deterministic. So if we have physics model that can take advantage of this uh interference and use that to our advantage because with multiple scattering, you can actually get more angles, right? So with that you get more field of view, you get more uh uh resolution. So uh I I think that part is pretty interesting.",
        "speaking duration": 89,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:17",
        "end_time": "04:46",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas related to super resolution techniques and multiple scattering, providing specific directions for research.",
            "encourage participation": "The speaker encourages others to participate by stating 'I can get started on one of the topics.'"
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "04:47-05:07",
        "transcript": "That's great and thank you. And I just realized that we did not introduce ourselves first. So uh Sishan, why why don't you start and introduce yourself? We'll go around, make sure we just it'll be a very brief so your name and institution which we can see, but um a brief uh introduction of your background and what perspective you have on this topic in particular.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 15.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:47",
        "end_time": "05:07",
        "annotations": {
            "encourage participation": "Kristen Maitland is directly inviting Sixian You to contribute by introducing himself.",
            "process management": "Kristen Maitland is managing the meeting flow and structure by suggesting they go around the room for introductions."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "05:08-05:26",
        "transcript": "Uh my name is Sishan Yo. I just started at MIT uh three months ago, two months ago. Uh my lab develops optical imaging technologies, especially for microscopy applications. We are interested in using optics and algorithms to solve real world biomedical problems.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 11.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:08",
        "end_time": "05:26",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise and qualifications related to the task by mentioning their background at MIT and their lab's focus areas."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:26-05:28",
        "transcript": "Thank you. Uh Dylan.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:26",
        "end_time": "05:28",
        "annotations": {
            "process management": "The speaker is managing the conversation flow by calling on the next person to contribute.",
            "encourage participation": "The speaker is inviting Dylan to participate in the conversation by calling his name."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "05:29-06:12",
        "transcript": "I am uh Dylan Burnette. I'm a an associate professor at Vanderbilt University. I just got tenure, so I'm technically now not uh new, although I feel new still. I have new people problems. Um I am a cell biologist by training and I've been using light microscopy for about 20 years now to study everything from neurons to cancer and now I work on heart. So I'm very interested in how the heart grows on a single cell level.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 2.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:29",
        "end_time": "06:12",
        "annotations": {
            "signal expertise": "The speaker explicitly states his qualifications and experience in cell biology and light microscopy, signaling his expertise in the field."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:12-06:12",
        "transcript": "Great.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:12",
        "end_time": "06:12",
        "annotations": {
            "Supportive response": "The utterance expresses agreement or validation for previous statements, indicating a positive sentiment towards the discussion."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:13-06:13",
        "transcript": "Aseema?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:13",
        "end_time": "06:13",
        "annotations": {
            "encourage participation": "The speaker, Kristen Maitland, is directly addressing Aseema and inviting them to contribute, likely to introduce themselves or share their thoughts."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "06:15-06:56",
        "transcript": "Hi, I'm Aseema Mohanty. Um, I recently started as a faculty at Tuffs University in Boston. Um, and I work on uh nanophotonics. Um, so that's like chip scale optics and so um uh we've been kind of working on um optical phase arrays and creating 3D structured light from a chip. Um, and so my kind of perspective on super resolution is is there anything that we can do to kind of, you know, handle some of the limitations of bulk um optics or high NA objectives and miniaturize that to make it kind of feasible for um more portable applications.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 41.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:15",
        "end_time": "06:56",
        "annotations": {
            "signal expertise": "The speaker explicitly states her own background and area of work related to the task.",
            "ask question": "The speaker requests information or ideas on how to handle limitations of bulk optics or high NA objectives in the context of super resolution.",
            "encourage participation": "The speaker invites discussion by posing a question about potential approaches to super resolution."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:56-06:57",
        "transcript": "Okay. Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:56",
        "end_time": "06:57",
        "annotations": {
            "acknowledge contribution": "verbally recognizes another group member's input",
            "supportive response": "Expressing agreement or positive sentiment"
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:57-06:57",
        "transcript": "Josh?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:57",
        "end_time": "06:57",
        "annotations": {
            "encourage participation": "The speaker is inviting Josh to contribute his thoughts or ideas, encouraging his participation in the discussion."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "07:00-07:54",
        "transcript": "Everybody, my name is Josh Brake. I am an assistant professor in the engineering department at Harvey Mudd College. My training is in engineering and specifically in electrical engineering. I did my PhD work in um biomedical optics, specifically looking at how to use optical wavefront shaping to peer deeper into tissue. And so I really resonated with what we were just talking about about the second option, which I think is the much better one, maybe unbiased, but uh to try to harness the multiply scattered photons and in some sense redeem those to make them make them useful for our for our optical imaging techniques. Uh the last thing I'll say is just that as an engineer, I'm a tool builder by nature and so I'm really looking forward to meeting all of you and hearing about Kristen what you said in the main session really resonated with me too. How can I bring engineering skills to bear to solve solve problems? So thanks.",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 11.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:00",
        "end_time": "07:54",
        "annotations": {
            "develop idea": "The speaker is expanding on his thoughts and relating them to the previous discussion.",
            "ask question": "The speaker asks a question about applying his engineering skills to solve problems.",
            "signal expertise": "The speaker explicitly states his background and expertise in engineering and biomedical optics."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:54-07:55",
        "transcript": "Great, thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:54",
        "end_time": "07:55",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing Josh Brake's input with a positive sentiment.",
            "supportive response": "The utterance expresses a positive evaluation for Josh Brake's contribution."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:55-07:56",
        "transcript": "Uh Luke?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:55",
        "end_time": "07:56",
        "annotations": {
            "encourage participation": "The speaker is explicitly inviting Luke to contribute to the discussion."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "07:57-08:55",
        "transcript": "Um, hi, I'm Luke Mortenson. I'm assistant professor at the University of Georgia. Um, although I will be associate as of July 1st, so I'm kind of in the intermediate space of still feeling new. Um, but um, uh uh my lab is primarily focused on uh multiphoton imaging. Um, so we do um like two photon, we're moving towards like second harmonic, third harmonic generation type stuff. Um, and we're looking at moving to kind of like near IR wavelengths to get um, I guess with 1300, 1700 to kind of like peer deeper into tissue and also some scattering correction approaches um to look at um as how much we can get in there and try to get rid of things that are causing negative interference, etc. And um um I guess our application is looking at bone and muscle regeneration primarily.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:57",
        "end_time": "08:55",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own qualifications and background.",
            "develop idea": "The speaker elaborates on his lab's research focus and techniques."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:55-08:56",
        "transcript": "Thank you. Matt.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:55",
        "end_time": "08:56",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing another group member's input with a 'Thank you'.",
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "09:06-09:54",
        "transcript": "Hi. Uh I'm Matt Lou. Um I'm an assistant professor in electrical and systems engineering at Washu. Uh my group works on um building single molecule imaging techniques for just understanding um chemical and biochemical dynamics in at the nano scale. Uh one of the things that that we really pushed recently is basically leveraging uh signals that are other than just brightness to to understand what's happening at the nano scale. So for us, uh a lot of it is uh fluorescence polarization.",
        "speaking duration": 48,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:06",
        "end_time": "09:54",
        "annotations": {
            "signal expertise": "The speaker explicitly states their position as an assistant professor, their department, and their group's work, indicating their expertise."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "00:00-00:47",
        "transcript": "I'm Stefan, I'm from the University of Oklahoma. I'm in biomedical engineering. Um, I'm trained as a chemist. Uh, now I'm in my fourth year as a system professor and my research group focuses on nanomedicine, so applying nanotechnology for treatment and diagnosis of cancer specifically and we are interested in understanding um the transport of drug carriers and small molecule drugs through the body and how those drug carriers interact with cell surface. So for us super resolution information is is really the key to understand those transport pathways. Um, and my lab is applying techniques such as expansion microscopy to get a better understanding of those intracellular transport pathways.",
        "speaking duration": 47,
        "nods_others": 10,
        "smile_self": 10,
        "smile_other": 20,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "10:00",
        "end_time": "10:47",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise, including his background in biomedical engineering, training as a chemist, and his research group's focus on nanomedicine.",
            "develop idea": "The speaker elaborates on his research group's work in nanomedicine and their interest in super resolution information for understanding transport pathways."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:47-00:52",
        "transcript": "Great, thank you. Um, Uzay, can you tell me how to pronounce your name correctly, please?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "10:47",
        "end_time": "10:52",
        "annotations": {
            "ask question": "Kristen Maitland is asking Uzay for information on how to pronounce his name, which is a direct question."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:52-00:53",
        "transcript": "Uzay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "10:52",
        "end_time": "10:53",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:53-00:54",
        "transcript": "Uzay, thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "10:53",
        "end_time": "10:54",
        "annotations": {
            "acknowledge contribution": "Kristen Maitland verbally recognizes Uzay's input by thanking him."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:54-02:12",
        "transcript": "Thank you so much. So, um, I'm Uzay and I'm from Purdue University and I'm at the School of Health Sciences as a biomedical engineering. I'm electrical engineer in principle, but I have been doing biomedical stuff since I graduated and that includes all developing new techniques for diagnostic purpose of MRI and the reason I'm interested in super resolution is always try to find the link between the lab resolution to to in vivo or contact animal resolution so microscopic scale. So I always keep an eye on what's happening in the smaller scale higher super resolution and to see what can be translatable to animal. So my research is ranging from cancer to neurological imaging and lipidomics to metabolomics and also cancer and also includes physiological intervention and also bone sodium content and X nuclei and phosphorus all types of imaging but I really like to make the link between the lab to do from bench to bedside actually.",
        "speaking duration": 78,
        "nods_others": 1,
        "smile_self": 30,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "10:54",
        "end_time": "12:12",
        "annotations": {
            "signal expertise": "The speaker explicitly states his educational background and research experience.",
            "acknowledge contribution": "The speaker starts with 'Thank you so much,' which can be seen as acknowledging the context or previous discussion."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:12-02:13",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "12:12",
        "end_time": "12:13",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:13-02:23",
        "transcript": "Vivian?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "12:13",
        "end_time": "12:23",
        "annotations": {
            "encourage participation": "The speaker is inviting Vivian to contribute, indicating a desire for her participation in the discussion."
        }
    },
    {
        "speaker": "Vivian Qian Lu",
        "timestamp": "02:23-03:11",
        "transcript": "Hello, uh, I'm Vivian Lou. I'm from McGill University. Uh, I'm at the the Institute of parasitology and also McGill Center for viral diseases. I'm trained as a molecular virologist and molecular cell biologist as a PhD student and then in my postdoc, I uh, I joined a biophysical lab where I learned how to do uh single molecule localization microscopy and I study uh virus life cycle using uh super resolution microscope. So I looked at how the virus are entered uh replicated and egress from their host cell.",
        "speaking duration": 48,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "12:23",
        "end_time": "13:11",
        "annotations": {
            "signal expertise": "The speaker explicitly states her own expertise and qualifications related to the task, mentioning her background in molecular virology and molecular cell biology, and her experience with single molecule localization microscopy and super resolution microscopy."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:11-03:19",
        "transcript": "Great, thank you. And Candace is in our room but she um is on another zoom, so when she gets back in we can um have her introduce herself. So thank you for that um kind of brief introduction that really helps put things in context for us.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "13:11",
        "end_time": "13:19",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing the group members' input (their introductions) but not agreeing or expanding.",
            "supportive response": "The speaker is expressing agreement and validation for the group members' contributions (introductions) without adding new content.",
            "encourage participation": "The speaker is inviting someone else in the group to contribute their expertise or ideas when they become available."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:19-03:33",
        "transcript": "And maybe if we could just pick up where we left off with the discussion. Josh, did you want to build off of um what you were saying in about using away from uh go ahead.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "13:19",
        "end_time": "13:33",
        "annotations": {
            "encourage participation": "The speaker is inviting Josh to contribute to the discussion, encouraging his participation.",
            "process management": "The speaker is managing the discussion flow by suggesting they pick up where they left off."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:39-05:00",
        "transcript": "Sure, sure. So I think that um I just see a a game of diminishing returns if we're just trying to get better at gating things out. Um, and so especially now we push to multiphoton two, three, I don't know, can we do four or five? Like at what level does that get so complicated and so expensive that it's not really it's not really useful. And so I I would really like to I think my background is is in more of the second thinking more about the second part of this question, but I think what intrigues me about this room is thinking about the two of these together, especially because super resolution microscopy I think is often speaking as somebody who's not well trained in that area, but seems to me to be very photon start in general. Like you need a lot of light.",
        "speaking duration": 81,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "13:39",
        "end_time": "15:00",
        "annotations": {
            "develop idea": "Josh is expanding on existing ideas, providing his perspective and thoughts on the matter.",
            "ask question": "Josh asks a question about the practicality of pushing to higher multiphoton levels.",
            "critical response": "Josh questions the feasibility of certain approaches, providing a critical perspective."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "05:00-05:57",
        "transcript": "Um, and so if you're saying, okay, well, I'm going to throw out all the scattered photons, you're walking a you know, that line is going to get hard to walk pretty quickly. So I I think that I really like the thinking about how how can we maybe take these two together and I'm not I haven't seen too much looking at super resolution combined with thinking deeper into tissue and how to think about scattering. And the last thing I'll say just to uh is I also wonder what the room is for conversations in between let's say minimally invasive types of technology as a stepping stone to getting to the ultimate goal where we just shine some light outside the body and then capture everything outside the body non invasively, but maybe minimally invasive with um, you know, fibers, fiber bundles, uh, these kind of things can be a a nice stepping stone to push things into the into practice because I think with biomedical imaging outside of the like really big success of OCT, there's not so many optical like biomedical optical techniques that have really made a significant um, you know, push into the clinic.",
        "speaking duration": 57,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "15:00",
        "end_time": "15:57",
        "annotations": {
            "develop idea": "Josh is expanding on previous ideas about handling scattered photons and combining super resolution with deeper tissue imaging.",
            "propose new idea": "Josh suggests exploring minimally invasive technologies as a stepping stone for non-invasive imaging.",
            "ask question": "Josh is seeking discussion on topics related to minimally invasive technologies and their potential as a stepping stone."
        }
    },
    {
        "speaker": "Vivian Qian Lu",
        "timestamp": "05:57-09:17",
        "transcript": "Uh, I I want to add something uh to to uh idea. So she was mentioned about using uh how to uh how to manipulate the scattering interference. So there is something um I was thinking about. Uh, I was doing uh uh super resolution when I was doing super resolution microscope, I always wanted to stabilize the sample so that with a with a long uh long-term imaging for example like 30 minutes, I don't get a great uh sample drift. So one way I was thinking while I was a postdoc is to use the scattering light from the cell. So we take uh we take the scattering light the image using scattering light of the cell at at the beginning of the imaging and after a few minutes we take another one. So by the end like by the end of the imaging we could use those image to align um kind of put to the kind of uh correct the drift. So that's one thing I was thinking about. Uh, but I haven't tapped it. I'm not sure how precisely I can do as my uh uh I claim a 10 nanometer uh uh uh precision. So I'm trying to make sure how I can how precisely I can do that. And uh some thoughts for the first uh question like how can super resolution uh methods can be translated to uh uh organismal applications. Um, I have been thinking about that for the past few years. Um, one thing I found uh uh that could be helpful is maybe lizing the floor for chemistry because right now uh I spend a lot of time on doing uh imaging analysis uh like look at all the localization and how to cluster them and how to figure out the organization of the proteins. But uh at the end of the day I thought if we could use different floor for to map these what I mean is if I put it in a example, see if we have a DNA molecule, they can uh kind of fold into different structure. Like if we wanted to figure out the structure, let's see uh we can use uh maybe the barcoding system like we can since we know the sequence we probably can uh use the barcoding to map the entire sequence, then then we label that the molecule uh ourselves, then we can image that maybe we know we would figure out like uh how they position the spatial. So that's So I think um maybe uh aside from the imaging processing just using AI or deep learning to look at the cluster or organization, maybe uh uh floor for can might be helpful. That was my thought.",
        "speaking duration": 204,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "15:57",
        "end_time": "19:17",
        "annotations": {
            "propose new idea": "Vivian suggests using scattering light from the cell to correct for sample drift and proposes using barcoding to map molecular structures.",
            "develop idea": "Vivian elaborates on her previous thoughts about using scattering light and discusses the potential of barcoding for mapping molecular structures.",
            "signal expertise": "Vivian shares her experience with super resolution microscopy and stabilizing samples during imaging."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "09:18-09:57",
        "transcript": "So I would say that this this this question is well beyond what I think about normally. Um, because we're trying to get to structural resolution and if you do that in an animal, it would be too much data. We don't have big enough computers for that. And so this is a very interesting, you know, concept because when we want to look at an animal, we just cut off a piece of our zebra fish and take that tissue and we call that an animal or an organism.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
        "start_time": "19:18",
        "end_time": "19:57",
        "annotations": {
            "identify gap": "Dylan Burnette explicitly mentions a limitation related to computational power for handling large data from animal models.",
            "critical response": "He provides a negative evaluation of the feasibility of achieving structural resolution in animal models due to computational limitations."
        }
    },
    {
        "speaker": "Dylan Burnette, Vanderbilt University",
        "timestamp": "00:00-00:32",
        "transcript": "illumination or single molecule imaging on top of that. And I'm calculating resolution and it's scaring me already and it's a single cell. So do we have any idea what we do with that kind of data if we have super res and like I'm I'm I'm just it's exciting but also scary at the same time.",
        "speaking duration": 32,
        "nods_others": 1,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:32",
        "annotations": {
            "identify gap": "The speaker recognizes a gap in their ability to handle large amounts of data from super-resolution imaging.",
            "critical response": "The speaker expresses concern about the feasibility of working with super-resolution data.",
            "ask question": "The speaker directly asks the group for ideas on how to handle super-resolution data."
        }
    },
    {
        "speaker": "Uzay Emir, Purdue University",
        "timestamp": "00:32-01:25",
        "transcript": "Can I uh so similar to your question actually your question is originating from a problem actually going back to whole animal or big organism will be ring a lot of data. Now the question is how from my point of view I'm a microscopic person and even our data is big but uh it's not as complicated as yours uh but it has its own difficulties. How you are seeing all you guys are optical imaging and super resolution compared to myself to make it really translatable to real life or big animal or live animal uh thing. So what is your pathway to bring those techniques to this and considering your concern about the size of the data.",
        "speaking duration": 53,
        "nods_others": 1,
        "smile_self": 30,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:32",
        "end_time": "21:25",
        "annotations": {
            "ask question": "The speaker is requesting information on how to translate techniques from microscopic to larger systems.",
            "identify gap": "The speaker identifies a gap in his understanding or approach regarding data size and complexity when moving from microscopic to larger systems."
        }
    },
    {
        "speaker": "Dylan Burnette, Vanderbilt University",
        "timestamp": "01:26-02:35",
        "transcript": "So is it possible to to combine structured light and of scattering at the same time? Is that too complicated? Sorry, I'm not I'm not a physicist, but we are using structured light uh through the line of slide sheet and and and it's the same, you know, basic run of the mill technologies. Um but can you collect scattered light from that sort of information? Because that's already up and running of in many, many labs around the country and world right now. Uh would be able to combine something like the lighter slide sheet which penetrates into tissues pretty decently, let's not say great, but decently. But now it's good as four photo time would. But um um but we uh but that also has already structured information with it. Does that complicate getting scattered light or not? Because that's kind of a fascinating idea uh that I hadn't really thought too much about. And at least three of you had thought a lot about it. So that's pretty cool.",
        "speaking duration": 69,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:26",
        "end_time": "22:35",
        "annotations": {
            "ask question": "The speaker is requesting information about combining structured light and scattering.",
            "develop idea": "The speaker is expanding on his idea by providing context and asking for its implications."
        }
    },
    {
        "speaker": "Josh Brake, Harvey Mudd College",
        "timestamp": "02:36-03:03",
        "transcript": "I guess my two cents on this is by de facto as optical engineers, we try to throw out the scattered light. That's the conventional wisdom. We always have done that. And so every optical system you pick up whether it's your iPhone or a microscope is designed to throw that information out. And that's the that I think is the kernel of the revolutionary idea here is like let's remove that constraint and go back to the drawing board and think differently.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:36",
        "end_time": "23:03",
        "annotations": {
            "propose new idea": "The speaker suggests a new perspective on optical engineering by proposing to utilize scattered light that is conventionally discarded.",
            "develop idea": "The speaker elaborates on the conventional wisdom in optical engineering and then develops the idea of changing this approach to harness scattered light."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "03:03-04:24",
        "transcript": "Yeah, Josh, I I'd like to to build off of that. So I think you did made a great point about the uh the the sort of the paradigm of of at least microscopy uh and ballistic imaging that we throw away all the scattered light. Then we're kind of forgetting our friends in the diffuse optics regime. So let's think of DOT diffuse optical tomography and people sort of um uh there's there's actually a colleague here at Washu who builds the whole brain uh uh imaging uh device, right? And and looks at uh sort of function uh um by collecting diffuse light off of there. So maybe um maybe a a regime of pushing the resolution there might be helpful. Uh right now it's sort of spatially resolved based upon the average number of scattering events that takes light longer to travel further or or uh uh and and you can sort of resolve some things in depth that way. So maybe that's one way we can think about it. I think maybe another question is um like if we take our existing technologies that can penetrate deep but somehow are deficient in some other axis. So let's just say pet for example, right? The gold standard in in specifically detecting something uh uh within within the body and an organism. Uh is there something that optical imaging if engineered the right way, maybe with the the fancy uh fluorescent based reporters that we saw uh earlier in the keynote. Um maybe there's something that we can do to to to solve a more targeted problem as a as a as a prototype for for for uh for solving the the bigger question that that was posed. Um just a couple ideas there.",
        "speaking duration": 81,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:03",
        "end_time": "24:24",
        "annotations": {
            "develop idea": "Matt Lew is expanding on previous ideas by suggesting alternative approaches and technologies, such as diffuse optical tomography, to overcome current limitations in super resolution microscopy.",
            "propose new idea": "Matt Lew introduces new ideas by suggesting the use of diffuse optical tomography and combining optical imaging with fluorescent-based reporters to address challenges in super resolution microscopy.",
            "ask question": "Matt Lew asks if there's potential for optical imaging, with the right engineering and reporters, to solve targeted problems, indicating a quest for further information or exploration."
        }
    },
    {
        "speaker": "Aseema Mohseny, Tufts U. (she/her)",
        "timestamp": "04:24-04:45",
        "transcript": "I'd like to I'd like to kind of jump on that as well. Um I I feel like one thing that I I and this might just be my inexperience with the super resolution field, but like um one thing we don't really talk about much is what and and similar to what Matt was talking about is um what could we kind of learn from, you know, we're kind of used to a a certain type of imaging with an objective with a very high NA, you know, lens and and I feel like that's kind of a bulk of the problem.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 80,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:24",
        "end_time": "24:45",
        "annotations": {
            "Develop idea": "Aseema is expanding on ideas previously discussed, specifically Matt's suggestion, by offering another perspective on the problem.",
            "Supportive response": "Aseema is expressing agreement or validation with the previous speakers' concerns.",
            "Offer feedback": "Aseema provides a suggestion for potentially exploring different approaches."
        }
    },
    {
        "speaker": "Dylan Burnette, Vanderbilt University",
        "timestamp": "04:45-04:45",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:45",
        "end_time": "24:45",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging another group member's input without adding new information.",
            "supportive response": "The utterance expresses agreement or positive evaluation for other group members' contributions."
        }
    },
    {
        "speaker": "Aseema Mohseny, Tufts U. (she/her)",
        "timestamp": "04:45-04:45",
        "transcript": "Yeah, okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:45",
        "end_time": "24:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Dylan Burnette, Vanderbilt University",
        "timestamp": "04:45-06:03",
        "transcript": "So I would say that from because I'm the I'm I'm the uh I'm the holer here not the forger. I don't uh I don't uh I I developed one technique and no one ever used it. So it was called bomb because back in the day anything with single molecules had to have a acronym. Uh and I learned through that that I should not develop techniques. I should just take other people's and Um but I'll say as a as a user and we're pretty advanced users uh that we are pretty much addicted to the high NA lens because it's what's available. It's what's commercially available, it's what we can order. We're not going to build our own lenses. And that is why we use them. There's no one has come up with a better way that I can purchase to do this and it's very limiting because the high NA is usually uh uh for the most of our of our work for super res which is single molecule or structured light. Um and I generally put those in just two categories. I know that some of you are have four categories of super res. Um but when you think about it from that way, it's very limiting as far as Z depth, so how far you can go, so your axial dimension that you can penetrate your sample is limited.",
        "speaking duration": 78,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:45",
        "end_time": "26:03",
        "annotations": {
            "identify gap": "Dylan points out that high NA lenses are limiting in terms of Z-depth penetration, indicating a gap in current technology.",
            "supportive response": "Dylan shares his experience and reasons for using high NA lenses, contributing to a supportive discussion about challenges and limitations.",
            "critical response": "Dylan discusses the limitations of high NA lenses, providing a critical perspective on current methodologies in super-resolution microscopy."
        }
    },
    {
        "speaker": "Aseema Mohseny, Tufts U. (she/her)",
        "timestamp": "06:03-06:03",
        "transcript": "Right.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:03",
        "end_time": "26:03",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous statement."
        }
    },
    {
        "speaker": "Dylan Burnette, Vanderbilt University",
        "timestamp": "06:03-06:03",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:03",
        "end_time": "26:03",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement or acknowledgment with a previous statement, which is a supportive response."
        }
    },
    {
        "speaker": "Aseema Mohseny, Tufts U. (she/her)",
        "timestamp": "06:03-06:03",
        "transcript": "So it's.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:03",
        "end_time": "26:03",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Aseema Mohseny, Tufts U. (she/her)",
        "timestamp": "06:03-07:33",
        "transcript": "I mean, yeah, no, I'm I'm I'm just I'm coming from a different kind of world of of, you know, you know, we everything we do is like little chips and so that you could do like fine resolution here and fine resolution here, you know, what are kind of the limitations um from people who are actually using super resolution um with those objective lenses that that you guys use. Um in terms of I guess field of view and like the amount of power that you need to be able to illuminate an entire section.",
        "speaking duration": 90,
        "nods_others": 0,
        "smile_self": 70,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:03",
        "end_time": "27:33",
        "annotations": {
            "ask question": "The speaker is requesting information about the limitations of super resolution techniques, specifically concerning field of view and illumination power.",
            "develop idea": "The speaker is also expanding on their perspective and relating it to their own experience with 'little chips'."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "00:00-00:14",
        "transcript": "you know, light coming out here and creating patterns and but we don't have the I mean, it's it's crazy for me to think about being able to combine that with a microscope, but you know, I think there must be ways.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 86,
        "smile_other": 14,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:14",
        "annotations": {
            "develop idea": "Aseema is exploring the possibility of combining light pattern creation with microscopy, developing on existing ideas.",
            "identify gap": "Aseema implicitly identifies a gap in current capabilities by stating 'we don't have' certain technologies or ways to combine them."
        }
    },
    {
        "speaker": "Andrew Feig",
        "timestamp": "00:15-00:18",
        "transcript": "Dylan, your task is to have the right quarter cell at the right time.",
        "speaking duration": 3,
        "nods_others": 1,
        "smile_self": 0,
        "smile_other": 33,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:15",
        "end_time": "30:18",
        "annotations": {
            "assign task": "The speaker assigns a specific task to Dylan, which is to have the right quarter cell at the right time."
        }
    },
    {
        "speaker": "Andrew Feig",
        "timestamp": "00:18-00:20",
        "transcript": "to capture what it is you want to see.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:18",
        "end_time": "30:20",
        "annotations": {
            "clarify goal": "The speaker is commenting on the goal or objective of capturing what one wants to see, which relates to defining or clarifying the purpose or objectives of their work."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "00:21-00:49",
        "transcript": "Yes, and and and and and and and now with expansion microscopy we were having to do uh what we now refer to as structured illumination as low back imaging. Um, and we had to we do that live, fix that cell and then expand it, find the cell again and then image what is getting down to, you know, we're estimating five to 10 nanometer resolution lateral. So we're really good, but this is all people give me. I I I I I'm I'm I'm I'm I'm wanting for the uh next thing. So that's I I I I think I'm here because I am the user of the next thing, not the inventor of the next thing. So I'm getting excited but I'm also kind of confused at the same time.",
        "speaking duration": 28,
        "nods_others": 1,
        "smile_self": 50,
        "smile_other": 21,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:21",
        "end_time": "30:49",
        "annotations": {
            "develop idea": "Dylan is explaining and building upon existing ideas related to expansion microscopy and structured illumination.",
            "identify gap": "Dylan mentions the current state of their work and implies a need for more advanced technology, indicating a gap in their capabilities."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:01-01:04",
        "transcript": "Yeah, I guess one of the fundamental limitations, at least with fluorescence.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:01",
        "end_time": "31:04",
        "annotations": {
            "critical response": "The speaker acknowledges a limitation of fluorescence, which can be seen as a mild critique of its capabilities."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:08-01:09",
        "transcript": "just a standard dipole radiation pattern.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:08",
        "end_time": "31:09",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:10-01:24",
        "transcript": "So what that will mean is that then the light just goes everywhere. I mean, of course it's zero along the dipole axis, but that's a sine squared kind of fall off. So what that means is you just need a huge collection angle to efficiently collect if you want to do single molecule at least.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:10",
        "end_time": "31:24",
        "annotations": {
            "develop idea": "The speaker is expanding on an idea by explaining the implications of the dipole radiation pattern for single molecule imaging, discussing the need for a huge collection angle to efficiently collect light."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:24-01:28",
        "transcript": "Uh, because you're just not going to get enough photons to even detect the thing uh without it.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 25,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:24",
        "end_time": "31:28",
        "annotations": {
            "identify gap": "The speaker is pointing out a limitation or challenge in super resolution microscopy, which is not having enough photons to detect something."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:29-01:34",
        "transcript": "Um, in terms of decoupling excitation and emission, there's a lot of interesting light sheet stuff.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:29",
        "end_time": "31:34",
        "annotations": {
            "propose new idea": "The utterance introduces a new idea or perspective by mentioning decoupling excitation and emission and referencing light sheet stuff."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:34-01:41",
        "transcript": "It turns out that that's now a mechanical engineering problem because you if you want high NA and two high NA objectives next to each other, it's it's impossible.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:34",
        "end_time": "31:41",
        "annotations": {
            "identify gap": "The speaker explains a limitation in using high NA objectives, highlighting a challenge in experimental design.",
            "process management": "The speaker discusses a practical limitation related to the management of experimental tools and design."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:41-01:50",
        "transcript": "So, um, one of the most cool things that's coming out of uh Calico labs, which is an independent sort of foundation funded thing is is Andrew York's work on remote focusing.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:41",
        "end_time": "31:50",
        "annotations": {
            "supportive response": "The speaker is providing information about relevant work in the field, which can be seen as supportive to the conversation."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:51-02:13",
        "transcript": "And uh basically doing some interesting optical tricks to get a light sheet scanning in there along with high NA detection and that I think is probably where the sort of classic uh uh innovation like frontier is right now in terms of high resolution and organism and fast. Like that um I've been impressed by that recently.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 14,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:51",
        "end_time": "32:13",
        "annotations": {
            "develop idea": "The speaker is elaborating on existing ideas related to optical tricks for light sheet scanning and high NA detection.",
            "supportive response": "The speaker is expressing a positive view on certain approaches, indicating a supportive stance towards the ideas being discussed."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "02:15-02:47",
        "transcript": "Is is there tolerance in the community um for having something that let's say you have a objective lens and then you have something next to it, but it's very tiny, let's say it's, you know, 50 microns thin.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:15",
        "end_time": "32:47",
        "annotations": {
            "ask question": "The speaker is requesting information about the community's acceptance or tolerance for a particular setup, which involves a question about the feasibility of having a tiny component next to an objective lens."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "02:47-02:51",
        "transcript": "Is there tolerance in the community for having something that's some semi, you know, invasive to be able to kind of get some of these light sheet techniques um more portable or, you know, useful for an organism.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:47",
        "end_time": "32:51",
        "annotations": {
            "ask question": "The speaker is explicitly asking for information about the community's tolerance for semi-invasive methods."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "02:52-03:05",
        "transcript": "Yeah, I mean, I think so. Um the at least, you know, if you think about like the head mounted microscopes and things, like building a cranial window in and then having some small thing next next to that's not a big deal.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:52",
        "end_time": "33:05",
        "annotations": {
            "supportive response": "The speaker provides an example and a perspective that supports the feasibility of certain semi-invasive techniques, aligning with the discussion.",
            "clarify goal": "The speaker discusses practical considerations and community tolerance for certain approaches, which helps in understanding the goals and challenges of implementing super resolution techniques."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "03:05-03:16",
        "transcript": "And then a lot of the sort of super stuff right now is still cover slip based, you know, epi fluorescence so you can easily put stuff down at least on on on that epi side.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:05",
        "end_time": "33:16",
        "annotations": {
            "develop idea": "The speaker is expanding on previous ideas by providing more details on current super resolution microscopy techniques, specifically mentioning their limitations and common practices.",
            "identify gap": "The speaker implicitly points out a limitation of current super resolution microscopy techniques, that they are often cover slip based and might not be easily adaptable to different applications."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:26-03:33",
        "transcript": "Okay, um, I have lots of ideas on things to talk about, but um, Stefan, how about you? What are what do you have to bring up?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 57,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:26",
        "end_time": "33:33",
        "annotations": {
            "encourage participation": "The speaker is inviting another group member to contribute their expertise, opinions, or ideas."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "03:33-04:14",
        "transcript": "Yeah, so this is an interesting discussion and uh basically I have similar concerns that Dylan mentioned earlier. Uh like with all uh the huge amount of data that you collect, but then actually how would we do this? How do we how will we get a super resolution image of entire mouse, for example, uh uh while the mouse is still alive. So, um this is a really important question and um my group and I we have thought a lot about this and how can we overcome this and how can we find a method that would allow us to to give us something reasonable and the best we came up with is, well, we probably cannot do live imaging.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "33:33",
        "end_time": "34:14",
        "annotations": {
            "identify gap": "The speaker recognizes the challenge of getting a super resolution image of an entire mouse while it is still alive.",
            "develop idea": "The speaker is expanding on the idea by discussing the challenges and potential limitations of achieving super resolution imaging in live animals."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "04:14-04:27",
        "transcript": "But what we could do is um uh use end points and then make tissues optically transparent, right? So removing all the the scattering.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "34:14",
        "end_time": "34:27",
        "annotations": {
            "propose new idea": "The speaker introduces a specific approach (using end points and making tissues optically transparent) to address the challenge of scattering in tissues.",
            "develop idea": "The speaker elaborates on the idea by explaining the process of removing scattering to improve imaging."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "04:27-04:31",
        "transcript": "Uh and then light can penetrate into the tissue.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "34:27",
        "end_time": "34:31",
        "annotations": {
            "develop idea": "The utterance develops the idea of using optical transparency to enhance imaging by specifying the goal of allowing light to penetrate into the tissue.",
            "clarify goal": "The utterance helps clarify the goal of making tissues transparent for better imaging."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "04:31-04:41",
        "transcript": "And the interesting thing that we found is that when we do this, we can now actually see um our nanoparticle carriers because they are still there and they scatter light efficiently.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "34:31",
        "end_time": "34:41",
        "annotations": {
            "develop idea": "The speaker is sharing specific research findings that build upon the idea of using optical transparency to improve imaging of nanoparticle carriers.",
            "offer feedback": "The speaker's findings offer a practical approach for others working on similar imaging challenges."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "04:41-05:06",
        "transcript": "And now since you remove everything else in the background that will interfere, now you get a pretty clear and crisp view of where your your carriers are. So this was pretty intriguing uh when when we saw this and um it allows you to have volumetric imaging. Um, but now of course you're losing super resolution, right?",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "34:41",
        "end_time": "35:06",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by explaining how removing background interference allows for clearer imaging.",
            "identify gap": "The speaker acknowledges a limitation of their approach, which is the loss of super resolution."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "05:06-05:11",
        "transcript": "So then you need to go and expand your samples to get super resolution.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "35:06",
        "end_time": "35:11",
        "annotations": {
            "develop idea": "The speaker suggests expanding samples as a method to achieve super resolution, building on previously discussed challenges and ideas."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "05:11-05:24",
        "transcript": "But then you're only looking at a tiny field of view. So these are all these challenges, but at least for our research, uh what we found is that if we use the right type of nano material that scatters light efficiently.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "35:11",
        "end_time": "35:24",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by discussing challenges and potential solutions.",
            "signal expertise": "The speaker demonstrates their expertise by discussing nano materials and their efficiency in scattering light.",
            "identify gap": "The speaker highlights a challenge in their research, which is the limitation of only being able to look at a tiny field of view."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "05:24-05:36",
        "transcript": "And then we work with uh tissue clearing method and expansion microscopy methods, um we can get somewhere at least um but it's not the the ideal state, but yeah, I would agree that scattering is a big problem.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "35:24",
        "end_time": "35:36",
        "annotations": {
            "Develop Idea": "Stefan is discussing and elaborating on specific methods (tissue clearing and expansion microscopy) and their limitations in achieving super resolution microscopy results.",
            "Supportive Response": "Stefan agrees with the concern about scattering, showing a supportive attitude towards acknowledging the problem."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "05:36-05:37",
        "transcript": "But scattering can also be.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "35:36",
        "end_time": "35:37",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "05:37-05:40",
        "transcript": "very informative depending how you utilize it.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "35:37",
        "end_time": "35:40",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea that scattering, while a problem, can also be informative depending on how it is utilized.",
            "supportive response": "The speaker's comment is supportive of the discussion, acknowledging the complexity and potential utility of scattering in super resolution microscopy."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "06:27-06:36",
        "transcript": "Can someone explain how one would detect the scattered light? How what kind of detectors will we need?",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:27",
        "end_time": "36:36",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on how to detect scattered light and what kind of detectors are needed, which is a direct question seeking expertise from others."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:36-06:41",
        "transcript": "I just a flat CMOS chip, I bet, right?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:36",
        "end_time": "36:41",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:41-06:43",
        "transcript": "So what kind of detectors are you imagining?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:41",
        "end_time": "36:43",
        "annotations": {
            "ask question": "The speaker is asking a question about the kind of detectors being imagined."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:48-07:02",
        "transcript": "Because I'm I'm a practical guy. I kind of want to imagine what you're going to where where where you're going to capture this with, right? Um is it is is there something that exists or you are you have to invent it?",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:48",
        "end_time": "37:02",
        "annotations": {
            "ask question": "The speaker is explicitly asking if there are detectors for scattered light and if they need to be invented.",
            "identify gap": "The speaker highlights a practical gap in detection technology for scattered light."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:05-07:06",
        "transcript": "So I can jump in if needed.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:05",
        "end_time": "37:06",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:06-07:27",
        "transcript": "Um, so if you think of um structured illumination and you're capturing that image with a camera and so with the structured illumination, you're illuminating certain areas, your light gets scattered, so you collect light from everywhere.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:06",
        "end_time": "37:27",
        "annotations": {
            "develop idea": "The speaker explains how structured illumination works in terms of imaging and light scattering.",
            "clarify goal": "The speaker aims to clarify the process of structured illumination in imaging."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:27-07:41",
        "transcript": "And then usually you do um there's an algorithm that automatically calculates where that light is coming from and it removes that scattering light. So you're already capturing the scattered light, it's just that you are removing it.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:27",
        "end_time": "37:41",
        "annotations": {
            "code name": "develop idea",
            "explanation": "The speaker is expanding on an existing idea by explaining how structured illumination works with scattered light."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:41-08:00",
        "transcript": "In confocal, you're using a pin hole to collect that um the light the ballistic photons that you are interested in and you're using that pin hole to block all those other scattered lights um you're it's coming from.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:41",
        "end_time": "38:00",
        "annotations": {
            "develop idea": "expanding on an existing idea by explaining how confocal microscopy works in terms of handling ballistic photons and scattered light."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:00-08:16",
        "transcript": "And so if you collect with a camera and you focus if you collect that light from where your pin hole would be, that would be your, you know, from your central focal area, but you could collect the scattered um multi photon light so that you can then collect more of that signal.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:00",
        "end_time": "38:16",
        "annotations": {
            "develop idea": "The speaker explains how collecting light with a camera and focusing on the central focal area allows for the collection of scattered multiphoton light to gather more signal."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:16-08:22",
        "transcript": "Um, so it just depends a little bit on your imaging strategy and and what the um orientation would be.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:16",
        "end_time": "38:22",
        "annotations": {
            "Develop idea": "The speaker is expanding on a previous idea about imaging strategies and how they relate to detecting scattered light and orientation."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:22-08:30",
        "transcript": "Yeah, yeah, we try to deconvolve out almost all the what we refer to it as out of focus light in not scattered light, but um.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:22",
        "end_time": "38:30",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and sharing a relevant experience related to dealing with light issues in imaging, supporting the line of thought on handling scattered light.",
            "develop idea": "The speaker is elaborating on how they address the issue of out of focus or scattered light in their work, providing insight into their methodology."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:30-08:33",
        "transcript": "So I'm still kind of confused. How is that going to work?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:30",
        "end_time": "38:33",
        "annotations": {
            "ask question": "The speaker is requesting clarification on how a previously discussed approach is going to work."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:39-08:42",
        "transcript": "on on on on an engine. This is kind of why we're here, right?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:39",
        "end_time": "38:42",
        "annotations": {
            "summarize conversation": "The speaker is summarizing that the current topic is the reason for their meeting."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:42-08:49",
        "transcript": "I I I I don't understand how that is going to be a thing that can be developed.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:42",
        "end_time": "38:49",
        "annotations": {
            "critical response": "The speaker expresses doubt about the feasibility of an idea, questioning how it can be developed."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:49-08:56",
        "transcript": "Because if if it was just as simple as I have a CMOS camera and I have very images, I can make them sharp, we would have probably already done that, right?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:49",
        "end_time": "38:56",
        "annotations": {
            "critical response": "The speaker is questioning the feasibility of an approach, implying that it's not as simple as others might think."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:56-09:03",
        "transcript": "Um and and we do our best that we can by by reassigning uh the out of focus photons into the plane that we're supposed to be.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:56",
        "end_time": "39:03",
        "annotations": {
            "develop idea": "The speaker is explaining and elaborating on the idea of reassigning out-of-focus photons into the correct plane during an imaging process."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "09:03-09:06",
        "transcript": "There's algorithms for that. So we're talking about.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:03",
        "end_time": "39:06",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:00-00:35",
        "transcript": "through your filters, that might be one aspect. Um, so I think um it it would take a big picture look at what are you trying to do, what are is your imaging system or your microscope that you're trying to use and um how is scattering affecting your ability to image what you're trying to see or image at a depth, you know, that maybe you can't reach. Um, and then taking into into consideration your sample that the light is traveling through and how does that influence or impact your ability to image whether it be resolution or depth or field of view.",
        "speaking duration": 35,
        "nods_others": 1,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:35",
        "annotations": {
            "develop idea": "Elaborating on how to approach the problem of scattering in imaging by considering the imaging system and sample.",
            "offer feedback": "Providing feedback on how to approach the problem of scattering.",
            "supportive response": "Encouraging a comprehensive approach, which is supportive."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "00:35-02:05",
        "transcript": "Yeah, maybe to to jump off that and and bridge back to what uh what Sian was talking about at the beginning. Like if we're in the fluorescence and uh some of the light from your floor for gets multiply scattered, there's kind of two ways that we might think of detecting it. One is just waiting long enough because those multiply scattered photons will take longer to get to you. So you you kind of wait long enough and see where they landed and maybe those were your scattered photons. The other thing that I think Josh is really better expert at is um if you change your imaging instrument in some way because that light was determinate that scattering was deterministic, like the cell boundaries that the light scattered off of were at certain some place relative to your imaging system. If you change the instrument a little bit to better leverage those scattering patterns and get more light out now and get more light in, then you have a signature for for for fixing your image in the bit. So the the the the imaging problem becomes harder now because it's no longer uh uh optically engineered perfect objective that does your job for you. Now you've got to reoptimize the imaging system on the fly for your specific sample and then you got to make sure that whatever you thought the scattering was from wherever it was from and whenever it was from like that's actually what you're detecting because it in principle at least with elastically scattered light, there's no way to identify it any other way. Like the photon energy is going to be the same, right? And uh and so yeah.",
        "speaking duration": 90,
        "nods_others": 2,
        "smile_self": 15,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:35",
        "end_time": "42:05",
        "annotations": {
            "develop idea": "Matt Lew is expanding on an idea by discussing methods to detect multiply scattered photons.",
            "offer feedback": "Matt Lew provides an alternative approach to handling scattered photons, which can be seen as offering feedback on the discussion.",
            "ask question": "While primarily developing an idea, Matt Lew's discussion could be seen as framing a question for further consideration."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "02:05-03:40",
        "transcript": "There's also some interesting things with scattering connecting back to our conversation about numerical aperture, which counter, you know, counterintuitively scattering can actually help you because at the fundamental level, high NA is about high spatial frequencies is about high angle illumination and so scattering has a way of creating this for you because of the, you know, in strongly scattering tissue after you, you know, scatter enough, you're at lambda over two. Um, so that I think is something else too that you make your you make your your enemy your friend in some sense by, you know, taking advantage of what's happening there and then maybe you maybe you decouple from the traditional connection with lenses between field of view and working depth and NA and the geometrical piece of lens design, there's only so many parameters you have to to tweak, but if you can think about your lens as a and I think Sian will be, you know, with Laura, she always talks about like your lens is a Laura Waller, your lens is a matrix basically, which I love that like picture thinking about um, you know, and in the wavefront shaping community, we think of like replacing a lens with a cube of salt or something like, you know, cube of sugar or something and just sending light through it and if you know what the you know, the matrix is, mathematically there may be some interesting properties there that you can leverage that may actually help you and not hurt you.",
        "speaking duration": 95,
        "nods_others": 1,
        "smile_self": 20,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:05",
        "end_time": "43:40",
        "annotations": {
            "develop idea": "Josh Brake is expanding on previous discussions about scattering and numerical aperture, suggesting new perspectives on how scattering can be beneficial.",
            "propose new idea": "He suggests novel approaches to leveraging scattering and redesigning lens systems, such as thinking of a lens as a matrix or using a cube of salt/sugar."
        }
    },
    {
        "speaker": "Sian You",
        "timestamp": "03:40-04:00",
        "transcript": "That's a great point. Um, I was also doing post in Laura Waller's lab and uh I really like her perspective that uh lens is just a phase mask, right? So whatever whatever point spread function you want in the end, you can somehow engineer the lens you want.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:40",
        "end_time": "44:00",
        "annotations": {
            "develop idea": "The speaker is elaborating on existing ideas about lens engineering and optical phase masks, sharing a related perspective from Laura Waller's work.",
            "signal expertise": "The speaker is indicating their connection to Laura Waller's lab and their familiarity with her perspective on lenses as phase masks."
        }
    },
    {
        "speaker": "Sian You",
        "timestamp": "04:00-05:31",
        "transcript": "And uh back to Dylan's question, that's actually really um uh I think it's also a very good point to start framing off. Um, so to solve the problem, I think we can start from two. Uh one is detection, how can you reassign photons based on different properties, based on different characteristics of photons you capture and then how can you reassign it. And then second way is uh second way, how can you form the beam for for example, for light sheet microscopy, it's very hard to get a nice light sheet after scattering. So how can you use wavefront engineering or scattering compensation to get a nice illumination in the beginning. So you don't worry that much about detection later. Um, my question is um like what is the fundamental limit in either direction. So if we try all these methods and we push our depths like 10% more, is it worth it? Uh, and this applies for both um detection and illumination. Detection, you have photo photon starvation, you have noise issue and for illumination, um no matter how much you compensate, at some point you lose the correlation between photons and you lost uh at one point it's just random walk. So how much more can we push and what is the fundamental challenge in the in the field right now.",
        "speaking duration": 91,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:00",
        "end_time": "45:31",
        "annotations": {
            "propose new idea": "The speaker introduces two new directions to explore the problem: detection and illumination.",
            "ask question": "The speaker asks about the fundamental limits and challenges in detection and illumination approaches."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:31-05:36",
        "transcript": "And Luke, can we hear from you as well?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:31",
        "end_time": "45:36",
        "annotations": {
            "encourage participation": "invites someone else in the group to contribute their expertise, opinions or ideas"
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "05:36-06:15",
        "transcript": "Um, yeah, sure. So I I think I mean, I think that one of the challenges that I see is is like how much deeper can you go? How much further can you go is a major problem. But I think a a bigger problem that we've noticed is how long does it take you to get there? You know, because you can do a decent job of understanding what's happening to the light and like recreating a focus and then detecting whatever signal you get out.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:36",
        "end_time": "46:15",
        "annotations": {
            "identify gap": "The speaker highlights challenges or gaps in current imaging methods, specifically regarding depth and time required.",
            "ask question": "The speaker poses questions about the limitations of current techniques, specifically how much deeper one can go and the time it takes to achieve imaging goals."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "06:15-07:35",
        "transcript": "But you're really going to have to detect for a really long time to get enough photons out and overcome your SNR problems or it's going to take you quite a while to do the correction factor and even you know, current best in class it's pretty, you know, for a whole organism or, you know, whether it's like the whole organism or just a whole organism, in both cases you're looking at problems with, you know, signal and movement and time. And um, you know, those those seem like like major issues that in order to get it from the point of where it requires full um deconstruction of the organism, you know, which is definitely and a useful and insightful approach back to something that's maybe hopefully happening in a dynamic setting, we can understand like how things are are altering with time. Um, you know, sort of like our keynote talk is. I think, you know, trying to bridge those two two spectrum I think is sort of as a as a challenge.",
        "speaking duration": 80,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:15",
        "end_time": "47:35",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes limitations in current imaging techniques, such as the need for longer detection times and challenges with signal, movement, and time.",
            "critical response": "The speaker implies criticism of current methods by highlighting their significant limitations.",
            "offer feedback": "The speaker suggests a direction for improvement by bridging the gap between static and dynamic imaging.",
            "develop idea": "The speaker expands on the discussion by emphasizing the importance of considering time and dynamic settings in imaging."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:36-08:33",
        "transcript": "But if you're trying to detect things in multiple dimensions such as you say time, if things are going to take longer to get there, is it possible that you could just use multiple detectors? Because when we when we go and put two cameras on our system, we want them to be par focal basically. We want to them to be in the exact same focal plane. But can you alternate the detectors to detect um things that take longer to get there, just move the camera closer. I mean can I don't know if if with one detector we're going to be able to get to this thing and you and you guys are the physics people, but I can't imagine this is going to be solved with one camera. It's just going to take too darn long to image an organism.",
        "speaking duration": 57,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:36",
        "end_time": "48:33",
        "annotations": {
            "ask question": "The speaker is asking a question about using multiple detectors to detect things in multiple dimensions.",
            "develop idea": "The speaker is discussing and potentially expanding on an idea related to detecting things in multiple dimensions.",
            "encourage participation": "The speaker is engaging in a discussion and asking for opinions or insights from others."
        }
    },
    {
        "speaker": "Sian You",
        "timestamp": "08:33-09:31",
        "transcript": "You're definitely not crazy. There is definitely a lot of multi view uh microscopes for all kinds of modalities over there. Uh actually people do it. I I think there are like uh several ways to come about it. One is kind of multi view, so you scan uh different regions at the same time and somehow they end up in different pathways and you can use different cameras to detect it. And for scattering problems or for aberration problems, uh you have this pupil plane where you can also simultaneously uh kind of correct uh different aberrations and scattering for different regions. So there are ways to deal with it, but uh then if you do that, then you are at the danger of even being more photon starved. Um, so it's always a tradeoff. The more multiplex, the the the less photons you have. So.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:33",
        "end_time": "49:31",
        "annotations": {
            "develop idea": "Sian is expanding on previous ideas about dealing with scattering and aberration problems by suggesting the use of multi-view microscopes and pupil planes for correction.",
            "offer feedback": "Sian is providing specific suggestions for addressing the challenges discussed, such as using multi-view approaches and pupil planes to correct for scattering and aberrations."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:40-09:52",
        "transcript": "Uh Candace, would you like to introduce yourself? I know that we've been talking without you, but if you'd like to just mention um your area um that you work in and especially related to super resolution and maybe your interest in this area just briefly.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:40",
        "end_time": "49:52",
        "annotations": {
            "encourage participation": "The speaker invites Candace to contribute her expertise and opinions by introducing herself and sharing her background related to super resolution."
        }
    },
    {
        "speaker": "Candace Fleischer",
        "timestamp": "09:52-10:15",
        "transcript": "Yeah, I I really apologize about that. Um, so I'm Candace Fleischer, I'm at Emory University in Atlanta. Um, my",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:52",
        "end_time": "50:15",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Candace Fleischer",
        "timestamp": "00:00-00:29",
        "transcript": "my group primarily focuses on MR spectroscopy and of the brain and you know, we don't do a lot of super resolution in the I I also came from an optical background. So we don't do it in that sense, but maybe Oze, maybe you've already discussed like compressed sensing. I'm not sure if we've gotten that far, but in MR, we do kind of have ways that we refer to as super resolution, but certainly not in the same way. I came I heard multiplexing. So I imagine we're talking about optical imaging.",
        "speaking duration": 29,
        "nods_others": 4,
        "smile_self": 21,
        "smile_other": 21,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:29",
        "annotations": {
            "signal expertise": "The speaker mentions their background in optical imaging and current work in MR spectroscopy.",
            "ask question": "The speaker asks if compressed sensing has been discussed.",
            "identify gap": "The speaker notes the difference in 'super resolution' approaches between MR spectroscopy and optical imaging."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:29-01:10",
        "transcript": "No resolution wise we we are not on the same level so far. So I didn't want to intervene any part of the discussion, but I was thinking to introduce to my whether we will be able to use the magnetic properties and you know, to change the optical behavior and make it useful and do multimodality imaging with your approaches. I have been reading and I have been approached a couple of colleagues to use the ultra high field to change the optical properties.",
        "speaking duration": 41,
        "nods_others": 3,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:29",
        "end_time": "51:10",
        "annotations": {
            "propose new idea": "Uzay Emir introduces a new concept of utilizing magnetic properties to alter optical behavior for multimodality imaging.",
            "ask question": "Uzay Emir asks if it's possible to use magnetic properties to change optical behavior and do multimodality imaging."
        }
    },
    {
        "speaker": "Kristen Marland",
        "timestamp": "01:11-02:23",
        "transcript": "Well, I will definitely say that there's an opportunity for people from different modalities to learn from each other. And so I do think I'm really glad that there are two of you that are in MR in this room because I feel like as you discuss with each other in the next couple days, um if you can talk about um how you approach you know, resolution and improving resolution and some like compressed sensing, you know, which is applied in both fields, but the different approaches, I think sometimes it's hard for them to bridge over those those gaps between fields. And so the more you can talk together about, well, how do you do this or why do you do that or um there's a real opportunity there I think in terms of working together across fields. Um, so I'll just point that out. Um, we have about um 15 minutes left, I believe. Um, yeah. And so uh we'll maybe just talk for another five minutes and then I think we should revisit kind of our key points and and try to narrow those down so that when Josh reports out, we have a a more focused report out.",
        "speaking duration": 72,
        "nods_others": 4,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:11",
        "end_time": "52:23",
        "annotations": {
            "encourage participation": "The speaker encourages team members from different modalities to discuss and share approaches.",
            "process management": "The speaker manages the meeting flow by discussing the time left and planning the next steps."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "02:24-03:09",
        "transcript": "maybe just oh, I'll throw out one quick one and and maybe it goes nowhere. Um in terms of interesting ways of probing the tissues optically, is there some way that we can engineer photons or maybe even coupled photons so that their probability of scattering is less without let's say not, you know, not even knowing what the tissue looks like. Um I don't know, let's say entangled photons for instance example, right? Uh are there cute little tricks that we could do to uh make them more robust to what classical detection would fail at. Uh you know, maybe it it requires us to to go about that way. Just just a thought.",
        "speaking duration": 45,
        "nods_others": 2,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:24",
        "end_time": "53:09",
        "annotations": {
            "propose new idea": "Introducing a new idea about engineering photons to reduce scattering probability.",
            "ask question": "Requesting information about engineering photons or coupled photons."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "03:09-03:55",
        "transcript": "Oh, people are going longer wavelengths to avoid scattering. Uh, so that's one way and I feel like uh the notion you mentioned entangled photons could be very interesting because people are already doing that for telescope and as we know, we are the retarded grandkids from the astronomers as micro says. So maybe maybe that's the I I feel like that could be a very high risk, high reward uh uh notion to do.",
        "speaking duration": 46,
        "nods_others": 1,
        "smile_self": 15,
        "smile_other": 15,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:09",
        "end_time": "53:55",
        "annotations": {
            "propose new idea": "The speaker introduces the concept of using entangled photons, a new idea, and suggests it could be a high-risk, high-reward approach.",
            "develop idea": "The speaker expands on existing ideas by mentioning longer wavelengths to avoid scattering and then delves deeper into the concept of entangled photons.",
            "express humor": "The speaker uses humor with the phrase 'as we know, we are the retarded grandkids from the astronomers as micro says'."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "04:40-05:35",
        "transcript": "So one thing to add to this one, I think for engineering uh is quite intriguing and uh from a nano particle perspective, uh there are materials out there where you can uh tune the lifetime. So maybe it's it's not just the spectral properties but also um like the luminescence lifetime of those materials that that can then be used as as labels um for certain features um of of interest, right? And one example um uh material is called up conversion nano particles that have anti stokes emission um they um typically have luminescence lifetimes in like the millisecond or microsecond range. So that's um orders of magnitude difference to to what you would have with the commercial for so this may also be uh helpful in the end.",
        "speaking duration": 55,
        "nods_others": 1,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:40",
        "end_time": "55:35",
        "annotations": {
            "propose new idea": "Stefan introduces the concept of using up-conversion nanoparticles with tunable lifetimes as labels for certain features.",
            "develop idea": "He elaborates on the properties of these nanoparticles, specifically their anti-Stokes emission and long luminescence lifetimes.",
            "offer feedback": "Stefan provides specific suggestions for using nanoparticles to address the challenges discussed."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "05:41-06:03",
        "transcript": "So maybe that's uh that brings up an idea in my head. Um Stefan on on like modulating those like how about magnetic fields to let's say prepare them to be more scattering or less or more up converting or less and that gives us maybe a way of uh controlling them and making them better emitters for deep tissue imaging. I'm not sure.",
        "speaking duration": 22,
        "nods_others": 1,
        "smile_self": 5,
        "smile_other": 5,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:41",
        "end_time": "56:03",
        "annotations": {
            "propose new idea": "The speaker introduces a new idea of using magnetic fields to modulate material properties for deep tissue imaging.",
            "ask question": "The speaker is asking for Stefan's opinion or expertise on the idea, indicating a request for information or clarification."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "06:04-06:26",
        "transcript": "Yeah, absolutely. Like when uh when you mentioned this, I thought immediately about um assembling um uh objects at the nano scale that as a single object do not scatter but when they come together and form an assembly then all of a sudden they scatter light very efficiently. So this definitely something that that we could could work on.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 5,
        "smile_other": 5,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:04",
        "end_time": "56:26",
        "annotations": {
            "propose new idea": "Stefan Wilhelm proposes an idea of assembling nano-scale objects that scatter light efficiently when assembled.",
            "signal expertise": "Stefan Wilhelm shares his expertise related to nano materials and their optical properties."
        }
    },
    {
        "speaker": "Silvia Ronco",
        "timestamp": "06:29-06:39",
        "transcript": "Sorry, sorry to interrupt. Do you know where you need to put the main main discussions in the PowerPoint?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:29",
        "end_time": "56:39",
        "annotations": {
            "process management": "The speaker is asking about organizing or managing the main discussions in the PowerPoint, which pertains to meeting flow and organization."
        }
    },
    {
        "speaker": "Silvia Ronco",
        "timestamp": "06:39-06:40",
        "transcript": "Okay. Good. Thanks.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:39",
        "end_time": "56:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Marland",
        "timestamp": "07:00-07:26",
        "transcript": "Okay, so I think we should um try to summarize and come up with our key points, but we had lots of different great ideas. And so I would say if you know, from our discussion, we should use that parking lot to capture some of those as potential um areas that we could probe further in your later discussions and and may, you know, result in in a proposal.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:00",
        "end_time": "57:26",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting to summarize key points and use a parking lot for further discussion ideas."
        }
    },
    {
        "speaker": "Kristen Marland",
        "timestamp": "07:26-07:27",
        "transcript": "Um",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:26",
        "end_time": "57:27",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Marland",
        "timestamp": "07:27-07:51",
        "transcript": "But at this time, I think we should look at um what we want to report out for our key points.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:27",
        "end_time": "57:51",
        "annotations": {
            "process management": "The speaker is directing the discussion towards focusing on key points to report out."
        }
    },
    {
        "speaker": "Kristen Marland",
        "timestamp": "07:51-08:07",
        "transcript": "So what are what should we try to narrow it down to three topic areas of what we discussed? I think that because it is such a short recording report out time, um I think you want to go with the um the most exciting ideas, not necessarily what we talked about the most.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:51",
        "end_time": "58:07",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting how to narrow down the discussion points.",
            "clarify goal": "The speaker is clarifying the goal of summarizing their discussion, which is to focus on the most exciting ideas due to time constraints."
        }
    },
    {
        "speaker": "Kristen Marland",
        "timestamp": "08:07-08:16",
        "transcript": "So maybe but I'm going to leave it up to you to come up with um what we'll cover.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:07",
        "end_time": "58:16",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by delegating the responsibility to decide on what to cover next."
        }
    },
    {
        "speaker": "Josh Blake",
        "timestamp": "08:26-09:35",
        "transcript": "I guess one idea that's exciting me is thinking about how multimodal maybe non-traditional use of contrast. So this conversation that Stefan's point that he just brought up about thinking about how do we, you know, maybe something that separated these individual things don't scatter light well, but then due to some kind of biological or chemical change within the organism, they come together and then oops, now they're it's I mean, in some sense it's kind of like, you know, G camp or any other kind of reporter.",
        "speaking duration": 69,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:26",
        "end_time": "59:35",
        "annotations": {
            "propose new idea": "The speaker introduces a new idea about using multimodal or non-traditional contrast, building on previous discussions.",
            "develop idea": "The speaker expands on an existing idea by suggesting a new application or perspective, specifically in the context of responding to biological or chemical changes."
        }
    },
    {
        "speaker": "Josh Blake",
        "timestamp": "09:35-09:57",
        "transcript": "But like new reporters that maybe are ultrasonically or magnetically or some other modality that is deeper penetrating into tissue, you know, using that to modulate those to detect them optically.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "59:35",
        "end_time": "59:57",
        "annotations": {
            "propose new idea": "The utterance introduces a new idea of using reporters that can be modulated by different modalities (ultrasonic, magnetic, etc.) to detect optical signals deeper in tissues.",
            "develop idea": "The speaker elaborates on the idea by suggesting the use of external modalities to modulate optical reporters for better detection."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:10-00:13",
        "transcript": "Any other ideas we should be reporting out on?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:10",
        "end_time": "60:13",
        "annotations": {
            "ask question": "Kristen Maitland is requesting information or ideas from the group.",
            "encourage participation": "By asking for more ideas, Kristen Maitland is inviting others to contribute their thoughts."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "00:20-01:33",
        "transcript": "Uh, I think one idea uh that was brought up by a few people was pretty exciting. Uh, the idea of um I can summarize it as adaptive imaging. So I think Josh bring out this idea so first you have low resolution imaging and then you come in with high resolution imaging. So um so uh we can combine with MRI, right? So I was I forgot this person's name, but I was talking to another person in the breakout session that they were developing this low field MRI where they can be portable as a probe, right? So imagine uh you are doing uh clinic session and you have this probe with MRI and you're doing this scanning and then when you have a suspicious area, you heard a beep from the AI algorithms and then you have a needle that comes out that gives you the optical fiber and then insert into do kind of do a real time at a point of procedure diagnosis. Uh, so kind of combine this non-invasive MRI with non with minimal invasive optical cellular resolution imaging.",
        "speaking duration": 73,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:20",
        "end_time": "61:33",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of adaptive imaging, providing examples of its potential application in clinical settings.",
            "acknowledge contribution": "The speaker acknowledges Josh for bringing out the idea of adaptive imaging.",
            "clarify goal": "The speaker is discussing the potential goals and applications of adaptive imaging in a clinical context."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:37-03:03",
        "transcript": "Yes, so just from my my experience, I guess, that's um one area that in terms of optical imaging that, you know, I've tried to to develop was using actually fluorescence lifetime imaging of in a macroscopic view of tissue and oral cavity. Um and then using um we developed a confocal microscope that also would go into the world cavity and we design our own miniature lens that's about um less than a centimeter in diameter. So it's relatively small, can fit inside. Um and there you're doing kind of that point measurement, but it's with imaging looking at um cell nuclei um that have been identified based on the metabolic changes in the tissue um using the fluorescence lifetime. There's one other group that also uses distortion in the lens so that um on it captures a larger field of view that has a worse resolution, but at the center it has better resolution um but a very limited field of view so that you could use it to kind of guide around um and then you if you see something at the edge of the focus then you move it to the center and you get that higher resolution in the center. So there's just a couple ideas of some and then one thing that I I didn't really hear being brought up but photoacoustic imaging for increased depth um we didn't really discuss but for that kind of multimodality and and using a different type of excitation through your in comparison to your detection.",
        "speaking duration": 86,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:37",
        "end_time": "63:03",
        "annotations": {
            "develop idea": "The speaker is expanding on their own ideas and others' ideas in the field of optical imaging, specifically about techniques and tools for imaging.",
            "signal expertise": "Kristen Maitland is explicitly stating her own experience and involvement in developing optical imaging techniques."
        }
    },
    {
        "speaker": "Uzzay Emir",
        "timestamp": "03:04-03:31",
        "transcript": "Yeah, I do think that the photoacoustic is feasible for MRI as well. So I do see great illustration about this kidney and they embedded this photoacoustic and try to induce the ultrasound outside and try to write it up and you can also do the same thing with MRI that might be really interesting way to look at the photoacoustic. We don't have any chance to discuss that.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:04",
        "end_time": "63:31",
        "annotations": {
            "develop idea": "Uzzay Emir is expanding on an idea by suggesting photoacoustic imaging could be used with MRI, providing an example.",
            "supportive response": "Uzzay Emir finds the idea of using photoacoustic with MRI interesting.",
            "identify gap": "Uzzay Emir notes they haven't discussed this idea."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:32-04:13",
        "transcript": "So I do again encourage you to put ideas in the parking lot especially because even though this is a short virtual meeting this week, but um hopefully you will all be back next year and the year after and so if you plan to see now you might come back to it um in the future. Um so I hope this is just the beginning of your discussion together um not necessarily all of you together but um with individuals that you may find other people at the conference that were not in our room that um may be able to help build on some ideas that you're um starting to form.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:32",
        "end_time": "64:13",
        "annotations": {
            "encourage participation": "The speaker encourages the group to continue discussing and building on ideas.",
            "process management": "The speaker provides guidance on managing the discussion and ideas.",
            "supportive response": "The speaker expresses a positive sentiment towards continuing the discussion."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:13-04:24",
        "transcript": "This is what I have for our slide. I'm not sure what people think about this one if you want to give me any feedback. I was just trying to synthesize what we were just talking about.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
        "start_time": "64:13",
        "end_time": "64:24",
        "annotations": {
            "encourage participation": "The speaker is explicitly asking for feedback from the group.",
            "summarize conversation": "The speaker is trying to synthesize what the group was just discussing."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "05:02-05:14",
        "transcript": "I guess the second point is is somewhat related to big the big data. Like all the we had we talked quite a bit about how to deal with the data too. So thinking about how to trade those off.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
        "start_time": "65:02",
        "end_time": "65:14",
        "annotations": {
            "summarize conversation": "The speaker is referring back to a previous discussion about data.",
            "identify gap": "The speaker mentions dealing with data, implying a recognition of the challenge or gap in handling data."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:23-06:01",
        "transcript": "Yeah, and related to that data there we were looking at different um light sheet microscopes from different companies and how they handle the large data size and um just in their software aspect some would um just in how they manage the data so that when you go in you want to look like zoom into an area of interest it doesn't keep that whole large data set so you can kind of have that um just how you approach the data. I think really makes a difference in be able to work with it um because it yeah, it is a lot of a lot of data.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
        "start_time": "65:23",
        "end_time": "66:01",
        "annotations": {
            "code name": "offer feedback",
            "explanation": "The speaker is providing a suggestion on how to approach data management effectively."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "07:04-07:12",
        "transcript": "No, I think it went well. Thank you uh Kristen for for facilitating us and getting everyone a chance to speak.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "67:04",
        "end_time": "67:12",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and gratitude towards Kristen for facilitating the discussion, which is a positive evaluation of her contribution."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "07:13-08:11",
        "transcript": "Yeah, I really like the we have the questions to guide us and then we kind of each uh each one of us kind of just uh uh branch off that. Um I I think um what I would like better is uh I feel like um so first we can go around introduction for each one and then when we are having this discussion, uh I feel like a lot of people, everybody has really good points that we could build a more fluid and um more coherent coherent conversation instead of one by one. So uh but uh then I guess it's a trade off then maybe we cannot get to hear some people's opinions um maybe. So maybe we could do like first round table uh introduction round table short ideas and then uh more uh just kind of just very casual uh coherent fluid discussions.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "67:13",
        "end_time": "68:11",
        "annotations": {
            "code name": "offer feedback",
            "explanation": "The speaker provides suggestions for improving the discussion format, offering feedback on how the conversation could be more fluid and effective."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:12-09:55",
        "transcript": "Yes, I do feel that especially in this virtual format that it does feel like okay, it's your turn to talk and there's a little bit less flow. Um I was wondering if it would be better after the introductions that if each person talk like briefly state what they're interested in discussing and you could almost like group them in and say okay, first we're going to talk about this particular direction and then we'll cover this direction. Um so that would be one thought. I think it's hard because of the the topics are relatively broad actually even though you know, in some ways they're specific, but they're relatively broad and you can approach them in different ways and so it's um it's almost hard to put your ideas into, you know, kind of groups. You know, and when I was looking at this topic I was thinking we could talk about new applications for super resolution that are, you know, it's not currently applied to. We could talk about different um advances to the implementation and then um I was also I was glad to see that there were people from MRI in here that if we could um get some information from other fields in imaging that might influence our approaches. Um but I do feel that each person had something different to add that um it might have been hard to kind of narrow down the topics because they are um there's so much to cover. I think. But I hope that you continue to have your discussions with each other in the different um gather rooms or towns or without you get to be in um so you can continue these uh conversations.",
        "speaking duration": 103,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "68:12",
        "end_time": "69:55",
        "annotations": {
            "process management": "Kristen Maitland is suggesting ways to improve the discussion flow and manage the meeting process, especially in a virtual format.",
            "encourage participation": "She is also encouraging participation by proposing that participants briefly state their interests and suggesting a grouped discussion approach."
        }
    },
    {
        "speaker": "Kristen Macland",
        "timestamp": "00:00-00:06",
        "transcript": "notes and for reporting out for us and we will see you guys later in the conference.",
        "speaking duration": 6,
        "nods_others": 4,
        "smile_self": 20,
        "smile_other": 80,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:00",
        "end_time": "70:06",
        "annotations": {
            "code name": "process management",
            "explanation": "The speaker is discussing the next steps after the meeting and how she will report out for the group, managing the meeting flow."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "00:06-00:07",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 1,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:06",
        "end_time": "70:07",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Unidentified speaker",
        "timestamp": "00:07-00:07",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:07",
        "end_time": "70:07",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing someone's input."
        }
    },
    {
        "speaker": "Unidentified speaker",
        "timestamp": "00:08-00:08",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:08",
        "end_time": "70:08",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Unidentified speaker",
        "timestamp": "00:08-00:09",
        "transcript": "Nice meeting you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:08",
        "end_time": "70:09",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Unidentified speaker",
        "timestamp": "00:09-00:09",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:09",
        "end_time": "70:09",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Siksan You",
        "timestamp": "00:10-00:11",
        "transcript": "Great to meet everybody.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:10",
        "end_time": "70:11",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Andrew Feig",
        "timestamp": "01:29-01:30",
        "transcript": "Guys.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:29",
        "end_time": "71:30",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbazadeh",
        "timestamp": "01:32-01:35",
        "transcript": "God, my brain felt like as if I have to creak really.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:32",
        "end_time": "71:35",
        "annotations": {
            "express humor": "The speaker is making a humorous comment about their brain feeling like it needs to creak, implying mental fatigue or strain."
        }
    }
]