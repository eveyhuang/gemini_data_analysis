{
    "meeting_annotations": [
        {
            "speaker": "Dylan Burnette, Vanderbilt University",
            "timestamp": "00:00-00:32",
            "transcript": "illumination or single molecule imaging on top of that. And I'm calculating resolution and it's scaring me already and it's a single cell. So do we have any idea what we do with that kind of data if we have super res and like I'm I'm I'm just it's exciting but also scary at the same time.",
            "speaking duration": 32,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Uzay Emir, Purdue University",
            "timestamp": "00:32-01:25",
            "transcript": "Can I uh so similar to your question actually your question is originating from a problem actually going back to whole animal or big organism will be ring a lot of data. Now the question is how from my point of view I'm a microscopic person and even our data is big but uh it's not as complicated as yours uh but it has its own difficulties. How you are seeing all you guys are optical imaging and super resolution compared to myself to make it really translatable to real life or big animal or live animal uh thing. So what is your pathway to bring those techniques to this and considering your concern about the size of the data.",
            "speaking duration": 53,
            "nods_others": 1,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Dylan Burnette, Vanderbilt University",
            "timestamp": "01:26-02:35",
            "transcript": "So is it possible to to combine structured light and of scattering at the same time? Is that too complicated? Sorry, I'm not I'm not a physicist, but we are using structured light uh through the line of slide sheet and and and it's the same, you know, basic run of the mill technologies. Um but can you collect scattered light from that sort of information? Because that's already up and running of in many, many labs around the country and world right now. Uh would be able to combine something like the lighter slide sheet which penetrates into tissues pretty decently, let's not say great, but decently. But now it's good as four photo time would. But um um but we uh but that also has already structured information with it. Does that complicate getting scattered light or not? Because that's kind of a fascinating idea uh that I hadn't really thought too much about. And at least three of you had thought a lot about it. So that's pretty cool.",
            "speaking duration": 69,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Josh Brake, Harvey Mudd College",
            "timestamp": "02:36-03:03",
            "transcript": "I guess my two cents on this is by de facto as optical engineers, we try to throw out the scattered light. That's the conventional wisdom. We always have done that. And so every optical system you pick up whether it's your iPhone or a microscope is designed to throw that information out. And that's the that I think is the kernel of the revolutionary idea here is like let's remove that constraint and go back to the drawing board and think differently.",
            "speaking duration": 27,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matt Lew, WashU in St. Louis (he/him)",
            "timestamp": "03:03-04:24",
            "transcript": "Yeah, Josh, I I'd like to to build off of that. So I think you did made a great point about the uh the the sort of the paradigm of of at least microscopy uh and ballistic imaging that we throw away all the scattered light. Then we're kind of forgetting our friends in the diffuse optics regime. So let's think of DOT diffuse optical tomography and people sort of um uh there's there's actually a colleague here at Washu who builds the whole brain uh uh imaging uh device, right? And and looks at uh sort of function uh um by collecting diffuse light off of there. So maybe um maybe a a regime of pushing the resolution there might be helpful. Uh right now it's sort of spatially resolved based upon the average number of scattering events that takes light longer to travel further or or uh uh and and you can sort of resolve some things in depth that way. So maybe that's one way we can think about it. I think maybe another question is um like if we take our existing technologies that can penetrate deep but somehow are deficient in some other axis. So let's just say pet for example, right? The gold standard in in specifically detecting something uh uh within within the body and an organism. Uh is there something that optical imaging if engineered the right way, maybe with the the fancy uh fluorescent based reporters that we saw uh earlier in the keynote. Um maybe there's something that we can do to to to solve a more targeted problem as a as a as a prototype for for for uh for solving the the bigger question that that was posed. Um just a couple ideas there.",
            "speaking duration": 81,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Mohseny, Tufts U. (she/her)",
            "timestamp": "04:24-04:45",
            "transcript": "I'd like to I'd like to kind of jump on that as well. Um I I feel like one thing that I I and this might just be my inexperience with the super resolution field, but like um one thing we don't really talk about much is what and and similar to what Matt was talking about is um what could we kind of learn from, you know, we're kind of used to a a certain type of imaging with an objective with a very high NA, you know, lens and and I feel like that's kind of a bulk of the problem.",
            "speaking duration": 21,
            "nods_others": 0,
            "smile_self": 80,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Dylan Burnette, Vanderbilt University",
            "timestamp": "04:45-04:45",
            "transcript": "Yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Mohseny, Tufts U. (she/her)",
            "timestamp": "04:45-04:45",
            "transcript": "Yeah, okay.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Dylan Burnette, Vanderbilt University",
            "timestamp": "04:45-06:03",
            "transcript": "So I would say that from because I'm the I'm I'm the uh I'm the holer here not the forger. I don't uh I don't uh I I developed one technique and no one ever used it. So it was called bomb because back in the day anything with single molecules had to have a acronym. Uh and I learned through that that I should not develop techniques. I should just take other people's and Um but I'll say as a as a user and we're pretty advanced users uh that we are pretty much addicted to the high NA lens because it's what's available. It's what's commercially available, it's what we can order. We're not going to build our own lenses. And that is why we use them. There's no one has come up with a better way that I can purchase to do this and it's very limiting because the high NA is usually uh uh for the most of our of our work for super res which is single molecule or structured light. Um and I generally put those in just two categories. I know that some of you are have four categories of super res. Um but when you think about it from that way, it's very limiting as far as Z depth, so how far you can go, so your axial dimension that you can penetrate your sample is limited.",
            "speaking duration": 78,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Mohseny, Tufts U. (she/her)",
            "timestamp": "06:03-06:03",
            "transcript": "Right.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Dylan Burnette, Vanderbilt University",
            "timestamp": "06:03-06:03",
            "transcript": "Yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Mohseny, Tufts U. (she/her)",
            "timestamp": "06:03-06:03",
            "transcript": "So it's.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Mohseny, Tufts U. (she/her)",
            "timestamp": "06:03-07:33",
            "transcript": "I mean, yeah, no, I'm I'm I'm just I'm coming from a different kind of world of of, you know, you know, we everything we do is like little chips and so that you could do like fine resolution here and fine resolution here, you know, what are kind of the limitations um from people who are actually using super resolution um with those objective lenses that that you guys use. Um in terms of I guess field of view and like the amount of power that you need to be able to illuminate an entire section.",
            "speaking duration": 90,
            "nods_others": 0,
            "smile_self": 70,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}