{
    "meeting_annotations": [
        {
            "speaker": "Sitian You",
            "timestamp": "00:21-00:22",
            "transcript": "Hi everyone.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Sitian You",
            "timestamp": "00:22-01:37",
            "transcript": "So I think for the first part, I can talk about the multi model probes. So basically, the idea is that we can use different types of energy to deliver deep tissue stimulation. For example, we can use magnetic, acoustic, and also electrical stimulation. And the second part is adaptive imaging. So basically, we can tune the resolution and field of view to maximize the information that you capture. And the third part is co-designing illumination and collection. So basically, we can think about the system broadly in terms of light delivery and collection.",
            "speaking duration": 75,
            "nods_others": 3,
            "smile_self": 10.0,
            "smile_other": 10.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:38-04:08",
            "transcript": "Okay, so I think that's a great summary. And I think that the goal of this room is to think about how we can combine these different modalities. So, for example, can we use light to activate some of these multi-modal probes? Can we use light to do adaptive imaging? And then how do we co-design the illumination and collection to optimize the information that we're getting out? So I think that's the goal of this room. And so I think we can start by just kind of brainstorming some ideas. And then we can kind of narrow down and think about what's feasible and what's not. So I'm happy to kind of start us off with some ideas, but I also want to open it up to the group. So, for example, one of the things that I've been thinking about is using light to activate some of these multi-modal probes. So, for example, we could use light to activate a magnetic probe, and then we could use that magnetic probe to stimulate a specific region of the brain. Or we could use light to activate an acoustic probe, and then we could use that acoustic probe to stimulate a specific region of the brain. So I think that's one area that we could explore. And then another area that we could explore is using light to do adaptive imaging. So, for example, we could use light to change the resolution of our microscope, or we could use light to change the field of view of our microscope. And then we could use that to optimize the information that we're getting out. So I think those are just a couple of ideas to get us started. But I'm happy to open it up to the group and see what other ideas people have.",
            "speaking duration": 150,
            "nods_others": 3,
            "smile_self": 20.0,
            "smile_other": 20.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Uzzay Emir",
            "timestamp": "04:08-04:08",
            "transcript": "[Silence]",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Josh Brake",
            "timestamp": "04:09-04:09",
            "transcript": "[Silence]",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        },
        {
            "speaker": "Uzzay Emir",
            "timestamp": "04:09-04:31",
            "transcript": "So I think one of the things that I'm thinking about is, uh, you know, we have all these new tools, uh, to do single cell transcriptomics, and, uh, you know, spatial transcriptomics. And I'm wondering if we can use some of these probes to, uh, you know, stimulate cells and then, uh, you know, do some sort of, uh, you know, single cell transcriptomics to see what the effect of the stimulation is.",
            "speaking duration": 22,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "04:33-04:48",
            "transcript": "Yeah, I think that's a great idea. So, for example, we could use light to activate a specific gene, and then we could use single cell transcriptomics to see what other genes are affected by that activation. And then we could use that information to design better probes.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        },
        {
            "speaker": "Josh Brake",
            "timestamp": "05:13-05:17",
            "transcript": "Yeah, I think that's a great idea. I think that's a really interesting direction to go.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:24-05:58",
            "transcript": "So I think one of the challenges with that is that single cell transcriptomics is still pretty low throughput. So it's hard to do a lot of different conditions. So I think one of the things that we could think about is how we could use some of these other modalities to screen for conditions that are likely to be interesting. So, for example, we could use light to activate a specific gene, and then we could use some sort of imaging modality to see what other cells are affected by that activation. And then we could use that information to narrow down the conditions that we want to use for single cell transcriptomics.",
            "speaking duration": 34,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "07:05-07:12",
            "transcript": "Yeah, I think that's a great idea. I think that's a really interesting direction to go.",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 80.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        },
        {
            "speaker": "Sitian You",
            "timestamp": "07:13-08:12",
            "transcript": "Yeah, I think that's a great idea. So basically, we can use the light to activate a specific gene, and then we can use the single cell transcriptomics to see what other genes are affected by that activation. And then we can use that information to design better probes. And also, I think we can use the light to do adaptive imaging. So, for example, we can use light to change the resolution of our microscope, or we can use light to change the field of view of our microscope. And then we can use that to optimize the information that we're getting out.",
            "speaking duration": 59,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:13-09:59",
            "transcript": "So I think one of the challenges with that is that single cell transcriptomics is still pretty low throughput. So it's hard to do a lot of different conditions. So I think one of the things that we could think about is how we could use some of these other modalities to screen for conditions that are likely to be interesting. So, for example, we could use light to activate a specific gene, and then we could use some sort of imaging modality to see what other cells are affected by that activation. And then we could use that information to narrow down the conditions that we want to use for single cell transcriptomics. And then we could use that information to design better probes. So I think that's a really interesting direction to go.",
            "speaking duration": 106,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog: ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points: Super-resolution methods\" and lists multi-modal probes, adaptive imaging, and co-designing illumination and collection as key points. The slide also lists the participants and facilitators of the meeting."
        }
    ]
}