[
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:20-00:31",
        "transcript": "Okay, so I will call out names in alphabetical order so you can introduce yourself and then give your area of interest related to this topic. So we'll start with Shiva.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:20",
        "end_time": "00:31",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by outlining the procedure for introductions.",
            "assign task": "The speaker is implying that each person is responsible for introducing themselves when their name is called."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "00:31-00:55",
        "transcript": "Hi, this is Shiva Abbaszadeh. I'm assistant professor in University of California Santa Cruz. My background is electrical engineering and I do work on radiation detection, basically for X-ray CT and positron emission tomography and then how from the hardware and signal processing aspect we can improve the image quality in these modalities.",
        "speaking duration": 24,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:31",
        "end_time": "00:55",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own qualifications and area of work, signaling their expertise in electrical engineering and radiation detection."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:56-00:58",
        "transcript": "Thank you. Benjamin.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:56",
        "end_time": "00:58",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes another group member's input or action, in this case, saying 'Thank you' to Benjamin."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "00:59-01:37",
        "transcript": "Hi, my name is Benjamin Bartelle. Um, my I'm an assistant professor at Arizona State University. Uh, my goal is uh non-invasive to non-invasively resolve and manipulate the neuroimmune system. I primarily do that with MRI uh and develop methods called molecular FMRI. So that means designing molecular probes usually through synthetic biology methods to bring molecular specificity to the MRI signal and my my target is largely the neuroimmune interactions um occurring in a living mouse.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:59",
        "end_time": "01:37",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise and qualifications as an assistant professor at Arizona State University.",
            "develop idea": "The speaker elaborates on his research goals, methods, and specifics, providing a detailed overview of his work in non-invasive neuroimmune system manipulation and molecular FMRI."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:37-01:39",
        "transcript": "Thank you. Larry.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:37",
        "end_time": "01:39",
        "annotations": {
            "process management": "This code applies because Kristen Maitland is managing the meeting flow by moving to the next person for introduction.",
            "encourage participation": "This code applies because by calling out 'Larry.', Kristen Maitland is inviting or prompting Larry to contribute to the discussion by introducing himself."
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "01:40-02:41",
        "transcript": "Hi, my name is Larry. I'm assistant professor at Penn State University. My background is in mechanical engineering. I'm trying to apply the deformable structure and devices for the health monitoring and imaging of the human health condition, more continuous monitoring activities. And we have been interested in the stretch or acoustic photoacoustic wave for the brain imaging and electrical impedance tomography to complement the MRI for the fast imaging capabilities as well as the remote monitoring in term of the mesh surface for the microwave scattering so that we can do that behind the obstacles and that could be also a unique application with the physical implementation of the machine learning imaging with that modality.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:40",
        "end_time": "02:41",
        "annotations": {
            "signal expertise": "The speaker explicitly states their background and current position as an assistant professor at Penn State University, indicating their expertise in mechanical engineering."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:41-02:43",
        "transcript": "Thank you. Mini.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:41",
        "end_time": "02:43",
        "annotations": {
            "encourage participation": "Kristen Maitland is inviting Mini to contribute by introducing themselves.",
            "process management": "Kristen Maitland is managing the meeting flow by moving to the next participant."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:43-03:33",
        "transcript": "Hi, this is Mini Das from University of Houston. I'm an associate professor in physics and biomedical engineering. My background is applied physics, optical sciences and some of the recent work has been in looking at using light transport model or electromagnetic transport models in conjunction with advanced detectors to to come up with methods for identifying new contrast mechanism, for example, phase changes of X-rays rather than simple absorption and then looking at more recently also multimodality and near infrared optical imaging where the inverse problem is very ill conditioned and how can you potentially improve those those kind of problems.",
        "speaking duration": 50,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:43",
        "end_time": "03:33",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise and background in physics and biomedical engineering."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:33-03:35",
        "transcript": "Thank you. Joyoni.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:33",
        "end_time": "03:35",
        "annotations": {
            "process management": "This code applies because Kristen Maitland is managing the meeting flow by calling out the next person's name for introduction."
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "03:36-05:24",
        "transcript": "Hi, I'm a physics faculty at LSU. I teach at the medical physics. My research is also in phase contrast X-ray and I'm trying to develop a phase contrast mammography system as well as a CT system is contrast. And I also I have worked in the past on spec reconstruction, iterative reconstruction with motion correction and also novel MPG sorry multipinol geometries and stuff like that. So I the just relevant to this topic what I'm kind of interested right now I would be interested is to have a iterative reconstruction method for phase contrast with the raw interferometric data. So as you know that phase contrast you have to derive so from the projections you have to derive the you know the attenuation image, the phase image and the scatter image and then you reconstruct and so if I could do it from the raw interference patterns it's very challenging because of the very computational requirements. Okay it's very high computational requirements. And I'm also interested in deep learning methods for that like for some of these reconstruction methods. And also I think that will help our phase contrast in in correcting some of the errors due to large you know grating artifacts. So you know like it can learn a lot of things that ordinary reconstruction methods would not. And as for just a quick addition that no that's okay yeah I think that's enough.",
        "speaking duration": 108,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:36",
        "end_time": "05:24",
        "annotations": {
            "signal expertise": "Joyoni explicitly states her own expertise in physics, medical physics, and phase contrast X-ray.",
            "identify gap": "Joyoni identifies a gap in her current capability - the ability to perform iterative reconstruction with raw interferometric data due to computational requirements.",
            "clarify goal": "Joyoni clarifies her research goals and interests, specifically in developing phase contrast systems and improving reconstruction methods."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:30-05:33",
        "transcript": "Okay, thank you. Um, Uzay.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:30",
        "end_time": "05:33",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:34-05:56",
        "transcript": "Hello. Uh my name is Uzay and I'm assistant professor at the School of Health Science Purdue University. And my focus of research is developing novel imaging techniques for pre-clinical and clinical MRI that spans from application from top to bottom of the body.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:34",
        "end_time": "05:56",
        "annotations": {
            "signal expertise": "Uzay Emir explicitly states his position as an assistant professor and his research focus, signaling his expertise in the field."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:56-05:58",
        "transcript": "Thank you. Beck.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:56",
        "end_time": "05:58",
        "annotations": {
            "encourage participation": "This code applies because Kristen Maitland's utterance 'Thank you. Beck. ' serves as an invitation for Beck to contribute to the discussion by introducing themselves."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:59-07:12",
        "transcript": "Hi everyone. So I'm an assistant professor at in computer science and also in EE at Washington University in St. Louis. Um what I do is I do um algorithms for for image processing in different levels. So we do image analysis, image reconstruction and artifact correction, classification registration. Uh so in the topics uh in this um group uh so I do work on um X-ray CT for scientific imaging where uh some of the issue we look at is uh uh registration of um uh um um of measurements of tomograms. We do work I do have a project on increasing SNR computationally for pet. Uh one on um incorporating multiple light scattering into uh optical tomography uh so um label free optical tomography and another one is building optical coherence tomography but by scanning different angles instead of just by using uh uh look at one side. Uh so those are the projects I do but I do all my work is essentially computational with a lot of deep learning in it.",
        "speaking duration": 73,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:59",
        "end_time": "07:12",
        "annotations": {
            "signal expertise": "The speaker explicitly states his position as an assistant professor in computer science and EE at Washington University in St. Louis and describes his work areas.",
            "develop idea": "The speaker elaborates on his work areas including image analysis, image reconstruction, artifact correction, and specific projects related to X-ray CT, PET, optical tomography, and optical coherence tomography."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:12-07:14",
        "transcript": "Great. Thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:12",
        "end_time": "07:14",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes another group member's input, in this case, their introduction."
        }
    },
    {
        "speaker": "Morteza Mahmoudi",
        "timestamp": "07:14-08:28",
        "transcript": "Hi everyone. My name is Morteza Mahmoudi and I'm an assistant professor at Michigan State University. So my research is focused on nanomedicine and regenerative medicine. From nanomedicine point of view, we basically develop magnetic based contrast agents for MRI basically we can track nanoparticles themselves or like we use them for cell therapy applications. Um another part of the research that we do is like imaging the nanobio interfaces where nanoparticles basically interact with biological fluids and the proteins and other like biomolecules come to their surfaces. So for that purpose we use cryo transmission electron microscopy which with combined with imaging technique to get a 3D structure of the nanoparticles.",
        "speaking duration": 74,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:14",
        "end_time": "08:28",
        "annotations": {
            "develop idea": "The speaker is elaborating on his existing research areas, providing details on his work in nanomedicine and regenerative medicine.",
            "signal expertise": "The speaker is explicitly stating his own expertise and qualifications related to the task by sharing his research focus and methods."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:28-08:32",
        "transcript": "Thank you. And last but not least, Mark.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:28",
        "end_time": "08:32",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by introducing participants.",
            "encourage participation": "The speaker is encouraging Mark to participate by introducing him."
        }
    },
    {
        "speaker": "Mark Sellmyer",
        "timestamp": "08:33-09:13",
        "transcript": "Fair enough. Um, so I'm Mark Sellmeyer. I'm an assistant professor, my third year at UPenn. Um, I am chemical biologist and synthetic biologist. So we develop small molecule tools for biologists and um on the molecular imaging front try to make new diagnostics or approaches that let us both image and control gene and cell therapies. Um, I do uh deal one day a week of clinical nuclear radiology and um have been the PI on clinical protocols before that translate molecular imaging approaches.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:33",
        "end_time": "09:13",
        "annotations": {
            "signal expertise": "Mark explicitly states his own expertise and qualifications related to the task, mentioning his position, background, and research areas."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:13-09:14",
        "transcript": "Great.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:13",
        "end_time": "09:14",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and a positive evaluation after the introductions."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:14-09:44",
        "transcript": "Thank you. Well, we have an exciting mix of different modalities and different scales and both technology application and maybe contrast. Um, so I think I will first just open it up if anybody wants to respond based on what they've heard from someone else, um,",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:14",
        "end_time": "09:44",
        "annotations": {
            "Summarize conversation": "Kristen Maitland summarizes the diversity of the group's expertise and interests.",
            "Encourage participation": "Kristen Maitland invites others to respond based on what they've heard from someone else."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:44-09:44",
        "transcript": "I'll give it a few seconds.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:44",
        "end_time": "09:44",
        "annotations": {
            "process management": "This code applies because Kristen Maitland is managing the meeting flow by pausing and giving participants time to respond."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:44-09:44",
        "transcript": "Go ahead.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:44",
        "end_time": "09:44",
        "annotations": {
            "encourage participation": "The speaker is inviting someone else in the group to contribute their expertise, opinions, or ideas."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "09:45-10:00",
        "transcript": "Well we're talking. Uh I mean it was really surprising how the previous sessions had a lot of convergences. There was a lot of um agreeance on the need for reporter genes, a lot of agreeance on multimodal approaches and I thought I thought all that",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:45",
        "end_time": "10:00",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and positive evaluation of previous discussions, highlighting convergences on topics like reporter genes and multimodal approaches.",
            "acknowledge contribution": "The speaker is recognizing and building upon the ideas and agreements mentioned in previous sessions by other participants."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "00:10-00:54",
        "transcript": "I'll say that, you know, on this my my 30 seconds of thinking about the very first um question is that yeah, pet and CTR are already reconstructed very well and you know, have the software platforms that are easily amenable to scroll through an imaging set.",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:10",
        "end_time": "10:54",
        "annotations": {
            "Supportive response": "Mark is expressing agreement and a positive view on the current state of PET and CT technology, indicating that they are well-developed."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "00:54-01:04",
        "transcript": "sort of like imaging probe readout on one scroll side and pathologic, you know, um IHC or whatever on the other and be able to correlate.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:54",
        "end_time": "11:04",
        "annotations": {
            "propose new idea": "The speaker is introducing a new suggestion for correlating imaging probe readout with pathological information, proposing a method to visualize or handle data that combines these two aspects."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "01:04-01:24",
        "transcript": "I think in my world, you know, one of the challenges is like if we um have a probe that shows uptake in one part of the tumor. Um, you know, how do you go back and then validate that that uptake was really become from the target that you set out to at the very beginning.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:04",
        "end_time": "11:24",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes a challenge or gap in his current methodology, specifically in validating probe uptake in tumors."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "01:24-01:57",
        "transcript": "Um, that can be for tumor heterogeneity, but I also think about it for like some of our infectious disease probes where like it's not a nicely matted tumor that's, you know, growing in a circle and you can pinpoint the spot, it's like interpolating amongst among the cells and among the normal um tissues of the person for an infection. And so there the challenge is even harder. So, um, getting path to be a little more 3D would be lovely.",
        "speaking duration": 33,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:24",
        "end_time": "11:57",
        "annotations": {
            "identify gap": "Mark Sellmyer recognizes the limitation of current pathology techniques in being more 3D, especially in the context of tumor and infection imaging.",
            "develop idea": "Mark Sellmyer expands on previous discussions by highlighting the specific challenge of interpolating among cells and tissues in infectious disease probes."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "01:59-02:17",
        "transcript": "I think that's a great point about tumor heterogeneity whether um our currently available 3D imaging systems are allowing us to capture this correctly uh and that the limitations comes from uh signal corruption for the most part.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:59",
        "end_time": "12:17",
        "annotations": {
            "supportive response": "Mini Das agrees with the previous point about tumor heterogeneity.",
            "ask question": "Mini Das asks if current 3D imaging systems can capture tumor heterogeneity correctly.",
            "identify gap": "Mini Das points out that signal corruption is a limitation in capturing tumor heterogeneity."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:17-02:30",
        "transcript": "It could be scatter or the need to correct them accurately. But I was wondering if if multimodality could help in that regard maybe if anyone has thoughts on I I I was intrigued by that last point.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:17",
        "end_time": "12:30",
        "annotations": {
            "ask question": "Mini Das is requesting thoughts from others on the potential of multimodality to help with the challenges discussed.",
            "develop idea": "Mini Das is expanding on the idea of using multimodality to address the challenges of tumor heterogeneity and probe validation.",
            "acknowledge contribution": "Mini Das is verbally recognizing Mark Sellmyer's input and showing interest in his point."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:30-02:47",
        "transcript": "I think uh it was presented in I don't remember the group now, but where uh there was a discussion on targeting uh and then my thought was region of interest reconstruction.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:30",
        "end_time": "12:47",
        "annotations": {
            "develop idea": "Mini Das is building upon or referencing a previous discussion and suggesting a related idea (region of interest reconstruction).",
            "propose new idea": "Mini Das introduces the specific idea of 'region of interest reconstruction' in the context of targeting."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:47-03:16",
        "transcript": "If you could uh for example have a targeting with one probe then we know that well, this is around the area that's of interest and then for example your your your data data that you really want to deal with uh you know that everything else is kind of not of interest maybe it would help data reduction maybe.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:47",
        "end_time": "13:16",
        "annotations": {
            "offer feedback": "Mini Das is providing a suggestion for how to improve imaging techniques by targeting with one probe."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:16-03:16",
        "transcript": "That was kind of what I was trying to say at that time when we just moved on.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:16",
        "end_time": "13:16",
        "annotations": {
            "acknowledge contribution": "The speaker is trying to bring back a point they previously attempted to make, ensuring their contribution is recognized."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:17-03:19",
        "transcript": "was in our group. I think I was.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:17",
        "end_time": "13:19",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging their involvement or potential involvement in a group."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:19-03:25",
        "transcript": "It was it was I think I don't remember the number now, but that's correct.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:19",
        "end_time": "13:25",
        "annotations": {
            "acknowledge contribution": "Mini Das is acknowledging a previous point made by someone else.",
            "supportive response": "Mini Das is expressing agreement or validation for the previous statement."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:25-03:34",
        "transcript": "Yes, if if that would be an interesting uh idea to think in that yes and data reduction with multimodality.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:25",
        "end_time": "13:34",
        "annotations": {
            "Supportive Response": "The speaker is expressing interest and potential agreement with a previously discussed idea.",
            "Develop Idea": "The speaker is building upon a previous idea by suggesting it could be interesting and mentioning a specific application (data reduction with multimodality)."
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "03:35-04:57",
        "transcript": "Yeah, I'm not sure whether this is a proper example, but well was trying to look at how we can do the uh balance between the temporal space resolution for the brain imaging. And we were looking at the functional MRI and optical imaging and they are each advantageous for certain aspects, but um by looking at the photo acoustic it seems to be better when we have the input signal from optical and attenuation will be um less concerned when we don't need to worry about the uh signal signal out from that uh skull attenuation by looking at the acoustic signature and this will actually enable us to push this imaging down to uh actually 1 millimeter down into the brain tissue. So, uh I think this is a combination of the optical and acoustic for the acoustic photo acoustic imaging. And maybe for the other things, I was also thinking about to use uh certain uh contrast agents and this is really something people have been looking at with uh maybe a different application for photo uh optogenetics operation and they seem to be able to get those non particle inside the brain. So maybe they can also be combined to uh help the multimodality imaging.",
        "speaking duration": 82,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:35",
        "end_time": "14:57",
        "annotations": {
            "propose new idea": "Larry suggests combining optical, acoustic, and possibly contrast agents for improved brain imaging.",
            "develop idea": "He elaborates on the benefits of combining functional MRI, optical imaging, and photoacoustic imaging.",
            "offer feedback": "Larry provides a suggestion for improving multimodality imaging by combining different techniques and using contrast agents."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:00-05:04",
        "transcript": "Mini regarding to your uh questions.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:00",
        "end_time": "15:04",
        "annotations": {
            "acknowledge contribution": "Uzay Emir is verbally recognizing Mini's input by addressing her questions."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:04-05:15",
        "transcript": "that we discussed with Blueberg in the same session. So I uh I think that's come from probing things is uh I give an example for that.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:04",
        "end_time": "15:15",
        "annotations": {
            "acknowledge contribution": "Uzay Emir is referencing a discussion with Blueberg, showing awareness of others' contributions or discussions."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:15-05:30",
        "transcript": "For example, the glioma patients I was discussing about that. So you you open the brain, you do have a sample right in front of you and you tailor your uh optical imaging technique that's sensitive to the certain enzyme.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:15",
        "end_time": "15:30",
        "annotations": {
            "develop idea": "The speaker provides a concrete example of how optical imaging techniques can be tailored for specific applications, such as detecting certain enzymes in glioma patients, thereby expanding on a previous idea."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:30-06:25",
        "transcript": "And you do get the information and you might find some corresponding things non invasive imaging modality coming from MRI, path contrast or whatever you do think. And then you do get since it is already open for histological analysis, you can take the pathology and do do DNA sequencing and do do so this dimension reduction is coming from that because there will be a massive amount of data is coming. So then one of our colleagues during that discussion suggested that to tailor the optical imaging to certain things and then this enzyme enzyme specific uh optical imaging or it can be tailored. I'm not an optical person, so I'm not an expert, so I really don't want to make uneducated uh assumptions, but that is how that uh tailored approach come up. Am I right Blueberg? So am I missing or",
        "speaking duration": 55,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:30",
        "end_time": "16:25",
        "annotations": {
            "develop idea": "Uzay Emir is expanding on the idea of using non-invasive imaging modalities and tailoring optical imaging to specific targets, building upon previous discussions.",
            "ask question": "Uzay Emir is seeking confirmation or clarification from Blueberg, indicating uncertainty about his understanding of the tailored approach in optical imaging.",
            "acknowledge contribution": "Uzay Emir is referencing a colleague's suggestion regarding tailoring optical imaging, which indicates he is recognizing and building upon someone else's input."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "06:25-06:26",
        "transcript": "No, you completely.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:25",
        "end_time": "16:26",
        "annotations": {
            "Supportive Response": "Beck Kamilov is expressing agreement with Uzay Emir's previous statement, indicating a positive evaluation without adding new content.",
            "None": "Not applicable as Supportive Response applies."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "06:26-06:35",
        "transcript": "It was Ellen, if some if you're interested to talk to her, Ellen was a person who brought it up and she said she's very interested in that area. she has specifically said it.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:26",
        "end_time": "16:35",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges Ellen's contribution by mentioning her interest and previous statement.",
            "encourage participation": "The speaker encourages others to talk to Ellen if they are interested in the area she is interested in."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "06:35-06:36",
        "transcript": "maybe maybe Brian can.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:35",
        "end_time": "16:36",
        "annotations": {
            "encourage participation": "Mini Das is suggesting that Brian could contribute, thereby encouraging his participation."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "06:36-07:37",
        "transcript": "comment on this uh near infrared diffuse optical imaging, the problem with the 3D uh the problem itself has been, you know, well known to be very ill conditioned problem. And uh I looked at it sometime ago for breast imaging and you know, there are ways to ways to make it improve it by for example adding some information uh we had uh we were looking at using for example ultrasound uh localization. But more recently what I'm seeing is you are people are moving towards saying instead of accurate quantitation or finding exact volumetric concentration, let's look at fluctuations uh that happen uh well when when I guess this is more for brain imaging now we are talking if. So Brian, could you comment on I haven't looked at what was the evolution and how what's what's happening now with the exact quantitation part has it been done or given up or what's what's where is the field in that regard.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:36",
        "end_time": "17:37",
        "annotations": {
            "develop idea": "Mini Das is expanding on the idea of near-infrared diffuse optical imaging, discussing its challenges and recent trends in the field.",
            "ask question": "Mini Das explicitly asks Brian for his comment on the current state of the field, especially regarding the evolution of exact quantitation in near-infrared diffuse optical imaging."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:37-08:22",
        "transcript": "Yeah, I mean I think most work has been done in functional near infrared, you know, to to to couple to MR. So that's a multimodality, right, where you get the structure from MR and then temporal dynamics from near infrared. Um, certainly a lot going on. Um, we've we've we've spent a lot of time trying to do image guided spectroscopy with diffuse light and that's possible. So that's sort of a hybrid approach, right, where you've got the structure from CT or ultrasound or MRI and then layer in that as a a priori guide to the optical spectroscopy because you know optics is terrible, right? It's really blurry and",
        "speaking duration": 45,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:37",
        "end_time": "18:22",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas of multimodality and hybrid imaging approaches, discussing how different imaging techniques can be combined for better outcomes."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:22-08:30",
        "transcript": "Diffuse optics anyway, it's really terrible. I'm intrigued by the idea of trying to get pathologic level information from a",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:22",
        "end_time": "18:30",
        "annotations": {
            "critical response": "Brian Pogue expresses a negative sentiment towards diffuse optics, calling it 'really terrible'."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:30-08:44",
        "transcript": "from MR scan like through an endoscope or something. Um, optics is tough though, right? Because either it's diffuse or it's microscopic.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:30",
        "end_time": "18:44",
        "annotations": {
            "None": "No relevant code perfectly applies to this utterance as it is a general statement about the challenges of optics in medical imaging."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:44-08:44",
        "transcript": "There's almost no in between.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:44",
        "end_time": "18:44",
        "annotations": {
            "identify gap": "Brian Pogue is highlighting a limitation in optical imaging, indicating a gap in its capabilities.",
            "critical response": "Brian Pogue is pointing out a challenge or limitation in optical imaging."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "08:45-08:45",
        "transcript": "So the",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:45",
        "end_time": "18:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "08:45-08:45",
        "transcript": "So the",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:45",
        "end_time": "18:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:18-09:18",
        "transcript": "Because of the",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:18",
        "end_time": "19:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "09:29-09:36",
        "transcript": "diffusing kind of gets rid of most adaptive optics uh in my experience.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:29",
        "end_time": "19:36",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:38-09:41",
        "transcript": "because of the the way wave is modeled or because of the",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:38",
        "end_time": "19:41",
        "annotations": {
            "develop idea": "Beck Kamilov is expanding on a previous discussion by offering reasons.",
            "offer feedback": "Beck Kamilov is providing potential explanations, which can be seen as a form of feedback."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:41-09:46",
        "transcript": "So where where does where do you lose that adaptivity in the optics?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:41",
        "end_time": "19:46",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on where adaptivity is lost in optics, indicating a need for further understanding or explanation."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "00:00-00:07",
        "transcript": "banana shape path. So you have a source and detector at the same plane, you're collecting maybe the reflected or you could do transmit it.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:07",
        "annotations": {
            "develop idea": "Mini Das is expanding on an existing concept by explaining the 'banana shape path' in imaging techniques, providing details about source and detector positioning and data collection methods."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:08-00:20",
        "transcript": "Yeah, as far as I understand like optical coherence kind of uses coherence to kind of select where you do and then there is um um there's another technique. What's Oh yeah, photoacoustic, right? And where they use uh acoustic wave to zoom.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:08",
        "end_time": "20:20",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by explaining and comparing different imaging techniques, specifically optical coherence and photoacoustic techniques."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "00:20-00:22",
        "transcript": "Right, there is.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:20",
        "end_time": "20:22",
        "annotations": {
            "Supportive response": "The utterance 'Right, there is.' expresses agreement with a previous statement, validating the discussion without adding new content."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:22-00:30",
        "transcript": "Now, seems like there's almost uh so when you want to you go to a diffuse regime, okay, of course, we lose because of scattering everything.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:22",
        "end_time": "20:30",
        "annotations": {
            "develop idea": "The speaker is elaborating on the challenges of optical imaging in the diffuse regime.",
            "identify gap": "The speaker is highlighting a limitation or challenge in optical imaging (the issue of scattering in the diffuse regime)."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:30-00:42",
        "transcript": "But then if there is some form of selectivity you can impact there, right? Where you can get information and then you can combine that with adaptive optics to kind of focus there.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:30",
        "end_time": "20:42",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by suggesting the use of selectivity and combining it with adaptive optics to improve imaging techniques.",
            "ask question": "The speaker ends with a question, indicating a request for agreement or further clarification."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:42-01:00",
        "transcript": "There was like a very nice nature communication paper, I think last year where guys were trying to go in depth by trying to do adaptive optics and compensating for diffusion. I mean the images didn't look so great, but the claims sounded good.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:42",
        "end_time": "21:00",
        "annotations": {
            "None": "No relevant code directly applies to this utterance based on the provided definitions and the emphasis on explicit observation."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:00-01:04",
        "transcript": "sort of approaches with like a guide star type refocusing, that kind of thing.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:00",
        "end_time": "21:04",
        "annotations": {
            "develop idea": "The speaker is commenting on and potentially building upon previous discussions about imaging techniques, specifically mentioning 'guide star type refocusing'.",
            "offer feedback": "The speaker is providing a suggestion or an example related to imaging techniques, which can be seen as a form of feedback."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "01:05-01:17",
        "transcript": "No, that that's the thing. So it's kind of trying to imitate guided star, but there is no real guided star. It's more like using adaptive optics and rejection of scatter by using scattering model at different depths, so there is no specific guided star.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:05",
        "end_time": "21:17",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by explaining how their approach relates to the concept of a 'guided star' in adaptive optics, providing technical details and clarification."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:18-01:18",
        "transcript": ".",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:18",
        "end_time": "21:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "01:22-01:57",
        "transcript": "larger question about that. So we want as someone who's spent their entire life on MRI. We want optics because the wealth of probes, right? The specific labeling, sensors, ratiometric imaging, that is that that's why we want and the resolution I suppose. But if we didn't need that, if we had MR specific sensors, if we had pet specific probes and you didn't you didn't need those those sensor technologies that are already established, what's left for optics? Just the resolution?",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:22",
        "end_time": "21:57",
        "annotations": {
            "develop idea": "Benjamin is expanding on the idea of the advantages of optics in imaging and questioning its unique value proposition compared to other technologies like MRI and PET.",
            "ask question": "Benjamin is posing a question about the comparative advantages of optics if other imaging modalities had similar capabilities."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "01:57-01:58",
        "transcript": "Cost. I would say cost.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:57",
        "end_time": "21:58",
        "annotations": {
            "supportive response": "The speaker is expressing a positive evaluation of cost as an advantage of optics.",
            "develop idea": "The speaker is expanding on a previous idea by providing a specific advantage of optics, which is cost."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:59-01:59",
        "transcript": "Cost.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:59",
        "end_time": "21:59",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "02:01-02:05",
        "transcript": "MR cost and then it's a speed also. I guess the speed.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:01",
        "end_time": "22:05",
        "annotations": {
            "supportive response": "The speaker is engaging with the discussion, providing a brief comment that acknowledges previous points about MRI."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:05-02:16",
        "transcript": "Also I guess non radiological. There are there is a big group of people interested in probing without ionizing radiation. Of course MR does not have that, but the cost is much less, right?",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:05",
        "end_time": "22:16",
        "annotations": {
            "Supportive response": "Mini Das is expressing agreement or validation on certain aspects of imaging modalities.",
            "Develop idea": "Mini Das is building upon previous discussions by adding her points about non-ionizing radiation and cost."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:17-02:19",
        "transcript": "And also dimensionality.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:17",
        "end_time": "22:19",
        "annotations": {
            "develop idea": "Adding another point (dimensionality) to the discussion on imaging techniques and their limitations."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:19-02:34",
        "transcript": "So it's just portable, you can take it depending on what device you are having and that's making it feasible. You can get into the surgery room and get immediate response what the tumor is before you take the biopsies.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:19",
        "end_time": "22:34",
        "annotations": {
            "Develop idea": "Uzay is expanding on the idea of using a portable device for imaging, specifically in the context of surgery rooms.",
            "Supportive response": "Uzay is expressing a positive view on the portability and feasibility of the technique."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:34-02:43",
        "transcript": "So you can identify this with this Raman spectroscopies and those things it has been shown. So it is powerful when it comes to do this kind of diagnostic purposes.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:34",
        "end_time": "22:43",
        "annotations": {
            "supportive response": "The speaker is expressing a positive evaluation of Raman spectroscopy for diagnostic purposes, showing its effectiveness and power in such applications.",
            "develop idea": "The speaker is expanding on the idea of using Raman spectroscopy for diagnostics, providing a specific example of its application and benefits."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:44-03:11",
        "transcript": "So the multi spectral aspect of it is also the the thing that you want, right? you bring upscopy, I was talking about sensors. The fact that light is multi spectral means it's never going to go away. You can't replace it with ultrasound. I don't even think you can replace it with optoacoustics just because your readout is always funnel through that um one channel pipeline of the the acoustics.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:44",
        "end_time": "23:11",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of optical imaging's advantages, specifically its multi-spectral nature.",
            "ask question": "The speaker poses a question about the replaceability of optical imaging with other modalities like ultrasound and optoacoustics."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:11-03:12",
        "transcript": "I just bring that because I think that's the pernicious problem of it.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:11",
        "end_time": "23:12",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or support for a previous point made in the discussion.",
            "develop idea": "The speaker is slightly expanding on a previous thought, providing additional perspective."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "03:13-03:30",
        "transcript": "Well, you know, your your question made me think about, you know, what about pet CT? I mean that that's actually pretty pretty awesome. Pet CT works really well. It's got, you know, in principle pet has molecular tracers for all kinds of targets.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:13",
        "end_time": "23:30",
        "annotations": {
            "supportive response": "Brian Pogue expresses agreement and positive evaluation of PET CT, indicating its effectiveness and capabilities.",
            "develop idea": "Brian Pogue elaborates on the capabilities of PET CT, expanding on its potential applications and benefits."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "03:30-03:38",
        "transcript": "And yet it's really not widely used that much. And presumably due to cost.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:30",
        "end_time": "23:38",
        "annotations": {
            "critical response": "The speaker is questioning the widespread use of PET/CT, implying potential drawbacks.",
            "offer feedback": "The speaker provides a possible reason (cost) for the limited adoption of PET/CT."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:39-03:40",
        "transcript": "But it's also not multi spectral.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:39",
        "end_time": "23:40",
        "annotations": {
            "critical response": "The speaker is providing a negative evaluation of an approach by pointing out its limitation (not being multi-spectral).",
            "None": "No other relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:40-03:41",
        "transcript": "Mini.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:40",
        "end_time": "23:41",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging Mini Das, likely referencing a previous contribution or presence in the discussion."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:41-05:11",
        "transcript": "I had a question like uh in say for example in X-ray uh lot of like say mammography, okay? So you have content scatter and uh you use scatter grid to take out the content scatter, but nowadays you have these um you know, modeling methods where you iteratively as you like even in the projection, you know, as you iteratively get the thickness, you actually model the scatter. It can be fast Monte Carlo, it can be some linear model of the scatter. Have you seen that kind of work for um like light?",
        "speaking duration": 90,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:41",
        "end_time": "25:11",
        "annotations": {
            "ask question": "The speaker is explicitly requesting information about the existence of certain modeling methods for light."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "05:12-05:14",
        "transcript": "Uh you you're talking about optical now?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:12",
        "end_time": "25:14",
        "annotations": {
            "ask question": "Mini Das is requesting clarification on whether Joyoni Dey is talking about optical imaging."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "05:14-05:18",
        "transcript": "Yeah, optical like, you know, for optical scatter iterative.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:14",
        "end_time": "25:18",
        "annotations": {
            "ask question": "The speaker is seeking clarification or information on the topic of optical scatter iterative methods."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "05:18-05:35",
        "transcript": "There are people working on scatter modeling scatter and even using that for imaging in depth. There's there's a new range of papers coming in that regard. Uh so yeah, there are people working on that uh we haven't looked at it in that.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:18",
        "end_time": "25:35",
        "annotations": {
            "develop idea": "Mini Das is expanding on the idea of scatter modeling in optical imaging, mentioning that there are people working on it and new papers are emerging.",
            "identify gap": "Mini Das mentions 'we haven't looked at it in that,' indicating a recognition of a gap in their own research."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "05:36-06:15",
        "transcript": "It seems to be like lot of the just two more minutes like yeah, so if if it seems to me lot of the answers to this is like this current catch word deep learning. So like I know CT denoising is done by deep learning. Scatter if I give a lot of you know, scatter grid with scatter grid and with like with scatter, it can possibly learn correcting the scatter.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:36",
        "end_time": "26:15",
        "annotations": {
            "Supportive response": "The speaker is expressing a positive view towards the use of deep learning for solving problems like scatter correction.",
            "Offer feedback": "The speaker is suggesting a potential application of deep learning in correcting scatter.",
            "Develop idea": "The speaker is building upon existing knowledge by suggesting that if deep learning can be used for CT denoising and potentially for correcting scatter in CT scans, it might also be applied to similar problems in optical imaging."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "06:15-06:36",
        "transcript": "Um I know I I have done some work on correcting some physical errors due to that's more of a calibration problem, it's a easier problem to solve like you know, like grating based. But you know, and deep learning the thing is after you train with millions of data after that it's fast. You just throw in one set of data and out comes you know, a cleaned image.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:15",
        "end_time": "26:36",
        "annotations": {
            "develop idea": "The speaker is expanding on their experience with correcting physical errors and discussing the potential of deep learning in this context.",
            "signal expertise": "Joyoni Dey is explicitly stating their own experience and knowledge in the field, particularly with correcting physical errors and working with deep learning methods."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "06:36-06:36",
        "transcript": "It's easy, you know, like like the computation wise it's not that hard.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:36",
        "end_time": "26:36",
        "annotations": {
            "Supportive response": "The speaker expresses a positive sentiment about the computational ease.",
            "Offer feedback": "The speaker provides feedback that the computation is not hard."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:36-06:37",
        "transcript": "Yeah, that's a good point.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:36",
        "end_time": "26:37",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes another group member's input.",
            "supportive response": "The utterance expresses agreement or validation for another group member's contributions without adding new content."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:37-07:06",
        "transcript": "I just wanted to say yeah, actually there are people doing the scatter correction in optical tomography and what so I have worked on it and published several papers on this, but the I see the one I like the most, which is I find fascinating is when you do model the scattering process itself as a convolutional neural network.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:37",
        "end_time": "27:06",
        "annotations": {
            "offer feedback": "The speaker is providing specific information and his viewpoint on the topic, which can be seen as offering feedback."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "07:06-07:07",
        "transcript": "Yeah, exactly.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:06",
        "end_time": "27:07",
        "annotations": {
            "supportive response": "Beck Kamilov is expressing agreement with a previous statement, showing a supportive response to the conversation."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:08-07:14",
        "transcript": "They are my exactly. But it's object dependent, so you have to uh.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:08",
        "end_time": "27:14",
        "annotations": {
            "develop idea": "The speaker is commenting on and building upon a previously mentioned idea about scatter correction and its object dependency.",
            "critical response": "The speaker points out a limitation of the approach mentioned, which is its object dependency."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:15-07:17",
        "transcript": "It's a little bit of a chicken and egg problem.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:15",
        "end_time": "27:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:17-07:17",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:17",
        "end_time": "27:17",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging a prior statement or contribution from another group member.",
            "supportive response": "The speaker is expressing agreement or validation for a prior statement or idea."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:18-07:23",
        "transcript": "You find the you have to start somewhere with some approximation, I guess.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:18",
        "end_time": "27:23",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:23-07:30",
        "transcript": "We are looking a little bit into this for uh X-ray uh scatter.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:23",
        "end_time": "27:30",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:30-07:50",
        "transcript": "Yeah. X-ray scatter, I know that they have some in the clinic like prime by, you know, Siemens. They have already for mammography at least even for the projection and assume they have to assume something about that equation, so they assume like a water mu, like average attenuation to for the correction of the scatter.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:30",
        "end_time": "27:50",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:50-07:50",
        "transcript": "Sorry, Mini, what say that?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:50",
        "end_time": "27:50",
        "annotations": {
            "ask question": "The speaker is requesting clarification or more information about a prior statement made by Mini Das."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:51-07:51",
        "transcript": "I'm done.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:51",
        "end_time": "27:51",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:51-07:52",
        "transcript": "Oh okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:51",
        "end_time": "27:52",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:52-07:54",
        "transcript": "I I'm just waiting for other ideas to note now.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:52",
        "end_time": "27:54",
        "annotations": {
            "None": "No relevant code strongly applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:00-08:11",
        "transcript": "We did a like my master student did recently a simple version of this because I'm working on this uh uh with a new my extra system has this MPG which is so the regular uh the regular um interferometry systems have this something called analyzer which is also acts as a scatter grid.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:00",
        "end_time": "28:11",
        "annotations": {
            "signal expertise": "The speaker explicitly states their experience and current work in the field of physics, specifically in interferometry.",
            "develop idea": "The speaker is expanding on their current project and related concepts, providing more details about their work."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:11-08:30",
        "transcript": "So they don't have that much scatter. But my system to preserve the dose, I'm not using that um analyzer. So I will now have to correct for scatter and the scatter is in the the zeroth harmonic, the in the attenuation image, not so much in the uh small angle scatter or the, you know, or the phase image.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:11",
        "end_time": "28:30",
        "annotations": {
            "signal expertise": "The speaker is explicitly stating their own expertise in the area of imaging systems, specifically regarding scatter correction.",
            "develop idea": "The speaker is expanding on existing ideas by sharing specific technical details about their system and the challenges with scatter correction."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:30-09:23",
        "transcript": "So I have to correct it. So we are we apply a simpler algorithm than like a fast Monte Carlo for the breast images like, you know, I just use a linear model and we did MLM reconstruction that works at least in simulated images from giant Monte Carlo simulated images. It seems to work. Now we are trying to do it for actual experiments. So um so I'm just saying that we can potentially try similar things for uh but it is object dependent and so it has to be a iterative process.",
        "speaking duration": 53,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:30",
        "end_time": "29:23",
        "annotations": {
            "develop idea": "The speaker is elaborating on their approach to correcting for scatter, including the use of a linear model and MLM reconstruction.",
            "identify gap": "The speaker mentions the challenge of object dependency and the need for an iterative process, implying a gap in current methods.",
            "offer feedback": "The speaker is sharing their approach and thoughts, which could be seen as offering feedback or insights into their work on scatter correction in imaging."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:00-00:57",
        "transcript": "optical diffraction tomography, but it was not reflection. So some people are interested in reflection mode in optical diffraction tomography, it was transmission of light. Now, in there there is no real depth, but it's a multicellular organisms who are collecting across and then we're using multiple scattering to get higher resolution images. And then another context where I worked on it is more like subsurface, right, imaging, so we're underground. So it's a higher uh it's more used in in oil exploration or archaeological, there they also have a scattering of of wave. But it's exactly the same model in fact. Used but in the reflection regime. Right now I'm starting something with optical well they're building a new type of optical coherence but in fact a tomography where there is a sample rotation.",
        "speaking duration": 57,
        "nods_others": 3,
        "smile_self": 25,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:57",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas related to optical diffraction tomography and its applications.",
            "signal expertise": "The speaker is explicitly stating their own expertise in the field of optical imaging and tomography."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "00:58-01:03",
        "transcript": "What's the scale of that system? We're we talking about small samples and microscopy or we're talking larger?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:58",
        "end_time": "31:03",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification about the scale of a system being discussed, indicating a need for more details."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "01:04-01:15",
        "transcript": "it's going to be microscopy. but it's going to be more than diffraction tomography. so it's not going to be just like few cells, but they want to do like a bigger kind of objects, but it's still going to be microscopy level.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:04",
        "end_time": "31:15",
        "annotations": {
            "clarify goal": "The speaker is defining and clarifying the objectives and scale of the project, specifying that it will be at the microscopy level but aims to image larger objects than current technologies.",
            "develop idea": "The speaker is elaborating on the project's scope, comparing it to existing technologies like diffraction tomography, and specifying its capabilities and limitations."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:16-02:30",
        "transcript": "I can I can mention one development that's happening right now in CT. maybe it's of interest for others. it's in spectral CT where photon counting or spectral detectors we are we are we are looking at and Anushiva also knows about this. Uh so you know, there is a big interest in using spectral data for separating material properties. Uh this could be for multiple contrast agents, it could be for density classification. Uh but one thought could be someone else has an idea related to this. Uh you know, how could you use this information? Um maybe as a prior information or or as for a combined multimodality. Here we are we are looking into these problems. So if you have ideas on this, I'd be very interested in learning more. Uh I've thought about ideas on combining with ultrasound. I think pet is another one. But I'm also very interested in thinking about optical properties. Uh how can you use this information? Um yeah, I I don't want to keep going but the idea if that if if that ignites any thought on in anyone we can.",
        "speaking duration": 74,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:16",
        "end_time": "32:30",
        "annotations": {
            "develop idea": "Mini Das is expanding on the concept of spectral CT and its applications, discussing how it can be used for separating material properties.",
            "ask question": "Mini Das is seeking input from others on how to use spectral data, asking if they have ideas related to this."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:31-02:37",
        "transcript": "And and many you you you were that's particularly in reference to multispectral X-ray detectors, is that right?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:31",
        "end_time": "32:37",
        "annotations": {
            "ask question": "The utterance is a question seeking clarification or confirmation about a previous statement or topic, specifically regarding multispectral X-ray detectors."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:37-02:51",
        "transcript": "Yes, you can do it with either at the detector end or you can separate it by by by I guess eliminating with different bandwidth of X-ray, but then you have to do it multiple times. But at the detector end you can do it with one shot. Yeah.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:37",
        "end_time": "32:51",
        "annotations": {
            "develop idea": "Mini Das is elaborating on existing ideas regarding spectral data utilization in CT scans.",
            "offer feedback": "Mini Das is providing specific information on approaches to using spectral data.",
            "signal expertise": "Mini Das is demonstrating her expertise in imaging and spectral CT."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:52-03:41",
        "transcript": "But uh the thought I was having is more also in regards to uh would something like that help with combining with optical uh with a very low dose for example CT, right? since I picked up this near infrared back again, I'm seeing all the problems I saw before and I haven't seen solutions. Only solution I'm seeing is you can do the differential contrast easily, but you have to generate the differential contrast. In some problems the contrast occurs like in brain imaging, you're doing a task and or or you could you could be like doing something and there is a natural contrast in blood volume change, right? There is that's happening. But all problems don't lend to those contrast. So how do you how do you tackle this problem, right?",
        "speaking duration": 49,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:52",
        "end_time": "33:41",
        "annotations": {
            "ask question": "Brian is asking how to tackle the problem of generating contrast in optical imaging.",
            "identify gap": "Brian identifies a gap in current solutions for generating contrast in optical imaging.",
            "offer feedback": "Brian provides his insights based on experience with optical imaging and its challenges."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:41-03:44",
        "transcript": "I'm I'm happy to complain about that aspect of MRI.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:41",
        "end_time": "33:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:44-03:45",
        "transcript": "What about do we use uh MR contrast agents?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:44",
        "end_time": "33:45",
        "annotations": {
            "ask question": "The speaker is requesting information about using MR contrast agents, which is a clear example of asking a question."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:45-03:46",
        "transcript": "Oh, absolutely. Sure.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:45",
        "end_time": "33:46",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous suggestion about using MR contrast agents."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:46-04:34",
        "transcript": "If you can get a fold change with your contrast agent, like you are you're styling. But for sensors and things like that, that's one of the things that's limited. Nanoparticles can have a large signal change, but once you get them in vivo, they don't fill the whole volume of your imaging of your sort of imaging voxel. So even if you got a threefold signal change from a from a nanoparticle, it's only taking up a small percentage of your voxel and so it ends up just being a few percent signal at the end. always.",
        "speaking duration": 48,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:46",
        "end_time": "34:34",
        "annotations": {
            "critical response": "The speaker is discussing a limitation of nanoparticles as contrast agents, which is a critical evaluation of an approach.",
            "identify gap": "The speaker highlights that nanoparticles do not fill the whole volume of the imaging voxel, indicating a gap in current technology."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "04:34-04:34",
        "transcript": "I was.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:34",
        "end_time": "34:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Morteza Mahmoudi, MSU",
        "timestamp": "04:34-05:57",
        "transcript": "Yeah, I was I was about to make comment about like. So it depends on like how many basically first of all it depends on the like what you want to image. For example, if you want to image a cell, then it depends on how many nanoparticles basically gets into the cells. So it define basically the resolution. But the other interesting aspect about nanoparticles is that the validity of the like the signal is okay, but it's not it it may not correspond with like what you're looking for. For example, we label like some cells with iron oxide nanoparticles and that cells we basically um put the reporter gene to basically activate that with luciferase. So we can also get a bioluminescence image of the of the cells that we inject them. So what happens was that even though when the cells are dead, you get the signal from oxide nanoparticles for like a few days. So when using nanoparticles, you can increase concentration, but at the same time you need to make sure that it's safe and you need to make sure that they don't affect the like the functionality of the cells or like activate some like uh I don't know something like apoptotic like pathways there. So for nanoparticles, I would say we always need another modality just to make sure that what we see is real.",
        "speaking duration": 83,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:34",
        "end_time": "35:57",
        "annotations": {
            "identify gap": "The speaker highlights the need for another modality to ensure what is seen is real when using nanoparticles.",
            "develop idea": "The speaker elaborates on the challenges of using nanoparticles in imaging, including signal validity and safety.",
            "supportive response": "The speaker supports the idea of using multiple modalities for imaging with nanoparticles."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "05:58-06:00",
        "transcript": "In terms of using them as a die.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:58",
        "end_time": "36:00",
        "annotations": {
            "offer feedback": "The speaker provides a comment on using them as a die, offering a perspective or insight.",
            "develop idea": "The speaker is contributing to an ongoing discussion about imaging techniques and applications."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:00-06:17",
        "transcript": "as not just to detect their presence, but to use sort of aggregation based sensors and things like that. They work very well in vitro, but to view them in a living animal, um that experience you have to have a zero baseline to start with and then you can only image within a single um session.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:00",
        "end_time": "36:17",
        "annotations": {
            "identify gap": "The utterance highlights a limitation or gap in using nanoparticles for in vivo imaging - the need for a zero baseline and the limitation to a single imaging session.",
            "offer feedback": "The utterance provides insight into the challenges of in vivo imaging with nanoparticles, which could be seen as offering feedback on the approach."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:17-06:17",
        "transcript": "So.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:17-06:17",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:17-06:20",
        "transcript": "Benjamin, can you comment on in MRI currently.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:20",
        "annotations": {
            "ask question": "The speaker is requesting information or thoughts from Benjamin regarding the current state or aspects of MRI."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:20-06:20",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:20",
        "end_time": "36:20",
        "annotations": {
            "None": "The utterance is a simple acknowledgment without adding new content or context."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:20-06:30",
        "transcript": "What are the applications where the contrast agent is not needed or not used?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:20",
        "end_time": "36:30",
        "annotations": {
            "ask question": "The speaker is requesting information about applications where contrast agents are not needed or not used."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:30-06:30",
        "transcript": "Uh I I don't know.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:30",
        "end_time": "36:30",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:30-06:30",
        "transcript": "Or typically is it always used with contrast agent at this point?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:30",
        "end_time": "36:30",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on the use of contrast agents in MRI."
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "06:30-07:32",
        "transcript": "MRI is there an application where contrast agent is not required? Yeah, I would say probably only maybe 20 to 30% of MRI scans are with contrast. The bulk of them are meant to um do things like diagnosis stroke requires no contrast. diffusion weighted imaging, T2 weighted imaging can can make the stroke diagnosis. A lot of MRI right now is basically anatomic so that stroke is one where there's like functional data coming from the diffusion, but um the rest of them are mostly anatomy. So lumbar spine MRIs to look for whether or not there's a narrowed narrow frame where the nerve is coming out to say that's why this person's having, you know, pain. So they're it's pretty much workhorse anatomic technique with um high end contrast enhancement used for like tumor characterization, infection characterization. Um uh you don't even need it to do like gallbladder, you know, MRCP to characterize the biliary system. So and I think.",
        "speaking duration": 62,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:30",
        "end_time": "37:32",
        "annotations": {
            "clarify goal": "The speaker discusses the objectives and common practices in MRI scans regarding contrast agent usage."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "07:32-07:32",
        "transcript": "Enter it.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:32",
        "end_time": "37:32",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "07:32-07:33",
        "transcript": "Yeah, go ahead.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:32",
        "end_time": "37:33",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "07:33-08:10",
        "transcript": "Oh, and and the big push in that is so the the machine learning approaches they take is okay, well how can we sort of automatically score these things and just do pathology with a computer. It always ends up being some like this thing is slightly larger here and so by doing PCA, we can now have like a fast way of of seeing that that thing is slightly smaller. But it all comes back to like just training against the human eye.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:33",
        "end_time": "38:10",
        "annotations": {
            "develop idea": "The speaker is elaborating on existing ideas about machine learning approaches in pathology, discussing how they work and their limitations.",
            "clarify goal": "The speaker is defining what these machine learning approaches are trying to accomplish, specifically in terms of automating pathology tasks."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "00:00-00:48",
        "transcript": "contrast enhance space, as Mark was saying, the predominant contrast agent used in MRI is your blood, right? Like that's what we're looking at. We're looking at blood flow, we're looking at a bleed, etc. Now in the in the contrast enhance space, it's not as commonly used because it's not that necessary, but uh these gadolinium agents and these targeted agents, they're highly limited because they are they have to carry a large molecule around with them. So they're highly limited to mostly vascular targets. We're looking for some vascular marker of whatever that is, or we're counting on um your agent leaking out of the blood to to mark whatever you're going for. And that's again very limiting in in the standard sort of T1, T2 uh regime.",
        "speaking_duration": 48,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:48",
        "annotations": {
            "develop idea": "The speaker expands on existing ideas about MRI contrast agents, discussing their applications and limitations.",
            "identify gap": "The speaker highlights the limitation of current MRI contrast agents to vascular targets.",
            "offer feedback": "The speaker provides feedback on the use and limitations of gadolinium agents and targeted agents in MRI."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "00:48-01:30",
        "transcript": "For us for for making sensors which are almost exclusively used um just as proof of concept papers and sometimes in model organisms. Those things almost always are administered either like continual IV or being directly infused into the brain or being infused into whatever space they want to be in just because they have they're these macro molecular complexes and the only way to get them to work is to pump everything you need into the spot you're looking for. And in those situations it's almost like there's no reason to do that 3D because you know where you're putting it. It's uh it's almost academic to say that the imaging is not invasive because the delivery is definitely not uh invasive.",
        "speaking_duration": 42,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:48",
        "end_time": "41:30",
        "annotations": {
            "Develop idea": "The speaker is expanding on how they use sensors in their research, providing details about their application and limitations.",
            "Critical response": "The speaker critiques the concept of 'non-invasive' imaging when the method of delivery for sensors is invasive.",
            "Identify gap": "The speaker highlights a gap in current research methods, specifically the invasiveness and limitations of using macro molecular complexes as sensors."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:30-01:36",
        "transcript": "Can I um I'm just going to interrupt for a second and Mini um how's the scribing going? Are you are you",
        "speaking_duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:30",
        "end_time": "41:36",
        "annotations": {
            "ask question": "The speaker is requesting information about the status of the scribing process."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:37-01:40",
        "transcript": "Yeah, I'm taking",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:37",
        "end_time": "41:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:37-01:40",
        "transcript": "just noticed the Google Doc has nothing in it. So I'm just going",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:37",
        "end_time": "41:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:40-01:45",
        "transcript": "No, no, no. I'm I'm taking I'm taking manual notes, but I can't write on the Google Doc too.",
        "speaking_duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:40",
        "end_time": "41:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:45-01:47",
        "transcript": "Okay. Very retro of you. Yeah.",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:45",
        "end_time": "41:47",
        "annotations": {
            "express humor": "The speaker makes a joke about being 'retro,' which is a humorous comment."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:47-01:50",
        "transcript": "Hopefully everybody will pop out in the end.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:47",
        "end_time": "41:50",
        "annotations": {
            "encourage participation": "The speaker invites others to contribute to the discussion by expressing hope that everybody will participate."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:50-01:50",
        "transcript": "Okay.",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:50",
        "end_time": "41:50",
        "annotations": {
            "None": "No relevant code applies to this utterance as it is too short and only serves as an acknowledgment."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:51-02:15",
        "transcript": "I'm relying on the collective memory here of everyone. Okay. But I guess",
        "speaking_duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:51",
        "end_time": "42:15",
        "annotations": {
            "None": "No relevant code explicitly applies to this utterance as it is more of a passing comment than a substantial contribution to the discussion."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:56-01:59",
        "transcript": "I'm just wondering if we should start putting in sort of a",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:56",
        "end_time": "41:59",
        "annotations": {
            "ask question": "The speaker is explicitly asking if they should start doing something, indicated by 'I'm just wondering if'.",
            "propose new idea": "The speaker is suggesting or proposing the idea of starting something new, indicated by 'if we should start putting in sort of a'."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:59-02:15",
        "transcript": "I should bring up the post point uh of uh what what are the bottlenecks in rapid analysis. We don't have to follow the the bullet point but when when I I assume they're talking about human analysis or machine analysis, maybe we can have some point on that since it's one of the bullet points there.",
        "speaking_duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:59",
        "end_time": "42:15",
        "annotations": {
            "ask question": "The speaker asks for clarification on what 'rapid analysis' refers to, specifically if it's about human or machine analysis.",
            "process management": "The speaker is managing the discussion flow by suggesting a topic to discuss.",
            "encourage participation": "The speaker is inviting others to discuss or provide input on the topic of bottlenecks in rapid analysis."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:21-02:24",
        "transcript": "Well there's a comment from Mark here too about bottlenecks and rapid analysis.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:21",
        "end_time": "42:24",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "02:25-02:33",
        "transcript": "Uh I just put in there what what the questions were posed in there. There there's no useful information other than what we're supposed to be thinking about.",
        "speaking_duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:25",
        "end_time": "42:33",
        "annotations": {
            "critical response": "Mark Sellmyer is providing a negative evaluation of the usefulness of the posed questions and the information provided."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:34-02:37",
        "transcript": "Okay, got you. So refocusing effort.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:34",
        "end_time": "42:37",
        "annotations": {
            "supportive response": "The utterance 'Okay, got you' serves as a supportive response, acknowledging a previous statement.",
            "process management": "The phrase 'So refocusing effort' acts as a process management statement, aiming to redirect the discussion or efforts."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "02:37-02:39",
        "transcript": "There's um go ahead. Sorry.",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:37",
        "end_time": "42:39",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "02:41-03:21",
        "transcript": "I I have another question another thing point sorry I kind of bring up these new points at the last minute I'm so sorry but uh it just when it occurs to me so I can't help it but somebody said that uh what other imaging modalities lend themselves to 3D analysis as well. I know that ultrasound micro bubbles are useful but I don't know if that's useful for microscopy. Anybody has any thoughts or we can quickly skim over that. Like it's a very high contrast mechanism.",
        "speaking_duration": 40,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:41",
        "end_time": "43:21",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on other imaging modalities that lend themselves to 3D analysis, specifically mentioning ultrasound microbubbles and their potential use in microscopy."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:22-03:46",
        "transcript": "I mean another one I was thinking which has a big challenge it's one project I have is like light sheet microscopy. I don't know if anybody worked with it. Uh so that can be done as a tomography setup where you take you know orthogonal views to each other or even several views and the challenge is you have a data problem. So they do a 3D scan every two seconds over several weeks to watch how organism grows.",
        "speaking_duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:22",
        "end_time": "43:46",
        "annotations": {
            "develop idea": "The speaker is expanding on an idea related to imaging techniques, discussing light sheet microscopy and its challenges.",
            "ask question": "The speaker asks if anybody has worked with light sheet microscopy, seeking information or expertise."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:46-04:07",
        "transcript": "So now nobody's going to sit and look at it. I mean, maybe somebody will but across not across the whole week. So how to find and analyze that data set in a way that for biologist it's meaningful and they can kind of easily scan through it to find important parts in it and so on. That's kind of a different challenge but it's also 3D challenge, 3D plus time.",
        "speaking_duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:46",
        "end_time": "44:07",
        "annotations": {
            "identify gap": "Beck Kamilov recognizes a gap in current methods for analyzing large datasets, specifically in making the data meaningful and easily accessible for biologists.",
            "ask question": "Beck Kamilov asks how to find and analyze the dataset in a way that is meaningful for biologists and easily scannable."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "04:07-04:17",
        "transcript": "Well and and you need labels too to get um 3D light sheet microscopy working. Yeah. Sometimes. Yeah. Most times yes.",
        "speaking_duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:07",
        "end_time": "44:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "04:18-04:41",
        "transcript": "I was thinking if we can convert that problem to some sort of computer vision task because I do lots of work on like anomaly detection and then like",
        "speaking_duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:18",
        "end_time": "44:41",
        "annotations": {
            "propose new idea": "The speaker proposes converting the problem into a computer vision task.",
            "develop idea": "The speaker develops their idea by specifying their expertise in anomaly detection.",
            "signal expertise": "The speaker signals their expertise in anomaly detection."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "04:41-05:24",
        "transcript": "in order to do like really real time uh processing so that if you're gathering so much data and then you don't want to have them all save in the memory, you are able to uh like kind of like as if um get your system to learn what is the spatial temporal uh changes in a normal condition and then uh like have your network train so that kind of look for anomaly and then kind of have the output to the system to tell the user that okay this is the data that is important and then they are classifier that from the memory and pipelining point of view, they are very compatible to be implemented, you know, to the FPGA so that you can connect directly the output of your detector like ADC to the FPGA.",
        "speaking_duration": 43,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:41",
        "end_time": "45:24",
        "annotations": {
            "propose new idea": "The speaker introduces a specific approach to handling data processing challenges using machine learning for anomaly detection.",
            "develop idea": "The speaker expands on the proposed idea, discussing details such as learning normal spatial-temporal changes and implementation on FPGA.",
            "identify gap": "The speaker highlights the challenge of processing large data in real-time without saving it, implying a gap in current methods."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "05:24-05:35",
        "transcript": "So then like if I can learn more about, you know, that problem, maybe we have like some good discussion to go and see how like the anomaly detection task can be apply in order to reduce the data in your application.",
        "speaking_duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:24",
        "end_time": "45:35",
        "annotations": {
            "encourage participation": "The speaker is inviting others to discuss and explore the application of anomaly detection tasks to reduce data in their application, encouraging participation and sharing of ideas."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "05:45-06:07",
        "transcript": "Yeah, that's already become very popular in for two photon um functional imaging. So people are doing um G camp, which is this calcium sensitive um fluorophore and they'll image this whole field of tens of thousands of neurons",
        "speaking_duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:45",
        "end_time": "46:07",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by explaining two-photon functional imaging and its applications.",
            "signal expertise": "The speaker is explicitly stating their knowledge and expertise in two-photon functional imaging."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:07-06:26",
        "transcript": "and they'll train in specific activities and then use a classifier to kind of build out what is the typical response to that. And then once they have their classifier laid out, then they'll they'll start challenging that stimuli with different things and they'll look for the shifts in the network using that anomaly detection.",
        "speaking_duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:07",
        "end_time": "46:26",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by explaining how classifiers are trained for anomaly detection in two-photon functional imaging.",
            "signal expertise": "The speaker is demonstrating their expertise in two-photon functional imaging and anomaly detection methods."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:26-06:35",
        "transcript": "But they're it's it's surprising because they do these and it's just this like um MATLAB support vector machines model and they still get really interesting stuff out of it. Yeah, I think there's a lot of of growth for that.",
        "speaking_duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:26",
        "end_time": "46:35",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by providing an example of how simple models can yield interesting results.",
            "acknowledge contribution": "The speaker is recognizing the value of using MATLAB support vector machines models.",
            "supportive response": "The speaker is expressing agreement and optimism about the approach."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "06:36-06:37",
        "transcript": "I think it's coming, you know.",
        "speaking_duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:36",
        "end_time": "46:37",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement or a positive evaluation without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "06:37-06:41",
        "transcript": "because like last year",
        "speaking_duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:37",
        "end_time": "46:41",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "06:41-07:10",
        "transcript": "Zylinx uh like kind of give out a uh FPGA that has three 32 billion transistor is almost as much as you know the neurons in our brain and it's 80k. So it's not so super expensive and then like even before we had to have all the list data and then do the processing, but now the technology is like really tough time of flight pit that maybe soon we can get rid of even image reconstruction.",
        "speaking_duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:41",
        "end_time": "47:10",
        "annotations": {
            "signal expertise": "The speaker explicitly discusses technological details and their implications, showing expertise.",
            "propose new idea": "The speaker speculates about a potential future technological advancement (eliminating the need for image reconstruction)."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "07:10-07:17",
        "transcript": "So I think that regarding the question for our topic that how we can like go fast and then like kind of kind of reduce amount of the data.",
        "speaking_duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:10",
        "end_time": "47:17",
        "annotations": {
            "propose new idea": "The speaker introduces a suggestion related to speeding up and reducing data amount.",
            "summarize conversation": "The speaker references a previous question or topic, indicating a summary or reflection."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "07:17-07:21",
        "transcript": "I'm excited that kind of from the hardware point of view.",
        "speaking_duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:17",
        "end_time": "47:21",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "07:21-07:35",
        "transcript": "the technology is at a point that soon we are going to see more advances regarding the data processing and then, you know, just like combining the data in a real time format.",
        "speaking_duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:21",
        "end_time": "47:35",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "07:40-07:41",
        "transcript": "Another thing I was thinking",
        "speaking_duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:40",
        "end_time": "47:41",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "07:41-07:43",
        "transcript": "Okay, sorry.",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:41",
        "end_time": "47:43",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:43-07:43",
        "transcript": "I",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:43",
        "end_time": "47:43",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "07:44-07:44",
        "transcript": "I was going to say",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:44",
        "end_time": "47:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "07:44-08:06",
        "transcript": "you know, we have 15 minutes so let me try something here. I'd like uh each of us to think where could we have the most impact? You know, of all the topics we've discussed, you know, where could you um what most interests you and what do you think that would have the most impact and we could just go through and have people and then I'm going to have you write it down on the Google Doc to help out.",
        "speaking_duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:44",
        "end_time": "48:06",
        "annotations": {
            "assign task": "Brian Pogue assigns the task of writing down thoughts on a Google Doc."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "08:06-08:12",
        "transcript": "I started writing on the Google Doc the notes I have. Okay. Do you see?",
        "speaking_duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:06",
        "end_time": "48:12",
        "annotations": {
            "assign task": "The speaker informs the group she has started writing notes on the Google Doc, which can be seen as assigning a task or sharing a resource.",
            "clarify goal": "The speaker checks if others can see the Google Doc, aiming to clarify if the goal of sharing is being met."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "08:12-08:14",
        "transcript": "Do you see anything right now?",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:12",
        "end_time": "48:14",
        "annotations": {
            "process management": "The speaker is checking on the status of a shared Google Doc, facilitating collaboration and managing the meeting flow."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "08:14-08:14",
        "transcript": "Yep.",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:14",
        "end_time": "48:14",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "08:15-08:16",
        "transcript": "Yeah, so there's sort of a couple categories there, yeah.",
        "speaking_duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:15",
        "end_time": "48:16",
        "annotations": {
            "supportive response": "The utterance expresses agreement or acknowledgment of a previous point, indicating a supportive response without adding new content."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:16-08:21",
        "transcript": "I feel like I can probably contribute most to the scatter connection.",
        "speaking_duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:16",
        "end_time": "48:21",
        "annotations": {
            "signal expertise": "The speaker is explicitly stating their potential area of contribution, signaling their expertise or interest in the scatter connection."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:21-08:27",
        "transcript": "And um but uh as far as I had the most impact that I think what Dr. Shiva last um uh said was very interesting like most impactful.",
        "speaking_duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:21",
        "end_time": "48:27",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges Dr. Shiva's input by stating his last statement was very interesting and like most impactful."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "08:27-08:30",
        "transcript": "Okay, so get you get you to jot that down.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:27",
        "end_time": "48:30",
        "annotations": {
            "process management": "The speaker is instructing someone to jot down information, which is related to managing the meeting process."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "08:36-08:39",
        "transcript": "Would it be possible to share the link for the Google Doc?",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:36",
        "end_time": "48:39",
        "annotations": {
            "process management": "The speaker is asking to share a resource (the link for the Google Doc) to facilitate collaboration and information exchange within the group."
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "00:00-00:03",
        "transcript": "I I am typing just a second just because Dr.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 66.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:03",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:03-00:11",
        "transcript": "Yeah, yeah, so we're all going to collectively help you, Minnie. We're we're it's going to be nine people writing the summary notes here.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 25.0,
        "smile_other": 66.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:03",
        "end_time": "50:11",
        "annotations": {
            "process management": "The speaker is organizing the group's work process by stating they will collectively help Minnie write summary notes."
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "00:11-00:12",
        "transcript": "Also the uh",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:11",
        "end_time": "50:12",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:12-00:22",
        "transcript": "So who else? Where where else could you think that the maximum impact would be?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:12",
        "end_time": "50:22",
        "annotations": {
            "encourage participation": "invites someone else in the group to contribute their expertise, opinions or ideas"
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "00:22-01:24",
        "transcript": "I I can talk I I'm typing so I I can also talk. You know, as I kind of got to at the very beginning, my my issue is that there is a lot of data there's a lot of information that can be from pathology about the different biochemical processes that are in a tissue. It could also be a little bit at a higher scale like what cells are present in that tissue. So a little larger scale, cellular micron level or micrometer level. Um, and then how do you take that data set, that 3D data set from pathology across the tissue, you know, tissue clearing technique, whatever it is that gave you really nice resolution and correlate that with the the MRI signals, the spectroscopic signal, the pet signal and build this like map of like what what is actually going on? Is is the is the imaging signal reflective of some of the more detailed pathology.",
        "speaking duration": 62,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:22",
        "end_time": "51:24",
        "annotations": {
            "ask question": "The speaker asks a question about whether the imaging signal reflects detailed pathology.",
            "develop idea": "The speaker expands on the idea of correlating pathology data with imaging signals.",
            "identify gap": "The speaker identifies a gap in current capabilities regarding correlating detailed pathology with imaging signals."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:25-01:26",
        "transcript": "Yeah, or even could you use like machine learning to sort of learn",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:25",
        "end_time": "51:26",
        "annotations": {
            "propose new idea": "The speaker suggests using machine learning to learn from data, introducing a new approach to tackle the problem at hand."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:26-01:33",
        "transcript": "what the underlying causes of the MR signature is.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:26",
        "end_time": "51:33",
        "annotations": {
            "code name": "ask question",
            "explanation": "The speaker is requesting information about the underlying causes of the MR signature, seeking clarification or understanding of a topic discussed in the context of imaging modalities."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:35-01:36",
        "transcript": "So you're going to write that out?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:35",
        "end_time": "51:36",
        "annotations": {
            "ask question": "Brian Pogue is seeking confirmation or information about whether someone is going to write something out."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "01:36-01:36",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:36",
        "end_time": "51:36",
        "annotations": {
            "supportive response": "The utterance 'Yeah' is a simple acknowledgment that expresses agreement or validation for a prior statement, fitting the definition of a supportive response."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:37-01:38",
        "transcript": "Okay, five words.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:37",
        "end_time": "51:38",
        "annotations": {
            "process management": "Managing the discussion flow by requesting a concise summary."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:43-01:44",
        "transcript": "Maybe 10.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:43",
        "end_time": "51:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:45-01:45",
        "transcript": "Anybody else?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:45",
        "end_time": "51:45",
        "annotations": {
            "encourage participation": "The speaker is inviting others in the group to contribute their thoughts or ideas."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:50-01:58",
        "transcript": "And you know, this can be specific to your expertise base or just what you think is going to be have the maximum impact.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:50",
        "end_time": "51:58",
        "annotations": {
            "encourage participation": "The speaker is inviting participants to contribute their thoughts based on their expertise or potential impact."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:58-03:20",
        "transcript": "I can get in here. So I I do find this question actually from the beginning a little bit broad because each modality has strength for different types of diseases. So you can't use one modality for all types of diseases you will end up and that's obvious. And for example, you lung imaging with MRI without using hyperpolarize it is it is really difficult and but you can get very well x-rays and CTs from for lung imaging. So that is my main problem. So it is disease specific. And the second thing if what what I would like to do is most likely to increase the accuracy accuracy because MRI, I'm an MRI physicist, multi contrast, flexible contrast acquisition. So you can tailor the spins depending on however you want and generate the different contrast for different parameters. So you do have million parameters and it all affects the contrast. So that you can tailor the acquisition for lung imaging, but that doesn't necessarily mean it's going to be very better than x-ray. It can come close enough, maybe. Uh, but that is the limitation. We all know that. So that is most likely I might contribute to this question in a way that I can accelerate and the acquisition and increase the accuracy of the findings.",
        "speaking duration": 82,
        "nods_others": 0,
        "smile_self": 20.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:58",
        "end_time": "53:20",
        "annotations": {
            "signal expertise": "Uzay Emir explicitly states his own expertise as an MRI physicist.",
            "identify gap": "He points out the limitation of MRI in lung imaging without hyperpolarization.",
            "offer feedback": "Uzay Emir discusses potential improvements in MRI's accuracy and acquisition speed."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:20-03:24",
        "transcript": "Okay, so five if you can summarize that in five to 10 words.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:20",
        "end_time": "53:24",
        "annotations": {
            "process management": "The speaker is managing the discussion flow by asking for a summary.",
            "ask question": "The speaker is requesting a summary, which is a question."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "03:27-03:29",
        "transcript": "I think the I think the Google Doc crashed.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:27",
        "end_time": "53:29",
        "annotations": {
            "process management": "The speaker is commenting on a technical issue affecting the collaborative document, which impacts the meeting's process."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "03:31-03:31",
        "transcript": "Really?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:31",
        "end_time": "53:31",
        "annotations": {
            "process management": "The speaker is reacting to a statement about the Google Doc crashing, indicating a concern about the meeting process."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "03:33-03:34",
        "transcript": "No, I am writing.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:33",
        "end_time": "53:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:36-03:39",
        "transcript": "I think you just crashed the whole Google. You cannot even search anymore.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:36",
        "end_time": "53:39",
        "annotations": {
            "process management": "The speaker is addressing an issue with the collaborative tool (Google Doc) that is being used for the meeting, which affects the group's ability to continue their work efficiently."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "03:43-03:44",
        "transcript": "I can write.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:43",
        "end_time": "53:44",
        "annotations": {
            "signal expertise": "Uzay Emir explicitly states his capability to write, signaling his expertise or capability in performing this specific task within the context of the meeting.",
            "process management": "By stating he can write, Uzay Emir is contributing to the management of the group's activity, specifically addressing the issue at hand (the Google Doc crashing)."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:52-03:55",
        "transcript": "I think maybe couple of people tried to open it at the same time, I don't know.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:52",
        "end_time": "53:55",
        "annotations": {
            "supportive response": "Mini Das provides a possible explanation for the Google Doc crash, showing engagement and support for resolving the issue."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "03:58-04:02",
        "transcript": "I can see anonymous fox and anonymous bat and anonymous blob fish.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:58",
        "end_time": "54:02",
        "annotations": {
            "process management": "The speaker is commenting on a technical issue related to collaboration (sharing a Google Doc) and its consequences."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:03-04:05",
        "transcript": "I see anonymous rhino. It might be you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:03",
        "end_time": "54:05",
        "annotations": {
            "express humor": "The speaker makes a joke about seeing 'anonymous rhino' and suggests it might be another participant, showing a lighthearted or humorous tone."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:09-04:18",
        "transcript": "What else? We talked about uh we talked a lot about optical systems about diffuse measurement versus microscopy.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:09",
        "end_time": "54:18",
        "annotations": {
            "ask question": "Brian Pogue is seeking more information or ideas as indicated by 'What else?'",
            "summarize conversation": "Brian Pogue is summarizing previous discussions on optical systems, diffuse measurement, and microscopy."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "04:18-04:33",
        "transcript": "I like to build off I like to think about multimodality systems to reduce the the the need for the data intensiveness or maybe even make the problem better condition in one one or the other.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:18",
        "end_time": "54:33",
        "annotations": {
            "propose new idea": "The speaker introduces the idea of using multimodality systems to reduce data intensiveness and make problems better conditioned.",
            "develop idea": "The speaker expands on her thoughts about multimodality systems, suggesting potential solutions."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:33-04:34",
        "transcript": "Okay. Do you want to jot that down on the",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:33",
        "end_time": "54:34",
        "annotations": {
            "Ask question": "The speaker is asking a question about what others want to do regarding documenting their discussion.",
            "Process management": "The speaker is managing how the group's discussion is documented."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:34-04:39",
        "transcript": "Excel or the the Google Doc?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:34",
        "end_time": "54:39",
        "annotations": {
            "process management": "The speaker is asking about using Excel or the Google Doc for organizing and sharing information during the meeting."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "04:40-05:03",
        "transcript": "To build off something was saying that like no one disease or organ, there's no one size fits all answer to that. And we see that a lot in our in model organisms. Uh, we we talked about light sheet microscopy.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:40",
        "end_time": "55:03",
        "annotations": {
            "develop idea": "The speaker is expanding on a previous idea about the complexity of imaging different diseases and organs.",
            "acknowledge contribution": "The speaker references and builds upon something someone else said.",
            "supportive response": "The speaker's statement supports and agrees with the previous discussion about the complexity of the problem."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "05:03-06:02",
        "transcript": "You're not going to use light sheet microscopy to diagnose neurodegenerative disorder in a person, right? But it is an incredible tool for looking at model organisms. It's it takes advantage of just the host of light based technologies we have available and we wouldn't have biomedical research without that. So how do you connect these clinically accessible imaging modalities like MRI where you can't see anything. You can see structures, you can tag a few things, maybe some spectroscopy, but compared to what light can do, it's just the the tiniest scratch, um, mechanistically speaking. So how do you relate those two imaging modalities to get the maximum value from an a a research and analytical modality and a more clinically accessible or clinically relevant modality. I think for me that's that's always been my sort of challenge, uh, coming up as was trained as a as a biologist and then went into biophysics. How do you connect those two things?",
        "speaking duration": 59,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:03",
        "end_time": "56:02",
        "annotations": {
            "identify gap": "Recognizing the gap in current capabilities to connect research-oriented imaging modalities with clinically accessible ones.",
            "ask question": "Implicitly asking how to bridge the gap between research and clinical imaging modalities.",
            "develop idea": "Elaborating on the challenge and potential of integrating different imaging modalities for maximum value."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:03-06:06",
        "transcript": "That that sounds similar sort of to what Mark was saying, I think a little bit of",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:03",
        "end_time": "56:06",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes another group member's (Mark) input.",
            "supportive response": "The utterance expresses agreement or validation for Mark's contribution without adding new content."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "06:07-06:09",
        "transcript": "I think it's it's a good idea, that's why.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:07",
        "end_time": "56:09",
        "annotations": {
            "supportive response": "The speaker expresses agreement or validation for a prior contribution without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:10-06:11",
        "transcript": "Yeah, yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:10",
        "end_time": "56:11",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:11-06:12",
        "transcript": "Anybody who has to interact with with uh",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:11",
        "end_time": "56:12",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "06:12-06:26",
        "transcript": "pathology and then they go into the deal with the radiologist and you're like, you're saying this gray blob is is the the root of the mechanism behind whatever that disease we're talking about it. It's an extremely frustrating experience.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:12",
        "end_time": "56:26",
        "annotations": {
            "critical response": "The speaker is expressing frustration and a negative evaluation of the interaction between pathology and radiology, specifically how radiologists interpret imaging results."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "06:28-07:05",
        "transcript": "because then you go back to the biologist and like here's a, you know, extremely rich data set with a thousand different transcripts all labeled in 3D space and we still don't know what the mechanism is. And to see that huge dichotomy and those scales of data and the just the richness of the data set you have, it's it's just the gap is like overwhelming to to see.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:28",
        "end_time": "57:05",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes a gap in understanding and data translation between biologists and clinicians, highlighting the challenge in bridging the two.",
            "clarify goal": "The speaker is also reflecting on the goal of improving this translation or understanding, though indirectly."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:05-07:05",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:05",
        "end_time": "57:05",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "07:06-08:04",
        "transcript": "Just like to build on the existing discussion, uh, we might be looking at a subset of the population or disease application where more concerned about the free moving human body rather than those um, you know, given location or given time point. So I think what we can contribute is uh, is there's um, further development with a need for the long-term and continuous monitoring capability, we can make that try to be uh conformal and deployed onto the body and to allow for the uh long-term longitudinal study of the uh disease because sometimes when we have this one a snapshot measurement, it might be limited, but when we correlate the information your long run or uh from multiple time points, that will certainly provide much more uh useful information.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:06",
        "end_time": "58:04",
        "annotations": {
            "develop idea": "Larry is expanding on existing ideas by suggesting a focus on free-moving human bodies and long-term monitoring.",
            "identify gap": "Larry identifies a gap in current capabilities, which is the need for long-term and continuous monitoring.",
            "supportive response": "The tone of Larry's statement is supportive and constructive.",
            "offer feedback": "Larry offers a specific suggestion for how his work could contribute to the discussion."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:04-08:04",
        "transcript": "Mhm.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:04",
        "end_time": "58:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:06-08:07",
        "transcript": "Okay. I'll drop that on the Google.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:06",
        "end_time": "58:07",
        "annotations": {
            "process management": "Brian Pogue is managing the flow of information by agreeing to add notes to a shared Google Doc."
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "08:08-08:10",
        "transcript": "Yeah, please do, yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:08",
        "end_time": "58:10",
        "annotations": {
            "Supportive response": "Larry Cheng is expressing agreement and a positive sentiment towards an action suggested."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:10-08:27",
        "transcript": "As we're doing that, I would I guess maybe push you to think about what's the bottleneck and what's the solution, you know, if you could maybe try to flush it out a little bit, you know, what in each of these problem areas or applications, what's the bottleneck and what's the solution, you know?",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:10",
        "end_time": "58:27",
        "annotations": {
            "code name": "process management",
            "explanation": "Brian Pogue is guiding the group's discussion and encouraging them to think about bottlenecks and solutions in their problem areas."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "08:28-09:59",
        "transcript": "So to me the bottleneck especially since I'm really interested in Mark's idea is that like is still although funding agency they are starting to give like more opportunities for sharing data, but then like as if there is not enough platform that give all of those like kind of clinical images and then all of those physiological, pathological images so that people that they are working, they can just make the connection and then use these tools in order to kind of from nanoscale to go to kind of like more of the clinical data to me.",
        "speaking duration": 91,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:28",
        "end_time": "59:59",
        "annotations": {
            "identify gap": "The speaker identifies a gap in the availability of platforms for sharing clinical and pathological images.",
            "supportive response": "The speaker discusses challenges and potential solutions in a collaborative tone.",
            "develop idea": "The speaker builds on Mark's idea by discussing its implications and challenges."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "00:02-00:54",
        "transcript": "Yeah, just like accessing data and then doing more like virtual clinical trial that like I'm really glad that FDA and NIH they started doing that more and more. But then I think more of the like I see the bottleneck is to have a like access access uniformly to data and then by that I mean like as if it should be data set from all the companies, all the like kind of images of those the company, they don't share the software, but um that's why it should be something that it can be standardized across the different modalities and across different, you know, protocols. So that's why I see that in my field that could be a bottleneck.",
        "speaking duration": 52,
        "nods_others": 3,
        "smile_self": 10,
        "smile_other": 30,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:02",
        "end_time": "60:54",
        "annotations": {
            "identify gap": "The speaker highlights the challenge of not having uniform access to data from various companies as a bottleneck.",
            "process management": "The speaker mentions the need for standardization across different modalities and protocols to address the bottleneck."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "00:54-01:00",
        "transcript": "Kristen, what's the slide number? I will start entering in the slides, I think. Shall I?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:54",
        "end_time": "61:00",
        "annotations": {
            "ask question": "The speaker is requesting information about the slide number.",
            "process management": "The speaker is managing the meeting flow by asking if they should start entering slides."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:01-01:03",
        "transcript": "I think um 55?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:01",
        "end_time": "61:03",
        "annotations": {
            "process management": "The speaker is referring to a specific slide number, indicating a need to navigate to that slide, which is a task related to managing the meeting flow."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:03-01:03",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:03",
        "end_time": "61:03",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "01:03-01:04",
        "transcript": "55.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:03",
        "end_time": "61:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:05-01:07",
        "transcript": "I don't think we have a lot of time left.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:05",
        "end_time": "61:07",
        "annotations": {
            "process management": "The speaker is expressing concern about the meeting or discussion running out of time, which relates to managing the meeting flow and time."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:07-01:13",
        "transcript": "I think there was competing Google Docs, Mark. you were saying you only saw yours. There was a",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:07",
        "end_time": "61:13",
        "annotations": {
            "process management": "The speaker is discussing an issue with the use of Google Docs during the meeting, indicating a management of meeting tools and flow."
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "01:13-01:17",
        "transcript": "I was I was putting it in the PowerPoint.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:13",
        "end_time": "61:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "01:18-01:27",
        "transcript": "So Dr. Shiva, did you want to write down your points on the doc? I I really appreciated.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:18",
        "end_time": "61:27",
        "annotations": {
            "ask question": "The speaker is asking Dr. Shiva if he wants to write down his points.",
            "acknowledge contribution": "The speaker expresses appreciation for Dr. Shiva's input.",
            "encourage participation": "The speaker invites Dr. Shiva to contribute his points."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:27-01:32",
        "transcript": "Yeah, we've got one minute, so it's probably best to just transcribe them over into the PowerPoint now.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:27",
        "end_time": "61:32",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting what to do with the remaining time."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:32-01:37",
        "transcript": "Let's copy and paste to the PowerPoint. If somebody's doing it, I won't do it, so we don't",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:32",
        "end_time": "61:37",
        "annotations": {
            "process management": "The speaker is suggesting an action to manage the group's task of copying and pasting content into PowerPoint to avoid duplication of work."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:37-01:38",
        "transcript": "Oh, you're not",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:37",
        "end_time": "61:38",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "01:39-01:40",
        "transcript": "Can I just do the numbered uh points?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:39",
        "end_time": "61:40",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting to proceed with listing or discussing points in a structured manner."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:40-01:40",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:40",
        "end_time": "61:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "01:40-01:44",
        "transcript": "Okay. I can copy it over.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:40",
        "end_time": "61:44",
        "annotations": {
            "process management": "Kristen Maitland is offering to copy the content into PowerPoint, which involves managing the flow of work or tasks."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:44-01:50",
        "transcript": "And I would say if anyone wants to make additions, just do it in directly in the PowerPoint.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:44",
        "end_time": "61:50",
        "annotations": {
            "process management": "The speaker is suggesting a method for how group members should collaborate on a document, specifically by making additions directly in the PowerPoint."
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "01:50-01:51",
        "transcript": "Thanks.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:50",
        "end_time": "61:51",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:51-01:55",
        "transcript": "Mini, you're you're it for the reporting note, so",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:51",
        "end_time": "61:55",
        "annotations": {
            "Process management": "Brian Pogue is managing the task assignment for reporting notes.",
            "Assign task": "Brian Pogue directly assigns or confirms a reporting task to Mini."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:55-02:02",
        "transcript": "I hope we we haven't reviewed it, but I'll try to make it",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:55",
        "end_time": "62:02",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges the current state of discussion and offers to contribute.",
            "supportive response": "The tone of the utterance is supportive and cooperative.",
            "process management": "The speaker is managing the discussion flow by offering help."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:02-02:04",
        "transcript": "You're gonna it's gonna be beautiful. It's gonna be beautiful.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:02",
        "end_time": "62:04",
        "annotations": {
            "express humor": "The speaker is making a humorous comment to lighten the mood or express optimism."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:04-02:04",
        "transcript": "You'll do great.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:04",
        "end_time": "62:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:04-02:06",
        "transcript": "Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:04",
        "end_time": "62:06",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:06-02:08",
        "transcript": "Okay, yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:06",
        "end_time": "62:08",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:09-02:10",
        "transcript": "We have faith in you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "Thumbs up",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:09",
        "end_time": "62:10",
        "annotations": {
            "supportive response": "The speaker is expressing support and encouragement to Mini Das who is tasked with reporting notes."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:10-02:16",
        "transcript": "Kristen, are have you? It's I I don't see any updates on the slide. Should I do it?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:10",
        "end_time": "62:16",
        "annotations": {
            "process management": "The speaker is inquiring about the procedure for updating a slide, seeking confirmation on whether to proceed with the action."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:16-02:18",
        "transcript": "Um Okay.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:16",
        "end_time": "62:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:18-02:18",
        "transcript": "There you go.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:18",
        "end_time": "62:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:18-02:20",
        "transcript": "Just popped in.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:18",
        "end_time": "62:20",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:20-02:24",
        "transcript": "Okay, let's review this and see if we are all happy with what's there.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:20",
        "end_time": "62:24",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting a review of the content."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:32-02:37",
        "transcript": "Well, good good working with you all and best of luck in your breakout sessions after this.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:32",
        "end_time": "62:37",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:37-02:38",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:37",
        "end_time": "62:38",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:38-02:38",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:38",
        "end_time": "62:38",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing another group member's input."
        }
    }
]