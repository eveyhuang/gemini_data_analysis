[
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:20-00:31",
        "transcript": "Okay, so I will call out names in alphabetical order so you can introduce yourself and then give your area of interest related to this topic. So we'll start with Shiva.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:20",
        "end_time": "00:31",
        "annotations": {
            "process management": "The speaker is explaining how she will manage the introduction process in the meeting.",
            "encourage participation": "The speaker is inviting participants to introduce themselves and share their areas of interest."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "00:31-00:55",
        "transcript": "Hi, this is Shiva Abbaszadeh. I'm assistant professor in University of California Santa Cruz. My background is electrical engineering and I do work on radiation detection, basically for X-ray CT and positron emission tomography and then how from the hardware and signal processing aspect we can improve the image quality in these modalities.",
        "speaking duration": 24,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:31",
        "end_time": "00:55",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise or qualifications related to the task, mentioning his background in electrical engineering and work on radiation detection."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:56-00:58",
        "transcript": "Thank you. Benjamin.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:56",
        "end_time": "00:58",
        "annotations": {
            "process management": "This code applies because Kristen Maitland is managing the meeting flow by calling out names for introductions."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "00:59-01:37",
        "transcript": "Hi, my name is Benjamin Bartelle. Um, my I'm an assistant professor at Arizona State University. Uh, my goal is uh non-invasive to non-invasively resolve and manipulate the neuroimmune system. I primarily do that with MRI uh and develop methods called molecular FMRI. So that means designing molecular probes usually through synthetic biology methods to bring molecular specificity to the MRI signal and my my target is largely the neuroimmune interactions um occurring in a living mouse.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:59",
        "end_time": "01:37",
        "annotations": {
            "signal expertise": "The speaker explicitly states his background, position, and research experience.",
            "clarify goal": "The speaker is defining his research goal and objectives."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:37-01:39",
        "transcript": "Thank you. Larry.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:37",
        "end_time": "01:39",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "01:40-02:41",
        "transcript": "Hi, my name is Larry. I'm assistant professor at Penn State University. My background is in mechanical engineering. I'm trying to apply the deformable structure and devices for the health monitoring and imaging of the human health condition, more continuous monitoring activities. And we have been interested in the stretch or acoustic photoacoustic wave for the brain imaging and electrical impedance tomography to complement the MRI for the fast imaging capabilities as well as the remote monitoring in term of the mesh surface for the microwave scattering so that we can do that behind the obstacles and that could be also a unique application with the physical implementation of the machine learning imaging with that modality.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:40",
        "end_time": "02:41",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise and qualifications related to their research background and position.",
            "None": "No other code directly and explicitly applies to the content of the utterance beyond signaling expertise."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:41-02:43",
        "transcript": "Thank you. Mini.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:41",
        "end_time": "02:43",
        "annotations": {
            "encourage participation": "This code applies because Kristen Maitland is inviting Mini to contribute by introducing themselves.",
            "process management": "This code applies because Kristen Maitland is managing the meeting flow by calling out the next participant's name."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:43-03:33",
        "transcript": "Hi, this is Mini Das from University of Houston. I'm an associate professor in physics and biomedical engineering. My background is applied physics, optical sciences and some of the recent work has been in looking at using light transport model or electromagnetic transport models in conjunction with advanced detectors to to come up with methods for identifying new contrast mechanism, for example, phase changes of X-rays rather than simple absorption and then looking at more recently also multimodality and near infrared optical imaging where the inverse problem is very ill conditioned and how can you potentially improve those those kind of problems.",
        "speaking duration": 50,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:43",
        "end_time": "03:33",
        "annotations": {
            "signal expertise": "The speaker explicitly states her own expertise and qualifications related to the task, mentioning her position as an associate professor in physics and biomedical engineering and her background in applied physics and optical sciences.",
            "develop idea": "The speaker elaborates on her recent work, discussing specific research areas and providing detailed explanations of her methods and examples."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:33-03:35",
        "transcript": "Thank you. Joyoni.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:33",
        "end_time": "03:35",
        "annotations": {
            "process management": "This code applies because Kristen Maitland is managing the meeting flow by moving to the next person for introduction."
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "03:36-05:24",
        "transcript": "Hi, I'm a physics faculty at LSU. I teach at the medical physics. My research is also in phase contrast X-ray and I'm trying to develop a phase contrast mammography system as well as a CT system is contrast. And I also I have worked in the past on spec reconstruction, iterative reconstruction with motion correction and also novel MPG sorry multipinol geometries and stuff like that. So I the just relevant to this topic what I'm kind of interested right now I would be interested is to have a iterative reconstruction method for phase contrast with the raw interferometric data. So as you know that phase contrast you have to derive so from the projections you have to derive the you know the attenuation image, the phase image and the scatter image and then you reconstruct and so if I could do it from the raw interference patterns it's very challenging because of the very computational requirements. Okay it's very high computational requirements. And I'm also interested in deep learning methods for that like for some of these reconstruction methods. And also I think that will help our phase contrast in in correcting some of the errors due to large you know grating artifacts. So you know like it can learn a lot of things that ordinary reconstruction methods would not. And as for just a quick addition that no that's okay yeah I think that's enough.",
        "speaking duration": 108,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:36",
        "end_time": "05:24",
        "annotations": {
            "signal expertise": "She mentions her background and experience in medical physics and phase contrast X-ray.",
            "identify gap": "She mentions the challenge of high computational requirements for her desired reconstruction method.",
            "clarify goal": "She clearly states her research goals and interests in phase contrast X-ray and reconstruction methods."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:30-05:33",
        "transcript": "Okay, thank you. Um, Uzay.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:30",
        "end_time": "05:33",
        "annotations": {
            "process management": "This code applies because Kristen Maitland is managing the meeting flow by transitioning to the next person for introduction."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:34-05:56",
        "transcript": "Hello. Uh my name is Uzay and I'm assistant professor at the School of Health Science Purdue University. And my focus of research is developing novel imaging techniques for pre-clinical and clinical MRI that spans from application from top to bottom of the body.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:34",
        "end_time": "05:56",
        "annotations": {
            "signal expertise": "Uzay Emir explicitly states his own expertise or qualifications related to the task by mentioning his position as an assistant professor and his research focus on developing novel imaging techniques for pre-clinical and clinical MRI."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:56-05:58",
        "transcript": "Thank you. Beck.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:56",
        "end_time": "05:58",
        "annotations": {
            "process management": "Kristen Maitland is managing the meeting flow by calling out the next person's name, Beck, to continue the introductions process."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:59-07:12",
        "transcript": "Hi everyone. So I'm an assistant professor at in computer science and also in EE at Washington University in St. Louis. Um what I do is I do um algorithms for for image processing in different levels. So we do image analysis, image reconstruction and artifact correction, classification registration. Uh so in the topics uh in this um group uh so I do work on um X-ray CT for scientific imaging where uh some of the issue we look at is uh uh registration of um uh um um of measurements of tomograms. We do work I do have a project on increasing SNR computationally for pet. Uh one on um incorporating multiple light scattering into uh optical tomography uh so um label free optical tomography and another one is building optical coherence tomography but by scanning different angles instead of just by using uh uh look at one side. Uh so those are the projects I do but I do all my work is essentially computational with a lot of deep learning in it.",
        "speaking duration": 73,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:59",
        "end_time": "07:12",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise and qualifications related to the task.",
            "develop idea": "The speaker expands on his existing ideas through reasoning and examples."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:12-07:14",
        "transcript": "Great. Thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:12",
        "end_time": "07:14",
        "annotations": {
            "supportive response": "The speaker is expressing a positive sentiment towards the participants' introductions."
        }
    },
    {
        "speaker": "Morteza Mahmoudi",
        "timestamp": "07:14-08:28",
        "transcript": "Hi everyone. My name is Morteza Mahmoudi and I'm an assistant professor at Michigan State University. So my research is focused on nanomedicine and regenerative medicine. From nanomedicine point of view, we basically develop magnetic based contrast agents for MRI basically we can track nanoparticles themselves or like we use them for cell therapy applications. Um another part of the research that we do is like imaging the nanobio interfaces where nanoparticles basically interact with biological fluids and the proteins and other like biomolecules come to their surfaces. So for that purpose we use cryo transmission electron microscopy which with combined with imaging technique to get a 3D structure of the nanoparticles.",
        "speaking duration": 74,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:14",
        "end_time": "08:28",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise and qualifications related to the task by introducing himself and describing his research background and focus."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:28-08:32",
        "transcript": "Thank you. And last but not least, Mark.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:28",
        "end_time": "08:32",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by introducing the next speaker.",
            "encourage participation": "The speaker is inviting Mark to contribute to the discussion.",
            "acknowledge contribution": "The speaker is thanking previous speakers for their contributions."
        }
    },
    {
        "speaker": "Mark Sellmyer",
        "timestamp": "08:33-09:13",
        "transcript": "Fair enough. Um, so I'm Mark Sellmeyer. I'm an assistant professor, my third year at UPenn. Um, I am chemical biologist and synthetic biologist. So we develop small molecule tools for biologists and um on the molecular imaging front try to make new diagnostics or approaches that let us both image and control gene and cell therapies. Um, I do uh deal one day a week of clinical nuclear radiology and um have been the PI on clinical protocols before that translate molecular imaging approaches.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:33",
        "end_time": "09:13",
        "annotations": {
            "signal expertise": "Mark explicitly states his background as a chemical biologist and synthetic biologist and mentions his experience in molecular imaging, clinical nuclear radiology, and his role as a PI on clinical protocols."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:13-09:14",
        "transcript": "Great.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:13",
        "end_time": "09:14",
        "annotations": {
            "supportive response": "It expresses a positive sentiment towards the previous contributions or the state of the conversation."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:14-09:44",
        "transcript": "Thank you. Well, we have an exciting mix of different modalities and different scales and both technology application and maybe contrast. Um, so I think I will first just open it up if anybody wants to respond based on what they've heard from someone else, um,",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:14",
        "end_time": "09:44",
        "annotations": {
            "summarize conversation": "Kristen Maitland summarizes the group's diverse expertise in different modalities, scales, and technology applications.",
            "encourage participation": "Kristen Maitland invites group members to respond based on what they've heard from others."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:44-09:44",
        "transcript": "I'll give it a few seconds.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:44",
        "end_time": "09:44",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by giving participants time to respond before proceeding."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:44-09:44",
        "transcript": "Go ahead.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:44",
        "end_time": "09:44",
        "annotations": {
            "encourage participation": "The speaker is inviting someone to contribute their thoughts or continue speaking."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "09:45-10:00",
        "transcript": "Well we're talking. Uh I mean it was really surprising how the previous sessions had a lot of convergences. There was a lot of um agreeance on the need for reporter genes, a lot of agreeance on multimodal approaches and I thought I thought all that",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:45",
        "end_time": "10:00",
        "annotations": {
            "supportive response": "Benjamin is expressing agreement with previous discussions, indicating a positive evaluation of others' contributions.",
            "summarize conversation": "Benjamin is summarizing his understanding of previous sessions, highlighting convergences."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "00:10-00:54",
        "transcript": "I'll say that, you know, on this my my 30 seconds of thinking about the very first um question is that yeah, pet and CTR are already reconstructed very well and you know, have the software platforms that are easily amenable to scroll through an imaging set.",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:10",
        "end_time": "10:54",
        "annotations": {
            "Supportive response": "Mark is expressing agreement or alignment with previous discussions, indicating his support for the direction of research or existing technologies.",
            "Critical response": "Mark slightly questions the focus on PET and CTR by mentioning they are already well-developed, providing a form of critique."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "00:54-01:04",
        "transcript": "sort of like imaging probe readout on one scroll side and pathologic, you know, um IHC or whatever on the other and be able to correlate.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:54",
        "end_time": "11:04",
        "annotations": {
            "propose new idea": "The speaker is introducing a new suggestion for correlating imaging probe readout with pathological data.",
            "offer feedback": "The speaker is suggesting a specific method for approaching the correlation of imaging and pathological data."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "01:04-01:24",
        "transcript": "I think in my world, you know, one of the challenges is like if we um have a probe that shows uptake in one part of the tumor. Um, you know, how do you go back and then validate that that uptake was really become from the target that you set out to at the very beginning.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:04",
        "end_time": "11:24",
        "annotations": {
            "identify gap": "Mark Sellmyer explicitly mentions a challenge or gap in his research, which is how to validate probe uptake in tumors.",
            "ask question": "The utterance poses a question in a roundabout way, seeking insight into how to validate probe uptake, which can be seen as requesting information or clarification."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "01:24-01:57",
        "transcript": "Um, that can be for tumor heterogeneity, but I also think about it for like some of our infectious disease probes where like it's not a nicely matted tumor that's, you know, growing in a circle and you can pinpoint the spot, it's like interpolating amongst among the cells and among the normal um tissues of the person for an infection. And so there the challenge is even harder. So, um, getting path to be a little more 3D would be lovely.",
        "speaking duration": 33,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:24",
        "end_time": "11:57",
        "annotations": {
            "develop idea": "The utterance expands on existing ideas about challenges in probing and imaging, specifically comparing tumor heterogeneity with the challenges in infectious disease probes.",
            "identify gap": "The utterance identifies a gap in current capabilities, specifically the need for 3D pathology to better understand and validate probe uptake in complex environments like infectious diseases."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "01:59-02:17",
        "transcript": "I think that's a great point about tumor heterogeneity whether um our currently available 3D imaging systems are allowing us to capture this correctly uh and that the limitations comes from uh signal corruption for the most part.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:59",
        "end_time": "12:17",
        "annotations": {
            "develop idea": "Mini Das is expanding on Mark Sellmyer's idea about tumor heterogeneity and its challenges in imaging.",
            "ask question": "Mini Das is asking a question about the capability of current 3D imaging systems to capture tumor heterogeneity correctly."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:17-02:30",
        "transcript": "It could be scatter or the need to correct them accurately. But I was wondering if if multimodality could help in that regard maybe if anyone has thoughts on I I I was intrigued by that last point.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:17",
        "end_time": "12:30",
        "annotations": {
            "ask question": "Mini Das is explicitly asking for thoughts or opinions from others on whether multimodality could help in addressing the challenges mentioned.",
            "develop idea": "Mini Das is building upon a previous idea by suggesting multimodality as a potential solution to the challenges discussed."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:30-02:47",
        "transcript": "I think uh it was presented in I don't remember the group now, but where uh there was a discussion on targeting uh and then my thought was region of interest reconstruction.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:30",
        "end_time": "12:47",
        "annotations": {
            "acknowledge contribution": "The speaker references a previous discussion, showing awareness of others' input.",
            "develop idea": "The speaker suggests 'region of interest reconstruction' as a potential approach related to targeting, building on existing ideas."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "02:47-03:16",
        "transcript": "If you could uh for example have a targeting with one probe then we know that well, this is around the area that's of interest and then for example your your your data data that you really want to deal with uh you know that everything else is kind of not of interest maybe it would help data reduction maybe.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:47",
        "end_time": "13:16",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by suggesting a specific approach to handling data in imaging.",
            "offer feedback": "The speaker provides a specific suggestion for improvement regarding data reduction in imaging."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:16-03:16",
        "transcript": "That was kind of what I was trying to say at that time when we just moved on.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:16",
        "end_time": "13:16",
        "annotations": {
            "None": "No relevant code directly applies to this utterance based on the provided definitions."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:17-03:19",
        "transcript": "was in our group. I think I was.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:17",
        "end_time": "13:19",
        "annotations": {
            "None": "No relevant code explicitly applies to this utterance as it seems to be a minimal acknowledgment or engagement with previous discussion without adding substantial content."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:19-03:25",
        "transcript": "It was it was I think I don't remember the number now, but that's correct.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:19",
        "end_time": "13:25",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing a previous input from another group member, showing agreement but not expanding on it."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:25-03:34",
        "transcript": "Yes, if if that would be an interesting uh idea to think in that yes and data reduction with multimodality.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:25",
        "end_time": "13:34",
        "annotations": {
            "Supportive Response": "The speaker is expressing agreement and validation for a previous idea.",
            "Develop Idea": "The speaker is expanding on the idea by suggesting a potential application or benefit, specifically mentioning data reduction with multimodality."
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "03:35-04:57",
        "transcript": "Yeah, I'm not sure whether this is a proper example, but well was trying to look at how we can do the uh balance between the temporal space resolution for the brain imaging. And we were looking at the functional MRI and optical imaging and they are each advantageous for certain aspects, but um by looking at the photo acoustic it seems to be better when we have the input signal from optical and attenuation will be um less concerned when we don't need to worry about the uh signal signal out from that uh skull attenuation by looking at the acoustic signature and this will actually enable us to push this imaging down to uh actually 1 millimeter down into the brain tissue. So, uh I think this is a combination of the optical and acoustic for the acoustic photo acoustic imaging. And maybe for the other things, I was also thinking about to use uh certain uh contrast agents and this is really something people have been looking at with uh maybe a different application for photo uh optogenetics operation and they seem to be able to get those non particle inside the brain. So maybe they can also be combined to uh help the multimodality imaging.",
        "speaking duration": 82,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:35",
        "end_time": "14:57",
        "annotations": {
            "develop idea": "Larry Cheng is expanding existing ideas by discussing the combination of functional MRI, optical imaging, and photoacoustic imaging for improved brain imaging.",
            "propose new idea": "He introduces the idea of using contrast agents from optogenetics for multimodality imaging, suggesting a new approach."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:00-05:04",
        "transcript": "Mini regarding to your uh questions.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:00",
        "end_time": "15:04",
        "annotations": {
            "None": "The utterance is a simple acknowledgment of Mini Das's previous questions without adding new content or clearly fitting into one of the specified categories."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:04-05:15",
        "transcript": "that we discussed with Blueberg in the same session. So I uh I think that's come from probing things is uh I give an example for that.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:04",
        "end_time": "15:15",
        "annotations": {
            "acknowledge contribution": "The speaker references a previous discussion with Blueberg, indicating an awareness of past conversation content.",
            "develop idea": "The speaker attempts to provide an example or further explanation related to the previously discussed topic."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:15-05:30",
        "transcript": "For example, the glioma patients I was discussing about that. So you you open the brain, you do have a sample right in front of you and you tailor your uh optical imaging technique that's sensitive to the certain enzyme.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:15",
        "end_time": "15:30",
        "annotations": {
            "develop idea": "The speaker is providing an example related to glioma patients to illustrate a point, which develops the discussion by adding a concrete scenario."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:30-06:25",
        "transcript": "And you do get the information and you might find some corresponding things non invasive imaging modality coming from MRI, path contrast or whatever you do think. And then you do get since it is already open for histological analysis, you can take the pathology and do do DNA sequencing and do do so this dimension reduction is coming from that because there will be a massive amount of data is coming. So then one of our colleagues during that discussion suggested that to tailor the optical imaging to certain things and then this enzyme enzyme specific uh optical imaging or it can be tailored. I'm not an optical person, so I'm not an expert, so I really don't want to make uneducated uh assumptions, but that is how that uh tailored approach come up. Am I right Blueberg? So am I missing or",
        "speaking duration": 55,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:30",
        "end_time": "16:25",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea about tailoring optical imaging to specific needs, such as enzyme-specific imaging, and discussing its potential applications and benefits.",
            "ask question": "The speaker seeks validation or further input on their understanding of the tailored approach to optical imaging."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "06:25-06:26",
        "transcript": "No, you completely.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:25",
        "end_time": "16:26",
        "annotations": {
            "supportive response": "Beck Kamilov is expressing agreement with Uzay Emir's statement.",
            "acknowledge contribution": "Beck Kamilov is verbally recognizing Uzay Emir's input."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "06:26-06:35",
        "transcript": "It was Ellen, if some if you're interested to talk to her, Ellen was a person who brought it up and she said she's very interested in that area. she has specifically said it.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:26",
        "end_time": "16:35",
        "annotations": {
            "acknowledge contribution": "Beck Kamilov acknowledges Ellen's previous suggestion or interest in the topic.",
            "encourage participation": "Beck Kamilov invites others to talk to Ellen if they are interested in her area of interest."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "06:35-06:36",
        "transcript": "maybe maybe Brian can.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:35",
        "end_time": "16:36",
        "annotations": {
            "encourage participation": "The speaker suggests that Brian can contribute, which encourages participation by inviting someone to share their expertise or thoughts."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "06:36-07:37",
        "transcript": "comment on this uh near infrared diffuse optical imaging, the problem with the 3D uh the problem itself has been, you know, well known to be very ill conditioned problem. And uh I looked at it sometime ago for breast imaging and you know, there are ways to ways to make it improve it by for example adding some information uh we had uh we were looking at using for example ultrasound uh localization. But more recently what I'm seeing is you are people are moving towards saying instead of accurate quantitation or finding exact volumetric concentration, let's look at fluctuations uh that happen uh well when when I guess this is more for brain imaging now we are talking if. So Brian, could you comment on I haven't looked at what was the evolution and how what's what's happening now with the exact quantitation part has it been done or given up or what's what's where is the field in that regard.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:36",
        "end_time": "17:37",
        "annotations": {
            "develop idea": "The speaker expands on existing knowledge by discussing challenges and potential approaches in near-infrared diffuse optical imaging.",
            "ask question": "The utterance ends with a question directed at Brian, asking for his comment on the evolution of the field.",
            "signal expertise": "Mini Das mentions her past experience with the topic, specifically for breast imaging.",
            "identify gap": "The utterance explicitly mentions a challenge: the problem being 'very ill-conditioned' in 3D for near-infrared diffuse optical imaging.",
            "encourage participation": "The utterance ends with a direct question to Brian, encouraging his participation."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:37-08:22",
        "transcript": "Yeah, I mean I think most work has been done in functional near infrared, you know, to to to couple to MR. So that's a multimodality, right, where you get the structure from MR and then temporal dynamics from near infrared. Um, certainly a lot going on. Um, we've we've we've spent a lot of time trying to do image guided spectroscopy with diffuse light and that's possible. So that's sort of a hybrid approach, right, where you've got the structure from CT or ultrasound or MRI and then layer in that as a a priori guide to the optical spectroscopy because you know optics is terrible, right? It's really blurry and",
        "speaking duration": 45,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:37",
        "end_time": "18:22",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by discussing the combination of near infrared and MR for multimodality and the challenges and possibilities in image-guided spectroscopy.",
            "supportive response": "The speaker agrees with and builds upon previous discussions on multimodality, indicating a supportive stance towards the approach."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:22-08:30",
        "transcript": "Diffuse optics anyway, it's really terrible. I'm intrigued by the idea of trying to get pathologic level information from a",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:22",
        "end_time": "18:30",
        "annotations": {
            "critical response": "Brian is expressing a negative view of diffuse optics.",
            "offer feedback": "Brian is providing a critique and suggesting a direction for improvement.",
            "develop idea": "Brian is expanding on his view of diffuse optics and its potential, building on the context provided by previous discussions."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:30-08:44",
        "transcript": "from MR scan like through an endoscope or something. Um, optics is tough though, right? Because either it's diffuse or it's microscopic.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:30",
        "end_time": "18:44",
        "annotations": {
            "Develop idea": "Brian Pogue is elaborating on the challenges of using optics in imaging, building on previous discussions about imaging techniques.",
            "Identify gap": "Brian highlights the limitations of optics in imaging (either diffuse or microscopic), identifying a gap in current capabilities.",
            "Critical response": "Brian's comment critically evaluates the use of optics in certain contexts, highlighting its limitations."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:44-08:44",
        "transcript": "There's almost no in between.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:44",
        "end_time": "18:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "08:45-08:45",
        "transcript": "So the",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:45",
        "end_time": "18:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "08:45-08:45",
        "transcript": "So the",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:45",
        "end_time": "18:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:18-09:18",
        "transcript": "Because of the",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:18",
        "end_time": "19:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "09:29-09:36",
        "transcript": "diffusing kind of gets rid of most adaptive optics uh in my experience.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:29",
        "end_time": "19:36",
        "annotations": {
            "offer feedback": "Brian is providing his experience and insight about the challenges of diffusion in adaptive optics, which serves as feedback to the discussion."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:38-09:41",
        "transcript": "because of the the way wave is modeled or because of the",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:38",
        "end_time": "19:41",
        "annotations": {
            "ask question": "Beck Kamilov is requesting information or clarification on why something happens because of the way wave is modeled or because of something else."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:41-09:46",
        "transcript": "So where where does where do you lose that adaptivity in the optics?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:41",
        "end_time": "19:46",
        "annotations": {
            "ask question": "The speaker is explicitly asking for information or clarification on why adaptivity is lost in optics, making this an example of requesting knowledge or insight."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "00:00-00:07",
        "transcript": "banana shape path. So you have a source and detector at the same plane, you're collecting maybe the reflected or you could do transmit it.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:07",
        "annotations": {
            "develop idea": "The speaker is elaborating on an existing concept (banana shape path in optical imaging) by explaining how it works, which involves a source and detector at the same plane collecting reflected or transmitted signals."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:08-00:20",
        "transcript": "Yeah, as far as I understand like optical coherence kind of uses coherence to kind of select where you do and then there is um um there's another technique. What's Oh yeah, photoacoustic, right? And where they use uh acoustic wave to zoom.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:08",
        "end_time": "20:20",
        "annotations": {
            "develop idea": "The speaker is explaining and discussing existing techniques, building upon previous ideas.",
            "acknowledge contribution": "The speaker is acknowledging previous discussions about techniques.",
            "offer feedback": "The speaker is providing insights and information about imaging techniques."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "00:20-00:22",
        "transcript": "Right, there is.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:20",
        "end_time": "20:22",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:22-00:30",
        "transcript": "Now, seems like there's almost uh so when you want to you go to a diffuse regime, okay, of course, we lose because of scattering everything.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:22",
        "end_time": "20:30",
        "annotations": {
            "develop idea": "The speaker is elaborating on the challenges of optical imaging, specifically in the diffuse regime, discussing the loss of information due to scattering.",
            "signal expertise": "The speaker is sharing their knowledge about optical imaging and its limitations, indicating their expertise in the area."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:30-00:42",
        "transcript": "But then if there is some form of selectivity you can impact there, right? Where you can get information and then you can combine that with adaptive optics to kind of focus there.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:30",
        "end_time": "20:42",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by suggesting combining selectivity with adaptive optics.",
            "offer feedback": "The speaker provides a suggestion for how to improve or build upon existing ideas."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:42-01:00",
        "transcript": "There was like a very nice nature communication paper, I think last year where guys were trying to go in depth by trying to do adaptive optics and compensating for diffusion. I mean the images didn't look so great, but the claims sounded good.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:42",
        "end_time": "21:00",
        "annotations": {
            "supportive response": "Beck is expressing a positive evaluation of the paper's claims.",
            "critical response": "Beck mentions that the images from the paper 'didn't look so great', which is a form of criticism."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:00-01:04",
        "transcript": "sort of approaches with like a guide star type refocusing, that kind of thing.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:00",
        "end_time": "21:04",
        "annotations": {
            "develop idea": "The speaker is building upon existing ideas by mentioning a specific technique relevant to the discussion.",
            "offer feedback": "The speaker is providing a specific suggestion or technique that could be used."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "01:05-01:17",
        "transcript": "No, that that's the thing. So it's kind of trying to imitate guided star, but there is no real guided star. It's more like using adaptive optics and rejection of scatter by using scattering model at different depths, so there is no specific guided star.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:05",
        "end_time": "21:17",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by explaining how a certain approach (imitating guided star with adaptive optics) works, providing more details and examples.",
            "offer feedback": "The speaker provides an explanation that can be seen as feedback on how to approach a problem in optical imaging, discussing the use of adaptive optics and scattering models."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:18-01:18",
        "transcript": ".",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:18",
        "end_time": "21:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "01:22-01:57",
        "transcript": "larger question about that. So we want as someone who's spent their entire life on MRI. We want optics because the wealth of probes, right? The specific labeling, sensors, ratiometric imaging, that is that that's why we want and the resolution I suppose. But if we didn't need that, if we had MR specific sensors, if we had pet specific probes and you didn't you didn't need those those sensor technologies that are already established, what's left for optics? Just the resolution?",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:22",
        "end_time": "21:57",
        "annotations": {
            "develop idea": "Benjamin is expanding on previous ideas about the benefits and limitations of different imaging modalities.",
            "ask question": "Benjamin is seeking insights on what would be left for optics under certain conditions."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "01:57-01:58",
        "transcript": "Cost. I would say cost.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:57",
        "end_time": "21:58",
        "annotations": {
            "offer feedback": "Provides a specific consideration (cost) that could influence the discussion or decision-making process regarding imaging techniques."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:59-01:59",
        "transcript": "Cost.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:59",
        "end_time": "21:59",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "02:01-02:05",
        "transcript": "MR cost and then it's a speed also. I guess the speed.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:01",
        "end_time": "22:05",
        "annotations": {
            "develop idea": "The speaker is expanding on the discussion about imaging techniques by highlighting the cost and speed advantages of MRI.",
            "supportive response": "The speaker is expressing a positive view on MRI, indicating its advantages in terms of cost and speed."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:05-02:16",
        "transcript": "Also I guess non radiological. There are there is a big group of people interested in probing without ionizing radiation. Of course MR does not have that, but the cost is much less, right?",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:05",
        "end_time": "22:16",
        "annotations": {
            "supportive response": "The speaker engages with previous points and offers a consideration about non-ionizing radiation and cost.",
            "ask question": "The speaker ends with 'right?' implying a seek for agreement or confirmation."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:17-02:19",
        "transcript": "And also dimensionality.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:17",
        "end_time": "22:19",
        "annotations": {
            "develop idea": "The speaker adds another point (dimensionality) to the discussion, slightly expanding on the existing ideas."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:19-02:34",
        "transcript": "So it's just portable, you can take it depending on what device you are having and that's making it feasible. You can get into the surgery room and get immediate response what the tumor is before you take the biopsies.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:19",
        "end_time": "22:34",
        "annotations": {
            "Develop idea": "The speaker is expanding on the idea of using a specific device or technique, highlighting its portability and potential applications.",
            "Supportive response": "The speaker is expressing a positive view of the device's capabilities.",
            "Offer feedback": "The speaker is providing a positive perspective on the device's feasibility and applications."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:34-02:43",
        "transcript": "So you can identify this with this Raman spectroscopies and those things it has been shown. So it is powerful when it comes to do this kind of diagnostic purposes.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:34",
        "end_time": "22:43",
        "annotations": {
            "develop idea": "The speaker is elaborating on existing ideas by providing a specific example of Raman spectroscopy and its application in diagnostic purposes.",
            "supportive response": "The speaker is expressing a positive view on the use of Raman spectroscopy for diagnostic purposes, indicating its power in such applications."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:44-03:11",
        "transcript": "So the multi spectral aspect of it is also the the thing that you want, right? you bring upscopy, I was talking about sensors. The fact that light is multi spectral means it's never going to go away. You can't replace it with ultrasound. I don't even think you can replace it with optoacoustics just because your readout is always funnel through that um one channel pipeline of the the acoustics.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:44",
        "end_time": "23:11",
        "annotations": {
            "develop idea": "Benjamin is expanding on the idea of optical imaging's advantages, specifically its multi-spectral nature and how it can't be replaced by modalities like ultrasound or optoacoustics.",
            "supportive response": "Benjamin's statement supports the value of optical imaging by highlighting its unique multi-spectral aspect and irreplaceability by other modalities."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:11-03:12",
        "transcript": "I just bring that because I think that's the pernicious problem of it.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:11",
        "end_time": "23:12",
        "annotations": {
            "None": "No directly applicable code captures the reflective and somewhat critical nature of the speaker's contribution without inference."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "03:13-03:30",
        "transcript": "Well, you know, your your question made me think about, you know, what about pet CT? I mean that that's actually pretty pretty awesome. Pet CT works really well. It's got, you know, in principle pet has molecular tracers for all kinds of targets.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:13",
        "end_time": "23:30",
        "annotations": {
            "supportive response": "The speaker is expressing a positive evaluation of pet CT.",
            "develop idea": "The speaker is elaborating on the idea of using pet CT as an example of a technique that works well."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "03:30-03:38",
        "transcript": "And yet it's really not widely used that much. And presumably due to cost.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:30",
        "end_time": "23:38",
        "annotations": {
            "offer feedback": "It provides a potential reason (cost) for the limited use of PET/CT, which can be seen as a form of feedback."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:39-03:40",
        "transcript": "But it's also not multi spectral.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:39",
        "end_time": "23:40",
        "annotations": {
            "critical response": "Benjamin Bartelle is providing a negative evaluation of an approach by pointing out it's not multi-spectral, implying a limitation.",
            "None": "No additional code seems to apply directly besides critical response."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:40-03:41",
        "transcript": "Mini.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:40",
        "end_time": "23:41",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:41-05:11",
        "transcript": "I had a question like uh in say for example in X-ray uh lot of like say mammography, okay? So you have content scatter and uh you use scatter grid to take out the content scatter, but nowadays you have these um you know, modeling methods where you iteratively as you like even in the projection, you know, as you iteratively get the thickness, you actually model the scatter. It can be fast Monte Carlo, it can be some linear model of the scatter. Have you seen that kind of work for um like light?",
        "speaking duration": 90,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:41",
        "end_time": "25:11",
        "annotations": {
            "ask question": "The speaker requests information on whether similar work has been done for light, referencing modeling methods for scatter in X-ray imaging.",
            "develop idea": "The speaker is building upon the concept of modeling scatter in X-ray imaging and exploring its application to light."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "05:12-05:14",
        "transcript": "Uh you you're talking about optical now?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:12",
        "end_time": "25:14",
        "annotations": {
            "ask question": "The speaker is asking for clarification on whether Joyoni Dey is talking about optical imaging now."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "05:14-05:18",
        "transcript": "Yeah, optical like, you know, for optical scatter iterative.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:14",
        "end_time": "25:18",
        "annotations": {
            "ask question": "The speaker is seeking clarification or information about optical scatter iterative methods, indicating a request for information."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "05:18-05:35",
        "transcript": "There are people working on scatter modeling scatter and even using that for imaging in depth. There's there's a new range of papers coming in that regard. Uh so yeah, there are people working on that uh we haven't looked at it in that.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:18",
        "end_time": "25:35",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges the work of others in the area of scatter modeling for imaging in depth.",
            "develop idea": "The speaker expands on the current research state by mentioning new papers emerging in the area of scatter modeling."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "05:36-06:15",
        "transcript": "It seems to be like lot of the just two more minutes like yeah, so if if it seems to me lot of the answers to this is like this current catch word deep learning. So like I know CT denoising is done by deep learning. Scatter if I give a lot of you know, scatter grid with scatter grid and with like with scatter, it can possibly learn correcting the scatter.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:36",
        "end_time": "26:15",
        "annotations": {
            "Develop idea": "The speaker is discussing and expanding on the idea of using deep learning for specific applications, such as CT denoising and scatter correction.",
            "Offer feedback": "The speaker offers a suggestion for using deep learning to correct scatter, indicating a potential solution to a problem.",
            "Supportive response": "The speaker is expressing a positive view on the use of deep learning for solving imaging problems."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "06:15-06:36",
        "transcript": "Um I know I I have done some work on correcting some physical errors due to that's more of a calibration problem, it's a easier problem to solve like you know, like grating based. But you know, and deep learning the thing is after you train with millions of data after that it's fast. You just throw in one set of data and out comes you know, a cleaned image.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:15",
        "end_time": "26:36",
        "annotations": {
            "Develop idea": "The speaker is elaborating on their experience with correcting physical errors using calibration methods and deep learning.",
            "Signal expertise": "The speaker is explicitly stating their experience and expertise in correcting physical errors.",
            "Supportive response": "The speaker is expressing validation for certain approaches (calibration and deep learning)."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "06:36-06:36",
        "transcript": "It's easy, you know, like like the computation wise it's not that hard.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:36",
        "end_time": "26:36",
        "annotations": {
            "supportive response": "The speaker is expressing that something is computationally not hard, showing agreement or validation with previous sentiments expressed in the conversation."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:36-06:37",
        "transcript": "Yeah, that's a good point.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:36",
        "end_time": "26:37",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and validation for the previous speaker's contribution without adding new content."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:37-07:06",
        "transcript": "I just wanted to say yeah, actually there are people doing the scatter correction in optical tomography and what so I have worked on it and published several papers on this, but the I see the one I like the most, which is I find fascinating is when you do model the scattering process itself as a convolutional neural network.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:37",
        "end_time": "27:06",
        "annotations": {
            "develop idea": "The speaker is expanding on their previous work and sharing insights about modeling the scattering process as a convolutional neural network.",
            "signal expertise": "The speaker explicitly states their own expertise by mentioning that they have worked on and published papers about scatter correction in optical tomography.",
            "offer feedback": "The speaker is providing information based on their expertise, which could be seen as offering feedback on approaches to scatter correction."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "07:06-07:07",
        "transcript": "Yeah, exactly.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:06",
        "end_time": "27:07",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a prior statement, showing support without adding new content."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:08-07:14",
        "transcript": "They are my exactly. But it's object dependent, so you have to uh.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:08",
        "end_time": "27:14",
        "annotations": {
            "develop idea": "The speaker is elaborating on a point previously discussed about object dependency in scatter correction.",
            "offer feedback": "The speaker provides a specific comment that can be seen as feedback on the approach being discussed."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:15-07:17",
        "transcript": "It's a little bit of a chicken and egg problem.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:15",
        "end_time": "27:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:17-07:17",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:17",
        "end_time": "27:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:18-07:23",
        "transcript": "You find the you have to start somewhere with some approximation, I guess.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:18",
        "end_time": "27:23",
        "annotations": {
            "supportive response": "The speaker is acknowledging the complexity of the problem and the need for approximations, showing agreement and validation for the previous discussions."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:23-07:30",
        "transcript": "We are looking a little bit into this for uh X-ray uh scatter.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:23",
        "end_time": "27:30",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:30-07:50",
        "transcript": "Yeah. X-ray scatter, I know that they have some in the clinic like prime by, you know, Siemens. They have already for mammography at least even for the projection and assume they have to assume something about that equation, so they assume like a water mu, like average attenuation to for the correction of the scatter.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:30",
        "end_time": "27:50",
        "annotations": {
            "acknowledge contribution": "The speaker references existing clinical technology for scatter correction, acknowledging prior work."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:50-07:50",
        "transcript": "Sorry, Mini, what say that?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:50",
        "end_time": "27:50",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification from Mini, fitting the definition of asking a question."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:51-07:51",
        "transcript": "I'm done.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:51",
        "end_time": "27:51",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:51-07:52",
        "transcript": "Oh okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:51",
        "end_time": "27:52",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "07:52-07:54",
        "transcript": "I I'm just waiting for other ideas to note now.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:52",
        "end_time": "27:54",
        "annotations": {
            "encourage participation": "The speaker invites others to share their ideas, indicating a willingness to hear more before proceeding."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:00-08:11",
        "transcript": "We did a like my master student did recently a simple version of this because I'm working on this uh uh with a new my extra system has this MPG which is so the regular uh the regular um interferometry systems have this something called analyzer which is also acts as a scatter grid.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:00",
        "end_time": "28:11",
        "annotations": {
            "develop idea": "The speaker is sharing specific details about their research, which involves working on a new system with MPG and comparing it to regular interferometry systems, thus expanding on existing ideas or knowledge in the field."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:11-08:30",
        "transcript": "So they don't have that much scatter. But my system to preserve the dose, I'm not using that um analyzer. So I will now have to correct for scatter and the scatter is in the the zeroth harmonic, the in the attenuation image, not so much in the uh small angle scatter or the, you know, or the phase image.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:11",
        "end_time": "28:30",
        "annotations": {
            "develop idea": "The speaker is explaining and developing their approach to correcting for scatter in their imaging system, building on existing technical knowledge."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:30-09:23",
        "transcript": "So I have to correct it. So we are we apply a simpler algorithm than like a fast Monte Carlo for the breast images like, you know, I just use a linear model and we did MLM reconstruction that works at least in simulated images from giant Monte Carlo simulated images. It seems to work. Now we are trying to do it for actual experiments. So um so I'm just saying that we can potentially try similar things for uh but it is object dependent and so it has to be a iterative process.",
        "speaking duration": 53,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:30",
        "end_time": "29:23",
        "annotations": {
            "develop idea": "The speaker is elaborating on their approach to solving a specific problem of correcting for scatter in imaging.",
            "signal expertise": "The speaker is demonstrating their knowledge in the area of physics, specifically in phase contrast X-ray imaging and scatter correction.",
            "identify gap": "The speaker mentions that the approach is object-dependent and requires an iterative process, implying a recognition of limitations."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:00-00:57",
        "transcript": "optical diffraction tomography, but it was not reflection. So some people are interested in reflection mode in optical diffraction tomography, it was transmission of light. Now, in there there is no real depth, but it's a multicellular organisms who are collecting across and then we're using multiple scattering to get higher resolution images. And then another context where I worked on it is more like subsurface, right, imaging, so we're underground. So it's a higher uh it's more used in in oil exploration or archaeological, there they also have a scattering of of wave. But it's exactly the same model in fact. Used but in the reflection regime. Right now I'm starting something with optical well they're building a new type of optical coherence but in fact a tomography where there is a sample rotation.",
        "speaking duration": 57,
        "nods_others": 3,
        "smile_self": 25,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:57",
        "annotations": {
            "develop idea": "The speaker is expanding on their existing work and ideas related to optical diffraction tomography, its applications, and related projects.",
            "signal expertise": "The speaker is explicitly stating their experience and qualifications in the field of optical imaging techniques."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "00:58-01:03",
        "transcript": "What's the scale of that system? We're we talking about small samples and microscopy or we're talking larger?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:58",
        "end_time": "31:03",
        "annotations": {
            "ask question": "The speaker is requesting information about the scale of a system previously mentioned, seeking clarification on whether it pertains to small samples and microscopy or larger scales."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "01:04-01:15",
        "transcript": "it's going to be microscopy. but it's going to be more than diffraction tomography. so it's not going to be just like few cells, but they want to do like a bigger kind of objects, but it's still going to be microscopy level.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:04",
        "end_time": "31:15",
        "annotations": {
            "develop idea": "The speaker is expanding on their previous statement about the project, providing more specifics about its scope and scale."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:16-02:30",
        "transcript": "I can I can mention one development that's happening right now in CT. maybe it's of interest for others. it's in spectral CT where photon counting or spectral detectors we are we are we are looking at and Anushiva also knows about this. Uh so you know, there is a big interest in using spectral data for separating material properties. Uh this could be for multiple contrast agents, it could be for density classification. Uh but one thought could be someone else has an idea related to this. Uh you know, how could you use this information? Um maybe as a prior information or or as for a combined multimodality. Here we are we are looking into these problems. So if you have ideas on this, I'd be very interested in learning more. Uh I've thought about ideas on combining with ultrasound. I think pet is another one. But I'm also very interested in thinking about optical properties. Uh how can you use this information? Um yeah, I I don't want to keep going but the idea if that if if that ignites any thought on in anyone we can.",
        "speaking duration": 74,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:16",
        "end_time": "32:30",
        "annotations": {
            "encourage participation": "Mini Das invites others to share their ideas and thoughts on the topic"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:31-02:37",
        "transcript": "And and many you you you were that's particularly in reference to multispectral X-ray detectors, is that right?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:31",
        "end_time": "32:37",
        "annotations": {
            "Ask Question": "The utterance is a clear question seeking clarification on a previous statement or discussion, specifically asking if it was in reference to multispectral X-ray detectors."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:37-02:51",
        "transcript": "Yes, you can do it with either at the detector end or you can separate it by by by I guess eliminating with different bandwidth of X-ray, but then you have to do it multiple times. But at the detector end you can do it with one shot. Yeah.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:37",
        "end_time": "32:51",
        "annotations": {
            "develop idea": "Mini Das is elaborating on existing concepts in spectral CT imaging by discussing different approaches for obtaining spectral data."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:52-03:41",
        "transcript": "But uh the thought I was having is more also in regards to uh would something like that help with combining with optical uh with a very low dose for example CT, right? since I picked up this near infrared back again, I'm seeing all the problems I saw before and I haven't seen solutions. Only solution I'm seeing is you can do the differential contrast easily, but you have to generate the differential contrast. In some problems the contrast occurs like in brain imaging, you're doing a task and or or you could you could be like doing something and there is a natural contrast in blood volume change, right? There is that's happening. But all problems don't lend to those contrast. So how do you how do you tackle this problem, right?",
        "speaking duration": 49,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:52",
        "end_time": "33:41",
        "annotations": {
            "identify gap": "Brian Pogue recognizes gaps in current methods, specifically in solving problems with optical imaging and low-dose CT.",
            "ask question": "Brian Pogue asks for suggestions on how to tackle the problem of generating contrast in optical imaging.",
            "develop idea": "Brian Pogue explores the idea of combining optical imaging with low-dose CT and discusses potential solutions and limitations."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:41-03:44",
        "transcript": "I'm I'm happy to complain about that aspect of MRI.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:41",
        "end_time": "33:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:44-03:45",
        "transcript": "What about do we use uh MR contrast agents?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:44",
        "end_time": "33:45",
        "annotations": {
            "ask question": "The speaker is requesting information about using MR contrast agents, seeking clarification or expertise from other team members."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:45-03:46",
        "transcript": "Oh, absolutely. Sure.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:45",
        "end_time": "33:46",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous statement, indicating a positive evaluation of the idea proposed."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "03:46-04:34",
        "transcript": "If you can get a fold change with your contrast agent, like you are you're styling. But for sensors and things like that, that's one of the things that's limited. Nanoparticles can have a large signal change, but once you get them in vivo, they don't fill the whole volume of your imaging of your sort of imaging voxel. So even if you got a threefold signal change from a from a nanoparticle, it's only taking up a small percentage of your voxel and so it ends up just being a few percent signal at the end. always.",
        "speaking duration": 48,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:46",
        "end_time": "34:34",
        "annotations": {
            "critical response": "The speaker is discussing a limitation and challenge with the approach of using nanoparticles for imaging, questioning its effectiveness.",
            "identify gap": "The speaker identifies a gap in the capability of nanoparticles to fill the whole volume of the imaging voxel, which limits their signal change."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "04:34-04:34",
        "transcript": "I was.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:34",
        "end_time": "34:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Morteza Mahmoudi, MSU",
        "timestamp": "04:34-05:57",
        "transcript": "Yeah, I was I was about to make comment about like. So it depends on like how many basically first of all it depends on the like what you want to image. For example, if you want to image a cell, then it depends on how many nanoparticles basically gets into the cells. So it define basically the resolution. But the other interesting aspect about nanoparticles is that the validity of the like the signal is okay, but it's not it it may not correspond with like what you're looking for. For example, we label like some cells with iron oxide nanoparticles and that cells we basically um put the reporter gene to basically activate that with luciferase. So we can also get a bioluminescence image of the of the cells that we inject them. So what happens was that even though when the cells are dead, you get the signal from oxide nanoparticles for like a few days. So when using nanoparticles, you can increase concentration, but at the same time you need to make sure that it's safe and you need to make sure that they don't affect the like the functionality of the cells or like activate some like uh I don't know something like apoptotic like pathways there. So for nanoparticles, I would say we always need another modality just to make sure that what we see is real.",
        "speaking duration": 83,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:34",
        "end_time": "35:57",
        "annotations": {
            "identify gap": "Pointing out limitations and potential misinterpretations of nanoparticle signals in imaging.",
            "offer feedback": "Sharing insights based on his research experience about the challenges and limitations of using nanoparticles.",
            "develop idea": "Elaborating on existing concepts related to nanoparticle imaging and the necessity of multimodality for accurate results."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "05:58-06:00",
        "transcript": "In terms of using them as a die.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:58",
        "end_time": "36:00",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:00-06:17",
        "transcript": "as not just to detect their presence, but to use sort of aggregation based sensors and things like that. They work very well in vitro, but to view them in a living animal, um that experience you have to have a zero baseline to start with and then you can only image within a single um session.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:00",
        "end_time": "36:17",
        "annotations": {
            "develop idea": "The speaker is elaborating on the challenges of using aggregation-based sensors in living animals, discussing their effectiveness in vitro versus in vivo.",
            "identify gap": "The speaker highlights a significant gap in current technology: the need for a zero baseline to start imaging and limitations to single-session imaging.",
            "offer feedback": "The speaker provides insights into the limitations of current approaches, suggesting areas for potential improvement or consideration."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:17-06:17",
        "transcript": "So.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:17-06:17",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:17-06:20",
        "transcript": "Benjamin, can you comment on in MRI currently.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:20",
        "annotations": {
            "ask question": "The speaker is asking Benjamin for his comments or insights on MRI, seeking expertise."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:20-06:20",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:20",
        "end_time": "36:20",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:20-06:30",
        "transcript": "What are the applications where the contrast agent is not needed or not used?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:20",
        "end_time": "36:30",
        "annotations": {
            "ask question": "The utterance is a clear request for information about applications where contrast agents are not needed or used."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:30-06:30",
        "transcript": "Uh I I don't know.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:30",
        "end_time": "36:30",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "06:30-06:30",
        "transcript": "Or typically is it always used with contrast agent at this point?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:30",
        "end_time": "36:30",
        "annotations": {
            "ask question": "The utterance is a direct request for information about the typical use of contrast agents in MRI."
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "06:30-07:32",
        "transcript": "MRI is there an application where contrast agent is not required? Yeah, I would say probably only maybe 20 to 30% of MRI scans are with contrast. The bulk of them are meant to um do things like diagnosis stroke requires no contrast. diffusion weighted imaging, T2 weighted imaging can can make the stroke diagnosis. A lot of MRI right now is basically anatomic so that stroke is one where there's like functional data coming from the diffusion, but um the rest of them are mostly anatomy. So lumbar spine MRIs to look for whether or not there's a narrowed narrow frame where the nerve is coming out to say that's why this person's having, you know, pain. So they're it's pretty much workhorse anatomic technique with um high end contrast enhancement used for like tumor characterization, infection characterization. Um uh you don't even need it to do like gallbladder, you know, MRCP to characterize the biliary system. So and I think.",
        "speaking duration": 62,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:30",
        "end_time": "37:32",
        "annotations": {
            "identify gap": "The speaker points out that 70-80% of MRI scans do not require contrast agents, highlighting a gap in the necessity of contrast agents across all MRI applications.",
            "develop idea": "The speaker elaborates on MRI applications that do not require contrast agents, providing specific examples such as stroke diagnosis, diffusion-weighted imaging, and anatomic imaging like lumbar spine MRIs."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "07:32-07:32",
        "transcript": "Enter it.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:32",
        "end_time": "37:32",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "07:32-07:33",
        "transcript": "Yeah, go ahead.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:32",
        "end_time": "37:33",
        "annotations": {
            "supportive response": "This utterance encourages someone to continue speaking, providing a positive and supportive feedback."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "07:33-08:10",
        "transcript": "Oh, and and the big push in that is so the the machine learning approaches they take is okay, well how can we sort of automatically score these things and just do pathology with a computer. It always ends up being some like this thing is slightly larger here and so by doing PCA, we can now have like a fast way of of seeing that that thing is slightly smaller. But it all comes back to like just training against the human eye.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:33",
        "end_time": "38:10",
        "annotations": {
            "develop idea": "The speaker is expanding on how machine learning approaches are used in pathology, explaining their functionality and limitations.",
            "signal expertise": "The speaker demonstrates expertise in machine learning applications, specifically in the context of pathology.",
            "critical response": "The speaker critiques the current state of machine learning approaches, pointing out that they often rely on being trained against human judgment."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "00:00-00:48",
        "transcript": "contrast enhance space, as Mark was saying, the predominant contrast agent used in MRI is your blood, right? Like that's what we're looking at. We're looking at blood flow, we're looking at a bleed, etc. Now in the in the contrast enhance space, it's not as commonly used because it's not that necessary, but uh these gadolinium agents and these targeted agents, they're highly limited because they are they have to carry a large molecule around with them. So they're highly limited to mostly vascular targets. We're looking for some vascular marker of whatever that is, or we're counting on um your agent leaking out of the blood to to mark whatever you're going for. And that's again very limiting in in the standard sort of T1, T2 uh regime.",
        "speaking_duration": 48,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:48",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of using contrast agents in MRI, discussing their role and limitations.",
            "identify gap": "The speaker highlights the limitations of current MRI contrast agents, particularly in targeting specific areas or molecules.",
            "critical response": "The speaker is critically evaluating the current state of MRI contrast agents, discussing their limitations."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "00:48-01:30",
        "transcript": "For us for for making sensors which are almost exclusively used um just as proof of concept papers and sometimes in model organisms. Those things almost always are administered either like continual IV or being directly infused into the brain or being infused into whatever space they want to be in just because they have they're these macro molecular complexes and the only way to get them to work is to pump everything you need into the spot you're looking for. And in those situations it's almost like there's no reason to do that 3D because you know where you're putting it. It's uh it's almost academic to say that the imaging is not invasive because the delivery is definitely not uh invasive.",
        "speaking_duration": 42,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:48",
        "end_time": "41:30",
        "annotations": {
            "signal expertise": "Benjamin is sharing his expertise on the use of sensors in imaging.",
            "develop idea": "He is expanding on existing knowledge about sensor administration and imaging techniques.",
            "offer feedback": "Providing practical feedback on the utility of 3D imaging when sensors are directly administered."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:30-01:36",
        "transcript": "Can I um I'm just going to interrupt for a second and Mini um how's the scribing going? Are you are you",
        "speaking_duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:30",
        "end_time": "41:36",
        "annotations": {
            "ask question": "The speaker is requesting information about the status of 'scribing'."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:37-01:40",
        "transcript": "Yeah, I'm taking",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:37",
        "end_time": "41:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:37-01:40",
        "transcript": "just noticed the Google Doc has nothing in it. So I'm just going",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:37",
        "end_time": "41:40",
        "annotations": {
            "express humor": "The speaker makes a lighthearted comment about the Google Doc being empty.",
            "process management": "The speaker mentions the state of the Google Doc, which relates to the management of shared resources or meeting materials."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:40-01:45",
        "transcript": "No, no, no. I'm I'm taking I'm taking manual notes, but I can't write on the Google Doc too.",
        "speaking_duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:40",
        "end_time": "41:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:45-01:47",
        "transcript": "Okay. Very retro of you. Yeah.",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:45",
        "end_time": "41:47",
        "annotations": {
            "express humor": "The speaker makes a joke about using manual notes, calling it 'retro', which is a humorous comment."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:47-01:50",
        "transcript": "Hopefully everybody will pop out in the end.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:47",
        "end_time": "41:50",
        "annotations": {
            "encourage participation": "The speaker is expressing hope that everyone will participate in the discussion."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:50-01:50",
        "transcript": "Okay.",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:50",
        "end_time": "41:50",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:51-02:15",
        "transcript": "I'm relying on the collective memory here of everyone. Okay. But I guess",
        "speaking_duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:51",
        "end_time": "42:15",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:56-01:59",
        "transcript": "I'm just wondering if we should start putting in sort of a",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:56",
        "end_time": "41:59",
        "annotations": {
            "ask question": "The speaker is requesting input or thoughts from others on a particular matter."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:59-02:15",
        "transcript": "I should bring up the post point uh of uh what what are the bottlenecks in rapid analysis. We don't have to follow the the bullet point but when when I I assume they're talking about human analysis or machine analysis, maybe we can have some point on that since it's one of the bullet points there.",
        "speaking_duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:59",
        "end_time": "42:15",
        "annotations": {
            "ask question": "The speaker is asking about bottlenecks in rapid analysis and inquiring about the type of analysis (human or machine) being discussed."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:21-02:24",
        "transcript": "Well there's a comment from Mark here too about bottlenecks and rapid analysis.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:21",
        "end_time": "42:24",
        "annotations": {
            "acknowledge contribution": "Brian Pogue acknowledges Mark's comment about bottlenecks and rapid analysis."
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "02:25-02:33",
        "transcript": "Uh I just put in there what what the questions were posed in there. There there's no useful information other than what we're supposed to be thinking about.",
        "speaking_duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:25",
        "end_time": "42:33",
        "annotations": {
            "Critical response": "The speaker is providing a negative evaluation of the information provided.",
            "Offer feedback": "The speaker is providing specific suggestions or comments about the information."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:34-02:37",
        "transcript": "Okay, got you. So refocusing effort.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:34",
        "end_time": "42:37",
        "annotations": {
            "supportive response": "The utterance acknowledges a prior statement with 'Okay, got you', showing agreement or acknowledgment.",
            "process management": "The utterance aims to steer the discussion or effort in a particular direction with 'So refocusing effort'."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "02:37-02:39",
        "transcript": "There's um go ahead. Sorry.",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:37",
        "end_time": "42:39",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "02:41-03:21",
        "transcript": "I I have another question another thing point sorry I kind of bring up these new points at the last minute I'm so sorry but uh it just when it occurs to me so I can't help it but somebody said that uh what other imaging modalities lend themselves to 3D analysis as well. I know that ultrasound micro bubbles are useful but I don't know if that's useful for microscopy. Anybody has any thoughts or we can quickly skim over that. Like it's a very high contrast mechanism.",
        "speaking_duration": 40,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:41",
        "end_time": "43:21",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on imaging modalities that lend themselves to 3D analysis, specifically asking if ultrasound microbubbles are useful for microscopy."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:22-03:46",
        "transcript": "I mean another one I was thinking which has a big challenge it's one project I have is like light sheet microscopy. I don't know if anybody worked with it. Uh so that can be done as a tomography setup where you take you know orthogonal views to each other or even several views and the challenge is you have a data problem. So they do a 3D scan every two seconds over several weeks to watch how organism grows.",
        "speaking_duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:22",
        "end_time": "43:46",
        "annotations": {
            "develop idea": "Beck is expanding on a thought about imaging techniques, specifically discussing light sheet microscopy and its challenges.",
            "ask question": "Beck asks if anybody has worked with light sheet microscopy, seeking information or expertise from others."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:46-04:07",
        "transcript": "So now nobody's going to sit and look at it. I mean, maybe somebody will but across not across the whole week. So how to find and analyze that data set in a way that for biologist it's meaningful and they can kind of easily scan through it to find important parts in it and so on. That's kind of a different challenge but it's also 3D challenge, 3D plus time.",
        "speaking_duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:46",
        "end_time": "44:07",
        "annotations": {
            "ask question": "The speaker asks for solutions on how to analyze a large dataset, indicating a request for information.",
            "identify gap": "The speaker highlights a gap in the ability to efficiently analyze 3D plus time datasets.",
            "develop idea": "The speaker elaborates on the challenges of analyzing large datasets, building on existing discussion."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "04:07-04:17",
        "transcript": "Well and and you need labels too to get um 3D light sheet microscopy working. Yeah. Sometimes. Yeah. Most times yes.",
        "speaking_duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:07",
        "end_time": "44:17",
        "annotations": {
            "signal expertise": "The speaker is explicitly stating their knowledge about the requirements for 3D light sheet microscopy to work."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "04:18-04:41",
        "transcript": "I was thinking if we can convert that problem to some sort of computer vision task because I do lots of work on like anomaly detection and then like",
        "speaking_duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:18",
        "end_time": "44:41",
        "annotations": {
            "propose new idea": "Shiva introduces a new approach by suggesting converting a problem into a computer vision task.",
            "signal expertise": "Shiva explicitly mentions his work on anomaly detection, signaling his expertise in this area."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "04:41-05:24",
        "transcript": "in order to do like really real time uh processing so that if you're gathering so much data and then you don't want to have them all save in the memory, you are able to uh like kind of like as if um get your system to learn what is the spatial temporal uh changes in a normal condition and then uh like have your network train so that kind of look for anomaly and then kind of have the output to the system to tell the user that okay this is the data that is important and then they are classifier that from the memory and pipelining point of view, they are very compatible to be implemented, you know, to the FPGA so that you can connect directly the output of your detector like ADC to the FPGA.",
        "speaking_duration": 43,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:41",
        "end_time": "45:24",
        "annotations": {
            "propose new idea": "Shiva introduces a new approach for real-time data processing and anomaly detection.",
            "develop idea": "Shiva elaborates on his proposed approach, including its implementation details and potential applications."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "05:24-05:35",
        "transcript": "So then like if I can learn more about, you know, that problem, maybe we have like some good discussion to go and see how like the anomaly detection task can be apply in order to reduce the data in your application.",
        "speaking_duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:24",
        "end_time": "45:35",
        "annotations": {
            "encourage participation": "The speaker invites discussion on applying anomaly detection tasks, encouraging participation.",
            "propose new idea": "The speaker suggests exploring anomaly detection as a method for data reduction, proposing a new idea."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "05:45-06:07",
        "transcript": "Yeah, that's already become very popular in for two photon um functional imaging. So people are doing um G camp, which is this calcium sensitive um fluorophore and they'll image this whole field of tens of thousands of neurons",
        "speaking_duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:45",
        "end_time": "46:07",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by providing specific examples of techniques used in two-photon functional imaging.",
            "signal expertise": "The speaker is signaling his expertise by mentioning specific techniques like G camp and its applications in imaging tens of thousands of neurons."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:07-06:26",
        "transcript": "and they'll train in specific activities and then use a classifier to kind of build out what is the typical response to that. And then once they have their classifier laid out, then they'll they'll start challenging that stimuli with different things and they'll look for the shifts in the network using that anomaly detection.",
        "speaking_duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:07",
        "end_time": "46:26",
        "annotations": {
            "develop idea": "The speaker is elaborating on an existing idea by providing details about the use of anomaly detection in two-photon functional imaging, explaining how a classifier is trained and used to identify shifts in network activity."
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "06:26-06:35",
        "transcript": "But they're it's it's surprising because they do these and it's just this like um MATLAB support vector machines model and they still get really interesting stuff out of it. Yeah, I think there's a lot of of growth for that.",
        "speaking_duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:26",
        "end_time": "46:35",
        "annotations": {
            "supportive response": "The speaker expresses surprise and agreement about the effectiveness of simple models like MATLAB support vector machines in obtaining interesting results, showing a positive evaluation of others' contributions.",
            "acknowledge contribution": "The speaker acknowledges the work of others by commenting on the interesting results obtained from using MATLAB support vector machines models."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "06:36-06:37",
        "transcript": "I think it's coming, you know.",
        "speaking_duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:36",
        "end_time": "46:37",
        "annotations": {
            "None": "The utterance is a minimal expression of agreement and does not clearly fit into any of the provided codes."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "06:37-06:41",
        "transcript": "because like last year",
        "speaking_duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:37",
        "end_time": "46:41",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "06:41-07:10",
        "transcript": "Zylinx uh like kind of give out a uh FPGA that has three 32 billion transistor is almost as much as you know the neurons in our brain and it's 80k. So it's not so super expensive and then like even before we had to have all the list data and then do the processing, but now the technology is like really tough time of flight pit that maybe soon we can get rid of even image reconstruction.",
        "speaking_duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:41",
        "end_time": "47:10",
        "annotations": {
            "propose new idea": "The speaker introduces a speculative idea about the future capability of technology to potentially make image reconstruction unnecessary.",
            "develop idea": "The speaker elaborates on the implications of current technological advancements, specifically mentioning FPGAs and their potential to change image reconstruction processes."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "07:10-07:17",
        "transcript": "So I think that regarding the question for our topic that how we can like go fast and then like kind of kind of reduce amount of the data.",
        "speaking_duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:10",
        "end_time": "47:17",
        "annotations": {
            "supportive response": "The speaker is expressing a supportive response by engaging with previous discussion topics and suggesting a direction for further discussion."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "07:17-07:21",
        "transcript": "I'm excited that kind of from the hardware point of view.",
        "speaking_duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:17",
        "end_time": "47:21",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSD",
        "timestamp": "07:21-07:35",
        "transcript": "the technology is at a point that soon we are going to see more advances regarding the data processing and then, you know, just like combining the data in a real time format.",
        "speaking_duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:21",
        "end_time": "47:35",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "07:40-07:41",
        "transcript": "Another thing I was thinking",
        "speaking_duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:40",
        "end_time": "47:41",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "07:41-07:43",
        "transcript": "Okay, sorry.",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:41",
        "end_time": "47:43",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "07:43-07:43",
        "transcript": "I",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:43",
        "end_time": "47:43",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "07:44-07:44",
        "transcript": "I was going to say",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:44",
        "end_time": "47:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "07:44-08:06",
        "transcript": "you know, we have 15 minutes so let me try something here. I'd like uh each of us to think where could we have the most impact? You know, of all the topics we've discussed, you know, where could you um what most interests you and what do you think that would have the most impact and we could just go through and have people and then I'm going to have you write it down on the Google Doc to help out.",
        "speaking_duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:44",
        "end_time": "48:06",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting a group activity and task to be completed within a specified timeframe."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "08:06-08:12",
        "transcript": "I started writing on the Google Doc the notes I have. Okay. Do you see?",
        "speaking_duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:06",
        "end_time": "48:12",
        "annotations": {
            "ask question": "The speaker asks for confirmation or acknowledgment with the question 'Do you see?'"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "08:12-08:14",
        "transcript": "Do you see anything right now?",
        "speaking_duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:12",
        "end_time": "48:14",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification from other group members regarding their ability to see the notes on the Google Doc."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "08:14-08:14",
        "transcript": "Yep.",
        "speaking_duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:14",
        "end_time": "48:14",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "08:15-08:16",
        "transcript": "Yeah, so there's sort of a couple categories there, yeah.",
        "speaking_duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:15",
        "end_time": "48:16",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or validation for what was previously discussed, without adding new content."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:16-08:21",
        "transcript": "I feel like I can probably contribute most to the scatter connection.",
        "speaking_duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:16",
        "end_time": "48:21",
        "annotations": {
            "signal expertise": "The speaker is indicating their potential area of contribution, which signals their interest and possibly expertise in the scatter connection aspect of the project."
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "08:21-08:27",
        "transcript": "And um but uh as far as I had the most impact that I think what Dr. Shiva last um uh said was very interesting like most impactful.",
        "speaking_duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:21",
        "end_time": "48:27",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging and showing appreciation for Dr. Shiva's previous contribution to the discussion."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "08:27-08:30",
        "transcript": "Okay, so get you get you to jot that down.",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:27",
        "end_time": "48:30",
        "annotations": {
            "process management": "The speaker is instructing someone to write down information, which involves managing the flow of the meeting and ensuring that information is recorded."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "08:36-08:39",
        "transcript": "Would it be possible to share the link for the Google Doc?",
        "speaking_duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:36",
        "end_time": "48:39",
        "annotations": {
            "ask question": "The speaker is requesting information about sharing a Google Doc link.",
            "process management": "The speaker is managing the flow of information or collaboration by asking for a Google Doc link."
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "00:00-00:03",
        "transcript": "I I am typing just a second just because Dr.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 66.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:03",
        "annotations": {
            "process management": "The speaker is managing the conversation flow by indicating a brief pause to type."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:03-00:11",
        "transcript": "Yeah, yeah, so we're all going to collectively help you, Minnie. We're we're it's going to be nine people writing the summary notes here.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 25.0,
        "smile_other": 66.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:03",
        "end_time": "50:11",
        "annotations": {
            "process management": "The speaker is explaining the process of how they will collectively write the summary notes."
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "00:11-00:12",
        "transcript": "Also the uh",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:11",
        "end_time": "50:12",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "00:12-00:22",
        "transcript": "So who else? Where where else could you think that the maximum impact would be?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:12",
        "end_time": "50:22",
        "annotations": {
            "ask question": "The speaker is requesting information or opinions from other team members.",
            "encourage participation": "The speaker is inviting others to contribute their thoughts or ideas."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "00:22-01:24",
        "transcript": "I I can talk I I'm typing so I I can also talk. You know, as I kind of got to at the very beginning, my my issue is that there is a lot of data there's a lot of information that can be from pathology about the different biochemical processes that are in a tissue. It could also be a little bit at a higher scale like what cells are present in that tissue. So a little larger scale, cellular micron level or micrometer level. Um, and then how do you take that data set, that 3D data set from pathology across the tissue, you know, tissue clearing technique, whatever it is that gave you really nice resolution and correlate that with the the MRI signals, the spectroscopic signal, the pet signal and build this like map of like what what is actually going on? Is is the is the imaging signal reflective of some of the more detailed pathology.",
        "speaking duration": 62,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:22",
        "end_time": "51:24",
        "annotations": {
            "identify gap": "The speaker identifies a gap in current methods regarding correlation of detailed pathology with imaging signals.",
            "develop idea": "The speaker is expanding on the idea of integrating pathology data with imaging techniques to understand tissue properties better.",
            "ask question": "The speaker is asking a question about how to achieve this correlation and what the imaging signals reflect about the pathology."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:25-01:26",
        "transcript": "Yeah, or even could you use like machine learning to sort of learn",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:25",
        "end_time": "51:26",
        "annotations": {
            "propose new idea": "The speaker suggests using machine learning as a new approach to learn from data, potentially addressing the challenge of correlating different types of imaging data with pathology."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:26-01:33",
        "transcript": "what the underlying causes of the MR signature is.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:26",
        "end_time": "51:33",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on the underlying causes of the MR signature, seeking deeper understanding."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:35-01:36",
        "transcript": "So you're going to write that out?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:35",
        "end_time": "51:36",
        "annotations": {
            "ask question": "The speaker is requesting confirmation or clarification about whether someone is going to write something down, which is a direct question."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "01:36-01:36",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:36",
        "end_time": "51:36",
        "annotations": {
            "None": "The utterance is a simple acknowledgment or agreement without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:37-01:38",
        "transcript": "Okay, five words.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:37",
        "end_time": "51:38",
        "annotations": {
            "process management": "Managing the flow of discussion or task at hand."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:43-01:44",
        "transcript": "Maybe 10.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:43",
        "end_time": "51:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:45-01:45",
        "transcript": "Anybody else?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:45",
        "end_time": "51:45",
        "annotations": {
            "encourage participation": "The speaker is inviting others in the group to contribute their thoughts or ideas."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "01:50-01:58",
        "transcript": "And you know, this can be specific to your expertise base or just what you think is going to be have the maximum impact.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:50",
        "end_time": "51:58",
        "annotations": {
            "process management": "The speaker is guiding the participants on how to approach the task of identifying areas where they could have the most impact."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:58-03:20",
        "transcript": "I can get in here. So I I do find this question actually from the beginning a little bit broad because each modality has strength for different types of diseases. So you can't use one modality for all types of diseases you will end up and that's obvious. And for example, you lung imaging with MRI without using hyperpolarize it is it is really difficult and but you can get very well x-rays and CTs from for lung imaging. So that is my main problem. So it is disease specific. And the second thing if what what I would like to do is most likely to increase the accuracy accuracy because MRI, I'm an MRI physicist, multi contrast, flexible contrast acquisition. So you can tailor the spins depending on however you want and generate the different contrast for different parameters. So you do have million parameters and it all affects the contrast. So that you can tailor the acquisition for lung imaging, but that doesn't necessarily mean it's going to be very better than x-ray. It can come close enough, maybe. Uh, but that is the limitation. We all know that. So that is most likely I might contribute to this question in a way that I can accelerate and the acquisition and increase the accuracy of the findings.",
        "speaking duration": 82,
        "nods_others": 0,
        "smile_self": 20.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:58",
        "end_time": "53:20",
        "annotations": {
            "develop idea": "Uzay Emir expands on the idea that different imaging modalities have strengths for different types of diseases and discusses the specifics of MRI.",
            "signal expertise": "Uzay Emir explicitly states his background as an MRI physicist and discusses the flexibility of MRI.",
            "clarify goal": "Uzay Emir discusses his goal of increasing accuracy and potentially accelerating acquisition in MRI."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "03:20-03:24",
        "transcript": "Okay, so five if you can summarize that in five to 10 words.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:20",
        "end_time": "53:24",
        "annotations": {
            "process management": "The speaker is managing the discussion flow by asking for a concise summary of a previous point."
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "03:27-03:29",
        "transcript": "I think the I think the Google Doc crashed.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:27",
        "end_time": "53:29",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "03:31-03:31",
        "transcript": "Really?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:31",
        "end_time": "53:31",
        "annotations": {
            "None": "No relevant code directly applies to this utterance as it is a brief expression of surprise or skepticism."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "03:33-03:34",
        "transcript": "No, I am writing.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:33",
        "end_time": "53:34",
        "annotations": {
            "None": "The utterance is a simple statement and does not explicitly fit into any of the other categories provided in the codebook."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:36-03:39",
        "transcript": "I think you just crashed the whole Google. You cannot even search anymore.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:36",
        "end_time": "53:39",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "03:43-03:44",
        "transcript": "I can write.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:43",
        "end_time": "53:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "03:52-03:55",
        "transcript": "I think maybe couple of people tried to open it at the same time, I don't know.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:52",
        "end_time": "53:55",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "mark sellmyer",
        "timestamp": "03:58-04:02",
        "transcript": "I can see anonymous fox and anonymous bat and anonymous blob fish.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:58",
        "end_time": "54:02",
        "annotations": {
            "express humor": "The speaker makes a joke about seeing anonymous users (fox, bat, blob fish) in the Google Doc, indicating humor."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:03-04:05",
        "transcript": "I see anonymous rhino. It might be you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:03",
        "end_time": "54:05",
        "annotations": {
            "express humor": "The speaker makes a joke about seeing 'anonymous rhino' and suggests it might be another user, indicating humor."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:09-04:18",
        "transcript": "What else? We talked about uh we talked a lot about optical systems about diffuse measurement versus microscopy.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:09",
        "end_time": "54:18",
        "annotations": {
            "ask question": "The speaker is asking for additional information or topics for discussion.",
            "encourage participation": "By asking 'What else?', the speaker is inviting others to contribute.",
            "summarize conversation": "The speaker is referencing and summarizing previous discussions about optical systems."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "04:18-04:33",
        "transcript": "I like to build off I like to think about multimodality systems to reduce the the the need for the data intensiveness or maybe even make the problem better condition in one one or the other.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:18",
        "end_time": "54:33",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by discussing multimodality systems to reduce data intensiveness and improve problem conditions.",
            "identify gap": "The speaker recognizes the need to reduce data intensiveness and improve problem conditions in multimodality systems.",
            "offer feedback": "The speaker provides a suggestion for improving multimodality systems."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:33-04:34",
        "transcript": "Okay. Do you want to jot that down on the",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:33",
        "end_time": "54:34",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting that the group write down information on a shared document."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "04:34-04:39",
        "transcript": "Excel or the the Google Doc?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:34",
        "end_time": "54:39",
        "annotations": {
            "process management": "The speaker is asking about the best tool (Excel or Google Doc) for sharing information or taking notes during the meeting, which pertains to managing the group's process of information sharing."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "04:40-05:03",
        "transcript": "To build off something was saying that like no one disease or organ, there's no one size fits all answer to that. And we see that a lot in our in model organisms. Uh, we we talked about light sheet microscopy.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:40",
        "end_time": "55:03",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea about the complexity of biological systems and the need for varied approaches.",
            "acknowledge contribution": "The speaker is referencing previous discussions or ideas."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "05:03-06:02",
        "transcript": "You're not going to use light sheet microscopy to diagnose neurodegenerative disorder in a person, right? But it is an incredible tool for looking at model organisms. It's it takes advantage of just the host of light based technologies we have available and we wouldn't have biomedical research without that. So how do you connect these clinically accessible imaging modalities like MRI where you can't see anything. You can see structures, you can tag a few things, maybe some spectroscopy, but compared to what light can do, it's just the the tiniest scratch, um, mechanistically speaking. So how do you relate those two imaging modalities to get the maximum value from an a a research and analytical modality and a more clinically accessible or clinically relevant modality. I think for me that's that's always been my sort of challenge, uh, coming up as was trained as a as a biologist and then went into biophysics. How do you connect those two things?",
        "speaking duration": 59,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:03",
        "end_time": "56:02",
        "annotations": {
            "identify gap": "Recognizing the gap between research-oriented and clinically accessible imaging modalities.",
            "develop idea": "Elaborating on the challenges and potential of connecting different imaging modalities.",
            "ask question": "Implicitly asking for solutions or thoughts on bridging the gap between research and clinical imaging modalities."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:03-06:06",
        "transcript": "That that sounds similar sort of to what Mark was saying, I think a little bit of",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:03",
        "end_time": "56:06",
        "annotations": {
            "code name": "acknowledge contribution",
            "explanation": "Brian Pogue references Mark's previous statement and indicates that his comment is related to what Mark said."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "06:07-06:09",
        "transcript": "I think it's it's a good idea, that's why.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:07",
        "end_time": "56:09",
        "annotations": {
            "supportive response": "The speaker expresses agreement or validation for another group member's contribution without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:10-06:11",
        "transcript": "Yeah, yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:10",
        "end_time": "56:11",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "06:11-06:12",
        "transcript": "Anybody who has to interact with with uh",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:11",
        "end_time": "56:12",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "06:12-06:26",
        "transcript": "pathology and then they go into the deal with the radiologist and you're like, you're saying this gray blob is is the the root of the mechanism behind whatever that disease we're talking about it. It's an extremely frustrating experience.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:12",
        "end_time": "56:26",
        "annotations": {
            "critical response": "The speaker is expressing frustration and a negative evaluation of current practices in dealing with radiologists and interpreting imaging results.",
            "None": "No other codes seem to directly apply to this utterance beyond critical response."
        }
    },
    {
        "speaker": "Benjamin Bartelle",
        "timestamp": "06:28-07:05",
        "transcript": "because then you go back to the biologist and like here's a, you know, extremely rich data set with a thousand different transcripts all labeled in 3D space and we still don't know what the mechanism is. And to see that huge dichotomy and those scales of data and the just the richness of the data set you have, it's it's just the gap is like overwhelming to to see.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:28",
        "end_time": "57:05",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes the gap between having extremely rich data sets and not understanding the underlying mechanisms."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "07:05-07:05",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:05",
        "end_time": "57:05",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "07:06-08:04",
        "transcript": "Just like to build on the existing discussion, uh, we might be looking at a subset of the population or disease application where more concerned about the free moving human body rather than those um, you know, given location or given time point. So I think what we can contribute is uh, is there's um, further development with a need for the long-term and continuous monitoring capability, we can make that try to be uh conformal and deployed onto the body and to allow for the uh long-term longitudinal study of the uh disease because sometimes when we have this one a snapshot measurement, it might be limited, but when we correlate the information your long run or uh from multiple time points, that will certainly provide much more uh useful information.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:06",
        "end_time": "58:04",
        "annotations": {
            "develop idea": "Larry expands on existing ideas by providing a specific example of how their technology can contribute to the discussion on long-term and continuous monitoring.",
            "propose new idea": "Larry introduces a specific application area (long-term monitoring in free-moving humans) and suggests a solution (conformal and deployable technology).",
            "signal expertise": "Larry mentions the capability of making technology conformal and deployed onto the body, indicating his expertise."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:04-08:04",
        "transcript": "Mhm.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:04",
        "end_time": "58:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:06-08:07",
        "transcript": "Okay. I'll drop that on the Google.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:06",
        "end_time": "58:07",
        "annotations": {
            "process management": "Brian Pogue is agreeing to add information to the Google document, which is a task related to managing the meeting's notes or output."
        }
    },
    {
        "speaker": "Huanyu Cheng",
        "timestamp": "08:08-08:10",
        "transcript": "Yeah, please do, yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:08",
        "end_time": "58:10",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement and encouragement in a brief manner."
        }
    },
    {
        "speaker": "Brian Pogue",
        "timestamp": "08:10-08:27",
        "transcript": "As we're doing that, I would I guess maybe push you to think about what's the bottleneck and what's the solution, you know, if you could maybe try to flush it out a little bit, you know, what in each of these problem areas or applications, what's the bottleneck and what's the solution, you know?",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:10",
        "end_time": "58:27",
        "annotations": {
            "process management": "The speaker is managing the discussion by suggesting a direction for the group's thoughts and contributions.",
            "encourage participation": "The speaker is encouraging the group to contribute their thoughts and ideas about bottlenecks and solutions."
        }
    },
    {
        "speaker": "Mini Das",
        "timestamp": "08:28-09:59",
        "transcript": "So to me the bottleneck especially since I'm really interested in Mark's idea is that like is still although funding agency they are starting to give like more opportunities for sharing data, but then like as if there is not enough platform that give all of those like kind of clinical images and then all of those physiological, pathological images so that people that they are working, they can just make the connection and then use these tools in order to kind of from nanoscale to go to kind of like more of the clinical data to me.",
        "speaking duration": 91,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:28",
        "end_time": "59:59",
        "annotations": {
            "identify gap": "Mini Das identifies a gap in the availability of platforms for sharing clinical and pathological images.",
            "supportive response": "Mini Das provides a supportive response by engaging with and building upon Mark's idea.",
            "encourage participation": "Mini Das encourages participation by discussing a relevant issue and inviting further conversation."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "00:02-00:54",
        "transcript": "Yeah, just like accessing data and then doing more like virtual clinical trial that like I'm really glad that FDA and NIH they started doing that more and more. But then I think more of the like I see the bottleneck is to have a like access access uniformly to data and then by that I mean like as if it should be data set from all the companies, all the like kind of images of those the company, they don't share the software, but um that's why it should be something that it can be standardized across the different modalities and across different, you know, protocols. So that's why I see that in my field that could be a bottleneck.",
        "speaking duration": 52,
        "nods_others": 3,
        "smile_self": 10,
        "smile_other": 30,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:02",
        "end_time": "60:54",
        "annotations": {
            "identify gap": "The speaker identifies a gap in uniform data access and standardization across different modalities and protocols, seeing it as a bottleneck in his field."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "00:54-01:00",
        "transcript": "Kristen, what's the slide number? I will start entering in the slides, I think. Shall I?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:54",
        "end_time": "61:00",
        "annotations": {
            "process management": "The speaker is asking about the slide number and offering to start entering information into the slides, which relates to managing the meeting flow or organizing group activities."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:01-01:03",
        "transcript": "I think um 55?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:01",
        "end_time": "61:03",
        "annotations": {
            "process management": "The speaker is trying to manage the meeting flow by referencing a specific slide number."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:03-01:03",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:03",
        "end_time": "61:03",
        "annotations": {
            "supportive response": "The speaker is acknowledging or showing agreement with a previous statement."
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "01:03-01:04",
        "transcript": "55.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:03",
        "end_time": "61:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:05-01:07",
        "transcript": "I don't think we have a lot of time left.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:05",
        "end_time": "61:07",
        "annotations": {
            "process management": "The speaker is commenting on the time left in the meeting, indicating awareness and management of the meeting's temporal aspects."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:07-01:13",
        "transcript": "I think there was competing Google Docs, Mark. you were saying you only saw yours. There was a",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:07",
        "end_time": "61:13",
        "annotations": {
            "process management": "The speaker is discussing an issue related to managing the collaborative work process, specifically the use of Google Docs for sharing information among team members."
        }
    },
    {
        "speaker": "mark sellmyer -UPenn",
        "timestamp": "01:13-01:17",
        "transcript": "I was I was putting it in the PowerPoint.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:13",
        "end_time": "61:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "01:18-01:27",
        "transcript": "So Dr. Shiva, did you want to write down your points on the doc? I I really appreciated.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:18",
        "end_time": "61:27",
        "annotations": {
            "ask question": "The speaker is requesting information or action from Dr. Shiva.",
            "encourage participation": "The speaker is inviting Dr. Shiva to contribute his thoughts or ideas."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:27-01:32",
        "transcript": "Yeah, we've got one minute, so it's probably best to just transcribe them over into the PowerPoint now.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:27",
        "end_time": "61:32",
        "annotations": {
            "process management": "The speaker is suggesting an action to manage the meeting flow due to time constraints."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:32-01:37",
        "transcript": "Let's copy and paste to the PowerPoint. If somebody's doing it, I won't do it, so we don't",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:32",
        "end_time": "61:37",
        "annotations": {
            "process management": "This code applies because the speaker is suggesting a method to organize and potentially avoid duplicating work within the group."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:37-01:38",
        "transcript": "Oh, you're not",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:37",
        "end_time": "61:38",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "01:39-01:40",
        "transcript": "Can I just do the numbered uh points?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:39",
        "end_time": "61:40",
        "annotations": {
            "process management": "Kristen Maitland is asking to organize the discussion into numbered points, which is an attempt to manage the meeting flow and structure."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:40-01:40",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:40",
        "end_time": "61:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "01:40-01:44",
        "transcript": "Okay. I can copy it over.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:40",
        "end_time": "61:44",
        "annotations": {
            "acknowledge contribution": "Kristen Maitland acknowledges a previous suggestion or task and agrees to perform it.",
            "supportive response": "Kristen Maitland provides a positive and supportive response by agreeing to copy something over."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:44-01:50",
        "transcript": "And I would say if anyone wants to make additions, just do it in directly in the PowerPoint.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:44",
        "end_time": "61:50",
        "annotations": {
            "process management": "The speaker is instructing on how to make additions to a shared document, specifically suggesting to do it directly in PowerPoint, which relates to managing the collaborative process."
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "01:50-01:51",
        "transcript": "Thanks.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:50",
        "end_time": "61:51",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "01:51-01:55",
        "transcript": "Mini, you're you're it for the reporting note, so",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:51",
        "end_time": "61:55",
        "annotations": {
            "assign task": "The speaker assigns a responsibility or task to a group member."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "01:55-02:02",
        "transcript": "I hope we we haven't reviewed it, but I'll try to make it",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:55",
        "end_time": "62:02",
        "annotations": {
            "Supportive response": "The speaker is expressing a willingness to contribute, showing support for the task or document.",
            "Encourage participation": "By offering to try to make it, Mini encourages participation in the collaborative process.",
            "Process management": "The utterance relates to managing the process of contributing to a document or task."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:02-02:04",
        "transcript": "You're gonna it's gonna be beautiful. It's gonna be beautiful.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:02",
        "end_time": "62:04",
        "annotations": {
            "express humor": "The speaker makes a joke or a lighthearted comment, expressing humor."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:04-02:04",
        "transcript": "You'll do great.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:04",
        "end_time": "62:04",
        "annotations": {
            "supportive response": "The speaker is expressing encouragement and support to Brian Pogue, providing a positive evaluation without adding new content."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:04-02:06",
        "transcript": "Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:04",
        "end_time": "62:06",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:06-02:08",
        "transcript": "Okay, yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:06",
        "end_time": "62:08",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:09-02:10",
        "transcript": "We have faith in you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "Thumbs up",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:09",
        "end_time": "62:10",
        "annotations": {
            "supportive response": "The speaker is expressing support and confidence in Mini Das's ability to compile the notes or summary effectively."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:10-02:16",
        "transcript": "Kristen, are have you? It's I I don't see any updates on the slide. Should I do it?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:10",
        "end_time": "62:16",
        "annotations": {
            "process management": "Mini Das is asking for guidance on whether she should update the slide, indicating a need for direction on managing the task at hand."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:16-02:18",
        "transcript": "Um Okay.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:16",
        "end_time": "62:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:18-02:18",
        "transcript": "There you go.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:18",
        "end_time": "62:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:18-02:20",
        "transcript": "Just popped in.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:18",
        "end_time": "62:20",
        "annotations": {
            "express humor": "The speaker makes a joke or a lighthearted comment about just joining the conversation."
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:20-02:24",
        "transcript": "Okay, let's review this and see if we are all happy with what's there.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:20",
        "end_time": "62:24",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting a review of the discussed content."
        }
    },
    {
        "speaker": "Brian Pogue - DARTMOUTH",
        "timestamp": "02:32-02:37",
        "transcript": "Well, good good working with you all and best of luck in your breakout sessions after this.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:32",
        "end_time": "62:37",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Mini Das (U. Houston)",
        "timestamp": "02:37-02:38",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:37",
        "end_time": "62:38",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Benjamin Bartelle ASU",
        "timestamp": "02:38-02:38",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:38",
        "end_time": "62:38",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    }
]