[
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:10",
        "transcript": "bullet points under quantitative imaging, right? Kind of jot down in case you you know, your thoughts and let's just take a minute and then we're going to do intros, okay?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:00",
        "end_time": "00:10",
        "annotations": {
            "process management": "The speaker manages the meeting flow by instructing participants on what to do next.",
            "assign task": "The speaker assigns a task to participants (to jot down bullet points under quantitative imaging)."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:29-00:35",
        "transcript": "Uh Vivian who just joined, we're jotting down our own ideas during this first minute.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:29",
        "end_time": "00:35",
        "annotations": {
            "Process management": "The speaker is managing the meeting flow by informing a new participant about the current activity."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:23-01:25",
        "transcript": "Okay, about 10 more seconds.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:23",
        "end_time": "01:25",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by specifying the remaining time for participants to write down their ideas."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:35-01:43",
        "transcript": "Well if you have a lot of ideas you're writing, I don't want to lose those.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:35",
        "end_time": "01:43",
        "annotations": {
            "process management": "This code applies because the speaker is managing the flow of ideas and ensuring that participants' thoughts are captured and not lost during the collaborative session."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:45-02:25",
        "transcript": "Okay. So maybe um we'll start off with introductions. Um we some of us have met already. I'm Mary Ellen Giger, I'm a professor of radiology and medical physics at the University of Chicago. I've been doing AI for multiple decades. Um and I work mainly with medical images to come up with new diagnostics as well as AI for microscopy to help expedite discovery by letting the computer find the cells instead of a human doing.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0.05,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:45",
        "end_time": "02:25",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting a transition to introductions.",
            "signal expertise": "The speaker mentions being a professor of radiology and medical physics and having worked on AI for multiple decades, indicating their expertise."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:25-02:25",
        "transcript": "David, you're in my upper left.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:25",
        "end_time": "02:25",
        "annotations": {
            "process management": "This code applies because the speaker is managing the meeting flow by facilitating introductions among the participants."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:26-02:31",
        "transcript": "Oh, uh so okay, so question one, how can I get the most information?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:26",
        "end_time": "02:31",
        "annotations": {
            "ask question": "The speaker is requesting information on how to get the most information, seeking clarification or guidance."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:31-02:33",
        "transcript": "Oh no, just say you're",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:31",
        "end_time": "02:33",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by guiding David on how to proceed with his introduction."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:33-03:03",
        "transcript": "Oh sorry. I'm David Van Valen. Uh I'm assistant professor at Caltech um biology biological engineering um specialization deep learning and particular uh data annotation. Um so I think the uh one sentence version of the world I'm trying to make is one where if you had imaging data and you want to get annotated, the marginal cost of annotation would be so low it's it would almost be free.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0.1,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:33",
        "end_time": "03:03",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise and qualifications, mentioning his position at Caltech and his specialization in deep learning and data annotation.",
            "propose new idea": "The speaker introduces a new idea about making the marginal cost of annotation for imaging data very low, almost free, which has not been previously discussed."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:03-03:03",
        "transcript": "Um and so how do we actually get there?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:03",
        "end_time": "03:03",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on how to achieve the goal they previously mentioned, which is to make the marginal cost of annotation so low it's almost free."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:04-03:05",
        "transcript": "Okay, and Matt?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:04",
        "end_time": "03:05",
        "annotations": {
            "encourage participation": "Maryellen is inviting Matt to contribute his introduction, thereby encouraging participation in the meeting."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "03:06-03:07",
        "transcript": "Uh thanks yeah I'm",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:06",
        "end_time": "03:07",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:07-03:11",
        "transcript": "Oh oh two Matts and you're right next to each other too.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:07",
        "end_time": "03:11",
        "annotations": {
            "express humor": "The speaker is making a joke about the coincidence of having two individuals named Matt sitting next to each other."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:11-03:12",
        "transcript": "Matt LEW, Lou.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:11",
        "end_time": "03:12",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "03:13-03:45",
        "transcript": "Matt Lou please. Okay, thanks. Uh hi I'm Matt Lou. I'm at Wash U in St. Louis. I've been here for six years. Um I work my uh lab works on single molecule spectroscopy and one of the things that we'd like to do is engineer fluorescence microscopes to not just give you just morphology or concentrations of things but tell you something about the function of what's happening, protein confirmations, activity of of of uh enzymes, things like this.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:13",
        "end_time": "03:45",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise and qualifications related to the task by introducing themselves and describing their work in single molecule spectroscopy."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "03:45-03:45",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:45",
        "end_time": "03:45",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing Maryellen Giger's input in facilitating the introductions."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:45-03:47",
        "transcript": "And Matt uh Lovett.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:45",
        "end_time": "03:47",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "03:48-04:35",
        "transcript": "Uh yeah, I'm Matt Love Baron. I'm I'm an assistant professor at UC San Diego. I've been here almost a year uh and we're really focused on on neuroscience on trying to understand the brain and to understand how neurons work by looking across multiple levels from their activity to how they connect to each other to um what are the biochemical activities within the cell. And so I'm interested in a lot of these ideas that are coming up here as to how to yeah link together all sorts of different types of data sets and this was touched upon in the previous session as well. Um but also how to get more information out of our our images and and set of images and I'm really interested in learning how to optimize this um as we start to collect these really huge data sets. So I'm excited to learn more about that.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:48",
        "end_time": "04:35",
        "annotations": {
            "Signal expertise": "The speaker mentions his position as an assistant professor at UC San Diego and his focus on neuroscience, indicating his expertise.",
            "Identify gap": "The speaker implies a current limitation in optimizing information from large data sets of images.",
            "Clarify goal": "The speaker defines his objectives and interests in understanding the brain, neurons, and optimizing data from images."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:35-04:36",
        "transcript": "Thank you and Goku?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:35",
        "end_time": "04:36",
        "annotations": {
            "encourage participation": "The speaker is directly inviting Goku to contribute to the conversation by introducing themselves."
        }
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "04:38-05:15",
        "transcript": "Yeah. Um my name is Gokul. Uh I'm assistant professor at UC Berkeley. I've been here almost two years now. Um yeah, what we do is basically at the um intersection of instrument development, the application of these instruments um and uh quantitative image analysis. Um so what we're generally interested in is being able to understand and quantify dynamics across um scales uh both in time and space. So ranging from milliseconds and nanometers to um uh uh minutes, hours over over millimeters.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:38",
        "end_time": "05:15",
        "annotations": {
            "signal expertise": "The speaker explicitly states their position as an assistant professor and mentions their work focus, signaling their expertise."
        }
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "05:15-05:16",
        "transcript": "Um yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:15",
        "end_time": "05:16",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:16-05:17",
        "transcript": "Okay, thank you. Arnold.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:16",
        "end_time": "05:17",
        "annotations": {
            "process management": "She is managing the meeting flow by moving to the next introduction.",
            "encourage participation": "By saying 'Arnold,' she is encouraging him to participate."
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "05:19-06:27",
        "transcript": "Hi everyone, some of you know me already. So I'm my name is Arnold Hayer. I'm an assistant professor at McGill University in the Department of Biology. I've been there for about three years now. And my lab is a cell biology lab. We do a lot of imaging and uh we ask the questions of how local signaling dynamics result in cell shape changes during cell migration. We do that in individually migrating cells and in collectively migrating cells. So there's this scale issue of of molecular organelles and cells and super cellular structures where we try to to bridge those different domains by using different modes of microscopy. So my lab relies a lot of on on on live cell imaging and I think uh for us it's a bottleneck to to do quantitative uh imaging. We do like cell edge tracking, cell tracking but but we would like to have better ways and faster ways of developing um analysis modalities that suit our questions and it's they're always changing so so one needs to adapt these um algorithms quickly and that's something that I'm hoping to to discuss more uh in this group.",
        "speaking duration": 68,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:19",
        "end_time": "06:27",
        "annotations": {
            "encourage participation": "Arnold expresses his hope to discuss these issues further in the group, inviting others to contribute."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:27-06:28",
        "transcript": "Thank you and Fanny.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:27",
        "end_time": "06:28",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "06:29-07:25",
        "transcript": "Hi, I'm Fanny Chapin from the University of Kentucky. I primarily work with magnetic resonance imaging to uh visualize inflammation and uh response to a cancer response to therapy uh using either iron oxide nanoparticles or fluorine imaging. And one of the limitations specific specifically in iron oxides is you do see a signal change on your image that is quantitative, but you cannot really correlate it to the number of cells that have influxed in the area. So I would be interested in uh developing things like this.",
        "speaking duration": 56,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:29",
        "end_time": "07:25",
        "annotations": {
            "Signal expertise": "The speaker mentions their primary work with magnetic resonance imaging, indicating their expertise area.",
            "Identify gap": "The speaker explicitly mentions a limitation in their work, specifically with iron oxides and correlating signal changes to the number of cells.",
            "Clarify goal": "The speaker implies a goal of developing something to address the identified limitation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:25-07:26",
        "transcript": "Great. Um",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:25",
        "end_time": "07:26",
        "annotations": {
            "supportive response": "The speaker expresses a positive sentiment towards the meeting's progress.",
            "process management": "The utterance helps to transition between segments of the meeting."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:26-07:55",
        "transcript": "again, we've got a a really nice um broad imaging group here of we have folks at the human, folks at the cellular level, some looking at functions at those different levels, some in um more of um AI and others are in hardware. So I'm looking forward to a great conversation. Before we get going, we need a uh and for those who just joined, I think it was Vivian and Fanny, we did spend the first minute kind of thinking at those bullet points and jotting down on our own thoughts if you want to do that.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:26",
        "end_time": "07:55",
        "annotations": {
            "supportive response": "She's expressing a positive sentiment towards the group composition and the upcoming conversation.",
            "encourage participation": "She's inviting newcomers to share their thoughts.",
            "process management": "She's managing the meeting flow by referring to a previous activity and setting the stage for the next part of the meeting."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:55-07:56",
        "transcript": "But now we need a recorder.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:55",
        "end_time": "07:56",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by mentioning the need for a recorder to document the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:09",
        "transcript": "I've been a recorder, you can't do it again. So if you are there any volunteers of someone who has not done it yet.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:00",
        "end_time": "10:09",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by ensuring a recorder is assigned.",
            "assign task": "The speaker is asking for volunteers to take on the role of recorder, which is an action item."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "00:10-00:12",
        "transcript": "Uh, I'm happy to do it.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:10",
        "end_time": "10:12",
        "annotations": {
            "supportive response": "Matt is expressing agreement and willingness to help by volunteering for the task of being the recorder."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:12-00:27",
        "transcript": "Thank you, Matt Lew. Just I didn't want the other Matt thinking, what? Okay, we have two Matts. All right, good. Um, and I'm going to I I can't even say Matt L. You're both Matt L's. Okay, we got Matt Lew and Matt Lovett Barron. Got it.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 53,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:12",
        "end_time": "10:27",
        "annotations": {
            "express humor": "The speaker makes a lighthearted comment about the potential confusion between the two Matts, indicating an attempt to express humor.",
            "process management": "The speaker ensures clarity on who has taken the role of recorder and distinguishes between the two Matts, facilitating smooth interaction."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:28-00:39",
        "transcript": "Um, okay, that's good. And I'm going to have you guys take over this this discussion, but I have one question first. I need to hear your definitions of quantitative imaging.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:28",
        "end_time": "10:39",
        "annotations": {
            "ask question": "The speaker explicitly requests definitions of quantitative imaging from the group members, making this an example of asking a question to gather information."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:39-00:43",
        "transcript": "Because I've I've run into multiple kinds throughout my lifetime.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:39",
        "end_time": "10:43",
        "annotations": {
            "process management": "The speaker is managing the discussion flow by prompting for input after asking for definitions.",
            "clarify goal": "The utterance seeks to understand the group's perspectives on quantitative imaging, relating to defining or clarifying objectives."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:43-00:50",
        "transcript": "Anyone tell me what quantitative imaging is and Matt Lew is oh, before we go Matt, so what in the other two groups.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:43",
        "end_time": "10:50",
        "annotations": {
            "ask question": "The speaker is explicitly asking for information or clarification on what quantitative imaging is.",
            "encourage participation": "The speaker is inviting group members to contribute their thoughts or definitions."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:50-01:11",
        "transcript": "The recorder opened up a Google Doc. And so half my screen are you guys because I like to actually see you and that's why I don't really like the recorder sharing their screen because then you're all bunched up. But then if you put the link of the Google Drive in the chat and we click on it, we've got the Google Drive on one side and our Hollywood squares on the other.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:50",
        "end_time": "11:11",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by discussing technical aspects of collaboration, such as screen sharing and using a Google Doc."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:12-01:12",
        "transcript": "Is that good?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:12",
        "end_time": "11:12",
        "annotations": {
            "Ask question": "The speaker is seeking confirmation or agreement from the group on a proposed arrangement."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "01:13-01:17",
        "transcript": "Yeah, I'll try that right now. So let me create a doc and then I'll put the link in the chat.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:13",
        "end_time": "11:17",
        "annotations": {
            "Process Management": "The speaker is managing the meeting flow by agreeing to create a doc and share it, which facilitates the group's collaboration process.",
            "Supportive Response": "The speaker is also providing a supportive response by agreeing to take action that helps the group move forward."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:17-01:30",
        "transcript": "Okay. And while Matt's doing that, maybe um we could um go back to what's the definition of quantitative imaging? What does that remind you, David?",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:17",
        "end_time": "11:30",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on the definition of quantitative imaging.",
            "encourage participation": "The speaker is inviting someone else in the group to contribute their expertise, opinions, or ideas."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:31-01:48",
        "transcript": "Uh imaging done in such a way that the images can be converted into some numerical um format where the numbers actually have meaning. Um that's probably probably closest I could I could I could give you.",
        "speaking duration": 17,
        "nods_others": 1,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:31",
        "end_time": "11:48",
        "annotations": {
            "clarify goal": "David is providing a definition of quantitative imaging, which helps in understanding and setting the objectives for their discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:49-01:53",
        "transcript": "Okay, I'm going to push on that. Yeah.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:49",
        "end_time": "11:53",
        "annotations": {
            "ask question": "The speaker is prompting for more information or clarification by saying 'I'm going to push on that.'"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:56-02:06",
        "transcript": "Because actually I'm I'm actually in your ballpark. I'm an AI person. So now I want someone who is um Arnold, what's quantitative imaging to you?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:56",
        "end_time": "12:06",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on what 'quantitative imaging' means to Arnold.",
            "encourage participation": "The speaker is inviting Arnold to contribute his thoughts or opinions to the discussion."
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "02:06-02:35",
        "transcript": "Maybe maybe I can say contrasting to to qualitative imaging where you just look at morphology, shapes and you know, describe them in in in a in a non non numerical form, quantitative imaging would would be to to convert features or intensities into into numbers so that you can make them make those observations or the you what you detect comparable between experiments between cells and conditions.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:06",
        "end_time": "12:35",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of quantitative imaging by defining it and contrasting it with qualitative imaging, providing a clearer understanding of the term."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:36-02:43",
        "transcript": "Okay. Um anyone else want to say something different? Because if not, I'm going to go to Matt Lew who's who and and who's does functional.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:36",
        "end_time": "12:43",
        "annotations": {
            "ask question": "The speaker is requesting input or thoughts from other group members.",
            "encourage participation": "The speaker is inviting others to contribute their ideas or definitions.",
            "process management": "The speaker is managing the discussion flow, deciding how to proceed based on group input."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "02:44-02:44",
        "transcript": "I I",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:44",
        "end_time": "12:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:44-02:44",
        "transcript": "I",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:44",
        "end_time": "12:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "02:51-03:28",
        "transcript": "Yeah, I'm going to say I was going to say beyond and that's where I said in uh earlier in the number of cells. Beyond having an estimate of it's lower or higher contrast or signal or things like that, being able to to know what this higher or lower means because if you don't have a point of reference to begin with, what is higher lower, especially if you're thinking of translating your signal to the clinic, you may not have that baseline. Uh, so to me quantitative is also being able to interpret a number on its own.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 89,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:51",
        "end_time": "13:28",
        "annotations": {
            "develop idea": "The speaker expands on existing ideas about quantitative imaging by providing a nuanced view on what it means to have quantitative data, especially in the context of clinical translation.",
            "signal expertise": "The speaker signals her expertise by offering a detailed perspective on quantitative imaging, showing her understanding of the field.",
            "acknowledge contribution": "The speaker acknowledges previous discussion by referencing 'earlier' statements about the number of cells."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:28-03:32",
        "transcript": "Okay. Good. Um others who wants to add to this list?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:28",
        "end_time": "13:32",
        "annotations": {
            "encourage participation": "The speaker invites others to contribute their thoughts or ideas to the discussion on definitions of quantitative imaging."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "03:32-04:00",
        "transcript": "I agree with that and I I'd say that one thing that um I think about with quantitative imaging is something that would be uh able to take something that has meaning in one experiment and be able to actually compare it to something in another experiment. So not only that there are numbers, but that those numbers um are are regular enough that we know how to interpret them with respect to one another.",
        "speaking duration": 28,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:32",
        "end_time": "14:00",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges a prior contribution with 'I agree with that'.",
            "develop idea": "The speaker expands on existing ideas about quantitative imaging, focusing on comparability across experiments.",
            "offer feedback": "The speaker provides his perspective as feedback on the concept of quantitative imaging, emphasizing the aspect of comparability."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:00-04:01",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:00",
        "end_time": "14:01",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:01-04:07",
        "transcript": "And I anyone else? I know Matt Lew, you were going to say some I cut you off to go to the other Matt. I'll let you.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:01",
        "end_time": "14:07",
        "annotations": {
            "encourage participation": "The speaker is inviting Matt Lew to contribute his thoughts or ideas, encouraging participation."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "04:07-05:01",
        "transcript": "No worries. Um, so one aspect of quantitation that I uh think about is um there is probably some underlying biological phenomenon or process, maybe it's molecular, maybe it's signaling, maybe it's, you know, phoslation or what have you. Um, that can be quantified uh so that it can become a testable hypothesis and that, you know, ultimately our images are just a uh our data is just a way to actually get at the underlying phenomenon and and how it is changing over time or what have you. So I would I would say uh it it kind of builds off of of of the other Matt's point that we we need to to take our data to describe the fundamental science that we're trying to understand and and then um be able to compare in that space.",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 11,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:07",
        "end_time": "15:01",
        "annotations": {
            "develop idea": "Matt Lew is expanding on the concept of quantitative imaging by discussing the importance of quantifying underlying biological phenomena to make them testable hypotheses.",
            "clarify goal": "Matt Lew's discussion aims to clarify the goal of quantitative imaging, which is to describe fundamental science and enable comparison."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:01-05:02",
        "transcript": "Great. You can have the recorder write that down.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:01",
        "end_time": "15:02",
        "annotations": {
            "process management": "The speaker instructs the recorder to document the discussion, managing the meeting flow and organization of group activities."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "05:02-05:02",
        "transcript": "We'll work on it.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:02",
        "end_time": "15:02",
        "annotations": {
            "final answer": {
                "None": "No relevant code explicitly applies to this utterance as it is a simple agreement to take action."
            }
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:02-05:20",
        "transcript": "Um, so the reason I asked this question, so I I do a lot of AI mainly at medical images. And if we take for example, uh not um like dynamic contrast enhance MRI. So we're looking at say the uptake of a contrast agent.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:02",
        "end_time": "15:20",
        "annotations": {
            "develop idea": "The utterance expands on the discussion by providing a specific example from the speaker's experience related to AI in medical images.",
            "signal expertise": "The speaker explicitly mentions her experience with AI in medical images, indicating her expertise in the area."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:20-05:31",
        "transcript": "In AI, we try to model that, I'll put that in quotes, using um knowledge of some input image that we choose wisely, we don't just put any old image in.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:20",
        "end_time": "15:31",
        "annotations": {
            "develop idea": "The speaker is expanding on previous ideas about AI and imaging by providing more details on how AI models are used with specific input images."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:31-06:02",
        "transcript": "But then I have colleagues who say the number you have out can't be measured. So I'm glad someone brought that up. It has to be measurable relative to some biomedical situation, you know, I relate it maybe to the likelihood of cancer or not. So then we have the people who come up and say, well no, it has to be where you are measuring based on the known physiology and the acquisition something like the the K trans value.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:31",
        "end_time": "16:02",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of quantitative imaging by discussing the necessity of measurability in biomedical contexts.",
            "clarify goal": "The speaker is clarifying the goals and requirements for quantitative imaging measurements, emphasizing their need to be meaningful and comparable in biomedical situations."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:02-06:11",
        "transcript": "And so I've always run into those two um camps and I think it's useful to to see those two camps as we go forward. I'm going to be quiet in a second.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:02",
        "end_time": "16:11",
        "annotations": {
            "summarize conversation": "The speaker reflects on the discussion, mentioning 'those two camps' to highlight different perspectives within the field of quantitative imaging.",
            "process management": "The speaker indicates her intention to step back and allow others to contribute to the discussion ('I'm going to be quiet in a second')."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:11-06:35",
        "transcript": "Um, but uh it has to be um measurable and to me, I think both types are useful and in fact you can merge them. It all depends on your task. The clinical task, biological task, what do you want your to do.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:11",
        "end_time": "16:35",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by emphasizing measurability and the importance of the task type (clinical or biological).",
            "supportive response": "The utterance expresses a positive view towards combining different approaches.",
            "clarify goal": "The speaker is contributing to defining what should be considered in the context of quantitative imaging, relating to clarifying goals or objectives."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:35-06:36",
        "transcript": "So with that.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:35",
        "end_time": "16:36",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:36-06:37",
        "transcript": "Now that we.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:36",
        "end_time": "16:37",
        "annotations": {
            "process management": "The speaker is transitioning to the next part of the meeting or discussion, managing the flow of conversation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:37-06:41",
        "transcript": "Now that we kind of all agree, disagree on what quantitative imaging is.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:37",
        "end_time": "16:41",
        "annotations": {
            "summarize conversation": "The speaker is summarizing the current state of the discussion about the definition of quantitative imaging, noting that there is both agreement and disagreement among the participants."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:41-06:45",
        "transcript": "Um, now we can go forward, I think. I think that was important.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:41",
        "end_time": "16:45",
        "annotations": {
            "summarize conversation": "The speaker indicates that the previous discussion was important and now they can move forward, summarizing the conversation's progress.",
            "supportive response": "The speaker expresses a positive sentiment about the discussion, indicating agreement or validation of its importance."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:47-07:22",
        "transcript": "Uh, and looking at the bullets for um it it you know, how can we get the most information out of an image? Can algorithm scoring, which to me is like um uh output from machine learning AI or some other model algorithmic model uh based more on the physiology uh can that provide searchable and archivable records.",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:47",
        "end_time": "17:22",
        "annotations": {
            "ask question": "The speaker is explicitly asking if algorithm scoring can provide searchable and archivable records.",
            "develop idea": "The speaker is expanding on previous discussions about quantitative imaging and now focusing on algorithm scoring.",
            "clarify goal": "The speaker is exploring what can be achieved with algorithm scoring, relating to the goal of quantitative imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:22-07:22",
        "transcript": "So let's.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:22",
        "end_time": "17:22",
        "annotations": {
            "process management": "The speaker is attempting to move the conversation forward, indicating a transition to a next step or action."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:22-07:22",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:22",
        "end_time": "17:22",
        "annotations": {
            "Supportive response": "The utterance 'Yeah' expresses agreement or validation with previous statements, making it a supportive response."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:22-07:23",
        "transcript": "Let's start the discussion.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:22",
        "end_time": "17:23",
        "annotations": {
            "process management": "The speaker is transitioning the meeting to the discussion phase, managing the meeting flow."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:23-07:23",
        "transcript": "Um.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:23",
        "end_time": "17:23",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:23-07:23",
        "transcript": "Anyone.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:23",
        "end_time": "17:23",
        "annotations": {
            "encourage participation": "The speaker invites others in the group to contribute their expertise, opinions, or ideas."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:23-07:24",
        "transcript": "Go.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:23",
        "end_time": "17:24",
        "annotations": {
            "encourage participation": "The speaker is prompting others to contribute or start the discussion.",
            "process management": "The speaker is managing the meeting flow by prompting the discussion to begin."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:24-07:24",
        "transcript": "Goku.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:24",
        "end_time": "17:24",
        "annotations": {
            "encourage participation": "The speaker is directly addressing Goku, inviting him to contribute to the discussion."
        }
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "07:24-08:31",
        "transcript": "Yeah, I think for the first question at least, um, it really depends on whether we are hypothesis testing or we're hypothesis generating using the information or using the images that that we've collected. Um, of course the the latter, oh sorry, the the former of hypothesis generating um is most likely when we are likely to to um make new discoveries because that's something that we haven't seen. Um, but to do so requires um again, quantities of data where you're looking for needles in a haystack.",
        "speaking duration": 67,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:24",
        "end_time": "18:31",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea about hypothesis testing and generation in the context of image and data usage.",
            "clarify goal": "The speaker discusses the goals of making new discoveries and the importance of data quantities for hypothesis generation."
        }
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "08:31-08:31",
        "transcript": "Um.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:31-08:31",
        "transcript": "So.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "08:31-08:31",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:31-08:31",
        "transcript": "Uh.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "00:00-00:49",
        "transcript": "this would do would um would be um generating machine learning methods that, you know, taken images and produce a vector embedding. Um and so images would be quote unquote similar if they're close in this um in this lower dimensional um embedding space. And that's what ties into the last um part which is how can image matching be optimized to stitch together data sets collected at different times or with different modalities. Um and I think the embedding worldview that would be, you know, you'd want to have a way of mapping things to a shared embedding space.",
        "speaking duration": 49,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:49",
        "annotations": {
            "propose new idea": "David introduces a specific approach to image analysis using machine learning, suggesting generating methods to produce vector embeddings from images.",
            "develop idea": "He develops this idea by explaining that images would be similar if close in a lower-dimensional embedding space and discusses optimizing image matching.",
            "signal expertise": "David signals his expertise by discussing machine learning methods and vector embeddings."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "00:49-01:01",
        "transcript": "And I'd say like, you know, from the methods perspective, this isn't um, you know, this isn't crazy or even like that far out of the norm given like what machine learning methods can uh what machine learning methods can do now.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:49",
        "end_time": "21:01",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and validation for the approach by stating it's not beyond the current norm of machine learning capabilities."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:01-01:22",
        "transcript": "Um, you know, the contract the contrastive learning uh methods are very powerful for generating useful embeddings. And I know of at least one uh researcher Carolyn Uhler um uh who comes to mind who's like actively working on methods for, you know, building like these sort of shared embeddings. Um yeah.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:01",
        "end_time": "21:22",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of using contrastive learning methods for generating embeddings, providing more details about the approach.",
            "signal expertise": "The speaker is showing familiarity with the topic by mentioning specific methods and researchers, indicating his expertise.",
            "acknowledge contribution": "The speaker acknowledges Carolyn Uhler's work, recognizing her contribution."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "01:23-01:28",
        "transcript": "Can I can I ask is that the that is kinds of embeddings can be generated without metadata?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:23",
        "end_time": "21:28",
        "annotations": {
            "Ask Question": "The speaker is requesting information or clarification on whether certain kinds of embeddings can be generated without metadata."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:29-01:33",
        "transcript": "Uh what so what do you mean by? So what do you mean by without metadata?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:29",
        "end_time": "21:33",
        "annotations": {
            "ask question": "The speaker is requesting clarification on what is meant by 'without metadata', directly asking for information or understanding from another team member."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "01:33-01:44",
        "transcript": "Uh like without additional documentation about how the image yeah, I mean, I suppose without maybe without detailed metadata beyond just knowing what what um how big the pixels are, what type of microscope you got it from that type of thing.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:33",
        "end_time": "21:44",
        "annotations": {
            "Ask question": "The speaker is explicitly requesting information or clarification on the necessity of detailed metadata for generating embeddings.",
            "Develop idea": "The speaker is building upon a previous idea (about embeddings and metadata) by asking for more details."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:44-02:21",
        "transcript": "Okay. So I see no good reason why said metadata can't be made available. Uh the methods that I'm aware of do require enough metadata so that, you know, let's say like you're trying to make an embedding from, you know, three different modalities, you know, imaging, um, you know, RNA uh RNA sequencing and attack sequencing. You need to have enough metadata to know that these data sets came from like the same sample, right? Um, and without that, then, you know, you just don't get to like you just don't um get to play ball.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:44",
        "end_time": "22:21",
        "annotations": {
            "develop idea": "The speaker is expanding, building upon, or elaborating existing ideas through reasoning and examples, specifically discussing the requirements for machine learning methods to generate embeddings from different modalities."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:21-02:27",
        "transcript": "because you don't have the information, which is that these are all essentially the same thing, you know, is lost.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:21",
        "end_time": "22:27",
        "annotations": {
            "develop idea": "David is expanding on the concept of generating embeddings and the role of metadata.",
            "offer feedback": "David is providing specific information on the conditions necessary for generating embeddings."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "02:27-02:28",
        "transcript": "Yeah. Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:27",
        "end_time": "22:28",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or acknowledgment of the previous statements without adding new content."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:28-02:30",
        "transcript": "Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:28",
        "end_time": "22:30",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:30-02:42",
        "transcript": "You know, I I think you know, things that like the things that interest me um is getting uh the practices um of folks who collect data, myself being one. I'm I'm one of them.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:30",
        "end_time": "22:42",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise or familiarity with data collection practices.",
            "encourage participation": "The speaker's reflection on his own practices might invite others to share their experiences or insights."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:43-03:07",
        "transcript": "Uh but encouraging practices that make the data itself like more machine learnable, right? So that these issues of, you know, well, do I have the appropriate metadata, you know, do I know what microscope it came from? Do I know the appropriate resolution? dot dot dot dot. You know, were these things are just, you know, packaged with the data set. So, you know, if you're developing these computational methods either internally or externally, you don't have to worry about that that much because it's just there.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:43",
        "end_time": "23:07",
        "annotations": {
            "develop idea": "David is expanding on the concept of making data more machine learnable by highlighting the importance of metadata.",
            "offer feedback": "David is offering a perspective on how to improve data practices, specifically suggesting that having appropriate metadata makes data more machine learnable.",
            "identify gap": "David points out the issue of not having appropriate metadata, which can be seen as identifying a gap in current practices."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:07-03:26",
        "transcript": "Um and it seems like it's a, you know, the bare minimum that one would need for, you know, some notion of reproducibility. Uh, you know, I like that's usually enough metadata. Um, but right now, you know, even sharing data without that is a um community problem.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:07",
        "end_time": "23:26",
        "annotations": {
            "Critical response": "The speaker is pointing out a problem with current practices regarding data sharing and metadata, calling it a 'community problem'.",
            "Identify gap": "The speaker mentions that even sharing data without sufficient metadata is a community problem, implying a gap in current practices.",
            "Develop idea": "The speaker is building upon the context of metadata and its importance for reproducibility, suggesting that the bare minimum of metadata is needed."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:27-03:33",
        "transcript": "And what about the performance of these you you could have a really with system um and you can do searching on it.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:27",
        "end_time": "23:33",
        "annotations": {
            "ask question": "The speaker is requesting information about the performance of certain systems, indicating a question about their capabilities or effectiveness."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:34-03:51",
        "transcript": "Um, but I think the performance has to be at a high enough level that you're search you're, you know, say you're searching on a particular characteristic of cancer and if you get it wrong and all of a sudden your cancer cases are now being thrown in a a bunch of non cancer areas. So I think",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:34",
        "end_time": "23:51",
        "annotations": {
            "Develop idea": "She is elaborating on the existing ideas by highlighting the importance of performance levels in the system.",
            "Offer feedback": "She is providing specific feedback on the necessity of high performance to avoid misclassification of cancer cases.",
            "Signal expertise": "She is demonstrating her expertise, especially in AI for medical images, by discussing critical aspects of system performance."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:51-04:03",
        "transcript": "Yeah, that's true. I know like Google put together like a um an image searching algorithm for like cancer cases, right? If you have if you had a case where a patch of the image, you know, show me cases that are similar to this.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:51",
        "end_time": "24:03",
        "annotations": {
            "develop idea": "The speaker is elaborating on the concept of image searching algorithms using a specific example (Google's algorithm for cancer cases).",
            "supportive response": "The speaker is providing an example that supports the discussion, showing agreement or validation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:03-04:09",
        "transcript": "So the search metric as well so the the performance of the search metric and the search algorithm.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:03",
        "end_time": "24:09",
        "annotations": {
            "Develop idea": "The speaker is expanding on previous ideas by highlighting the importance of the search metric and algorithm performance.",
            "Offer feedback": "The speaker is providing feedback on what is important for their work or project, specifically the performance of the search metric and algorithm."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:09-04:11",
        "transcript": "Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:09",
        "end_time": "24:11",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:11-04:25",
        "transcript": "Um has to um yeah, so I guess my my my I guess my larger point is that from like the algorithmic perspective, I'm not saying like there aren't improvements to be made, um, but these are at least to my in my view like very addressable problems.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:11",
        "end_time": "24:25",
        "annotations": {
            "develop idea": "The speaker is expanding on previous discussions by providing his perspective on the challenges and addressability of problems in quantitative imaging and machine learning.",
            "signal expertise": "The speaker is sharing his viewpoint, which is informed by his expertise in machine learning and data analysis.",
            "supportive response": "The utterance acknowledges challenges but expresses optimism about addressing them, providing a supportive perspective to the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:25-04:27",
        "transcript": "There's always improvements.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:25",
        "end_time": "24:27",
        "annotations": {
            "supportive response": "Expressing agreement or validation of the previous speaker's contribution without adding new content."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:27-04:36",
        "transcript": "Yeah, from the algorithm side. It's more like what like uh what basically what Matt was like alluding to is like wrangling the data to a format where you actually can start to use these approaches.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:27",
        "end_time": "24:36",
        "annotations": {
            "develop idea": "The speaker is expanding on previous ideas about the challenges of data preparation for algorithmic approaches.",
            "supportive response": "The speaker is showing agreement or alignment with previous points, specifically Matt's, about the importance of data wrangling."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:36-04:50",
        "transcript": "Um for every every project that we've done internally or have been working with uh external collaborators that is like the most significant um pain point. And the folks who've been willing to engage in that effort have been the ones who've been like the most successful.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:36",
        "end_time": "24:50",
        "annotations": {
            "signal expertise": "The speaker shares their experience and insights, implying their expertise in the challenges of data analysis projects.",
            "identify gap": "The speaker highlights a significant pain point in projects, which is the effort required for data preparation."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "04:50-04:51",
        "transcript": "Mhm.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:50",
        "end_time": "24:51",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:51-05:03",
        "transcript": "And and I think where I think there's a lot of um potential here of things we can go. So I want you to push it, you know, even if you're saying oh it's going to take too much data, we can't do anything. Assume you can handle all the data you can get.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:51",
        "end_time": "25:03",
        "annotations": {
            "clarify goal": "The speaker is clarifying the goal of the discussion, which is to explore potential ideas without being limited by concerns about data quantity."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:03-05:07",
        "transcript": "So it doesn't take too much data.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:03",
        "end_time": "25:07",
        "annotations": {
            "supportive response": "The speaker is expressing a positive view on the feasibility of handling data, indicating it doesn't take too much data, which supports the discussion on potential solutions.",
            "develop idea": "The speaker is building upon the previous discussion about data requirements, suggesting that it might not be as difficult as implied."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:07-05:10",
        "transcript": "So that you can manipulate it.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:07",
        "end_time": "25:10",
        "annotations": {
            "develop idea": "The speaker is expanding on the previous idea of handling data to encourage thinking about its potential.",
            "clarify goal": "The speaker is directing the discussion towards understanding the objectives of data manipulation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:10-05:22",
        "transcript": "Well, some things don't take too much but some take a lot, but that's that shouldn't be that shouldn't limit you from saying I want to do that. That's what I'm getting at because we can always deal with more data.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:10",
        "end_time": "25:22",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea that the group should not limit themselves by the amount of data they think they can handle.",
            "supportive response": "The utterance is supportive in nature, encouraging the group not to limit their ambitions due to data handling capabilities.",
            "encourage participation": "The utterance encourages the group to think about their goals and ambitions without limiting themselves."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:22-05:23",
        "transcript": "We have a history of that.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:22",
        "end_time": "25:23",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:23-05:27",
        "transcript": "But it's not a matter of like not being able to like collect enough data.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:23",
        "end_time": "25:27",
        "annotations": {
            "critical response": "The speaker is downplaying the issue of not being able to collect enough data, providing a counterpoint to the discussion.",
            "offer feedback": "The speaker is offering a perspective on the challenge of data collection, suggesting it's not the primary issue."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:27-05:28",
        "transcript": "It's just getting in the right format.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:27",
        "end_time": "25:28",
        "annotations": {
            "develop idea": "The speaker is elaborating on the challenge of getting data into the right format, building on previous discussions about data analysis difficulties.",
            "supportive response": "The speaker's comment aligns with and supports the ongoing discussion about the challenges of data analysis and processing."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:28-05:28",
        "transcript": "Well,",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:28",
        "end_time": "25:28",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:28-05:41",
        "transcript": "That is correct in some fields. In other fields, collection of data, there's actually sometimes uh it's in in in the medical imaging field, that's a major problem for culture reason, not for technical reasons.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:28",
        "end_time": "25:41",
        "annotations": {
            "identify gap": "The speaker points out a challenge in data collection in the medical imaging field, noting it's a major problem for cultural reasons, not technical ones.",
            "develop idea": "The speaker is adding a nuanced view to the discussion about data collection challenges across different fields."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:41-05:42",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:41",
        "end_time": "25:42",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:42-06:03",
        "transcript": "So um good. And now Vivian, you're at the other end. You are looking at the mole the molecular level. How's your quantitative imaging and where do you think that is?",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:42",
        "end_time": "26:03",
        "annotations": {
            "ask question": "The speaker is asking Vivian about her experience with quantitative imaging at the molecular level.",
            "encourage participation": "By asking Vivian a direct question, the speaker is inviting her to contribute to the discussion."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "06:41-07:34",
        "transcript": "Well, um yeah, I guess as I was mentioning, um a lot of the traditional MR is about difference and contrast and it's so small contrast, less contrast, but it's not there it's not quantitative enough. Uh, you always need a a baseline measurement and and unfortunately the baseline measurement tends to be different uh from patient to patient uh even. And normalizing that or um having, yeah, finding ways to to normalize that um or or find the right range of it like a blood test, you know, we always say the normal range falls into this uh this amount. Um, I think would be valuable in the field and for any application really, but for MR quantification.",
        "speaking duration": 53,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:41",
        "end_time": "27:34",
        "annotations": {
            "identify gap": "The speaker recognizes a limitation in traditional MR methods regarding quantification and the need for baseline measurements.",
            "develop idea": "The speaker expands on the existing idea of MR limitations and potential improvements through normalization.",
            "propose new idea": "The speaker suggests a new approach by comparing MR quantification to blood tests for establishing a normal range."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:34-07:41",
        "transcript": "Yeah, that's a good point and that would kind that goes under what basically bullet number one where",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:34",
        "end_time": "27:41",
        "annotations": {
            "supportive response": "The speaker expresses agreement with a previous point."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:41-08:03",
        "transcript": "uh and people have talked about how it varies from institution to institution. So how are you how are you going to normalize your data or harmonize is sometimes a term used um uh to handle, you know, data from different institutions, different scanners, different populations. We collect data from around the world and we we see this um in our lab.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:41",
        "end_time": "28:03",
        "annotations": {
            "develop idea": "The speaker is elaborating on previous discussions about data variation and its challenges.",
            "ask question": "The speaker asks how to normalize or harmonize data from different institutions, scanners, and populations.",
            "signal expertise": "The speaker mentions her own experience with collecting data from around the world and seeing variations in her lab."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:03-08:04",
        "transcript": "Okay, um",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:03",
        "end_time": "28:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:04-08:06",
        "transcript": "Good and now Vivian, you're at the other end.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:04",
        "end_time": "28:06",
        "annotations": {
            "encourage participation": "The speaker is directly addressing Vivian to include her in the conversation.",
            "process management": "The utterance helps in managing the discussion flow by ensuring all participants are engaged."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:06-08:10",
        "transcript": "You are looking at the molecular level.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:06",
        "end_time": "28:10",
        "annotations": {
            "process management": "The speaker guides the discussion by pointing out the level of analysis (molecular level), which can be seen as a form of managing the discussion flow."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:10-08:14",
        "transcript": "How's your quantitative imaging and where do you think that is?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:10",
        "end_time": "28:14",
        "annotations": {
            "ask question": "The speaker is requesting information about the current state of quantitative imaging and where it stands, specifically from the perspective of someone working at the molecular level."
        }
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "08:15-08:25",
        "transcript": "Yes, I want to I want to ask one question. Uh, so in the second question, there was algorithm that make scoring. So I want to make sure the uh the purpose of the scoring.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:15",
        "end_time": "28:25",
        "annotations": {
            "ask question": "The speaker is requesting clarification or information about a prior statement regarding an algorithm for scoring mentioned in the second question."
        }
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "08:25-08:40",
        "transcript": "My understanding is uh the scoring can help us screening some information is that right? Is that uh like based on I mean our application. Is that uh everybody thinks or there is a different definition in the AI world?",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:25",
        "end_time": "28:40",
        "annotations": {
            "ask question": "The speaker is seeking clarification or information about the concept of scoring in AI and its application, indicating a request for information or expertise from other team members."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:46-08:49",
        "transcript": "Say scoring what is your definition of scoring again?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:46",
        "end_time": "28:49",
        "annotations": {
            "ask question": "Request information, clarification, or expertise from other team members on a prior statement or idea proposed by another group member."
        }
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "08:49-08:56",
        "transcript": "So I want to make sure the uh the purpose of the scoring.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:49",
        "end_time": "28:56",
        "annotations": {
            "ask question": "Vivian is seeking clarification on the purpose of scoring, indicating she wants to understand it better."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "00:00-00:20",
        "transcript": "So what I think the so the challenge here is in a in a cloud data set, we don't know uh we don't know which spot which dots are related to each other. So we don't have an algorithm to really section them.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:20",
        "annotations": {
            "None": "No"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:20-00:27",
        "transcript": "So so you need that at at a lower resolution to guide you to the specific areas?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:20",
        "end_time": "30:27",
        "annotations": {
            "ask question": "The speaker is requesting clarification on how to guide an algorithm to specific areas, seeking more information on a prior statement."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "00:27-01:28",
        "transcript": "Sort of. So we have have we have to have some previous experience, either it's a lower resolution imaging or either you know the biology. Either you know that these two proteins somehow interacted. So we don't we can't directly see it only by looking at those uh dots on the imaging or or the um so so that that brings me to another challenge. We have so many dots, we can't like with human eye, it is very easy to tell these two are clustering together. like these two species of proteins are related. But with the computer, when I wanted to generate uh get more data from it, like see uh how close they are, like how um how how and the the uh how much they interact. It's very difficult to have the computer do that for me.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:27",
        "end_time": "31:28",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes a limitation in their ability to analyze imaging data with computers, specifically in determining protein interactions.",
            "ask question": "The speaker implies a need for a solution to overcome the challenge of analyzing protein interactions with computers, though not phrased as a direct question."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:29-01:49",
        "transcript": "Well, that's where you're asking how can we get the most information out of an image or set of image if you're not quite sure where to go within that image. So you need some kind of lower resolution direction to the right spot on your high resolution to get the most information out.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:29",
        "end_time": "31:49",
        "annotations": {
            "develop idea": "The speaker is elaborating on a previous point about the challenges and needs in quantitative imaging, specifically about getting the most information out of an image.",
            "identify gap": "The speaker highlights a gap in current capabilities - the ability to effectively analyze images without prior knowledge of where to focus.",
            "offer feedback": "The speaker provides a perspective on how to approach the challenge, which can be seen as feedback."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "01:50-02:06",
        "transcript": "Yes, it's kind of mask first and then you like focus on this spot. But like the the the the the details and then you'll look uh you look for more information. So that was that was the big challenge.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 31,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:50",
        "end_time": "32:06",
        "annotations": {
            "identify gap": "The speaker is explicitly recognizing a challenge or gap in their current approach to image analysis, specifically in analyzing spots on an image.",
            "develop idea": "The speaker is elaborating on a previous point about the challenge in image analysis, specifically about masking and focusing on certain spots."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:06-02:32",
        "transcript": "So once we hear from um San Pun, I'm gonna and I think I've heard from everyone else, we should let this go to try to um satisfy these three bullets, which it seems like we've we've looked at them differently because of our different fields, which makes sense.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:06",
        "end_time": "32:32",
        "annotations": {
            "summarize conversation": "The speaker summarizes the current state of discussion and suggests next steps.",
            "process management": "The speaker manages the discussion flow by suggesting what to do next.",
            "encourage participation": "The speaker encourages San Pun to contribute to the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:32-02:32",
        "transcript": "So?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:32",
        "end_time": "32:32",
        "annotations": {
            "encourage participation": "The speaker uses 'So?' to encourage or prompt further discussion or responses from the group members."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "02:32-02:35",
        "transcript": "I think yeah, I think we're discussing those two questions.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:32",
        "end_time": "32:35",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement with the previous discussion, indicating they think they are discussing the two questions mentioned."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "02:35-03:41",
        "transcript": "But I think the at least for where I come from, I mean, I think the the major bottlenecks are I think very much what what Dave said, which is data sharing and being able to like if I get some data and then one of you get some data and somebody else gets some data and we did the exact same sample, do we get the same answer? And I think that's a pretty big bottleneck for quantitative imaging because I got to be honest and I think the answer is a resounding no for 90% of the cases. And I think that that's kind of sad, but like that's that's the truth, right? Like somebody has a little special trick there or a little trick there that they process it with and it's not always available. And I find that that that limits a lot of progress because it doesn't allow us to really standardize things across different institutions or instruments or setups and so I've seen some databases go up that try to provide that information. I've participated in some of them as well to just give away everything, all the metadata, all the code, everything you have to try to make it transferable, but I I don't know to me that's the bottleneck to doing really quantitative imaging.",
        "speaking duration": 66,
        "nods_others": 0,
        "smile_self": 11,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:35",
        "end_time": "33:41",
        "annotations": {
            "identify gap": "The speaker highlights a significant gap in current quantitative imaging practices regarding data sharing and standardization across different institutions or instruments.",
            "critical response": "The speaker critiques current practices for not allowing standardization across institutions.",
            "offer feedback": "The speaker suggests sharing metadata, code, and making data transferable to improve standardization."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:41-03:56",
        "transcript": "Right. And for and for what um uh Matt Lou wrote down here would need also uh the normalization and um actually across multiple stages. So Vivian, you had your hand up? Did you want to comment on that?",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:41",
        "end_time": "33:56",
        "annotations": {
            "acknowledge contribution": "The speaker references and builds upon Matt Lou's contribution.",
            "encourage participation": "The speaker invites Vivian to comment, encouraging participation."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "03:57-04:55",
        "transcript": "Yes. Um so that that's also another challenge I have. One is validation, like I got I got my algorithm. I analyze my data and I got this result and I can't compare it to other people. And also because right now, um for a lot of the images like processing uh at least uh my collaborator and me, we're still kind of using human eyes and or or like previous experience to guide the development of algorithm. But the previous experience may be not true. Uh so that's why we ask for AI or computation to do that without without any uh what is it? Um judgment. So without previous judgment, that way we get more um uh we get we get uh unbiased.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:57",
        "end_time": "34:55",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes a gap in current methodologies for validation and objectivity in algorithm development.",
            "clarify goal": "The speaker is clarifying the goal of seeking unbiased results through AI or computation."
        }
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "04:55-04:55",
        "transcript": "Unbiased.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:55",
        "end_time": "34:55",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "04:55-04:58",
        "transcript": "Yeah, yeah. Unbiased unbiased interpretation.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 66,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:55",
        "end_time": "34:58",
        "annotations": {
            "supportive response": "The utterance is an agreement with a previous statement, showing support for the concept of unbiased interpretation."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:00-05:03",
        "transcript": "Yeah, if I could if I could add.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:00",
        "end_time": "35:03",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:03-05:03",
        "transcript": "Okay, David and then Fanny.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:03",
        "end_time": "35:03",
        "annotations": {
            "process management": "The utterance manages the discussion flow by indicating who should speak next."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:03-06:01",
        "transcript": "Yeah, if I could add a thought that was um sparked by what Vivian had to say, which is uh people don't really understand like the full value of reference data sets. Um so when you're generating algorithms, you have no way of knowing what's an actual advance um and what isn't without a reference data set to benchmark things on. Um, you know, we just experienced this uh in the last like couple in the last like year or so. Um we've put together a reference data set for doing whole cell and nuclear segmentation human tissues.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:03",
        "end_time": "36:01",
        "annotations": {
            "develop idea": "The speaker is expanding on the importance of reference data sets in algorithm generation following Vivian's point.",
            "signal expertise": "The speaker shares their experience of putting together a reference data set for whole cell and nuclear segmentation in human tissues.",
            "identify gap": "The speaker implies a gap in understanding about the value and use of reference data sets."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "06:01-06:14",
        "transcript": "Yeah, we put out a data set very similar to that in the last year doing exactly that segmenting nuclei and and cells for people who want to develop algorithms because we are not good at that to actually try to do that.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:01",
        "end_time": "36:14",
        "annotations": {
            "supportive response": "The speaker describes providing a dataset to support others in developing algorithms, showing a supportive action.",
            "identify gap": "The speaker identifies a gap in their capability by stating 'we are not good at that'."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:15-06:16",
        "transcript": "Okay, so I'm going to go to Fanny.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:15",
        "end_time": "36:16",
        "annotations": {
            "process management": "The speaker is managing the discussion flow by transitioning to the next speaker, Fanny."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:16-06:24",
        "transcript": "I just want to point out um from these comments being um made, I think that's great that the research groups are putting those data sets out there.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:16",
        "end_time": "36:24",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges and supports the action of research groups sharing data sets, as mentioned in previous comments."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:24-06:27",
        "transcript": "Um and I am in one way.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:24",
        "end_time": "36:27",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:27-07:07",
        "transcript": "medical imaging is extremely organized because people use DICOM and we can get images from around the world and there's some it's part of it is very but people don't share as well. It seems here with the microscopy folks that are it seems that um you have data sets and you're trying to share them but the format from one institution, not even, you know, even if you go before the staining before the scanning, you've got the actual just good old fashioned file format isn't unified. So it's like we got to take these two fields and put them together. But Fanny, you've been wait waiting patiently.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:27",
        "end_time": "37:07",
        "annotations": {
            "identify gap": "The speaker identifies a gap in the unification of file formats in microscopy.",
            "develop idea": "The speaker expands on previous discussions about data sharing and format unification by comparing medical imaging and microscopy.",
            "signal expertise": "The speaker demonstrates expertise in medical imaging, specifically mentioning DICOM."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "07:09-07:51",
        "transcript": "Sure. Thanks. Um it's a bit of a sort of crazy idea but um and I'm not really a specialist in computers and algorithms at all. But I'm just picturing when sometimes we analyze data on just image J and they have those, you know, window levels where you can go from zero to 255 and intensity. I'm wondering if on the computational side, it's possible to maybe sort of develop something where you can reformat every single image acquired worldwide onto this fixed scale somehow so that we could really compare one to the other.",
        "speaking duration": 42,
        "nods_others": 0,
        "smile_self": 14,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:09",
        "end_time": "37:51",
        "annotations": {
            "propose new idea": "Fanny Chapelin suggests developing a method to reformat images onto a fixed scale for comparison.",
            "ask question": "Fanny Chapelin asks if it's possible to develop such a method on the computational side."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "07:51-07:52",
        "transcript": "Is that something completely crazy?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:51",
        "end_time": "37:52",
        "annotations": {
            "Ask Question": "Fanny Chapelin is requesting feedback on the feasibility of her idea.",
            "Critical Response": "Fanny Chapelin is expressing doubt about her own idea."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:53-08:54",
        "transcript": "Well, I I I don't think it's crazy. I think it's very um uh difficult because um you might lose imaging aspects um in making making them um conform to that. I I know even going having everything um going into say a deep net, they often require certain matrix size and bit. You lose it or not? Well, maybe if you have enough cases, it might be okay, but um um sometimes the formats can be exactly the same, but small things like uh timing could um change the acquisition such as in dynamic contrast enhanced MRI. You know, one country was at 92nd intervals and another one's 60 and cause big 10 changes in the data.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:53",
        "end_time": "38:54",
        "annotations": {
            "develop idea": "The speaker is elaborating on the challenges of standardizing image formats, which is an existing idea.",
            "identify gap": "The speaker is highlighting the challenges and limitations of standardizing image formats.",
            "offer feedback": "The speaker is providing feedback on the idea of standardizing image formats."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:54-08:55",
        "transcript": "But um, I don't know.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:54",
        "end_time": "38:55",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:55-08:55",
        "transcript": "Uh.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:55",
        "end_time": "38:55",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:55-08:57",
        "transcript": "Oh, we have two hands up. I'm sorry.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:55",
        "end_time": "38:57",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges that two people have their hands raised, indicating they want to contribute to the discussion.",
            "supportive response": "The speaker's tone is apologetic and acknowledges the group's engagement."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:57-08:58",
        "transcript": "Arnold does have his hand up.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:57",
        "end_time": "38:58",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by acknowledging Arnold's raised hand, indicating he wants to speak."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:58-08:58",
        "transcript": "Good.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:58",
        "end_time": "38:58",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:58-08:59",
        "transcript": "And then Matt Lou.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:58",
        "end_time": "38:59",
        "annotations": {
            "process management": "This code applies because the utterance manages the meeting flow by introducing the next speaker."
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "00:00-00:35",
        "transcript": "One one caveat here is that the technology and the methods are evolving very quickly and and constantly. So you might you might uh you know, there might not be a standard because everything is changing. Every two years there's a new camera that is gives you a better resolution that is slightly this and and you people use different cell lines. So so I can see a lot of potential but also a lot of problems of of implementing um a standardized uh data repository. But it's definitely something I feel could could have a lot of value. It's just um a lot of challenges to implementing it.",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:35",
        "annotations": {
            "identify gap": "The speaker recognizes the lack of standardization in data repositories due to rapidly evolving technologies and methods.",
            "critical response": "The speaker is questioning the feasibility of implementing a standardized data repository due to several challenges.",
            "offer feedback": "The speaker provides feedback on the potential and challenges of implementing a standardized data repository."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:36-00:44",
        "transcript": "Yes, we're coming up with a lot of good problems. We're going to get to solutions real soon. But Matt Lew, you could take you can breathe after you type your last sentence and tell us.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:36",
        "end_time": "40:44",
        "annotations": {
            "process management": "Maryellen is managing the discussion flow by transitioning and inviting specific participation.",
            "encourage participation": "She explicitly invites Matt Lew to contribute, encouraging his participation."
        }
    },
    {
        "speaker": "Matt Lew, WashU",
        "timestamp": "00:45-02:13",
        "transcript": "Thanks. Um, so I wanted to maybe propose something to uh to to sort of um come off of of David's um points from earlier as a as a possible solution, but I don't know how to solve it. So, you know, um, we typically try to harmonize data sets in the measurement space because that's quantitative. Uh, we kind of know how to think about photons or how to think about um uh, you know, magnetic fields or spins or you know, the things that that our instruments are designed to measure. Uh, but this this concept of a latent space or a low dimensional embedding that David talked about is kind of um interesting because honestly we're all imaging some some biological or chemical phenomena that that exists in some other space than the measurements that we've made. If you could figure out how to do this mapping, then you've got actually, you know, an object, a unique object that exists uh in its own space. It's defined by its chemical properties, it's it's it's it's biological state or what have you. And then the instrument is simply a mapping to to the to the data that you collect. And I'm just wondering um you know, what what possibilities are there for us to start learning what this common space might be or expressions of it so that we can um start uh, you know, making these things these comparisons more easy to to do on a routine basis. Um, so just just an idea.",
        "speaking duration": 88,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:45",
        "end_time": "42:13",
        "annotations": {
            "propose new idea": "The speaker introduces a new concept related to using a latent space for data comparison.",
            "develop idea": "The speaker elaborates on the idea by discussing its implications and potential applications.",
            "ask question": "The speaker requests information on the possibilities for learning about this common space."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:14-02:18",
        "transcript": "Great and and Goku, I want to make sure I I recognize these hands now.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:14",
        "end_time": "42:18",
        "annotations": {
            "Encourage participation": "Maryellen Giger UChicago is encouraging participation by indicating she will recognize the raised hands.",
            "Process management": "Maryellen Giger UChicago is managing the discussion flow by planning to acknowledge and call on participants."
        }
    },
    {
        "speaker": "Gokul Upadhyayayula (UC Berkeley)",
        "timestamp": "02:19-04:35",
        "transcript": "Yeah, thanks. Um, one one big elephant in the room is that or or rather the reasons why I feel like, you know, we still have these problems and we haven't been able to solve them given that the EM field has been able to do that, the medical imaging community has been able to do that is when we're looking at cells at either the cellular scale or the subcellular scale, the diversity um is is vast. Um, both in the context of the probes that you're using to to measure the responses like fluorescent proteins or or the conjugations of dyes, um, the expression levels can be different. Um, so so that makes it difficult to make it quantitative because you can take an image of mitochondria, uh, protein expression in one lab and try to draw the same conclusions than a different lab, it makes no sense, right? Because context is lacking. Um, the other thing the other comment related to um to the the data formats, like why is it so difficult for us to share data? Um, obviously the the context is is the eluding part, but more the data formats are also kind of the the issue. At the moment, um, I I again, I've been thinking about this problem for a while, right? Because the types of data sets that we kind of uh generate are usually, you know, a lot more problematic to transmit to other folks, even though we put them in Google buckets and things like that, they're like usually like a two terabyte limit in terms of like transfer per day or something like that. Uh, but more importantly like the the format, like why is it that we have not all conformed to a given format. Um, and the reason is we have all different requirements because the imaging um that one lab does uh could be in two dimensions, even if dynamics is just, you know, basically like a few megabytes to maybe a couple gigabytes. Um, if you're doing volumetric imaging that kind of explodes and if you're doing, you know, volumetric time series that kind of, you know, blows up even more. Now, for us, the main requirement has always been the ability to do parallel reads and parallel writes on some of these um computations to be able to kind of really kind of scale it with the computational resources one has, right? That may not always be the requirement, but that kind of severely limits the formats um that that one has access to. And of course, you know, there's this huge kind of uh balance between pros and cons as to the different file formats that allow for or that basically kind of um prevent some of the features. Um, so yeah, I mean, just general broad thoughts on on a few of the points that we were discussing.",
        "speaking duration": 136,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:19",
        "end_time": "44:35",
        "annotations": {
            "develop idea": "Gokul is expanding on the challenges of quantitative imaging at the cellular or subcellular scale, discussing diversity and data formats.",
            "identify gap": "He identifies the gap in standardization of imaging techniques and data formats.",
            "offer feedback": "Gokul provides insights on the challenges and potential areas for improvement in quantitative imaging practices."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:53-05:01",
        "transcript": "Lot of things to keep in mind. Um, Matt, Love it, Barron, can you pull this all to what do we um, I you know, I I think I'm really glad the cellular folks are recognizing that it would be great if you had a standard format.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:53",
        "end_time": "45:01",
        "annotations": {
            "process management": "The speaker is managing the discussion flow by guiding the conversation towards synthesizing ideas on standard formats for imaging data.",
            "summarize conversation": "The speaker is requesting a summary or synthesis of the discussion points related to standard formats, indicating a desire to consolidate information."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "06:25-08:22",
        "transcript": "Uh, yeah, I I I like the idea that David brought up earlier of having some sort of latent embedding space that you can put them in. Um, you know, something that's has tried to take off in in neuroscience or at least the world of neuroscience I'm in where people are recording neural activity from animals or humans and and it's oftentimes really hard to get that data. It's very, you know, challenging and so people want to be able to share and have lots of people use and there's sort of a transition now to try and have things in a common data format and have it open that people can share, but I think there is largely a resistance for this to be widely adopted because as it requires a lot of work from every individual lab because it isn't built in uh by the the corporations that produce various microscopes or electrode arrays and and so forth. So there's not a lot of uh it's not a lot of motivation for people to end up doing this. And it really is a lot of work from an individual scientist to take their data set and make it easy for others to use. And so I I think I I like the idea of having what David brought up and that you, you know, if you have the basic metadata that you need and maybe take some responsible notes as you're collecting data that you can at least put it into a common embedding space uh so that you can try and uh interpret what data can connect to what. Uh, I don't know if that's the solution for my particular field or what, but I've noticed this has been an issue, like more of a sociological issue of of people not all getting on board and maybe the DICOM uh situation where you effectively have the hardware manufacturers, the corporate overlords agreeing to have common formats kind of forces everyone into that world and and maybe that's a a good way to go.",
        "speaking duration": 117,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:25",
        "end_time": "48:22",
        "annotations": {
            "Develop idea": "Matt is expanding on David's idea of using a latent embedding space for data comparison, providing more context and discussing its application and challenges in neuroscience.",
            "Supportive response": "Matt is expressing agreement and validation for David's idea of using a latent embedding space.",
            "Identify gap": "Matt highlights the gap in the adoption of common data formats and the challenges in data sharing.",
            "Encourage participation": "By sharing his insights and experiences, Matt is encouraging further discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:23-09:01",
        "transcript": "Yeah, and maybe in your communities, I don't know what your where your society is at. If you have the societies come that cover get together. So at that level, then that you can tell the other researchers, the manufacturers, that's how it went. So if I if I go back to you, Matt Lou, how your main um, I know you're typing.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:23",
        "end_time": "49:01",
        "annotations": {
            "encourage participation": "The speaker invites Matt Lou to contribute his thoughts, encouraging participation.",
            "process management": "The speaker manages the discussion flow by directing a question to Matt Lou.",
            "supportive response": "The utterance expresses agreement and encouragement for discussion."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "09:26-09:43",
        "transcript": "I kind of feel like well, I I guess I feel like maybe a good thing to tell everybody from the reporter is what the definition that we come up with for quantitative imaging actually is. And how broad or narrow that might be because maybe they also see it differently.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:26",
        "end_time": "49:43",
        "annotations": {
            "clarify goal": "The speaker is suggesting that the group needs to define or clarify what quantitative imaging means to ensure a common understanding among all members."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "09:44-10:00",
        "transcript": "So one of your three bullets will be definition of quantitative imaging, at least have people agree um, because we went through I think I don't know, uh some uh quantitative a numeric value that is related to.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:44",
        "end_time": "50:00",
        "annotations": {
            "Summarize conversation": "Maryellen is summarizing previous discussions to highlight the need for a definition of quantitative imaging.",
            "Encourage participation": "She is encouraging group members to participate in agreeing on a definition.",
            "Clarify goal": "The utterance aims to clarify the goal of achieving a shared definition of quantitative imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:44",
        "transcript": "some biomedical phenomena or something, would that cover everybody in one line? So we have 15 minutes, we got the warning. Um, I so do you have yeah. So, um, right. So that's kind of the first bullet that Matt Lew just wrote. The second one was this situation which is not that fun scientifically but is a necessary evil to get and share data, which was how do you? So how do you want to word that folks?",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:44",
        "annotations": {
            "clarify goal": "The speaker is seeking a definition for quantitative imaging that everyone can agree on.",
            "process management": "The speaker mentions a time constraint, noting they have 15 minutes left.",
            "encourage participation": "The speaker invites others to contribute by asking how they want to word something."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "00:44-00:49",
        "transcript": "Context? Just the context in which the image",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:44",
        "end_time": "50:49",
        "annotations": {
            "ask question": "The speaker is requesting clarification or more information about the context in which the image is being discussed."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:49-01:14",
        "transcript": "Well, right, the one liner that describes that problem. Well, all you seem to bring it up so you I thought, you know, you want to tell the greater group that this is a problem. They all know it, but maybe if it's in a bullet point someone will react to it and get it done. What do you think, David?",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:49",
        "end_time": "51:14",
        "annotations": {
            "process management": "The speaker is suggesting a method for handling or presenting information within the group discussion.",
            "encourage participation": "The speaker directly asks for another group member's opinion, encouraging them to participate."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:14-01:19",
        "transcript": "Yeah.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:14",
        "end_time": "51:19",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or validation for a prior statement."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:19-01:33",
        "transcript": "I mean you don't have to, it's your they're they're your your your report back. I just want to get so you guys can get to some of the science that's being brought up in these bullets. So I think if we finalize that, you'll get there. Yes, Fanny.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:19",
        "end_time": "51:33",
        "annotations": {
            "supportive response": "The speaker encourages the group and acknowledges their work, helping to move the discussion forward.",
            "process management": "The speaker guides the discussion flow, suggesting to finalize certain points to proceed with the meeting."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "01:33-01:47",
        "transcript": "I think there are two main features. One was like in a sense the amount of data to process and to interpret and the second was the lack of uniformity in the data.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:33",
        "end_time": "51:47",
        "annotations": {
            "Identify gap": "Fanny explicitly recognizes gaps in the data, specifically the amount of data to process and the lack of uniformity.",
            "Summarize conversation": "Fanny summarizes the conversation by highlighting two main features or challenges."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:48-02:03",
        "transcript": "So the um, yeah, the quantity and lack of standardization of data is a major roadblock. It's kind of like your second big point.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:48",
        "end_time": "52:03",
        "annotations": {
            "summarize conversation": "The speaker is summarizing a point previously discussed.",
            "process management": "The speaker is guiding the discussion and ensuring that key points are highlighted and addressed."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "02:03-02:11",
        "transcript": "what about uh the uh like we do not have uh a standard for verification.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:03",
        "end_time": "52:11",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on the topic of standards for verification.",
            "identify gap": "The speaker explicitly mentions a lack of a standard for verification."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:11-02:31",
        "transcript": "So quantity comma lack of standardization and lack of reference data. Yeah. We got everything covered. It took me uh over 20 years to get to this point where I can consolidate multiple things but I get a lot of practice.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:11",
        "end_time": "52:31",
        "annotations": {
            "Signal expertise": "The speaker is stating her own experience and expertise.",
            "Supportive response": "The speaker is expressing a positive sentiment towards the discussion.",
            "Summarize conversation": "The speaker is summarizing the key points discussed.",
            "Process management": "The speaker is managing the discussion by summarizing."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:39-03:01",
        "transcript": "And then what's next, folks? Looking at those three bullets at the top. Now, given you know what you're doing and given this second major issue is not a problem, can you do that other stuff? What do you guys? That's where the science, that's where the proposal thinking comes in.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:39",
        "end_time": "53:01",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by referencing previous discussion points and directing the conversation towards next steps.",
            "encourage participation": "The speaker is inviting others to contribute their thoughts and ideas."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "03:02-03:17",
        "transcript": "I think you have it in your document uh the algorithm and metric performance uh like development of robust algorithms and metrics.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:02",
        "end_time": "53:17",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges that the topic of algorithm and metric performance is covered in a document."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "03:19-03:48",
        "transcript": "I guess I got to say I'm pretty intrigued by this idea of the latent space. I haven't read the paper that Dave uh put up there, but I I don't know. I mean, maybe you can just summarize Dave because I I haven't read it. It sounds like you have. So how many different modalities are we putting? I mean, are we talking about so when I think of a latent space, I think of some sort of reduction amount of materials that still conveys the let's call it the main idea or the main message from what that data set was and they're all in one smaller space.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:19",
        "end_time": "53:48",
        "annotations": {
            "ask question": "The speaker is requesting information about the latent space and its application to different modalities.",
            "develop idea": "The speaker is engaging with the idea of a latent space and exploring its implications for their field."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:49-04:06",
        "transcript": "No, that's appropriate. Yeah, so the paper describes a framework for integrating arbitrary number or arbitrary number of different modalities. Um, and they demonstrate that on imaging and sequencing data. Um, it works like fairly well.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:49",
        "end_time": "54:06",
        "annotations": {
            "develop idea": "David is expanding on the idea presented in the paper about integrating different modalities.",
            "supportive response": "David is providing a positive evaluation of the paper's approach."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "04:06-04:10",
        "transcript": "Okay.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:06",
        "end_time": "54:10",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement or acknowledgment with a prior statement."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:10-04:50",
        "transcript": "I mean I think that would be really that's I think that's slightly different than getting good data bookkeeping. I mean, I think it's a requirement for that to be able to do that, but I think that it's the next step of that. So one is you're doing good bookkeeping and then the next would be you put it into the latent space and and use it somehow appropriately the way that they they they've at least demonstrated is plausible in that paper.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:10",
        "end_time": "54:50",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea, discussing the relationship between data bookkeeping and using a latent space.",
            "supportive response": "The tone is supportive and explanatory, providing a perspective on how ideas relate to each other."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "04:51-05:32",
        "transcript": "I agree with this too because it I mean it allows for a few things. One is that if we all can't agree on labels, then at least having it in a more uh being able to organize our data in a more abstract uh space might be easy in the absence of us all sharing the same words we want to use to describe things. It also might help us see neighboring uh you know, ideas or or data sets that we wouldn't have realized had we decided to call them by, you know, whatever subjective names we decided on.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:51",
        "end_time": "55:32",
        "annotations": {
            "Develop idea": "Matt is expanding on the idea of using a latent space for organizing data, providing examples of its potential benefits.",
            "Supportive response": "He is expressing agreement with the idea and providing additional insights.",
            "Offer feedback": "Matt is offering feedback on the practical applications and benefits of the idea."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:32-05:37",
        "transcript": "and answers it takes care of all three bullets that were passed to us, right?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:32",
        "end_time": "55:37",
        "annotations": {
            "summarize conversation": "The speaker is summarizing how an approach addresses multiple points discussed earlier in the conversation.",
            "supportive response": "The speaker is expressing a positive view towards the approach by highlighting its comprehensive coverage of the discussed points."
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "05:37-05:37",
        "transcript": "If you can do this.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:37",
        "end_time": "55:37",
        "annotations": {
            "Supportive response": "The utterance expresses conditional agreement or interest in a previous idea, showing a positive evaluation.",
            "Acknowledge contribution": "The utterance acknowledges a previous statement or suggestion, showing that the speaker is engaged with the idea."
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "05:53-06:16",
        "transcript": "Yeah, I mean I was I was thinking about the the quantity lack of standardization and and it's it's also in the nature of of discovery, you know, medical imaging that that you do standardized procedures and and standardized type of imaging.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:53",
        "end_time": "56:16",
        "annotations": {
            "develop idea": "The speaker is elaborating on the challenges and current state of standardization in medical imaging, building on previous discussion.",
            "identify gap": "The speaker implicitly identifies a gap in the lack of standardization in medical imaging.",
            "supportive response": "The speaker is expressing a perspective that aligns with and supports the discussion on standardization and quantity in medical imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:16-06:24",
        "transcript": "Right, I'm going to agree with you and I'm going to go to Matt Lew, but I wanted to say that even in medical imaging, even though it's standardized.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:16",
        "end_time": "56:24",
        "annotations": {
            "acknowledge contribution": "The speaker agrees with a previous statement.",
            "supportive response": "The speaker expresses agreement with someone.",
            "process management": "The speaker manages the discussion flow by transitioning to another topic or participant."
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "06:24-06:50",
        "transcript": "But in in discovery where you you're pushing the knowledge, there there is no there is no not everybody will do the same experiment and produce the same data to make it to make it available, right? Because if once the experiment is done and it's accepted, you you move on to the next thing and then you you you evolve the the technology further and that will create a very heterogeneous type.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:24",
        "end_time": "56:50",
        "annotations": {
            "identify gap": "The speaker recognizes the gap in standardization and homogeneity in data produced during scientific discovery.",
            "develop idea": "The speaker expands on the challenges of data standardization in scientific discovery, building on previous context."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:51-07:15",
        "transcript": "Yeah. And I'm going to agree with you and I'm going to go to Matt Lew, but I wanted to say that even in medical imaging, even though it's standardized, discovery is done because with machine learning AI, we extract out characteristics of say the cancer.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:51",
        "end_time": "57:15",
        "annotations": {
            "develop idea": "The speaker expands on existing ideas by discussing the role of machine learning AI in discovery within standardized medical imaging.",
            "supportive response": "The speaker agrees with previous points before adding more information."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "07:19-08:06",
        "transcript": "Yeah, I um actually just wanted to to to expand on Arnold's point. Um, I guess when we map to this latent space is kind of reflective of all the experiments that you threw at the algorithm for it to learn and and and learn the mapping there. And if you're maybe there's some biological phenomenon that someone hasn't figured out the right sort of imaging conditions or probe or combination of temporal, I don't know, stimuli, right? To to to produce the result.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:19",
        "end_time": "58:06",
        "annotations": {
            "develop idea": "The speaker is expanding on Arnold's point about latent space and its implications for understanding biological phenomena.",
            "ask question": "The speaker asks about the possibility of finding the right imaging conditions or probes for certain biological phenomena.",
            "offer feedback": "The speaker provides a perspective on how to think about mapping to a latent space and its relation to experiments and biological phenomena."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "08:06-08:52",
        "transcript": "I would have I that's a that's a fair point, but I I guess I feel like in the combination in the latent space, you produce also new opportunities that you would have never recognized and you of course can, you know, some sort of uh subsume some of those that might have been fortuitous where you can try them along. But nobody's saying you couldn't acquire the data in your own lab in whatever that latent space or real space, you know, real instrument, the home build that you do.",
        "speaking duration": 46,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:06",
        "end_time": "58:52",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by elaborating on its implications and potential benefits.",
            "supportive response": "The speaker's response is supportive and positive, indicating agreement and validation of the previous idea."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "00:00-00:18",
        "transcript": "annotative algorithms, having something that's reproducible to compare against. So this reference data set idea, a ground truth for which you know you actually made something better, or you just made something that was cool for your microscope. Either one is fine, right? But I think it changes the perception of those of us outside.",
        "speaking duration": 18,
        "nods_others": 1,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:00",
        "end_time": "60:18",
        "annotations": {
            "develop idea": "The speaker elaborates on the concept of reference data sets and their significance.",
            "ask question": "The speaker seeks validation or opinion from the group with 'Either one is fine, right?'.",
            "clarify goal": "The speaker discusses the importance of reference data sets for achieving comparable and better results."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "00:29-00:31",
        "transcript": "Yeah, I agree. That's great.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:29",
        "end_time": "60:31",
        "annotations": {
            "supportive response": "Matt Lew is expressing agreement and a positive evaluation of a previous statement."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:39-00:41",
        "transcript": "Just did a grammar change, sorry.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:39",
        "end_time": "60:41",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "00:42-00:44",
        "transcript": "Thank you. I appreciate it.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:42",
        "end_time": "60:44",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes another group member's input or contribution."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:45-00:58",
        "transcript": "Can't get that part of reading too many student papers out of my head. Even though I do it with myself and colleagues. I know you guys aren't students, don't get me wrong. You know what I mean.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 31,
        "smile_other": 15,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:45",
        "end_time": "60:58",
        "annotations": {
            "express humor": "The speaker explicitly makes a joke about reading too many student papers and corrects their grammar usage, indicating humor."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:59-01:13",
        "transcript": "Um, I think this is exciting because you clarify some items, but you also have some good parts that could lead to, you know, a very necessary proposal. So, um,",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:59",
        "end_time": "61:13",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and a positive evaluation of the discussion, indicating that it has clarified items and has the potential to lead to a necessary proposal."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:22-01:30",
        "transcript": "Um, anyone else that hasn't had a chance to talk? I tried to make sure everyone did. We have a few minutes.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:22",
        "end_time": "61:30",
        "annotations": {
            "encourage participation": "invites someone else in the group to contribute their expertise, opinions or ideas",
            "process management": "Managing meeting flow, time, structure, or organizing group activities"
        }
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "01:42-01:47",
        "transcript": "related to uh Matt would it help you if we uh typed our names in this way?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:42",
        "end_time": "61:47",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification from another group member."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:48-01:50",
        "transcript": "Oh, that would be wonderful. Yes.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:48",
        "end_time": "61:50",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and appreciation for the suggestion made."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:53-01:54",
        "transcript": "Team effort. Yes.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:53",
        "end_time": "61:54",
        "annotations": {
            "supportive response": "Expressing agreement and positivity towards Fanny's suggestion, acknowledging her contribution."
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "02:10-02:15",
        "transcript": "Sorry, I still for some reason can't edit it online if someone wouldn't mind throwing my name on there. Thank you.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:10",
        "end_time": "62:15",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "02:16-02:17",
        "transcript": "I'll do it.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:16",
        "end_time": "62:17",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes and agrees to take on a task or action item presented by another group member."
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "02:17-02:18",
        "transcript": "Okay, thank you, Fanny.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:17",
        "end_time": "62:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:34-03:12",
        "transcript": "I appreciate in the definition of quantitative imaging that you guys use the word is related to. Because I've been up, you know, some people say if you extract out size, you can go in and measure exactly size, but if you extract out something like the texture that you're that's in there, 2D or 3D texture, uh it's not a quantitative imaging because you can't really go measure it, but you can measure it somewhere down the line and that it maybe differentiates between high risk and low risk breast cancer, um, screening patients.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:34",
        "end_time": "63:12",
        "annotations": {
            "develop idea": "expanding on existing ideas by providing examples and clarifying implications",
            "offer feedback": "providing specific suggestions for improvement or modification of existing ideas or approaches"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:13-03:21",
        "transcript": "So to I I'm always one that prefers the broader definition, but that's one of the main reasons I asked that in the beginning.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:13",
        "end_time": "63:21",
        "annotations": {
            "develop idea": "This code applies because Maryellen Giger is expanding on her thoughts about the definitions of quantitative imaging discussed earlier, sharing her preference for a broader definition."
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "03:26-03:32",
        "transcript": "There's one name in there who is not actually in our group, Dylan Burnett from UWM.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:26",
        "end_time": "63:32",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:32-03:33",
        "transcript": "What's the name?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:32",
        "end_time": "63:33",
        "annotations": {
            "ask question": "The speaker is requesting information about a specific name, indicating a question being asked."
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "03:34-03:38",
        "transcript": "There's some name in the in the list on the slide that wasn't actually in our group. So.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:34",
        "end_time": "63:38",
        "annotations": {
            "identify gap": "Arnold identifies a gap or inconsistency in the list of names presented.",
            "critical response": "Arnold questions the accuracy of the list by pointing out a name that doesn't belong.",
            "process management": "Arnold is managing the process by ensuring the accuracy of information."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:38-03:40",
        "transcript": "Uh, is it QIAN? That's Vivian.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:38",
        "end_time": "63:40",
        "annotations": {
            "code name": "ask question",
            "explanation": "The speaker is requesting clarification or information about whether 'QIAN' refers to 'Vivian'."
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "03:41-03:43",
        "transcript": "Dylan Burnett was there.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:41",
        "end_time": "63:43",
        "annotations": {
            "process management": "This code applies because the utterance is about clarifying or correcting information regarding group members or attendees, which relates to managing meeting flow or group activities."
        }
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "03:44-03:50",
        "transcript": "So I think they have the same group uh in uh room six, they have the same topic and he's in next.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:44",
        "end_time": "63:50",
        "annotations": {
            "code name": "process management",
            "explanation": "The utterance discusses the organization of groups and possibly the scheduling of presentations or discussions, which is a form of managing the meeting flow."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:51-03:57",
        "transcript": "Right, make sure you're in group 3.2 because they put quantitative imaging twice. I wonder what they will come up with.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:51",
        "end_time": "63:57",
        "annotations": {
            "process management": "The speaker is managing the group assignments and ensuring everyone is in the correct group for the discussion on quantitative imaging."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:00-04:02",
        "transcript": "It's very interesting when they do double.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:00",
        "end_time": "64:02",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "04:02-04:03",
        "transcript": "Good thing we're going first, I guess.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:02",
        "end_time": "64:03",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:04-04:13",
        "transcript": "We're going to close in 58 seconds. So I thank you. I've enjoyed working with you all. You guys know have a good time.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:04",
        "end_time": "64:13",
        "annotations": {
            "supportive response": "The speaker expresses gratitude and positive sentiment.",
            "process management": "The speaker indicates the meeting is about to close."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "04:13-04:13",
        "transcript": "Thank you very much.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:13",
        "end_time": "64:13",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "04:15-04:17",
        "transcript": "Well, thanks for a great discussion.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:15",
        "end_time": "64:17",
        "annotations": {
            "None": "No relevant code specifically applies to this utterance as it is a general expression of gratitude."
        }
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "04:17-04:17",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:17",
        "end_time": "64:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "04:18-04:18",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:18",
        "end_time": "64:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "04:19-04:20",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:19",
        "end_time": "64:20",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    }
]