[
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:10",
        "transcript": "bullet points under quantitative imaging, right? Kind of jot down in case you you know, your thoughts and let's just take a minute and then we're going to do intros, okay?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:00",
        "end_time": "00:10",
        "annotations": [
            {
                "assign task": "The speaker is assigning the task of jotting down thoughts under quantitative imaging to the team members."
            },
            {
                "propose decision": "The speaker proposes to take a minute to jot down thoughts and then do introductions."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:29-00:35",
        "transcript": "Uh Vivian who just joined, we're jotting down our own ideas during this first minute.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:29",
        "end_time": "00:35",
        "annotations": {
            "explain or define term or concept": "The speaker is explaining to Vivian, who just joined, what the team is currently doing, which is jotting down their own ideas.",
            "assign task": "The speaker is assigning the task of jotting down ideas to Vivian, who just joined the meeting."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:23-01:25",
        "transcript": "Okay, about 10 more seconds.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:23",
        "end_time": "01:25",
        "annotations": {
            "None": "No code applies to this utterance."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:35-01:43",
        "transcript": "Well if you have a lot of ideas you're writing, I don't want to lose those.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:35",
        "end_time": "01:43",
        "annotations": {
            "encourage participation": "Maryellen is encouraging the team members to write down their ideas so they don't lose them, which is a way to ensure everyone contributes.",
            "express enthusiasm": "Maryellen expresses enthusiasm by showing that she values the ideas that the team members are writing down."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:45-02:25",
        "transcript": "Okay. So maybe um we'll start off with introductions. Um we some of us have met already. I'm Mary Ellen Giger, I'm a professor of radiology and medical physics at the University of Chicago. I've been doing AI for multiple decades. Um and I work mainly with medical images to come up with new diagnostics as well as AI for microscopy to help expedite discovery by letting the computer find the cells instead of a human doing.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0.05,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:45",
        "end_time": "02:25",
        "annotations": {
            "propose decision": {
                "Explanation": "The speaker proposes to start off with introductions, suggesting a concrete action for the group to take."
            },
            "explain or define term or concept": {
                "Explanation": "The speaker introduces herself and her background, explaining her role and expertise in AI and medical imaging."
            }
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:25-02:25",
        "transcript": "David, you're in my upper left.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:25",
        "end_time": "02:25",
        "annotations": {
            "assign task": "Maryellen is directing David's attention to himself, which is a subtle way of assigning him the task of introducing himself next."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:26-02:31",
        "transcript": "Oh, uh so okay, so question one, how can I get the most information?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:26",
        "end_time": "02:31",
        "annotations": {
            "ask clarifying question": "David is asking a question to get more information, which is a clarifying question."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:31-02:33",
        "transcript": "Oh no, just say you're",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:31",
        "end_time": "02:33",
        "annotations": {
            "assign task": "Maryellen is about to ask David to introduce himself, assigning him the task of speaking next."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:33-03:03",
        "transcript": "Oh sorry. I'm David Van Valen. Uh I'm assistant professor at Caltech um biology biological engineering um specialization deep learning and particular uh data annotation. Um so I think the uh one sentence version of the world I'm trying to make is one where if you had imaging data and you want to get annotated, the marginal cost of annotation would be so low it's it would almost be free.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0.1,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:33",
        "end_time": "03:03",
        "annotations": {
            "explain or define term or concept": "David explains his specialization and the goal of his research, which is to lower the marginal cost of data annotation for imaging data."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:03-03:03",
        "transcript": "Um and so how do we actually get there?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:03",
        "end_time": "03:03",
        "annotations": {
            "ask clarifying question": "David is asking a question about how to achieve the goal of making data annotation almost free, which he mentioned in the previous turn."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:04-03:05",
        "transcript": "Okay, and Matt?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:04",
        "end_time": "03:05",
        "annotations": {
            "encourage participation": "Maryellen is inviting Matt to introduce himself, continuing the round of introductions."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "03:06-03:07",
        "transcript": "Uh thanks yeah I'm",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:06",
        "end_time": "03:07",
        "annotations": {
            "acknowledge contribution": "The utterance \"Uh thanks\" acknowledges Maryellen Giger for inviting him to speak."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:07-03:11",
        "transcript": "Oh oh two Matts and you're right next to each other too.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:07",
        "end_time": "03:11",
        "annotations": {
            "express humor": "Maryellen makes a lighthearted observation about having two Matts sitting next to each other, which is intended to be humorous."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:11-03:12",
        "transcript": "Matt LEW, Lou.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:11",
        "end_time": "03:12",
        "annotations": {
            "assign task": "Maryellen is assigning the task of introducing himself to Matt Lou."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "03:13-03:45",
        "transcript": "Matt Lou please. Okay, thanks. Uh hi I'm Matt Lou. I'm at Wash U in St. Louis. I've been here for six years. Um I work my uh lab works on single molecule spectroscopy and one of the things that we'd like to do is engineer fluorescence microscopes to not just give you just morphology or concentrations of things but tell you something about the function of what's happening, protein confirmations, activity of of of uh enzymes, things like this.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:13",
        "end_time": "03:45",
        "annotations": {
            "explain or define term or concept": "The speaker explains that his lab works on single molecule spectroscopy and aims to engineer fluorescence microscopes to reveal protein confirmations and enzyme activity, clarifying the lab's focus.",
            "expand on existing idea": "The speaker expands on the capabilities of fluorescence microscopes, adding that they can provide information about protein confirmations and enzyme activity, building on the general understanding of what microscopes do."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "03:45-03:45",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:45",
        "end_time": "03:45",
        "annotations": {
            "acknowledge contribution": "Matt Lew is acknowledging Maryellen Giger for letting him introduce himself."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:45-03:47",
        "transcript": "And Matt uh Lovett.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:45",
        "end_time": "03:47",
        "annotations": {
            "encourage participation": "Maryellen is inviting Matt Lovett-Barron to introduce himself, continuing the round of introductions."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "03:48-04:35",
        "transcript": "Uh yeah, I'm Matt Love Baron. I'm I'm an assistant professor at UC San Diego. I've been here almost a year uh and we're really focused on on neuroscience on trying to understand the brain and to understand how neurons work by looking across multiple levels from their activity to how they connect to each other to um what are the biochemical activities within the cell. And so I'm interested in a lot of these ideas that are coming up here as to how to yeah link together all sorts of different types of data sets and this was touched upon in the previous session as well. Um but also how to get more information out of our our images and and set of images and I'm really interested in learning how to optimize this um as we start to collect these really huge data sets. So I'm excited to learn more about that.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:48",
        "end_time": "04:35",
        "annotations": {
            "explain or define term or concept": "Matt Lovett-Barron explains his research focus on neuroscience, aiming to understand the brain and neuron functions across multiple levels, including activity, connections, and biochemical activities.",
            "expand on existing idea": "Matt Lovett-Barron builds on the ideas discussed in the previous session about linking different types of datasets and extracting more information from images.",
            "express enthusiasm": "Matt Lovett-Barron expresses excitement about learning how to optimize the process of collecting and analyzing large datasets."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:35-04:36",
        "transcript": "Thank you and Goku?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:35",
        "end_time": "04:36",
        "annotations": {
            "encourage participation": "Maryellen is inviting Goku to introduce themself, continuing the round of introductions."
        }
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "04:38-05:15",
        "transcript": "Yeah. Um my name is Gokul. Uh I'm assistant professor at UC Berkeley. I've been here almost two years now. Um yeah, what we do is basically at the um intersection of instrument development, the application of these instruments um and uh quantitative image analysis. Um so what we're generally interested in is being able to understand and quantify dynamics across um scales uh both in time and space. So ranging from milliseconds and nanometers to um uh uh minutes, hours over over millimeters.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:38",
        "end_time": "05:15",
        "annotations": [
            {
                "explain or define term or concept": "Gokul explains his research interests, focusing on instrument development, application, and quantitative image analysis to understand and quantify dynamics across different scales, providing context for his expertise."
            }
        ]
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "05:15-05:16",
        "transcript": "Um yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:15",
        "end_time": "05:16",
        "annotations": {
            "None": "This utterance does not contain any content that can be mapped to the codebook."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:16-05:17",
        "transcript": "Okay, thank you. Arnold.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:16",
        "end_time": "05:17",
        "annotations": {
            "acknowledge contribution": "Maryellen acknowledges Gokul's introduction before moving on to the next person, Arnold."
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "05:19-06:27",
        "transcript": "Hi everyone, some of you know me already. So I'm my name is Arnold Hayer. I'm an assistant professor at McGill University in the Department of Biology. I've been there for about three years now. And my lab is a cell biology lab. We do a lot of imaging and uh we ask the questions of how local signaling dynamics result in cell shape changes during cell migration. We do that in individually migrating cells and in collectively migrating cells. So there's this scale issue of of molecular organelles and cells and super cellular structures where we try to to bridge those different domains by using different modes of microscopy. So my lab relies a lot of on on on live cell imaging and I think uh for us it's a bottleneck to to do quantitative uh imaging. We do like cell edge tracking, cell tracking but but we would like to have better ways and faster ways of developing um analysis modalities that suit our questions and it's they're always changing so so one needs to adapt these um algorithms quickly and that's something that I'm hoping to to discuss more uh in this group.",
        "speaking duration": 68,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:19",
        "end_time": "06:27",
        "annotations": [
            {
                "explain or define term or concept": "The speaker explains their lab's focus on cell biology, imaging, and the relationship between signaling dynamics and cell shape changes, providing context for their research."
            },
            {
                "present new idea": "The speaker introduces the idea of bridging different domains using different modes of microscopy to address the scale issue of molecular organelles, cells, and super cellular structures."
            },
            {
                "express frustration": "The speaker expresses frustration with the bottleneck of quantitative imaging in their lab, specifically regarding cell edge and cell tracking, indicating a need for better and faster analysis methods."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:27-06:28",
        "transcript": "Thank you and Fanny.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:27",
        "end_time": "06:28",
        "annotations": {
            "acknowledge contribution": "Maryellen acknowledges the previous speaker's introduction before moving on to the next person, Fanny."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "06:29-07:25",
        "transcript": "Hi, I'm Fanny Chapin from the University of Kentucky. I primarily work with magnetic resonance imaging to uh visualize inflammation and uh response to a cancer response to therapy uh using either iron oxide nanoparticles or fluorine imaging. And one of the limitations specific specifically in iron oxides is you do see a signal change on your image that is quantitative, but you cannot really correlate it to the number of cells that have influxed in the area. So I would be interested in uh developing things like this.",
        "speaking duration": 56,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:29",
        "end_time": "07:25",
        "annotations": {
            "explain or define term or concept": "The speaker explains their work with magnetic resonance imaging, iron oxide nanoparticles, and fluorine imaging.",
            "present new idea": "The speaker introduces the idea of developing methods to correlate signal changes in iron oxide imaging with the number of cells in the area, which is a current limitation.",
            "express enthusiasm": "The speaker expresses interest in developing methods to correlate signal changes with cell numbers, indicating enthusiasm for the topic."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:25-07:26",
        "transcript": "Great. Um",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:25",
        "end_time": "07:26",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges the previous speaker's introduction, signaling a transition to the next person."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:26-07:55",
        "transcript": "again, we've got a a really nice um broad imaging group here of we have folks at the human, folks at the cellular level, some looking at functions at those different levels, some in um more of um AI and others are in hardware. So I'm looking forward to a great conversation. Before we get going, we need a uh and for those who just joined, I think it was Vivian and Fanny, we did spend the first minute kind of thinking at those bullet points and jotting down on our own thoughts if you want to do that.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:26",
        "end_time": "07:55",
        "annotations": {
            "express enthusiasm": "Maryellen expresses enthusiasm for the diverse imaging group, indicating optimism for the upcoming conversation.",
            "acknowledge contribution": "Maryellen acknowledges the presence of people working at different levels (human, cellular), in AI, and in hardware, recognizing their contributions to the group.",
            "encourage participation": "Maryellen encourages Vivian and Fanny, who recently joined, to jot down their thoughts, inviting them to participate in the brainstorming activity."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:55-07:56",
        "transcript": "But now we need a recorder.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:55",
        "end_time": "07:56",
        "annotations": {
            "assign task": "Maryellen assigns the task of being a recorder to someone in the group."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:09",
        "transcript": "I've been a recorder, you can't do it again. So if you are there any volunteers of someone who has not done it yet.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:00",
        "end_time": "10:09",
        "annotations": [
            {
                "encourage participation": "Maryellen is asking for a volunteer to be the recorder, encouraging someone who hasn't done it before to participate."
            }
        ]
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "00:10-00:12",
        "transcript": "Uh, I'm happy to do it.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:10",
        "end_time": "10:12",
        "annotations": {
            "express agreement": "Matt Lew agrees to be the recorder, which was requested by Maryellen in the prior turn."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:12-00:27",
        "transcript": "Thank you, Matt Lew. Just I didn't want the other Matt thinking, what? Okay, we have two Matts. All right, good. Um, and I'm going to I I can't even say Matt L. You're both Matt L's. Okay, we got Matt Lew and Matt Lovett Barron. Got it.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 53,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:12",
        "end_time": "10:27",
        "annotations": [
            {
                "acknowledge contribution": "Maryellen acknowledges Matt Lew's contribution of volunteering to be the recorder."
            },
            {
                "express humor": "Maryellen makes a joke about the two Matts having the same first initial to express humor."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:28-00:39",
        "transcript": "Um, okay, that's good. And I'm going to have you guys take over this this discussion, but I have one question first. I need to hear your definitions of quantitative imaging.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:28",
        "end_time": "10:39",
        "annotations": {
            "assign task": "Maryellen assigns the task of leading the discussion to the other participants.",
            "ask clarifying question": "Maryellen asks the participants to define quantitative imaging, seeking clarification on the term."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:39-00:43",
        "transcript": "Because I've I've run into multiple kinds throughout my lifetime.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:39",
        "end_time": "10:43",
        "annotations": {
            "explain or define term or concept": "Maryellen is asking for definitions of quantitative imaging, implying she wants to explain the different kinds she has encountered."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:43-00:50",
        "transcript": "Anyone tell me what quantitative imaging is and Matt Lew is oh, before we go Matt, so what in the other two groups.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:43",
        "end_time": "10:50",
        "annotations": {
            "ask clarifying question": "Maryellen is asking for a definition of quantitative imaging, indicating she wants clarification on the term.",
            "encourage participation": "Maryellen is inviting someone to provide a definition of quantitative imaging, encouraging participation from the group."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:50-01:11",
        "transcript": "The recorder opened up a Google Doc. And so half my screen are you guys because I like to actually see you and that's why I don't really like the recorder sharing their screen because then you're all bunched up. But then if you put the link of the Google Drive in the chat and we click on it, we've got the Google Drive on one side and our Hollywood squares on the other.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:50",
        "end_time": "11:11",
        "annotations": [
            {
                "assign task": "Maryellen is assigning the task of putting the Google Drive link in the chat to someone, likely the recorder, so everyone can access the document."
            },
            {
                "explain or define term or concept": "Maryellen is explaining why she prefers the recorder not to share their screen, because it bunches up the participants' video feeds, and she is suggesting an alternative way to view the Google Doc and the participants simultaneously."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:12-01:12",
        "transcript": "Is that good?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:12",
        "end_time": "11:12",
        "annotations": {
            "ask clarifying question": "Maryellen is asking if her suggestion of splitting the screen between the Google Doc and the video feed is a good solution for the participants."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "01:13-01:17",
        "transcript": "Yeah, I'll try that right now. So let me create a doc and then I'll put the link in the chat.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:13",
        "end_time": "11:17",
        "annotations": {
            "assign task": "Matt Lew volunteers to create a document and share the link in the chat, which is a task assigned to him by the group's need for a recorder.",
            "confirm decision": "Matt Lew confirms the decision to create a document and share the link in the chat by saying 'Yeah, I'll try that right now.'"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:17-01:30",
        "transcript": "Okay. And while Matt's doing that, maybe um we could um go back to what's the definition of quantitative imaging? What does that remind you, David?",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:17",
        "end_time": "11:30",
        "annotations": {
            "ask clarifying question": "Maryellen asks for the definition of quantitative imaging, seeking clarification on the term.",
            "encourage participation": "Maryellen asks David what the definition of quantitative imaging reminds him of, inviting him to contribute to the discussion."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:31-01:48",
        "transcript": "Uh imaging done in such a way that the images can be converted into some numerical um format where the numbers actually have meaning. Um that's probably probably closest I could I could I could give you.",
        "speaking duration": 17,
        "nods_others": 1,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:31",
        "end_time": "11:48",
        "annotations": {
            "explain or define term or concept": "David is explaining the definition of quantitative imaging in response to Maryellen's question."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:49-01:53",
        "transcript": "Okay, I'm going to push on that. Yeah.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:49",
        "end_time": "11:53",
        "annotations": {
            "expand on existing idea": "Maryellen is going to elaborate further on David's definition of quantitative imaging, building upon his initial explanation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:56-02:06",
        "transcript": "Because actually I'm I'm actually in your ballpark. I'm an AI person. So now I want someone who is um Arnold, what's quantitative imaging to you?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:56",
        "end_time": "12:06",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Maryellen acknowledges David's definition of quantitative imaging by saying she is in his 'ballpark', recognizing his input."
            },
            "encourage participation": {
                "Explanation": "Maryellen then invites Arnold to contribute his definition of quantitative imaging by asking him directly."
            }
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "02:06-02:35",
        "transcript": "Maybe maybe I can say contrasting to to qualitative imaging where you just look at morphology, shapes and you know, describe them in in in a in a non non numerical form, quantitative imaging would would be to to convert features or intensities into into numbers so that you can make them make those observations or the you what you detect comparable between experiments between cells and conditions.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:06",
        "end_time": "12:35",
        "annotations": {
            "explain or define term or concept": "Arnold is explaining quantitative imaging by contrasting it with qualitative imaging, describing how quantitative imaging converts features or intensities into numbers for comparison between experiments.",
            "expand on existing idea": "Arnold is expanding on the definition of quantitative imaging that was previously requested by Maryellen."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:36-02:43",
        "transcript": "Okay. Um anyone else want to say something different? Because if not, I'm going to go to Matt Lew who's who and and who's does functional.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:36",
        "end_time": "12:43",
        "annotations": {
            "encourage participation": "Maryellen is encouraging others to contribute their definitions of quantitative imaging, building on the previous discussion with David and Arnold.",
            "present new idea": "Maryellen is introducing the idea of hearing different perspectives on the definition of quantitative imaging, which hasn't been explicitly stated as a goal yet."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "02:44-02:44",
        "transcript": "I I",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:44",
        "end_time": "12:44",
        "annotations": {
            "None": "The utterance is incomplete and does not express a complete thought or idea."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:44-02:44",
        "transcript": "I",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:44",
        "end_time": "12:44",
        "annotations": {
            "encourage participation": "Maryellen is about to encourage someone to participate by saying \"I\", indicating she is about to call on someone."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "02:51-03:28",
        "transcript": "Yeah, I'm going to say I was going to say beyond and that's where I said in uh earlier in the number of cells. Beyond having an estimate of it's lower or higher contrast or signal or things like that, being able to to know what this higher or lower means because if you don't have a point of reference to begin with, what is higher lower, especially if you're thinking of translating your signal to the clinic, you may not have that baseline. Uh, so to me quantitative is also being able to interpret a number on its own.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 89,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:51",
        "end_time": "13:28",
        "annotations": {
            "expand on existing idea": "Fanny expands on the definition of quantitative imaging, building on previous contributions by David and Arnold, adding the importance of interpreting the numerical values in a meaningful way.",
            "explain or define term or concept": "Fanny explains the concept of quantitative imaging by highlighting the importance of having a point of reference to interpret the numerical values obtained from imaging, especially in clinical settings."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:28-03:32",
        "transcript": "Okay. Good. Um others who wants to add to this list?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:28",
        "end_time": "13:32",
        "annotations": {
            "encourage participation": "Maryellen is asking if anyone else wants to contribute to the discussion about the definition of quantitative imaging, encouraging participation from the group."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "03:32-04:00",
        "transcript": "I agree with that and I I'd say that one thing that um I think about with quantitative imaging is something that would be uh able to take something that has meaning in one experiment and be able to actually compare it to something in another experiment. So not only that there are numbers, but that those numbers um are are regular enough that we know how to interpret them with respect to one another.",
        "speaking duration": 28,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:32",
        "end_time": "14:00",
        "annotations": {
            "express agreement": "Matt Lovett-Barron explicitly agrees with Fanny's definition of quantitative imaging.",
            "expand on existing idea": "Matt Lovett-Barron builds on the definition of quantitative imaging by adding the idea that the numbers obtained should be comparable across different experiments, implying a level of standardization and interpretability."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:00-04:01",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:00",
        "end_time": "14:01",
        "annotations": {
            "acknowledge contribution": "Maryellen acknowledges the previous speaker's contribution to the discussion about quantitative imaging, signaling that she has heard and understood the point being made."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:01-04:07",
        "transcript": "And I anyone else? I know Matt Lew, you were going to say some I cut you off to go to the other Matt. I'll let you.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:01",
        "end_time": "14:07",
        "annotations": {
            "encourage participation": "Maryellen encourages Matt Lew to participate in the discussion by saying she cut him off earlier and now wants to hear his thoughts on quantitative imaging, which is a continuation of the discussion about definitions of quantitative imaging."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "04:07-05:01",
        "transcript": "No worries. Um, so one aspect of quantitation that I uh think about is um there is probably some underlying biological phenomenon or process, maybe it's molecular, maybe it's signaling, maybe it's, you know, phoslation or what have you. Um, that can be quantified uh so that it can become a testable hypothesis and that, you know, ultimately our images are just a uh our data is just a way to actually get at the underlying phenomenon and and how it is changing over time or what have you. So I would I would say uh it it kind of builds off of of of the other Matt's point that we we need to to take our data to describe the fundamental science that we're trying to understand and and then um be able to compare in that space.",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 11,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:07",
        "end_time": "15:01",
        "annotations": {
            "expand on existing idea": "Matt Lew builds on the previous Matt's point about quantitative imaging, adding that it should describe the fundamental science and be comparable.",
            "explain or define term or concept": "Matt Lew explains that quantitative imaging should quantify underlying biological phenomena to become a testable hypothesis.",
            "provide supporting evidence": "Matt Lew provides examples of biological phenomena like molecular processes, signaling, and phoslation that can be quantified through imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:01-05:02",
        "transcript": "Great. You can have the recorder write that down.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:01",
        "end_time": "15:02",
        "annotations": {
            "assign task": "Maryellen assigns the task of writing down the definition of quantitative imaging to the recorder, Matt Lew."
        }
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "05:02-05:02",
        "transcript": "We'll work on it.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:02",
        "end_time": "15:02",
        "annotations": {
            "assign task": "Matt Lew acknowledges the task assigned by Maryellen to record the definitions of quantitative imaging and confirms that he will work on it."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:02-05:20",
        "transcript": "Um, so the reason I asked this question, so I I do a lot of AI mainly at medical images. And if we take for example, uh not um like dynamic contrast enhance MRI. So we're looking at say the uptake of a contrast agent.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:02",
        "end_time": "15:20",
        "annotations": {
            "explain or define term or concept": "Maryellen explains the context of her question by stating that she works with AI on medical images, setting the stage for her example of dynamic contrast enhanced MRI.",
            "provide supporting evidence": "Maryellen provides an example of dynamic contrast enhanced MRI to support her question about the definition of quantitative imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:20-05:31",
        "transcript": "In AI, we try to model that, I'll put that in quotes, using um knowledge of some input image that we choose wisely, we don't just put any old image in.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:20",
        "end_time": "15:31",
        "annotations": {
            "explain or define term or concept": "Maryellen explains that in AI, they try to 'model' something using knowledge of a wisely chosen input image, clarifying their approach in the context of AI and medical imaging.",
            "expand on existing idea": "Maryellen expands on the discussion of quantitative imaging by describing how AI is used to model the uptake of a contrast agent, building upon the previous discussion of quantitative imaging definitions."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:31-06:02",
        "transcript": "But then I have colleagues who say the number you have out can't be measured. So I'm glad someone brought that up. It has to be measurable relative to some biomedical situation, you know, I relate it maybe to the likelihood of cancer or not. So then we have the people who come up and say, well no, it has to be where you are measuring based on the known physiology and the acquisition something like the the K trans value.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:31",
        "end_time": "16:02",
        "annotations": {
            "provide supporting evidence": "Maryellen mentions that her colleagues say the number from AI can't be measured, supporting the need for measurable outputs relative to a biomedical situation, which was brought up by someone earlier in the discussion.",
            "expand on existing idea": "Maryellen expands on the definition of quantitative imaging by providing an example of how it relates to biomedical situations like the likelihood of cancer, building on the previous discussion about the meaning of quantitative imaging.",
            "explain or define term or concept": "Maryellen explains the concept of measurable outputs in quantitative imaging by relating it to biomedical situations and mentioning the K trans value, clarifying the requirements for quantitative imaging outputs."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:02-06:11",
        "transcript": "And so I've always run into those two um camps and I think it's useful to to see those two camps as we go forward. I'm going to be quiet in a second.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:02",
        "end_time": "16:11",
        "annotations": {
            "explain or define term or concept": "Maryellen is explaining the two different perspectives or \"camps\" she has encountered regarding quantitative imaging, one focused on AI modeling and the other on measurable biomedical situations.",
            "propose decision": "Maryellen proposes that it will be useful for the group to consider these two perspectives as they proceed with their discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:11-06:35",
        "transcript": "Um, but uh it has to be um measurable and to me, I think both types are useful and in fact you can merge them. It all depends on your task. The clinical task, biological task, what do you want your to do.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:11",
        "end_time": "16:35",
        "annotations": {
            "expand on existing idea": "Maryellen expands on the discussion about the definition of quantitative imaging by stating that measurability is important and that both types of quantitative imaging (AI-based and physiology-based) are useful and can be merged, depending on the task.",
            "present new idea": "Maryellen presents the idea that the two camps of quantitative imaging can be merged depending on the task, which is a novel concept in the context of the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:35-06:36",
        "transcript": "So with that.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:35",
        "end_time": "16:36",
        "annotations": {
            "None": "This utterance does not fit any of the codes in the codebook, as it is a transitional phrase."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:36-06:37",
        "transcript": "Now that we.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:36",
        "end_time": "16:37",
        "annotations": {
            "None": "This utterance is incomplete and does not express a complete thought or idea, so no code applies."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:37-06:41",
        "transcript": "Now that we kind of all agree, disagree on what quantitative imaging is.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:37",
        "end_time": "16:41",
        "annotations": {
            "express humor": "Maryellen uses a self-deprecating tone by saying they \"agree, disagree\" on the definition of quantitative imaging, which is humorous given the preceding discussion where multiple definitions were offered."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:41-06:45",
        "transcript": "Um, now we can go forward, I think. I think that was important.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:41",
        "end_time": "16:45",
        "annotations": {
            "confirm decision": "Maryellen is confirming the decision to move forward with the discussion, now that they have established a shared understanding of quantitative imaging, building upon the previous discussion about its definition."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:47-07:22",
        "transcript": "Uh, and looking at the bullets for um it it you know, how can we get the most information out of an image? Can algorithm scoring, which to me is like um uh output from machine learning AI or some other model algorithmic model uh based more on the physiology uh can that provide searchable and archivable records.",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:47",
        "end_time": "17:22",
        "annotations": {
            "present new idea": "The speaker introduces the idea of using algorithm scoring, based on physiology, to provide searchable and archivable records, which is a novel concept in the context of the discussion.",
            "explain or define term or concept": "The speaker explains that algorithm scoring is like the output from machine learning AI or some other algorithmic model, clarifying the term for the group.",
            "ask clarifying question": "The speaker asks if algorithm scoring based on physiology can provide searchable and archivable records, seeking to explore the potential of this approach."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:22-07:22",
        "transcript": "So let's.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:22",
        "end_time": "17:22",
        "annotations": {
            "propose decision": "The phrase \"So let's\" suggests that Maryellen is about to propose a decision or action for the group to take, likely related to the discussion of quantitative imaging and the bullet points mentioned earlier."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:22-07:22",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:22",
        "end_time": "17:22",
        "annotations": [
            {
                "Yeah": "This utterance expresses agreement with the previous statement, though the specific point of agreement is unclear without more context."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:22-07:23",
        "transcript": "Let's start the discussion.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:22",
        "end_time": "17:23",
        "annotations": {
            "propose decision": "Maryellen proposes to start the discussion, moving the meeting forward after the introductions and definition of quantitative imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:23-07:23",
        "transcript": "Um.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:23",
        "end_time": "17:23",
        "annotations": {
            "None": "No code applies to this utterance."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:23-07:23",
        "transcript": "Anyone.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:23",
        "end_time": "17:23",
        "annotations": {
            "encourage participation": "Maryellen is encouraging anyone to participate in the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:23-07:24",
        "transcript": "Go.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:23",
        "end_time": "17:24",
        "annotations": {
            "encourage participation": "Maryellen is explicitly encouraging someone to speak up and contribute to the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:24-07:24",
        "transcript": "Goku.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:24",
        "end_time": "17:24",
        "annotations": [
            {
                "encourage participation": "Maryellen is explicitly inviting Goku to speak, continuing the round of introductions and prompting him to contribute to the discussion."
            }
        ]
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "07:24-08:31",
        "transcript": "Yeah, I think for the first question at least, um, it really depends on whether we are hypothesis testing or we're hypothesis generating using the information or using the images that that we've collected. Um, of course the the latter, oh sorry, the the former of hypothesis generating um is most likely when we are likely to to um make new discoveries because that's something that we haven't seen. Um, but to do so requires um again, quantities of data where you're looking for needles in a haystack.",
        "speaking duration": 67,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:24",
        "end_time": "18:31",
        "annotations": [
            {
                "present new idea": "Gokul introduces the idea that the approach to getting information from images depends on whether the goal is hypothesis testing or hypothesis generation, which is a novel consideration in the context of the discussion so far."
            },
            {
                "expand on existing idea": "Gokul expands on the idea of hypothesis generation, adding that it is more likely to lead to new discoveries but requires large quantities of data, building on the previous discussion about quantitative imaging and its applications."
            }
        ]
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "08:31-08:31",
        "transcript": "Um.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": {
            "None": "This utterance does not contain any content that can be coded."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:31-08:31",
        "transcript": "So.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": {
            "None": "This utterance does not contain any content that can be coded."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "08:31-08:31",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": {
            "express agreement": "David agrees with the previous statement made by Gokul about hypothesis testing and generation using images."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:31-08:31",
        "transcript": "Uh.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:31",
        "end_time": "18:31",
        "annotations": [
            {
                "None": "No code applies to this utterance."
            }
        ]
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "00:00-00:49",
        "transcript": "this would do would um would be um generating machine learning methods that, you know, taken images and produce a vector embedding. Um and so images would be quote unquote similar if they're close in this um in this lower dimensional um embedding space. And that's what ties into the last um part which is how can image matching be optimized to stitch together data sets collected at different times or with different modalities. Um and I think the embedding worldview that would be, you know, you'd want to have a way of mapping things to a shared embedding space.",
        "speaking duration": 49,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:49",
        "annotations": [
            {
                "present new idea": "David introduces the idea of using machine learning methods to generate vector embeddings from images, where similar images are close in a lower-dimensional embedding space, which is a novel concept not previously mentioned in the discussion.",
                "expand on existing idea": "David expands on the idea of image matching by suggesting that images can be optimized to stitch together data sets collected at different times or with different modalities by mapping things to a shared embedding space, building upon the previous discussion about getting the most information out of images.",
                "explain or define term or concept": "David explains the concept of vector embedding, stating that images are considered similar if they are close in a lower-dimensional embedding space, clarifying the terminology for the group."
            }
        ]
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "00:49-01:01",
        "transcript": "And I'd say like, you know, from the methods perspective, this isn't um, you know, this isn't crazy or even like that far out of the norm given like what machine learning methods can uh what machine learning methods can do now.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:49",
        "end_time": "21:01",
        "annotations": {
            "provide supporting evidence": "David is providing supporting evidence by stating that the machine learning methods he is suggesting are not unusual or far from the norm, implying that they are feasible and grounded in current capabilities."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:01-01:22",
        "transcript": "Um, you know, the contract the contrastive learning uh methods are very powerful for generating useful embeddings. And I know of at least one uh researcher Carolyn Uhler um uh who comes to mind who's like actively working on methods for, you know, building like these sort of shared embeddings. Um yeah.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:01",
        "end_time": "21:22",
        "annotations": {
            "provide supporting evidence": "The speaker mentions contrastive learning methods as powerful for generating useful embeddings and names a researcher, Carolyn Uhler, who is actively working on methods for building shared embeddings, providing evidence to support the idea of using machine learning methods to generate vector embeddings for images.",
            "expand on existing idea": "This utterance expands on the idea of generating machine learning methods that take images and produce a vector embedding, which was introduced in the previous turn by the same speaker."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "01:23-01:28",
        "transcript": "Can I can I ask is that the that is kinds of embeddings can be generated without metadata?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:23",
        "end_time": "21:28",
        "annotations": {
            "ask clarifying question": "Matt Lovett-Barron asks a question to clarify whether the embeddings David Van Valen mentioned can be generated without metadata, seeking further explanation on the topic."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:29-01:33",
        "transcript": "Uh what so what do you mean by? So what do you mean by without metadata?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:29",
        "end_time": "21:33",
        "annotations": {
            "ask clarifying question": "Matt Lovett-Barron asked if embeddings can be generated without metadata, and David is asking for clarification on what Matt means by 'without metadata' to better understand the question."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "01:33-01:44",
        "transcript": "Uh like without additional documentation about how the image yeah, I mean, I suppose without maybe without detailed metadata beyond just knowing what what um how big the pixels are, what type of microscope you got it from that type of thing.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:33",
        "end_time": "21:44",
        "annotations": {
            "ask clarifying question": "Matt Lovett-Barron is asking David Van Valen to clarify what he means by 'without metadata' in the context of generating embeddings, specifically inquiring if embeddings can be generated without detailed documentation about the image, beyond basic information like pixel size and microscope type, after David proposed generating machine learning methods that produce a vector embedding."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:44-02:21",
        "transcript": "Okay. So I see no good reason why said metadata can't be made available. Uh the methods that I'm aware of do require enough metadata so that, you know, let's say like you're trying to make an embedding from, you know, three different modalities, you know, imaging, um, you know, RNA uh RNA sequencing and attack sequencing. You need to have enough metadata to know that these data sets came from like the same sample, right? Um, and without that, then, you know, you just don't get to like you just don't um get to play ball.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:44",
        "end_time": "22:21",
        "annotations": {
            "expand on existing idea": "David expands on his idea of using vector embeddings for image analysis by stating that metadata is important for generating these embeddings, especially when integrating data from different modalities, building upon his previous explanation of how image matching can be optimized.",
            "provide supporting evidence": "David provides supporting evidence for the importance of metadata by explaining that the methods he knows require enough metadata to ensure that data sets from different modalities come from the same sample, strengthening his argument for the necessity of metadata in generating useful embeddings."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:21-02:27",
        "transcript": "because you don't have the information, which is that these are all essentially the same thing, you know, is lost.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:21",
        "end_time": "22:27",
        "annotations": {
            "expand on existing idea": "David is expanding on his idea of using vector embeddings for images, explaining that metadata is necessary to ensure the data sets being compared are from the same sample, building upon the previous discussion about image matching and shared embedding spaces."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "02:27-02:28",
        "transcript": "Yeah. Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:27",
        "end_time": "22:28",
        "annotations": [
            {
                "express agreement": "Matt Lovett-Barron expresses agreement with David Van Valen's explanation regarding the need for metadata in generating embeddings, confirming his understanding and acceptance of the point."
            }
        ]
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:28-02:30",
        "transcript": "Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:28",
        "end_time": "22:30",
        "annotations": {
            "express agreement": "David agrees with Matt's question about embeddings and metadata."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:30-02:42",
        "transcript": "You know, I I think you know, things that like the things that interest me um is getting uh the practices um of folks who collect data, myself being one. I'm I'm one of them.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:30",
        "end_time": "22:42",
        "annotations": {
            "None": "This utterance does not fit into any of the defined codes as it is a general statement about the speaker's interests."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "02:43-03:07",
        "transcript": "Uh but encouraging practices that make the data itself like more machine learnable, right? So that these issues of, you know, well, do I have the appropriate metadata, you know, do I know what microscope it came from? Do I know the appropriate resolution? dot dot dot dot. You know, were these things are just, you know, packaged with the data set. So, you know, if you're developing these computational methods either internally or externally, you don't have to worry about that that much because it's just there.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:43",
        "end_time": "23:07",
        "annotations": {
            "expand on existing idea": "David is expanding on the idea of using machine learning methods to generate vector embeddings by suggesting practices that make data more machine learnable, such as including appropriate metadata with the dataset.",
            "propose decision": "David proposes encouraging practices that make data more machine learnable by packaging metadata with the dataset, so that computational methods can be developed without worrying about metadata issues."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:07-03:26",
        "transcript": "Um and it seems like it's a, you know, the bare minimum that one would need for, you know, some notion of reproducibility. Uh, you know, I like that's usually enough metadata. Um, but right now, you know, even sharing data without that is a um community problem.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:07",
        "end_time": "23:26",
        "annotations": {
            "expand on existing idea": "David is expanding on the idea of metadata, adding that it is the bare minimum needed for reproducibility, building on the previous discussion about the importance of metadata for image analysis and comparison.",
            "provide supporting evidence": "David supports his argument about the importance of metadata by stating that it is the bare minimum for reproducibility, providing a reason to strengthen his point.",
            "present new idea": "David presents the idea that sharing data without sufficient metadata is a community problem, introducing a new perspective on the challenges of data sharing."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:27-03:33",
        "transcript": "And what about the performance of these you you could have a really with system um and you can do searching on it.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:27",
        "end_time": "23:33",
        "annotations": {
            "expand on existing idea": "Maryellen is expanding on the discussion of searchable and archivable records by asking about the performance of these systems, building on the previous discussion about algorithm scoring and its potential for creating such records."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:34-03:51",
        "transcript": "Um, but I think the performance has to be at a high enough level that you're search you're, you know, say you're searching on a particular characteristic of cancer and if you get it wrong and all of a sudden your cancer cases are now being thrown in a a bunch of non cancer areas. So I think",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:34",
        "end_time": "23:51",
        "annotations": {
            "provide supporting evidence": "The utterance provides a logical reasoning to strengthen the idea that the performance of a search system needs to be high enough, because if the search is wrong, cancer cases could be misclassified, which is a problem.",
            "offer constructive criticism": "The utterance critiques the performance of a search system, suggesting that it needs to be at a high enough level to avoid misclassifying cancer cases, which is a critique with the intent to improve the system."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:51-04:03",
        "transcript": "Yeah, that's true. I know like Google put together like a um an image searching algorithm for like cancer cases, right? If you have if you had a case where a patch of the image, you know, show me cases that are similar to this.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:51",
        "end_time": "24:03",
        "annotations": {
            "provide supporting evidence": "The speaker is providing supporting evidence by mentioning Google's image searching algorithm for cancer cases, which strengthens the discussion about image analysis and searching capabilities.",
            "expand on existing idea": "The speaker is expanding on the idea of image searching and analysis by providing a real-world example of Google's algorithm for cancer cases, building upon the previous discussion about searchable and archivable records."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:03-04:09",
        "transcript": "So the search metric as well so the the performance of the search metric and the search algorithm.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:03",
        "end_time": "24:09",
        "annotations": {
            "expand on existing idea": "This utterance builds upon the previous discussion about image searching algorithms for cancer cases, adding the importance of the search metric and algorithm performance to the discussion."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:09-04:11",
        "transcript": "Yeah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:09",
        "end_time": "24:11",
        "annotations": {
            "express agreement": "David agrees with Maryellen's point about the importance of search metric performance in image searching algorithms for cancer cases, which she brought up in the previous turn."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:11-04:25",
        "transcript": "Um has to um yeah, so I guess my my my I guess my larger point is that from like the algorithmic perspective, I'm not saying like there aren't improvements to be made, um, but these are at least to my in my view like very addressable problems.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:11",
        "end_time": "24:25",
        "annotations": {
            "express agreement": "David expresses agreement with Maryellen's point about the importance of search metric performance, acknowledging that improvements can be made from an algorithmic perspective.",
            "expand on existing idea": "David expands on the discussion about the performance of search metrics and algorithms, stating that the algorithmic problems are addressable."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:25-04:27",
        "transcript": "There's always improvements.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:25",
        "end_time": "24:27",
        "annotations": {
            "expand on existing idea": "This utterance builds upon the previous discussion about the algorithmic perspective and improvements to be made in image searching algorithms for cancer cases, suggesting that there is always room for further advancements."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:27-04:36",
        "transcript": "Yeah, from the algorithm side. It's more like what like uh what basically what Matt was like alluding to is like wrangling the data to a format where you actually can start to use these approaches.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:27",
        "end_time": "24:36",
        "annotations": {
            "expand on existing idea": "David is expanding on the previous discussion about algorithm performance and data search, suggesting that the main challenge is wrangling the data into a usable format, building upon Matt's earlier point about data standardization."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "04:36-04:50",
        "transcript": "Um for every every project that we've done internally or have been working with uh external collaborators that is like the most significant um pain point. And the folks who've been willing to engage in that effort have been the ones who've been like the most successful.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:36",
        "end_time": "24:50",
        "annotations": {
            "provide supporting evidence": "The speaker supports their claim about the most significant pain point in projects by stating that the folks who've been willing to engage in that effort have been the most successful, providing anecdotal evidence based on their experience."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "04:50-04:51",
        "transcript": "Mhm.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:50",
        "end_time": "24:51",
        "annotations": {
            "express agreement": "Matt Lovett-Barron expresses agreement with David Van Valen's point about the pain point being wrangling the data into a usable format."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:51-05:03",
        "transcript": "And and I think where I think there's a lot of um potential here of things we can go. So I want you to push it, you know, even if you're saying oh it's going to take too much data, we can't do anything. Assume you can handle all the data you can get.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:51",
        "end_time": "25:03",
        "annotations": {
            "encourage participation": "Maryellen encourages the group to push the boundaries of what's possible, even if it seems like it would require too much data, building on the discussion about quantitative imaging and data wrangling.",
            "express enthusiasm": "Maryellen expresses enthusiasm about the potential directions the discussion can take, following a conversation about the challenges and possibilities of quantitative imaging and data analysis."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:03-05:07",
        "transcript": "So it doesn't take too much data.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:03",
        "end_time": "25:07",
        "annotations": {
            "reject idea": "David rejects the idea that it takes too much data, which Maryellen suggested to push the limits of data handling."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:07-05:10",
        "transcript": "So that you can manipulate it.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:07",
        "end_time": "25:10",
        "annotations": {
            "encourage participation": "Maryellen is encouraging the team to push the boundaries of what's possible, even if it seems difficult, building on the previous discussion about data manipulation and potential limitations."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:10-05:22",
        "transcript": "Well, some things don't take too much but some take a lot, but that's that shouldn't be that shouldn't limit you from saying I want to do that. That's what I'm getting at because we can always deal with more data.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:10",
        "end_time": "25:22",
        "annotations": {
            "encourage participation": "Maryellen encourages the team to not be limited by data constraints and to freely express their ideas, building on the previous discussion about data wrangling and algorithmic improvements.",
            "express enthusiasm": "Maryellen expresses enthusiasm by encouraging the team to pursue their ideas even if they seem data-intensive, conveying optimism about handling more data."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:22-05:23",
        "transcript": "We have a history of that.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:22",
        "end_time": "25:23",
        "annotations": {
            "provide supporting evidence": "Maryellen is referring to the group's history of dealing with large amounts of data, which supports the idea that they can handle more data in the future."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:23-05:27",
        "transcript": "But it's not a matter of like not being able to like collect enough data.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:23",
        "end_time": "25:27",
        "annotations": {
            "reject idea": "David rejects the idea that the amount of data is a limiting factor, which Maryellen brought up in the previous utterance."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:27-05:28",
        "transcript": "It's just getting in the right format.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:27",
        "end_time": "25:28",
        "annotations": {
            "express agreement": "David agrees with Maryellen's point that wrangling the data into the right format is a significant pain point, building on the previous discussion about the challenges of using algorithmic approaches due to data formatting issues."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:28-05:28",
        "transcript": "Well,",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:28",
        "end_time": "25:28",
        "annotations": [
            {
                "None": "No code applies to this utterance."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:28-05:41",
        "transcript": "That is correct in some fields. In other fields, collection of data, there's actually sometimes uh it's in in in the medical imaging field, that's a major problem for culture reason, not for technical reasons.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:28",
        "end_time": "25:41",
        "annotations": {
            "provide supporting evidence": "Maryellen states that data collection is a major problem in the medical imaging field for cultural reasons, not technical ones, supporting her previous point about data wrangling being a significant pain point.",
            "expand on existing idea": "This utterance expands on the previous discussion about data wrangling and the challenges associated with it, particularly in the context of medical imaging."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:41-05:42",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:41",
        "end_time": "25:42",
        "annotations": {
            "express agreement": "David agrees with Maryellen's previous statement about the challenges of data wrangling, which is a form of agreement."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:42-06:03",
        "transcript": "So um good. And now Vivian, you're at the other end. You are looking at the mole the molecular level. How's your quantitative imaging and where do you think that is?",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:42",
        "end_time": "26:03",
        "annotations": {
            "encourage participation": "Maryellen invites Vivian to contribute to the discussion, asking about her perspective on quantitative imaging at the molecular level, after hearing from others."
        }
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "06:41-07:34",
        "transcript": "Well, um yeah, I guess as I was mentioning, um a lot of the traditional MR is about difference and contrast and it's so small contrast, less contrast, but it's not there it's not quantitative enough. Uh, you always need a a baseline measurement and and unfortunately the baseline measurement tends to be different uh from patient to patient uh even. And normalizing that or um having, yeah, finding ways to to normalize that um or or find the right range of it like a blood test, you know, we always say the normal range falls into this uh this amount. Um, I think would be valuable in the field and for any application really, but for MR quantification.",
        "speaking duration": 53,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:41",
        "end_time": "27:34",
        "annotations": {
            "expand on existing idea": "Fanny expands on the definition of quantitative imaging, building on previous discussion by stating that traditional MR imaging relies on differences in contrast but lacks sufficient quantification, needing a baseline measurement that varies between patients.",
            "present new idea": "Fanny presents the idea of normalizing MR measurements or finding a standard range, similar to blood tests, to improve quantification in the field, which has not been explicitly mentioned before.",
            "provide supporting evidence": "Fanny provides supporting evidence for the need for better MR quantification by drawing an analogy to blood tests and their established normal ranges, suggesting a similar approach could be valuable for MR imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:34-07:41",
        "transcript": "Yeah, that's a good point and that would kind that goes under what basically bullet number one where",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:34",
        "end_time": "27:41",
        "annotations": {
            "acknowledge contribution": "Maryellen acknowledges Fanny's point about the need for baseline measurements in MR quantification, indicating that it's a valuable contribution to the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:41-08:03",
        "transcript": "uh and people have talked about how it varies from institution to institution. So how are you how are you going to normalize your data or harmonize is sometimes a term used um uh to handle, you know, data from different institutions, different scanners, different populations. We collect data from around the world and we we see this um in our lab.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:41",
        "end_time": "28:03",
        "annotations": [
            {
                "explain or define term or concept": "Maryellen explains that 'harmonize' is a term sometimes used to handle data from different institutions, scanners, and populations, clarifying the concept of data normalization in the context of quantitative imaging."
            },
            {
                "expand on existing idea": "Maryellen expands on Fanny's point about the need for normalization in MR imaging by mentioning that the issue of data variation exists across institutions, scanners, and populations, which is relevant to the discussion of quantitative imaging."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:03-08:04",
        "transcript": "Okay, um",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:03",
        "end_time": "28:04",
        "annotations": [
            {
                "None": "No code applies to this utterance."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:04-08:06",
        "transcript": "Good and now Vivian, you're at the other end.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:04",
        "end_time": "28:06",
        "annotations": {
            "encourage participation": "Maryellen is explicitly inviting Vivian to contribute to the discussion, as she is moving around the group to gather different perspectives."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:06-08:10",
        "transcript": "You are looking at the molecular level.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:06",
        "end_time": "28:10",
        "annotations": {
            "encourage participation": "Maryellen Giger is inviting Vivian to contribute to the discussion by directing the conversation towards her area of expertise."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:10-08:14",
        "transcript": "How's your quantitative imaging and where do you think that is?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:10",
        "end_time": "28:14",
        "annotations": [
            {
                "encourage participation": "Maryellen is directly asking Vivian to share her perspective on quantitative imaging at the molecular level, encouraging her to contribute to the discussion."
            }
        ]
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "08:15-08:25",
        "transcript": "Yes, I want to I want to ask one question. Uh, so in the second question, there was algorithm that make scoring. So I want to make sure the uh the purpose of the scoring.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:15",
        "end_time": "28:25",
        "annotations": {
            "ask clarifying question": "Vivian is asking for clarification on the purpose of the algorithm scoring mentioned in the second question, which was brought up by Maryellen in the previous turn."
        }
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "08:25-08:40",
        "transcript": "My understanding is uh the scoring can help us screening some information is that right? Is that uh like based on I mean our application. Is that uh everybody thinks or there is a different definition in the AI world?",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:25",
        "end_time": "28:40",
        "annotations": {
            "ask clarifying question": "Vivian is asking for clarification on the purpose of the 'scoring' mentioned in the second question, specifically if it's meant for screening information, and if this understanding aligns with everyone else's or if there's a different definition in the AI world, following a discussion about quantitative imaging and its challenges."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:46-08:49",
        "transcript": "Say scoring what is your definition of scoring again?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:46",
        "end_time": "28:49",
        "annotations": {
            "ask clarifying question": "Maryellen asks Vivian to define \"scoring\" to ensure a shared understanding, following Vivian's question about the purpose of algorithm scoring."
        }
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "08:49-08:56",
        "transcript": "So I want to make sure the uh the purpose of the scoring.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:49",
        "end_time": "28:56",
        "annotations": {
            "ask clarifying question": "Vivian is asking for clarification on the purpose of \"scoring\" in the context of the discussion, specifically in relation to algorithm scoring mentioned in the second question."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "00:00-00:20",
        "transcript": "So what I think the so the challenge here is in a in a cloud data set, we don't know uh we don't know which spot which dots are related to each other. So we don't have an algorithm to really section them.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:20",
        "annotations": {
            "present new idea": "Vivian introduces the challenge of not knowing which spots or dots are related to each other in a cloud dataset, which is a novel problem presented to the group.",
            "explain or define term or concept": "Vivian explains the challenge of working with cloud datasets where the relationships between data points (spots/dots) are unknown, highlighting the need for algorithms to section or group them.",
            "ask clarifying question": "Although phrased as a statement, Vivian's utterance implicitly raises the question of how to address the challenge of identifying relationships between data points in cloud datasets, seeking potential solutions or approaches from the group."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:20-00:27",
        "transcript": "So so you need that at at a lower resolution to guide you to the specific areas?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:20",
        "end_time": "30:27",
        "annotations": {
            "ask clarifying question": "Maryellen is asking Vivian to confirm if she needs lower resolution images to guide her to specific areas in the cloud data set, following Vivian's explanation of the challenge of not knowing which spots are related to each other."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "00:27-01:28",
        "transcript": "Sort of. So we have have we have to have some previous experience, either it's a lower resolution imaging or either you know the biology. Either you know that these two proteins somehow interacted. So we don't we can't directly see it only by looking at those uh dots on the imaging or or the um so so that that brings me to another challenge. We have so many dots, we can't like with human eye, it is very easy to tell these two are clustering together. like these two species of proteins are related. But with the computer, when I wanted to generate uh get more data from it, like see uh how close they are, like how um how how and the the uh how much they interact. It's very difficult to have the computer do that for me.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:27",
        "end_time": "31:28",
        "annotations": [
            {
                "expand on existing idea": "Vivian is expanding on her previous question about algorithm scoring by explaining the challenges in analyzing cloud data sets where the relationships between data points are unknown, building on the discussion about quantitative imaging and data normalization."
            },
            {
                "present new idea": "Vivian presents the idea that prior knowledge (lower resolution imaging, biology, protein interactions) is needed to guide the analysis of cloud data sets, which is a novel concept in the context of the discussion."
            },
            {
                "express frustration": "Vivian expresses frustration about the difficulty of using computers to identify protein clusters and interactions in images, which is easy for the human eye, showing her dissatisfaction with the current computational methods."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:29-01:49",
        "transcript": "Well, that's where you're asking how can we get the most information out of an image or set of image if you're not quite sure where to go within that image. So you need some kind of lower resolution direction to the right spot on your high resolution to get the most information out.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:29",
        "end_time": "31:49",
        "annotations": {
            "explain or define term or concept": "Maryellen is explaining the problem Vivian is trying to solve, which involves getting the most information out of an image when the specific area of interest is unknown, requiring a lower resolution direction to guide the analysis.",
            "expand on existing idea": "Maryellen is building on Vivian's previous statements about the challenges of analyzing clustered data in high-resolution images, adding the idea of using lower resolution images to guide the analysis."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "01:50-02:06",
        "transcript": "Yes, it's kind of mask first and then you like focus on this spot. But like the the the the the details and then you'll look uh you look for more information. So that was that was the big challenge.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 31,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:50",
        "end_time": "32:06",
        "annotations": {
            "expand on existing idea": "Vivian is expanding on her previous explanation of the challenges she faces with analyzing molecular-level images, building on the idea of needing a lower resolution guide to focus on specific areas within the high-resolution image.",
            "explain or define term or concept": "Vivian is explaining the concept of using a \"mask\" to first identify a region of interest before focusing on the details within that region, clarifying her approach to image analysis.",
            "express frustration": "Vivian expresses frustration about the difficulty of getting a computer to identify protein clusters and interactions in images, which is easy for the human eye."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:06-02:32",
        "transcript": "So once we hear from um San Pun, I'm gonna and I think I've heard from everyone else, we should let this go to try to um satisfy these three bullets, which it seems like we've we've looked at them differently because of our different fields, which makes sense.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:06",
        "end_time": "32:32",
        "annotations": {
            "propose decision": "Maryellen proposes to move on to the next speaker and then address the three bullet points, suggesting a concrete choice for the group.",
            "resolve conflict": "Maryellen acknowledges that the group has different perspectives on the three bullets due to their different fields, but suggests moving forward to satisfy them, mediating between these different viewpoints to reach a consensus.",
            "assign task": "Maryellen implicitly assigns the task of addressing the three bullets to the group as a whole by suggesting they move on to satisfy them."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:32-02:32",
        "transcript": "So?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:32",
        "end_time": "32:32",
        "annotations": [
            {
                "encourage participation": "Maryellen is encouraging participation by ending her turn and inviting others to speak, following a series of turns by other participants."
            }
        ]
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "02:32-02:35",
        "transcript": "I think yeah, I think we're discussing those two questions.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:32",
        "end_time": "32:35",
        "annotations": [
            {
                "acknowledge contribution": "The speaker acknowledges the discussion, recognizing the contributions of others without necessarily agreeing or expanding on their points."
            }
        ]
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "02:35-03:41",
        "transcript": "But I think the at least for where I come from, I mean, I think the the major bottlenecks are I think very much what what Dave said, which is data sharing and being able to like if I get some data and then one of you get some data and somebody else gets some data and we did the exact same sample, do we get the same answer? And I think that's a pretty big bottleneck for quantitative imaging because I got to be honest and I think the answer is a resounding no for 90% of the cases. And I think that that's kind of sad, but like that's that's the truth, right? Like somebody has a little special trick there or a little trick there that they process it with and it's not always available. And I find that that that limits a lot of progress because it doesn't allow us to really standardize things across different institutions or instruments or setups and so I've seen some databases go up that try to provide that information. I've participated in some of them as well to just give away everything, all the metadata, all the code, everything you have to try to make it transferable, but I I don't know to me that's the bottleneck to doing really quantitative imaging.",
        "speaking duration": 66,
        "nods_others": 0,
        "smile_self": 11,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:35",
        "end_time": "33:41",
        "annotations": [
            {
                "provide supporting evidence": "Sapun supports his claim about bottlenecks in quantitative imaging by describing a scenario where different researchers analyzing the same sample may not arrive at the same answer, highlighting the lack of standardization and data sharing issues, which aligns with David's earlier point about data practices."
            },
            {
                "express frustration": "Sapun expresses frustration with the current state of quantitative imaging, stating that the lack of standardization and data sharing is a \"pretty big bottleneck\" and that the answer to whether different researchers get the same result from the same sample is \"a resounding no for 90% of the cases\", which he finds \"kind of sad.\""
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:41-03:56",
        "transcript": "Right. And for and for what um uh Matt Lou wrote down here would need also uh the normalization and um actually across multiple stages. So Vivian, you had your hand up? Did you want to comment on that?",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:41",
        "end_time": "33:56",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Maryellen acknowledges Matt Lou's written contribution by referring to it."
            },
            "encourage participation": {
                "Explanation": "Maryellen encourages Vivian to comment on the topic, building on the previous discussion about normalization and multiple stages."
            }
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "03:57-04:55",
        "transcript": "Yes. Um so that that's also another challenge I have. One is validation, like I got I got my algorithm. I analyze my data and I got this result and I can't compare it to other people. And also because right now, um for a lot of the images like processing uh at least uh my collaborator and me, we're still kind of using human eyes and or or like previous experience to guide the development of algorithm. But the previous experience may be not true. Uh so that's why we ask for AI or computation to do that without without any uh what is it? Um judgment. So without previous judgment, that way we get more um uh we get we get uh unbiased.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:57",
        "end_time": "34:55",
        "annotations": [
            {
                "express frustration": "The speaker expresses frustration about the difficulty of validating their algorithm results and comparing them to others, highlighting a challenge in their work."
            },
            {
                "present new idea": "The speaker presents the idea of using AI or computation to analyze images without prior human judgment or bias, aiming for more unbiased results."
            }
        ]
    },
    {
        "speaker": "Gokul Upadhyayula (UC Berkeley)",
        "timestamp": "04:55-04:55",
        "transcript": "Unbiased.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:55",
        "end_time": "34:55",
        "annotations": {
            "express agreement": "Gokul says \"Unbiased\", agreeing with Vivian's statement about the need for AI to provide unbiased analysis."
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "04:55-04:58",
        "transcript": "Yeah, yeah. Unbiased unbiased interpretation.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 66,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:55",
        "end_time": "34:58",
        "annotations": {
            "express agreement": "Vivian is agreeing with Gokul's suggestion of the word 'unbiased' to describe the type of interpretation they are seeking from AI, building on the discussion about validation and the need for algorithms to provide interpretations without previous judgment."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:00-05:03",
        "transcript": "Yeah, if I could if I could add.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:00",
        "end_time": "35:03",
        "annotations": {
            "encourage participation": "David is encouraging participation by signaling that he wants to add to the discussion, which is relevant as the group is discussing quantitative imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:03-05:03",
        "transcript": "Okay, David and then Fanny.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:03",
        "end_time": "35:03",
        "annotations": [
            {
                "encourage participation": "Maryellen is indicating the order in which David and Fanny will speak, encouraging them to participate in the discussion."
            }
        ]
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "05:03-06:01",
        "transcript": "Yeah, if I could add a thought that was um sparked by what Vivian had to say, which is uh people don't really understand like the full value of reference data sets. Um so when you're generating algorithms, you have no way of knowing what's an actual advance um and what isn't without a reference data set to benchmark things on. Um, you know, we just experienced this uh in the last like couple in the last like year or so. Um we've put together a reference data set for doing whole cell and nuclear segmentation human tissues.",
        "speaking duration": 58,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:03",
        "end_time": "36:01",
        "annotations": [
            {
                "expand on existing idea": "David is building on Vivian's point about validation and the need for unbiased interpretation by highlighting the importance of reference datasets for benchmarking algorithms and assessing their actual advancement."
            },
            {
                "provide supporting evidence": "David supports his point about the value of reference datasets by mentioning his team's experience in creating a reference dataset for cell and nuclear segmentation in human tissues."
            }
        ]
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "06:01-06:14",
        "transcript": "Yeah, we put out a data set very similar to that in the last year doing exactly that segmenting nuclei and and cells for people who want to develop algorithms because we are not good at that to actually try to do that.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:01",
        "end_time": "36:14",
        "annotations": {
            "provide supporting evidence": "Sapun mentions that they released a dataset for segmenting nuclei and cells, similar to what David mentioned, to help others develop algorithms, providing a concrete example of a resource available to the community.",
            "acknowledge contribution": "Sapun's statement acknowledges David's previous point about the value of reference datasets by mentioning their own similar contribution."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:15-06:16",
        "transcript": "Okay, so I'm going to go to Fanny.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:15",
        "end_time": "36:16",
        "annotations": [
            {
                "assign task": "Maryellen is assigning the turn to speak to Fanny, continuing the round of introductions or comments."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:16-06:24",
        "transcript": "I just want to point out um from these comments being um made, I think that's great that the research groups are putting those data sets out there.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:16",
        "end_time": "36:24",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Maryellen acknowledges the contributions of the research groups by pointing out that it is great that they are putting those datasets out there, recognizing their effort in making data available."
            }
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:24-06:27",
        "transcript": "Um and I am in one way.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:24",
        "end_time": "36:27",
        "annotations": {
            "acknowledge contribution": "Maryellen acknowledges the contributions of research groups who are putting out data sets, recognizing their input in the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:27-07:07",
        "transcript": "medical imaging is extremely organized because people use DICOM and we can get images from around the world and there's some it's part of it is very but people don't share as well. It seems here with the microscopy folks that are it seems that um you have data sets and you're trying to share them but the format from one institution, not even, you know, even if you go before the staining before the scanning, you've got the actual just good old fashioned file format isn't unified. So it's like we got to take these two fields and put them together. But Fanny, you've been wait waiting patiently.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:27",
        "end_time": "37:07",
        "annotations": [
            {
                "provide supporting evidence": "The speaker supports the idea that medical imaging is organized by stating that people use DICOM and can get images from around the world."
            },
            {
                "present new idea": "The speaker introduces the idea of combining the medical imaging field with the microscopy field to improve data sharing and standardization."
            },
            {
                "acknowledge contribution": "The speaker acknowledges Fanny's patience in waiting to speak."
            }
        ]
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "07:09-07:51",
        "transcript": "Sure. Thanks. Um it's a bit of a sort of crazy idea but um and I'm not really a specialist in computers and algorithms at all. But I'm just picturing when sometimes we analyze data on just image J and they have those, you know, window levels where you can go from zero to 255 and intensity. I'm wondering if on the computational side, it's possible to maybe sort of develop something where you can reformat every single image acquired worldwide onto this fixed scale somehow so that we could really compare one to the other.",
        "speaking duration": 42,
        "nods_others": 0,
        "smile_self": 14,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:09",
        "end_time": "37:51",
        "annotations": [
            {
                "present new idea": "Fanny introduces the idea of reformatting all images onto a fixed intensity scale (0-255) to enable comparison across different datasets, which hasn't been explicitly suggested before in this specific way."
            },
            {
                "expand on existing idea": "Fanny's idea builds upon the previous discussion about normalizing data across different institutions and scanners, suggesting a specific method for achieving this normalization by reformatting images onto a fixed intensity scale."
            }
        ]
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "07:51-07:52",
        "transcript": "Is that something completely crazy?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:51",
        "end_time": "37:52",
        "annotations": {
            "ask clarifying question": "Fanny is asking if her idea of reformatting every image onto a fixed scale is completely crazy, seeking validation or feedback on her suggestion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:53-08:54",
        "transcript": "Well, I I I don't think it's crazy. I think it's very um uh difficult because um you might lose imaging aspects um in making making them um conform to that. I I know even going having everything um going into say a deep net, they often require certain matrix size and bit. You lose it or not? Well, maybe if you have enough cases, it might be okay, but um um sometimes the formats can be exactly the same, but small things like uh timing could um change the acquisition such as in dynamic contrast enhanced MRI. You know, one country was at 92nd intervals and another one's 60 and cause big 10 changes in the data.",
        "speaking duration": 61,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:53",
        "end_time": "38:54",
        "annotations": [
            {
                "reject idea": "Maryellen expresses that while Fanny's idea isn't crazy, it's difficult because imaging aspects might be lost when conforming to a fixed scale, thus rejecting the idea."
            },
            {
                "provide supporting evidence": "Maryellen supports her rejection by providing the example of dynamic contrast enhanced MRI where timing differences can cause big changes in the data, thus providing evidence against the idea."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:54-08:55",
        "transcript": "But um, I don't know.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:54",
        "end_time": "38:55",
        "annotations": {
            "express uncertainty": "Maryellen expresses uncertainty with 'I don't know', indicating a lack of a definitive answer or opinion on the topic being discussed."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:55-08:55",
        "transcript": "Uh.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:55",
        "end_time": "38:55",
        "annotations": [
            {
                "None": "No code applies to this utterance."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:55-08:57",
        "transcript": "Oh, we have two hands up. I'm sorry.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:55",
        "end_time": "38:57",
        "annotations": [
            {
                "acknowledge contribution": "Maryellen acknowledges that two people have their hands raised, indicating they want to contribute to the discussion."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:57-08:58",
        "transcript": "Arnold does have his hand up.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:57",
        "end_time": "38:58",
        "annotations": {
            "acknowledge contribution": "Maryellen acknowledges Arnold's desire to speak by noting that he has his hand up, recognizing his intention to contribute to the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:58-08:58",
        "transcript": "Good.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:58",
        "end_time": "38:58",
        "annotations": {
            "express agreement": "Maryellen acknowledges the previous speaker's point, indicating agreement with the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:58-08:59",
        "transcript": "And then Matt Lou.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:58",
        "end_time": "38:59",
        "annotations": [
            {
                "encourage participation": "Maryellen is calling on Matt Lou to speak, encouraging him to participate in the discussion."
            }
        ]
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "00:00-00:35",
        "transcript": "One one caveat here is that the technology and the methods are evolving very quickly and and constantly. So you might you might uh you know, there might not be a standard because everything is changing. Every two years there's a new camera that is gives you a better resolution that is slightly this and and you people use different cell lines. So so I can see a lot of potential but also a lot of problems of of implementing um a standardized uh data repository. But it's definitely something I feel could could have a lot of value. It's just um a lot of challenges to implementing it.",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:35",
        "annotations": [
            {
                "provide supporting evidence": "Arnold explains why standardizing data is difficult, providing evidence that technology and methods are rapidly evolving, with new cameras and cell lines constantly emerging, which supports the idea that standardization is challenging."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:36-00:44",
        "transcript": "Yes, we're coming up with a lot of good problems. We're going to get to solutions real soon. But Matt Lew, you could take you can breathe after you type your last sentence and tell us.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:36",
        "end_time": "40:44",
        "annotations": [
            {
                "express enthusiasm": "The phrase \"we're coming up with a lot of good problems. We're going to get to solutions real soon\" expresses optimism and encouragement about the progress of the discussion.",
                "encourage participation": "Maryellen Giger is inviting Matt Lew to speak after he finishes typing, encouraging him to participate in the discussion."
            }
        ]
    },
    {
        "speaker": "Matt Lew, WashU",
        "timestamp": "00:45-02:13",
        "transcript": "Thanks. Um, so I wanted to maybe propose something to uh to to sort of um come off of of David's um points from earlier as a as a possible solution, but I don't know how to solve it. So, you know, um, we typically try to harmonize data sets in the measurement space because that's quantitative. Uh, we kind of know how to think about photons or how to think about um uh, you know, magnetic fields or spins or you know, the things that that our instruments are designed to measure. Uh, but this this concept of a latent space or a low dimensional embedding that David talked about is kind of um interesting because honestly we're all imaging some some biological or chemical phenomena that that exists in some other space than the measurements that we've made. If you could figure out how to do this mapping, then you've got actually, you know, an object, a unique object that exists uh in its own space. It's defined by its chemical properties, it's it's it's it's biological state or what have you. And then the instrument is simply a mapping to to the to the data that you collect. And I'm just wondering um you know, what what possibilities are there for us to start learning what this common space might be or expressions of it so that we can um start uh, you know, making these things these comparisons more easy to to do on a routine basis. Um, so just just an idea.",
        "speaking duration": 88,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:45",
        "end_time": "42:13",
        "annotations": [
            {
                "expand on existing idea": "Matt Lew builds on David's idea of latent space embeddings as a potential solution for harmonizing data, suggesting that instruments map to data collected from a common biological or chemical space."
            },
            {
                "present new idea": "Matt Lew proposes exploring the possibilities of learning what this common space might be to make comparisons easier on a routine basis, which is a novel suggestion for harmonizing data."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:14-02:18",
        "transcript": "Great and and Goku, I want to make sure I I recognize these hands now.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:14",
        "end_time": "42:18",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Maryellen acknowledges that Goku has been waiting to speak, recognizing his contribution to the discussion."
            }
        }
    },
    {
        "speaker": "Gokul Upadhyayayula (UC Berkeley)",
        "timestamp": "02:19-04:35",
        "transcript": "Yeah, thanks. Um, one one big elephant in the room is that or or rather the reasons why I feel like, you know, we still have these problems and we haven't been able to solve them given that the EM field has been able to do that, the medical imaging community has been able to do that is when we're looking at cells at either the cellular scale or the subcellular scale, the diversity um is is vast. Um, both in the context of the probes that you're using to to measure the responses like fluorescent proteins or or the conjugations of dyes, um, the expression levels can be different. Um, so so that makes it difficult to make it quantitative because you can take an image of mitochondria, uh, protein expression in one lab and try to draw the same conclusions than a different lab, it makes no sense, right? Because context is lacking. Um, the other thing the other comment related to um to the the data formats, like why is it so difficult for us to share data? Um, obviously the the context is is the eluding part, but more the data formats are also kind of the the issue. At the moment, um, I I again, I've been thinking about this problem for a while, right? Because the types of data sets that we kind of uh generate are usually, you know, a lot more problematic to transmit to other folks, even though we put them in Google buckets and things like that, they're like usually like a two terabyte limit in terms of like transfer per day or something like that. Uh, but more importantly like the the format, like why is it that we have not all conformed to a given format. Um, and the reason is we have all different requirements because the imaging um that one lab does uh could be in two dimensions, even if dynamics is just, you know, basically like a few megabytes to maybe a couple gigabytes. Um, if you're doing volumetric imaging that kind of explodes and if you're doing, you know, volumetric time series that kind of, you know, blows up even more. Now, for us, the main requirement has always been the ability to do parallel reads and parallel writes on some of these um computations to be able to kind of really kind of scale it with the computational resources one has, right? That may not always be the requirement, but that kind of severely limits the formats um that that one has access to. And of course, you know, there's this huge kind of uh balance between pros and cons as to the different file formats that allow for or that basically kind of um prevent some of the features. Um, so yeah, I mean, just general broad thoughts on on a few of the points that we were discussing.",
        "speaking duration": 136,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:19",
        "end_time": "44:35",
        "annotations": [
            {
                "provide supporting evidence": "Gokul explains that the diversity in cells at cellular and subcellular scales, along with differences in probes and expression levels, makes it difficult to achieve quantitative imaging across different labs, supporting the idea that standardization is challenging."
            },
            {
                "expand on existing idea": "Gokul expands on the discussion about data formats by explaining why it's difficult to share data and conform to a single format, citing the varying requirements of different labs, such as the need for parallel reads and writes for large volumetric datasets."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:53-05:01",
        "transcript": "Lot of things to keep in mind. Um, Matt, Love it, Barron, can you pull this all to what do we um, I you know, I I think I'm really glad the cellular folks are recognizing that it would be great if you had a standard format.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:53",
        "end_time": "45:01",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Maryellen acknowledges the points made during the discussion, recognizing the contributions of the participants."
            },
            "encourage participation": {
                "Explanation": "Maryellen is encouraging Matt Lovett-Barron to summarize the discussion."
            },
            "express enthusiasm": {
                "Explanation": "Maryellen expresses her enthusiasm that the cellular folks are recognizing the value of a standard format."
            }
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "06:25-08:22",
        "transcript": "Uh, yeah, I I I like the idea that David brought up earlier of having some sort of latent embedding space that you can put them in. Um, you know, something that's has tried to take off in in neuroscience or at least the world of neuroscience I'm in where people are recording neural activity from animals or humans and and it's oftentimes really hard to get that data. It's very, you know, challenging and so people want to be able to share and have lots of people use and there's sort of a transition now to try and have things in a common data format and have it open that people can share, but I think there is largely a resistance for this to be widely adopted because as it requires a lot of work from every individual lab because it isn't built in uh by the the corporations that produce various microscopes or electrode arrays and and so forth. So there's not a lot of uh it's not a lot of motivation for people to end up doing this. And it really is a lot of work from an individual scientist to take their data set and make it easy for others to use. And so I I think I I like the idea of having what David brought up and that you, you know, if you have the basic metadata that you need and maybe take some responsible notes as you're collecting data that you can at least put it into a common embedding space uh so that you can try and uh interpret what data can connect to what. Uh, I don't know if that's the solution for my particular field or what, but I've noticed this has been an issue, like more of a sociological issue of of people not all getting on board and maybe the DICOM uh situation where you effectively have the hardware manufacturers, the corporate overlords agreeing to have common formats kind of forces everyone into that world and and maybe that's a a good way to go.",
        "speaking duration": 117,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:25",
        "end_time": "48:22",
        "annotations": [
            {
                "express agreement": "Matt expresses agreement with David's idea of using a latent embedding space to harmonize data, building on the discussion about quantitative imaging and data normalization."
            },
            {
                "expand on existing idea": "Matt expands on the idea of a latent embedding space by discussing the challenges of data sharing in neuroscience and the resistance to adopting common data formats, drawing a parallel to the DICOM standard in medical imaging."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "08:23-09:01",
        "transcript": "Yeah, and maybe in your communities, I don't know what your where your society is at. If you have the societies come that cover get together. So at that level, then that you can tell the other researchers, the manufacturers, that's how it went. So if I if I go back to you, Matt Lou, how your main um, I know you're typing.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:23",
        "end_time": "49:01",
        "annotations": [
            {
                "encourage participation": "Maryellen is encouraging participation by directing the conversation back to Matt Lou, inviting him to contribute his thoughts after others have spoken."
            }
        ]
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "09:26-09:43",
        "transcript": "I kind of feel like well, I I guess I feel like maybe a good thing to tell everybody from the reporter is what the definition that we come up with for quantitative imaging actually is. And how broad or narrow that might be because maybe they also see it differently.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:26",
        "end_time": "49:43",
        "annotations": {
            "propose decision": {
                "Explanation": "Sapun suggests that the group should clarify the definition of quantitative imaging to ensure everyone is on the same page, building on the earlier discussion about its definition."
            }
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "09:44-10:00",
        "transcript": "So one of your three bullets will be definition of quantitative imaging, at least have people agree um, because we went through I think I don't know, uh some uh quantitative a numeric value that is related to.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:44",
        "end_time": "50:00",
        "annotations": {
            "propose decision": "Maryellen is proposing that one of the discussion points should be defining quantitative imaging, building on the earlier discussion where different definitions were presented.",
            "assign task": "Maryellen is assigning the task of defining quantitative imaging to the group, as part of the three discussion points."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:44",
        "transcript": "some biomedical phenomena or something, would that cover everybody in one line? So we have 15 minutes, we got the warning. Um, I so do you have yeah. So, um, right. So that's kind of the first bullet that Matt Lew just wrote. The second one was this situation which is not that fun scientifically but is a necessary evil to get and share data, which was how do you? So how do you want to word that folks?",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:44",
        "annotations": {
            "ask clarifying question": {
                "Explanation": "Maryellen asks if the definition of quantitative imaging covers everyone's perspective in one line, seeking confirmation and agreement on the definition."
            },
            "propose decision": {
                "Explanation": "Maryellen proposes to summarize the definition of quantitative imaging in one line and asks how to word the second bullet point, suggesting a concrete choice for the group to make."
            },
            "assign task": {
                "Explanation": "Maryellen assigns the task of defining quantitative imaging and wording the second bullet point to the group."
            },
            "encourage participation": {
                "Explanation": "Maryellen encourages participation by asking \"how do you want to word that folks?\"."
            }
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "00:44-00:49",
        "transcript": "Context? Just the context in which the image",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:44",
        "end_time": "50:49",
        "annotations": {
            "explain or define term or concept": "Sapun is defining the term 'context' in relation to the discussion about quantitative imaging and data sharing, which is relevant to the previous discussion about standardizing data across different institutions."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:49-01:14",
        "transcript": "Well, right, the one liner that describes that problem. Well, all you seem to bring it up so you I thought, you know, you want to tell the greater group that this is a problem. They all know it, but maybe if it's in a bullet point someone will react to it and get it done. What do you think, David?",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:49",
        "end_time": "51:14",
        "annotations": {
            "encourage participation": "Maryellen is asking David for his opinion on how to word the problem of data sharing and context, encouraging him to contribute to the discussion."
        }
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "01:14-01:19",
        "transcript": "Yeah.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:14",
        "end_time": "51:19",
        "annotations": {
            "express agreement": "David agrees with Maryellen, who was asking for a one-liner to describe the problem of sharing data."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:19-01:33",
        "transcript": "I mean you don't have to, it's your they're they're your your your report back. I just want to get so you guys can get to some of the science that's being brought up in these bullets. So I think if we finalize that, you'll get there. Yes, Fanny.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:19",
        "end_time": "51:33",
        "annotations": [
            {
                "encourage participation": "Maryellen encourages the group to finalize the discussion points so they can move on to the scientific aspects, inviting Fanny to speak."
            }
        ]
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "01:33-01:47",
        "transcript": "I think there are two main features. One was like in a sense the amount of data to process and to interpret and the second was the lack of uniformity in the data.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:33",
        "end_time": "51:47",
        "annotations": {
            "expand on existing idea": "Fanny is summarizing the discussion by highlighting two main features: the amount of data and the lack of uniformity, which builds on the previous discussion about challenges in quantitative imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:48-02:03",
        "transcript": "So the um, yeah, the quantity and lack of standardization of data is a major roadblock. It's kind of like your second big point.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:48",
        "end_time": "52:03",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Maryellen acknowledges Fanny's point about the quantity and lack of standardization of data being a major roadblock, recognizing her input in the discussion."
            }
        }
    },
    {
        "speaker": "Vivian Qian Liu_McGill",
        "timestamp": "02:03-02:11",
        "transcript": "what about uh the uh like we do not have uh a standard for verification.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:03",
        "end_time": "52:11",
        "annotations": {
            "present new idea": "Vivian is presenting the idea that there is a lack of a standard for verification, which has not been explicitly mentioned before in this specific way."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:11-02:31",
        "transcript": "So quantity comma lack of standardization and lack of reference data. Yeah. We got everything covered. It took me uh over 20 years to get to this point where I can consolidate multiple things but I get a lot of practice.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:11",
        "end_time": "52:31",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Maryellen acknowledges the points made by the group regarding the quantity, lack of standardization, and lack of reference data, recognizing their collective input."
            },
            "express humor": {
                "Explanation": "Maryellen makes a lighthearted comment about it taking her over 20 years to consolidate multiple things, adding that she gets a lot of practice, which is a form of self-deprecating humor."
            }
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:39-03:01",
        "transcript": "And then what's next, folks? Looking at those three bullets at the top. Now, given you know what you're doing and given this second major issue is not a problem, can you do that other stuff? What do you guys? That's where the science, that's where the proposal thinking comes in.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:39",
        "end_time": "53:01",
        "annotations": [
            {
                "encourage participation": "Maryellen is encouraging the group to participate and share their thoughts on the next steps, building on the previous discussion about quantitative imaging and data standardization."
            },
            {
                "propose decision": "Maryellen is proposing that the group move forward with scientific proposals, assuming the data standardization issue is resolved."
            }
        ]
    },
    {
        "speaker": "Fanny Chapelin, UKentucky",
        "timestamp": "03:02-03:17",
        "transcript": "I think you have it in your document uh the algorithm and metric performance uh like development of robust algorithms and metrics.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:02",
        "end_time": "53:17",
        "annotations": {
            "acknowledge contribution": {
                "Code Name": "acknowledge contribution",
                "Explanation": "The speaker acknowledges that the point about algorithm and metric performance is already present in the document, recognizing a prior contribution."
            }
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "03:19-03:48",
        "transcript": "I guess I got to say I'm pretty intrigued by this idea of the latent space. I haven't read the paper that Dave uh put up there, but I I don't know. I mean, maybe you can just summarize Dave because I I haven't read it. It sounds like you have. So how many different modalities are we putting? I mean, are we talking about so when I think of a latent space, I think of some sort of reduction amount of materials that still conveys the let's call it the main idea or the main message from what that data set was and they're all in one smaller space.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:19",
        "end_time": "53:48",
        "annotations": [
            {
                "express enthusiasm": "Sapun expresses his intrigue with the idea of a latent space, showing enthusiasm for the concept that Matt Lew proposed earlier.",
                "ask clarifying question": "Sapun asks Dave to summarize the paper and clarify how many different modalities are being put into the latent space, seeking a better understanding of the concept."
            }
        ]
    },
    {
        "speaker": "David Van Valen - Caltech",
        "timestamp": "03:49-04:06",
        "transcript": "No, that's appropriate. Yeah, so the paper describes a framework for integrating arbitrary number or arbitrary number of different modalities. Um, and they demonstrate that on imaging and sequencing data. Um, it works like fairly well.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:49",
        "end_time": "54:06",
        "annotations": [
            {
                "expand on existing idea": "David is expanding on the idea of latent space that Sapun brought up, adding details about a paper that describes a framework for integrating different modalities."
            },
            {
                "provide supporting evidence": "David mentions a paper that describes a framework for integrating an arbitrary number of different modalities, providing evidence to support the feasibility of the latent space idea."
            }
        ]
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "04:06-04:10",
        "transcript": "Okay.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:06",
        "end_time": "54:10",
        "annotations": [
            {
                "acknowledge contribution": "Sapun is acknowledging David's explanation of the latent space concept, but not necessarily agreeing or expanding on it."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:10-04:50",
        "transcript": "I mean I think that would be really that's I think that's slightly different than getting good data bookkeeping. I mean, I think it's a requirement for that to be able to do that, but I think that it's the next step of that. So one is you're doing good bookkeeping and then the next would be you put it into the latent space and and use it somehow appropriately the way that they they they've at least demonstrated is plausible in that paper.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:10",
        "end_time": "54:50",
        "annotations": [
            {
                "expand on existing idea": "Maryellen is building on the idea of a latent space, which David introduced earlier, by saying it's different from but requires good data bookkeeping."
            }
        ]
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "04:51-05:32",
        "transcript": "I agree with this too because it I mean it allows for a few things. One is that if we all can't agree on labels, then at least having it in a more uh being able to organize our data in a more abstract uh space might be easy in the absence of us all sharing the same words we want to use to describe things. It also might help us see neighboring uh you know, ideas or or data sets that we wouldn't have realized had we decided to call them by, you know, whatever subjective names we decided on.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:51",
        "end_time": "55:32",
        "annotations": {
            "express agreement": {
                "Explanation": "Matt Lovett-Barron explicitly agrees with the idea of using a latent space, which was previously introduced by David Van Valen."
            },
            "expand on existing idea": {
                "Explanation": "Matt expands on the idea of using a latent space by explaining that it allows for organization of data in a more abstract space, which is useful when there is disagreement on labels and can help identify connections between data sets that might not be apparent otherwise."
            }
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:32-05:37",
        "transcript": "and answers it takes care of all three bullets that were passed to us, right?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:32",
        "end_time": "55:37",
        "annotations": {
            "confirm decision": {
                "Explanation": "Maryellen is confirming that the latent space idea addresses the three discussion points (bullets) that were assigned to the group, indicating agreement and finalization of this direction."
            }
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "05:37-05:37",
        "transcript": "If you can do this.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:37",
        "end_time": "55:37",
        "annotations": {
            "express enthusiasm": "Matt Lovett-Barron expresses enthusiasm for the latent space idea, building on the discussion about data standardization and integration, indicating his excitement about the potential of this approach."
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "05:53-06:16",
        "transcript": "Yeah, I mean I was I was thinking about the the quantity lack of standardization and and it's it's also in the nature of of discovery, you know, medical imaging that that you do standardized procedures and and standardized type of imaging.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:53",
        "end_time": "56:16",
        "annotations": {
            "expand on existing idea": "Arnold is expanding on the previously discussed issue of quantity and lack of standardization of data, relating it to the nature of discovery and standardized procedures in medical imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:16-06:24",
        "transcript": "Right, I'm going to agree with you and I'm going to go to Matt Lew, but I wanted to say that even in medical imaging, even though it's standardized.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:16",
        "end_time": "56:24",
        "annotations": [
            {
                "express agreement": "Maryellen explicitly agrees with Arnold's point about the challenges of standardization in the context of discovery, building on the previous discussion about data standardization and its difficulties."
            },
            {
                "encourage participation": "Maryellen is transitioning the conversation to Matt Lew, inviting him to contribute to the discussion after acknowledging Arnold's point."
            }
        ]
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "06:24-06:50",
        "transcript": "But in in discovery where you you're pushing the knowledge, there there is no there is no not everybody will do the same experiment and produce the same data to make it to make it available, right? Because if once the experiment is done and it's accepted, you you move on to the next thing and then you you you evolve the the technology further and that will create a very heterogeneous type.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:24",
        "end_time": "56:50",
        "annotations": {
            "expand on existing idea": "Arnold is expanding on the discussion about standardization and data sharing, highlighting that in discovery-based research, experiments and data production are not standardized because researchers are constantly evolving their technology and moving on to new experiments, which contributes to data heterogeneity.",
            "provide supporting evidence": "Arnold supports his point about the lack of standardization in discovery research by explaining that researchers move on to new experiments and evolve technology, leading to heterogeneous data."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:51-07:15",
        "transcript": "Yeah. And I'm going to agree with you and I'm going to go to Matt Lew, but I wanted to say that even in medical imaging, even though it's standardized, discovery is done because with machine learning AI, we extract out characteristics of say the cancer.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:51",
        "end_time": "57:15",
        "annotations": [
            {
                "express agreement": "Maryellen explicitly agrees with Arnold's point about the challenges of standardization in discovery-based research, before transitioning to Matt Lew."
            },
            {
                "expand on existing idea": "Maryellen expands on the idea of discovery, stating that even in standardized medical imaging, machine learning AI is used to extract characteristics of cancer, building upon the previous discussion about standardization and discovery."
            }
        ]
    },
    {
        "speaker": "Matt Lew, WashU in St. Louis (he/him)",
        "timestamp": "07:19-08:06",
        "transcript": "Yeah, I um actually just wanted to to to expand on Arnold's point. Um, I guess when we map to this latent space is kind of reflective of all the experiments that you threw at the algorithm for it to learn and and and learn the mapping there. And if you're maybe there's some biological phenomenon that someone hasn't figured out the right sort of imaging conditions or probe or combination of temporal, I don't know, stimuli, right? To to to produce the result.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:19",
        "end_time": "58:06",
        "annotations": [
            {
                "expand on existing idea": "Matt Lew is building upon Arnold's point about the challenges of standardization in discovery-based research, adding that the latent space reflects the experiments used to train the algorithm."
            }
        ]
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "08:06-08:52",
        "transcript": "I would have I that's a that's a fair point, but I I guess I feel like in the combination in the latent space, you produce also new opportunities that you would have never recognized and you of course can, you know, some sort of uh subsume some of those that might have been fortuitous where you can try them along. But nobody's saying you couldn't acquire the data in your own lab in whatever that latent space or real space, you know, real instrument, the home build that you do.",
        "speaking duration": 46,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:06",
        "end_time": "58:52",
        "annotations": {
            "expand on existing idea": "Sapun builds on the idea of using a latent space for data integration, adding that it can create new opportunities and allow for the inclusion of fortuitous findings, which expands on the previous discussion about latent space and data standardization.",
            "express agreement": "Sapun agrees with the previous point made, acknowledging it as a fair point before expanding on the idea of latent space."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "00:00-00:18",
        "transcript": "annotative algorithms, having something that's reproducible to compare against. So this reference data set idea, a ground truth for which you know you actually made something better, or you just made something that was cool for your microscope. Either one is fine, right? But I think it changes the perception of those of us outside.",
        "speaking duration": 18,
        "nods_others": 1,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:00",
        "end_time": "60:18",
        "annotations": [
            {
                "expand on existing idea": "Building on the discussion about data standardization and sharing, the speaker expands on the idea of reference datasets, suggesting they are crucial for comparing and validating algorithms, which was brought up by Vivian and David."
            },
            {
                "provide supporting evidence": "The speaker supports the idea of reference datasets by stating that they provide a ground truth for comparison, allowing researchers to determine if an algorithm is truly an improvement or just specific to their microscope."
            }
        ]
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "00:29-00:31",
        "transcript": "Yeah, I agree. That's great.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:29",
        "end_time": "60:31",
        "annotations": {
            "express agreement": "Matt Lew explicitly agrees with the previous statement, indicating alignment with the ideas being discussed.",
            "express enthusiasm": "Matt Lew expresses enthusiasm with the statement \"That's great\", showing excitement and encouragement for the ideas being discussed."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:39-00:41",
        "transcript": "Just did a grammar change, sorry.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:39",
        "end_time": "60:41",
        "annotations": {
            "express humor": "This utterance expresses humor as Maryellen apologizes for a grammar change, likely in the shared document, in a lighthearted way."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "00:42-00:44",
        "transcript": "Thank you. I appreciate it.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:42",
        "end_time": "60:44",
        "annotations": {
            "acknowledge contribution": "Matt Lew acknowledges Maryellen's grammar correction, showing appreciation for her input."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:45-00:58",
        "transcript": "Can't get that part of reading too many student papers out of my head. Even though I do it with myself and colleagues. I know you guys aren't students, don't get me wrong. You know what I mean.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 31,
        "smile_other": 15,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:45",
        "end_time": "60:58",
        "annotations": [
            {
                "express humor": "This utterance expresses humor by Maryellen Giger, who jokes about her habit of correcting grammar, stemming from reading student papers, and then clarifies that she is not implying the current participants are students."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:59-01:13",
        "transcript": "Um, I think this is exciting because you clarify some items, but you also have some good parts that could lead to, you know, a very necessary proposal. So, um,",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:59",
        "end_time": "61:13",
        "annotations": [
            {
                "express enthusiasm": "The speaker expresses excitement about the discussion and its potential to lead to a proposal, indicating enthusiasm for the progress made."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:22-01:30",
        "transcript": "Um, anyone else that hasn't had a chance to talk? I tried to make sure everyone did. We have a few minutes.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:22",
        "end_time": "61:30",
        "annotations": [
            {
                "encourage participation": "Maryellen is explicitly inviting anyone who hasn't spoken yet to contribute to the discussion, encouraging participation from all members."
            }
        ]
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "01:42-01:47",
        "transcript": "related to uh Matt would it help you if we uh typed our names in this way?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:42",
        "end_time": "61:47",
        "annotations": {
            "encourage participation": "Fanny is encouraging Matt to participate by asking if a certain action (typing names in a specific way) would be helpful to him."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:48-01:50",
        "transcript": "Oh, that would be wonderful. Yes.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:48",
        "end_time": "61:50",
        "annotations": {
            "express agreement": "Matt Lew expresses agreement with Fanny's suggestion to type their names in a specific way, indicating he approves of the idea."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:53-01:54",
        "transcript": "Team effort. Yes.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:53",
        "end_time": "61:54",
        "annotations": {
            "express agreement": "The speaker explicitly agrees with the idea of a team effort, confirming the collaborative nature of the discussion."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "02:10-02:15",
        "transcript": "Sorry, I still for some reason can't edit it online if someone wouldn't mind throwing my name on there. Thank you.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:10",
        "end_time": "62:15",
        "annotations": [
            {
                "assign task": "Matt Lovett-Barron is asking someone to add his name to the document because he is having technical difficulties editing it himself, thus assigning a task to another person."
            }
        ]
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "02:16-02:17",
        "transcript": "I'll do it.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:16",
        "end_time": "62:17",
        "annotations": {
            "assign task": "Fanny Chapelin is volunteering to add Matt Lovett-Barron's name to the document, as he is having trouble editing it himself."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "02:17-02:18",
        "transcript": "Okay, thank you, Fanny.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:17",
        "end_time": "62:18",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Matt Lovett-Barron acknowledges Fanny's contribution of adding his name to the document."
            }
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:34-03:12",
        "transcript": "I appreciate in the definition of quantitative imaging that you guys use the word is related to. Because I've been up, you know, some people say if you extract out size, you can go in and measure exactly size, but if you extract out something like the texture that you're that's in there, 2D or 3D texture, uh it's not a quantitative imaging because you can't really go measure it, but you can measure it somewhere down the line and that it maybe differentiates between high risk and low risk breast cancer, um, screening patients.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:34",
        "end_time": "63:12",
        "annotations": [
            {
                "express agreement": "Maryellen expresses appreciation for the use of \"is related to\" in the definition of quantitative imaging, indicating agreement with the group's choice of words."
            },
            {
                "expand on existing idea": "Maryellen expands on the definition of quantitative imaging by providing examples of features like texture that may not be directly measurable but are related to biomedical phenomena, building on the previous discussion about the definition of quantitative imaging."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:13-03:21",
        "transcript": "So to I I'm always one that prefers the broader definition, but that's one of the main reasons I asked that in the beginning.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:13",
        "end_time": "63:21",
        "annotations": {
            "explain or define term or concept": "Maryellen is explaining her preference for a broader definition of quantitative imaging, which relates to the earlier discussion about the definition of quantitative imaging.",
            "acknowledge contribution": "Maryellen acknowledges the prior discussion and the different perspectives on the definition of quantitative imaging."
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "03:26-03:32",
        "transcript": "There's one name in there who is not actually in our group, Dylan Burnett from UWM.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:26",
        "end_time": "63:32",
        "annotations": [
            {
                "acknowledge contribution": "Arnold is pointing out that someone listed in the document is not part of the group, acknowledging their presence in the document but not necessarily agreeing with or expanding on their contributions."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:32-03:33",
        "transcript": "What's the name?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:32",
        "end_time": "63:33",
        "annotations": [
            {
                "ask clarifying question": "Maryellen is asking for clarification on the name of someone who is not in the group, as mentioned by Arnold in the previous utterance."
            }
        ]
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "03:34-03:38",
        "transcript": "There's some name in the in the list on the slide that wasn't actually in our group. So.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:34",
        "end_time": "63:38",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Arnold is pointing out a factual error regarding the list of participants, acknowledging that someone who is listed was not actually present in the group."
            }
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:38-03:40",
        "transcript": "Uh, is it QIAN? That's Vivian.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:38",
        "end_time": "63:40",
        "annotations": [
            {
                "explain or define term or concept": "Maryellen is clarifying the spelling of a name, specifically 'QIAN', and then identifying who that refers to, which is Vivian."
            }
        ]
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "03:41-03:43",
        "transcript": "Dylan Burnett was there.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:41",
        "end_time": "63:43",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Arnold acknowledges that Dylan Burnett was present in the group, which is a form of recognizing someone's participation without necessarily agreeing or disagreeing with their contributions."
            }
        }
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "03:44-03:50",
        "transcript": "So I think they have the same group uh in uh room six, they have the same topic and he's in next.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:44",
        "end_time": "63:50",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Fanny acknowledges that another group has the same topic and that Dylan Burnett is in the next room, recognizing their presence and relevance to the discussion."
            }
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:51-03:57",
        "transcript": "Right, make sure you're in group 3.2 because they put quantitative imaging twice. I wonder what they will come up with.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:51",
        "end_time": "63:57",
        "annotations": [
            {
                "express humor": "Maryellen makes a lighthearted comment about the other group discussing the same topic, expressing a bit of amusement and curiosity about their conclusions."
            }
        ]
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:00-04:02",
        "transcript": "It's very interesting when they do double.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:00",
        "end_time": "64:02",
        "annotations": {
            "express enthusiasm": "Maryellen expresses excitement about the fact that the topic of quantitative imaging is being discussed in two separate groups, indicating her interest in the topic."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "04:02-04:03",
        "transcript": "Good thing we're going first, I guess.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:02",
        "end_time": "64:03",
        "annotations": {
            "express humor": "Matt Lew makes a lighthearted comment about their group presenting first, implying it's advantageous, which expresses humor."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:04-04:13",
        "transcript": "We're going to close in 58 seconds. So I thank you. I've enjoyed working with you all. You guys know have a good time.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:04",
        "end_time": "64:13",
        "annotations": [
            {
                "acknowledge contribution": "Maryellen thanks the group for their participation, acknowledging their contributions to the discussion."
            }
        ]
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "04:13-04:13",
        "transcript": "Thank you very much.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:13",
        "end_time": "64:13",
        "annotations": {
            "acknowledge contribution": "Matt Lew is acknowledging Maryellen Giger's closing remarks and facilitation of the discussion."
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "04:15-04:17",
        "transcript": "Well, thanks for a great discussion.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:15",
        "end_time": "64:17",
        "annotations": {
            "acknowledge contribution": "Arnold is acknowledging the value of the discussion that took place."
        }
    },
    {
        "speaker": "Fanny Chapelin",
        "timestamp": "04:17-04:17",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:17",
        "end_time": "64:17",
        "annotations": {
            "express agreement": "Fanny is expressing agreement with the preceding discussion and thanking the group."
        }
    },
    {
        "speaker": "Matthew Lovett-Barron",
        "timestamp": "04:18-04:18",
        "transcript": "Thank you.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:18",
        "end_time": "64:18",
        "annotations": {
            "acknowledge contribution": "Matt Lovett-Barron is acknowledging Maryellen Giger's contribution to the discussion."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "04:19-04:20",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:19",
        "end_time": "64:20",
        "annotations": {
            "Matt Lew: Thank you very much. ": {
                "10": "express agreement",
                "Explanation": "Matt Lew is expressing agreement with Maryellen Giger's closing remarks and thanking the group for the discussion."
            }
        }
    }
]