[
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:00-00:30",
        "transcript": "Um I I did appreciate the suggestion to use a um shared document and so Matt I actually set one up and I'll put it in the chat and that way everybody can um reach it. Hopefully let me know if you cannot access it and I will adjust the permissions. Um and so that way people can follow along and they can actually add as well, but um we can use that and then uh summarize at the end and copy it in.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:00",
        "end_time": "00:30",
        "annotations": {
            "codes": [
                {
                    "code_name": "share resource",
                    "definition": "The act of offering to share a resource, such as a document, to facilitate collaboration or discussion.",
                    "justification": "The speaker mentions setting up a shared document and offering to adjust permissions, as evidenced by: \"I actually set one up and I'll put it in the chat and that way everybody can um reach it. Hopefully let me know if you cannot access it and I will adjust the permissions.\""
                },
                {
                    "code_name": "facilitate collaboration",
                    "definition": "Actions taken to make collaboration easier or more effective, such as setting up shared tools or spaces.",
                    "justification": "The speaker aims to facilitate collaboration by sharing a document that people can access and add to, as shown by: \"so that way people can follow along and they can actually add as well\""
                },
                {
                    "code_name": "organize discussion",
                    "definition": "The act of planning or structuring how a discussion will proceed.",
                    "justification": "The speaker proposes using the shared document to track progress and summarize at the end, indicated by: \"we can use that and then uh summarize at the end and copy it in.\""
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:30-01:01",
        "transcript": "Okay, so um similar to yesterday, we'll start off with taking a minute to think and write down um a question or a topic for discussion and then we will go around do some introductions. Hopefully you've interacted with some of you, but we'll we'll do kind of a brief intro and I would appreciate if your introduction um has some sort of direction towards this particular topic. So what you're interested in related to the imaging across temporal and spatial domains.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:30",
        "end_time": "01:01",
        "annotations": {
            "codes": [
                {
                    "code_name": "set agenda",
                    "definition": "The speaker outlines the procedure or plan for the meeting.",
                    "justification": "The speaker outlines the meeting procedure: 'Okay, so um similar to yesterday, we'll start off with taking a minute to think and write down um a question or a topic for discussion and then we will go around do some introductions.'"
                },
                {
                    "code_name": "request introduction",
                    "definition": "The speaker asks for brief introductions from the participants.",
                    "justification": "The speaker requests introductions: 'I would appreciate if your introduction um has some sort of direction towards this particular topic.'"
                },
                {
                    "code_name": "focus discussion",
                    "definition": "The speaker is trying to focus the discussion on a specific topic.",
                    "justification": "The speaker focuses the discussion on a specific topic: 'So what you're interested in related to the imaging across temporal and spatial domains.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:01-01:02",
        "transcript": "Okay, so I'll set a timer for one minute and we'll have some silence.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:01",
        "end_time": "01:02",
        "annotations": {
            "codes": [
                {
                    "code_name": "set ground rules",
                    "definition": "Establishing a procedure or expectation for the discussion.",
                    "justification": "The speaker is setting a timer for one minute of silence, indicating a structured discussion approach. Evidence: 'Okay, so I'll set a timer for one minute and we'll have some silence.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:06-02:28",
        "transcript": "Okay, hopefully you all had a chance to gather your thoughts. Um so I'll just go down the list based on I think it's last name alphabet last name alphabetical and and just call on each of you to um introduce yourselves and um maybe just a thought on what would be um an area within this topic that might need research. So uh Joyoni.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:06",
        "end_time": "02:28",
        "annotations": {
            "codes": [
                {
                    "code_name": "facilitate discussion",
                    "definition": "Guiding the conversation to ensure everyone's participation and setting the stage for the discussion.",
                    "justification": "The speaker is organizing the discussion and inviting participants to share their thoughts: 'Okay, hopefully you all had a chance to gather your thoughts. Um so I'll just go down the list... and just call on each of you to um introduce yourselves and um maybe just a thought on what would be um an area within this topic that might need research.'"
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "02:28-04:06",
        "transcript": "Hi, um I am uh physics faculty at LSU. Uh I teach medical imaging medical imaging to medical physics um it's a medical physics program. And um my area of interest is uh right now X-ray inter X-ray interferometry for mammography and also I work on neutron interferometry uh in collaboration with uh NIST NCR group, the neutron uh center for research um for neutron research in NIST um. So um I also have worked on spect uh and uh quite extensively spect and one thing like sorry like gun to the head I the only thing I can remember that is uh you can do simultaneously um multiple modalities. So um so for example, interferometry is giving you attenuation and uh phase and uh scatter images completely different three physical uh properties simultaneously because you're able to capture the phase shift and scatter and you can do it with uh different radio tracers for um multi tracers for pet um pet imaging for example, you know, at different energies um for the same detector and um so that's that's what comes to my head quickly and uh if somebody thinks it's useful. I lack the biological part so if somebody gives me a problem I can think about it. Thank you.",
        "speaking duration": 98,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:28",
        "end_time": "04:06",
        "annotations": {
            "codes": [
                {
                    "code_name": "Introduce Self",
                    "definition": "The speaker introduces themselves, their professional background, and their area of expertise.",
                    "justification": "The speaker starts with 'Hi, um I am uh physics faculty at LSU.' providing an introduction to their professional background and position."
                },
                {
                    "code_name": "Share Research Interests",
                    "definition": "The speaker shares their current research interests and areas of work.",
                    "justification": "The speaker mentions their area of interest: 'my area of interest is uh right now X-ray inter X-ray interferometry for mammography and also I work on neutron interferometry.'"
                },
                {
                    "code_name": "Offer Expertise",
                    "definition": "The speaker offers their expertise for potential collaboration, indicating what they can contribute.",
                    "justification": "The speaker states, 'I lack the biological part so if somebody gives me a problem I can think about it.' This shows they are open to collaborating and contributing their expertise."
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "04:06-04:07",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:06",
        "end_time": "04:07",
        "annotations": {
            "codes": [
                {
                    "code_name": "thank",
                    "definition": "Expression of gratitude.",
                    "justification": "Utterance is 'Thank you.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "04:07-04:09",
        "transcript": "Okay, uh Nick.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:07",
        "end_time": "04:09",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "04:11-05:30",
        "transcript": "Hi, my name's Domenico (Nick) Galati. I'm at Western Washington University. I'm in the biology department there. And uh the reason I think I was probably put in this group is because I I'm very interested in protein trafficking within small structures known as cilia and cilia are diffraction limited and they're really important for a lot of developmental clinical things so they they receive Sonic Hedgehog signaling and so that's really important for patterning. And what's interesting is that the cilia generally in terms of human mutations, they're not they're not abolished so they're still present but there's just minor defects in trafficking within the cilia and to the cilia. And so this has only been studied so far for the most part, the hardcore trafficking stuff has only been studied in static cells that aren't moving or in cilia that aren't moving but in a developing organism clearly they are moving. And so something that the field needs is to be able to study cilia trafficking in either a cilia that's beating because sometimes they beat back and forth to generate flow. Um that's really challenging because they can beat up to 15 to 20 hertz. So trying to image a diffraction limited spot and something that's beating at 20 hertz uh would be a challenge and so that's the kind of stuff that I'm interested in. I have the biological expertise and I can do, you know, I do fluorescence imaging and and live cell imaging and super resolution imaging and stuff like that. But um I think that that problem will need something beyond that. So thanks.",
        "speaking duration": 79,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:11",
        "end_time": "05:30",
        "annotations": {
            "codes": [
                {
                    "code_name": "Introduce Self",
                    "definition": "The speaker introduces themselves, their background, and their research interests.",
                    "justification": "The utterance starts with 'Hi, my name's Domenico (Nick) Galati. I'm at Western Washington University. I'm in the biology department there.'"
                },
                {
                    "code_name": "State Research Interest",
                    "definition": "The speaker explicitly states their research interest or area of expertise.",
                    "justification": "The speaker mentions, 'I'm very interested in protein trafficking within small structures known as cilia,' directly stating his research interest."
                },
                {
                    "code_name": "Identify Challenge/Opportunity",
                    "definition": "The speaker identifies a challenge or opportunity in their field of research.",
                    "justification": "The speaker notes, 'So something that the field needs is to be able to study cilia trafficking in either a cilia that's beating because sometimes they beat back and forth to generate flow.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:30-05:32",
        "transcript": "Great, thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:30",
        "end_time": "05:32",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:32-05:33",
        "transcript": "Okay, Arnold.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:32",
        "end_time": "05:33",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "05:33-07:41",
        "transcript": "Hi everyone, my name is Arnold Hayer. I'm a faculty in the Department of Biology in McGill University. And uh my lab is primarily interested in signal transduction that regulates cell motility. So migration of million cells and uh not only of single cells but also of collectives of groups of cells. So the the main challenge related to the topic of this breakout session um in the context of my research is I think to link molecular events to subcellular events and to super cellular events. So so it's kind of the we need to understand what's happening at the molecular level um what is happening with for example polymerizing acting structures um but they happen at a very very fast time scale and uh cells move at a much much slower cells time scale. So uh the the big challenge then is to to link uh these molecular events to the larger um cellular outcomes. And um I don't quite know how to do that because you know if we if we monitor on single molecules we we can probably do that. Um but how do we know that which molecular signal event would then translate into a cell for example to polarize as a whole which happens on the scale of tens of minutes. So that would be something to to think about. And regarding this this um other question of uh how can we collect simultaneously at different times of resolution I I guess um one could think of of um imaging live cell imaging streams where you resolve where you try to monitor events at a relatively low resolution and then have online um automated image analysis that ident identifies relevant events zooms in goes at really high uh imaging frequency so um this is something that we don't do but but that we that I thought could be something of interest of course the technical challenges to overcome and and developing a robust workflow for for doing this. So.",
        "speaking duration": 128,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:33",
        "end_time": "07:41",
        "annotations": {
            "codes": [
                {
                    "code_name": "Introduce Self",
                    "definition": "The speaker introduces themselves, their affiliation, and their research area.",
                    "justification": "The speaker starts by introducing himself, 'Hi everyone, my name is Arnold Hayer. I'm a faculty in the Department of Biology in McGill University.'"
                },
                {
                    "code_name": "State Research Interest",
                    "definition": "The speaker explains their research focus and interests.",
                    "justification": "Arnold explains, 'my lab is primarily interested in signal transduction that regulates cell motility.'"
                },
                {
                    "code_name": "Identify Challenge",
                    "definition": "The speaker discusses a challenge or problem in their research.",
                    "justification": "Arnold mentions, 'the main challenge related to the topic of this breakout session um in the context of my research is I think to link molecular events to subcellular events and to super cellular events.'"
                },
                {
                    "code_name": "Propose Idea/Mention Potential Method",
                    "definition": "The speaker suggests an idea or a potential method for addressing a challenge.",
                    "justification": "Arnold suggests, 'one could think of of um imaging live cell imaging streams where you resolve where you try to monitor events at a relatively low resolution and then have online um automated image analysis that ident identifies relevant events zooms in goes at really high uh imaging frequency.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:41-07:42",
        "transcript": "Great, thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:41",
        "end_time": "07:42",
        "annotations": {
            "codes": [
                {
                    "code_name": "express gratitude",
                    "definition": "Expression of thanks or appreciation.",
                    "justification": "The utterance 'Great, thank you.' is a clear expression of gratitude."
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "07:47-09:57",
        "transcript": "Hi, um I'm Melike Lakadamla. I'm at U Penn. Um my lab um um uses and develops single molecule uh methods and uh in particular super resolution imaging to study spatial and temporal organization of cells. Um one question of interest in the lab is genome folding genome organization um and how that uh regulates gene activity. Um and when we when we study uh genome organization again this is as as Nick said it's a diffraction um sort of limited imaging cannot visualize how the DNA is folded in uh 3D space inside the nucleus. Um nucleus is very crowded um uh chromatin DNA uh folding happens at small length scales. Um so to uh visualize this we need very high resolution um methods like super resolution microscopy. Uh but these super resolution microscopy methods are often uh very slow. Um and so we also are interested in dynamics of the nucleus and to study that we have to do it separately. Um so um for example label subsets of um um uh chromatin interacting proteins or chromatin components and and track their dynamics at fast time scales. Um and somehow sort of relate those two things together in in in separate experiments. And so um you know there's always uh in in microscopy I think trade off between spatial and temporal resolution um and um I don't know if it's possible to you know either optimize that trade off or or get rid of it completely. That would be um quite uh uh an an important challenge I think um to tackle.",
        "speaking duration": 130,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:47",
        "end_time": "09:57",
        "annotations": {
            "codes": [
                {
                    "code_name": "Introduce Self",
                    "definition": "The speaker introduces themselves, their affiliation, and their lab's focus.",
                    "justification": "The speaker starts by introducing themselves and their affiliation."
                },
                {
                    "code_name": "Describe Research",
                    "definition": "The speaker describes their current research or area of interest.",
                    "justification": "The speaker elaborates on their lab's use of single molecule methods and super resolution imaging."
                },
                {
                    "code_name": "Identify Challenge",
                    "definition": "The speaker points out a challenge or limitation in their research area.",
                    "justification": "The speaker discusses the challenge of visualizing DNA folding and the trade-off between spatial and temporal resolution."
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali, UPenn",
        "timestamp": "00:00-00:18",
        "transcript": "interesting regions within your sample um that uh are are are actually interesting to further look at higher resolution sort of zoom up to those and do that in a fully automated way uh with a sort of intelligent type microscope. Um so those are my thoughts.",
        "speaking duration": 18,
        "nods_others": 2,
        "smile_self": 11,
        "smile_other": 22,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:00",
        "end_time": "10:18",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose_idea",
                    "definition": "The speaker suggests a new method or approach for addressing a problem or challenge.",
                    "justification": "The speaker suggests using 'a sort of intelligent type microscope' for automated high-resolution imaging: '...with a sort of intelligent type microscope.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "00:18-00:23",
        "transcript": "Great, thank you. Vivian?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 20,
        "smile_other": 20,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:18",
        "end_time": "10:23",
        "annotations": {
            "codes": [
                {
                    "code_name": "transition",
                    "definition": "A speaker yields the floor to another participant.",
                    "justification": "The utterance ends with 'Vivian?' indicating that Kristen Maitland is yielding the floor to Vivian. The verbatim quote is 'Vivian?'."
                }
            ]
        }
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "00:24-03:11",
        "transcript": "Hello, uh I'm Vivian Liu. I'm from McGill University. Uh I'm at uh Institute of Cancer Technology and the McGill Center forology. I was trained as a molecularologist and uh worked in a biophysical lab on super resolution imaging on virus host interactions. So my lab uh I built a single molecule of polarization microscope to look at uh virus uh life cycle. Uh so far I have um so one of my question is uh when the virus replicates on the ER structure close to the nuclei uh nuclei and we uh by so our super resolution microscopy lose the ability to uh resolve those uh replication complex uh in 3D. So we can only do kind of turf. Uh so I'm hoping that uh if there's some methods that we can we can we can we can uh see those very small structures deep in the cell uh with high contrast. So I know that there are tradeoffs between um spatial resolution and the photo uh phototoxicity and as well as the floor for um you know, photon budget. So I think maybe a new floor for um uh that would be helpful and also uh adaptive imaging, for example, that you only uh activate the floor for that on your focal point will all the others uh you do not activate. So that's uh some uh some thoughts I have. Uh and also I am uh uh I really like to look at the dynamics of the virus moving um on the surface of the cells or moving from the inside to the out of the cells. So uh the challenge in here would be the temporal resolution. So um so far we use uh millisecond resolution to track the viruses, but I think there are some very tiny or detailed movements of these virus on the cell surface before they enter or before they enter the cells. So uh and also because virus are so small, they're like 100 to between 100 to 200 nanometers. So then that will require uh high spatial and temporal resolution to resolve those questions. So those are my thoughts on that.",
        "speaking duration": 167,
        "nods_others": 0,
        "smile_self": 1,
        "smile_other": 1,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:24",
        "end_time": "13:11",
        "annotations": {
            "codes": [
                {
                    "code_name": "Introduce Self",
                    "definition": "The speaker introduces themselves, their institution, and their background.",
                    "justification": "Vivian introduces herself: 'Hello, uh I'm Vivian Liu. I'm from McGill University. Uh I'm at uh Institute of Cancer Technology and the McGill Center forology. I was trained as a molecularologist and uh worked in a biophysical lab on super resolution imaging on virus host interactions.'"
                },
                {
                    "code_name": "State Research Challenge",
                    "definition": "The speaker discusses a challenge they face in their research.",
                    "justification": "Vivian discusses her challenges: 'So my lab uh I built a single molecule of polarization microscope to look at uh virus uh life cycle. Uh so far I have um so one of my question is uh when the virus replicates on the ER structure close to the nuclei uh nuclei and we uh by so our super resolution microscopy lose the ability to uh resolve those uh replication complex uh in 3D.'"
                },
                {
                    "code_name": "Propose Idea/Solution",
                    "definition": "The speaker suggests a potential solution or idea for addressing a research challenge.",
                    "justification": "Vivian proposes new methods: 'So I think maybe a new floor for um uh that would be helpful and also uh adaptive imaging, for example, that you only uh activate the floor for that on your focal point will all the others uh you do not activate.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "03:11-03:12",
        "transcript": "Great, thank you very much.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:11",
        "end_time": "13:12",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "03:12-03:15",
        "transcript": "Okay, Matt.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:12",
        "end_time": "13:15",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "03:15-05:12",
        "transcript": "Hi, Matt Love Baron. I'm in neurobiology at UC San Diego and in my lab uh we're really interested in how neural activity across the brain uh generates behaviors. And so I use microscopy because it's a great system to observe neural activity and I use small transgenic or small transparent fish species so that we can observe activity across the brain and uh without any kind of surgery using uh fluorescent sensors of neural activity like voltage or calcium. And one thing that I think is really important that neuroscience in general is trying to get at is how to link multiple levels of uh looking at the brain such as looking at the activity or the anatomy or what cells are connected to each other or what genes they express. And it's difficult to look at all these with the same method. So I've, you know, worked on some uh approaches to try and register different types of data together so we can look at the same cells under different conditions where we'll look at live uh neural activity imaging in an animal that's behaving and then we take the same animal, we fix it and we do, you know, multiple rounds of in situ hybridization to look at the genes expressed in those same cells using image registration to merge our live brain onto the fixed brain. And I'm really interested in kind of pushing that forward and seeing how many different types of data of imaging data we can merge together to try and link some of these different temporal and spatial domains. So using the tradeoffs of different types of microscopy in live tissue versus say fixed tissue where we can zoom in a lot more and look at, you know, single molecule gene expression and so forth. And so I'm I'm interested to see what what sorts of um imaging modalities we can apply to look at these other levels of organization in the brain and and what sorts of uh registration approaches would be best to merge very different types of data.",
        "speaking duration": 117,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:15",
        "end_time": "15:12",
        "annotations": {
            "codes": [
                {
                    "code_name": "introduce_self",
                    "definition": "The speaker introduces themselves and their research area.",
                    "justification": "The speaker starts with 'Hi, Matt Love Baron. I'm in neurobiology at UC San Diego and in my lab uh we're really interested in how neural activity across the brain uh generates behaviors.' This clearly indicates an introduction of themselves and their research area."
                },
                {
                    "code_name": "describe_research",
                    "definition": "The speaker describes their current research and methods.",
                    "justification": "The majority of the utterance describes the speaker's research in detail, including methods like microscopy, use of transgenic fish, and approaches to register different types of data together."
                },
                {
                    "code_name": "express_interest",
                    "definition": "The speaker expresses interest in a specific area or method.",
                    "justification": "The speaker expresses interest in 'pushing that forward and seeing how many different types of data of imaging data we can merge together' and in exploring 'what sorts of um imaging modalities we can apply to look at these other levels of organization in the brain and and what sorts of uh registration approaches would be best to merge very different types of data.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "05:12-05:14",
        "transcript": "Great, thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:12",
        "end_time": "15:14",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "05:14-05:16",
        "transcript": "Aseema?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:14",
        "end_time": "15:16",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Aseema Mohanty, Tufts U. (she/her)",
        "timestamp": "05:16-06:30",
        "transcript": "Hi everyone. Um I'm Aseema Mohanty. I'm an assistant professor at Toughs. Um just started this year um in the electrical engineering department and um I work on nanonics, so chip scale optical devices. And um a lot of my work focuses on how do we manipulate light in 3D from a chip. Um so uh what I've kind of primarily been using this for is um in implantable neural probes for optogenetic neural stimulation. And a lot of our problem is the same as what uh Matt said um is reaching across, you know, multiple different regions of the brain but being able to do high resolution stimulation um for optogenetics.",
        "speaking duration": 74,
        "nods_others": 0,
        "smile_self": 12,
        "smile_other": 12,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "15:16",
        "end_time": "16:30",
        "annotations": {
            "codes": [
                {
                    "code_name": "introduce_self",
                    "definition": "Introducing oneself and one's work.",
                    "justification": "Aseema introduces herself and her work as an assistant professor at Tufts University, working on nanonics."
                },
                {
                    "code_name": "share_research",
                    "definition": "Sharing details about one's research.",
                    "justification": "Aseema shares her research focus on chip-scale optical devices and its application in implantable neural probes."
                },
                {
                    "code_name": "identify_common_goal",
                    "definition": "Mentioning a common goal or problem with others.",
                    "justification": "Aseema mentions that her problem is similar to Matt's regarding reaching across multiple brain regions for high-resolution stimulation."
                }
            ]
        }
    },
    {
        "speaker": "Aseema Mohanty, Tufts U. (she/her)",
        "timestamp": "06:30-06:31",
        "transcript": "Great.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:30",
        "end_time": "16:31",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "06:31-06:32",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:31",
        "end_time": "16:32",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "06:32-06:34",
        "transcript": "Mimi?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:32",
        "end_time": "16:34",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is inquiring about something or someone.",
                    "justification": "The utterance 'Mimi?' is a clear example of asking a question, as it seeks a response from Mimi."
                }
            ]
        }
    },
    {
        "speaker": "Mimi Sammarco, Tulane",
        "timestamp": "06:35-08:07",
        "transcript": "I'm Mimi Smarco and I'm at T School of Medicine in New Orleans. I work um in the Department of Surgery and my field is um skeletal regeneration. Um we work in an adult model um and so a lot of what we do is sort of trying to overcome these phase specific um stages that you have where one is soft tissue and then that eventually develops into bone. Um so the imaging techniques um that we have to use are often really challenging. Um my lab specifically looks or has recently started to look at the effects of cell metabolism and how that actually drives um skeletal regeneration. Currently um it's fairly difficult to look at that in terms of we just started looking in terms of spatial transcriptomics and then um high plex proteomics, but really what you're looking at is um, you know, transcript before the enzyme or protein but not knowing if the enzyme is active. And so trying to look at different ways beyond Seahorse analytics, which is going to be an ex vivo analysis, um both spatially and over time in vivo would be incredibly useful to the field. Um and I think it would probably hold a lot of answers. So I'm really just here to see again what sort of imaging modalities which I think somebody else mentioned can be applied to the field. Um so looking at sort of what's here in these sorts of forums and then applying them back to my field.",
        "speaking duration": 92,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:35",
        "end_time": "18:07",
        "annotations": {
            "codes": [
                {
                    "code_name": "Introduce Self",
                    "definition": "The speaker introduces themselves, their institution, and their field of work.",
                    "justification": "The speaker starts by introducing themselves and their background: \"I'm Mimi Smarco and I'm at T School of Medicine in New Orleans. I work um in the Department of Surgery and my field is um skeletal regeneration.\""
                },
                {
                    "code_name": "Share Research Overview",
                    "definition": "The speaker provides an overview of their research and its challenges.",
                    "justification": "The speaker explains their work in skeletal regeneration, the challenges with imaging techniques, and their focus on cell metabolism: \"Um we work in an adult model um and so a lot of what we do is sort of trying to overcome these phase specific um stages... Um so the imaging techniques um that we have to use are often really challenging.\""
                },
                {
                    "code_name": "Seek Information",
                    "definition": "The speaker expresses a desire to learn about something, in this case, imaging modalities.",
                    "justification": "The speaker mentions their intent to learn about applicable imaging modalities: \"So I'm really just here to see again what sort of imaging modalities which I think somebody else mentioned can be applied to the field.\""
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "08:07-08:09",
        "transcript": "Great, thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:07",
        "end_time": "18:09",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "08:09-08:10",
        "transcript": "Doug?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:09",
        "end_time": "18:10",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask_question_or_invite",
                    "definition": "Inviting or calling someone to contribute or speak.",
                    "justification": "The utterance 'Doug?' is a clear invitation for Doug to speak."
                }
            ]
        }
    },
    {
        "speaker": "Doug Shepherd",
        "timestamp": "00:00-00:14",
        "transcript": "and it drives the technology sometimes because like there's a resolution race, right? But it it doesn't mean that we're answering questions better. And so I think some careful thought about what really needs to be quantified across space and time can make a big difference.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:14",
        "annotations": {
            "codes": [
                {
                    "code_name": "offer criticism",
                    "definition": "Expressing a negative opinion or disapproval about something.",
                    "justification": "The speaker mentions, \"it doesn't mean that we're answering questions better,\" which can be seen as a criticism of current approaches."
                },
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a new plan, solution, or way of thinking.",
                    "justification": "The speaker suggests, \"some careful thought about what really needs to be quantified across space and time can make a big difference,\" which is a proposal for a more thoughtful approach."
                },
                {
                    "code_name": "comment on methodology",
                    "definition": "Making a remark about the methods or approaches used.",
                    "justification": "The speaker comments on the drive for technology and its implications, \"and it drives the technology sometimes because like there's a resolution race, right?\" This indicates a discussion about methodology and technological advancements."
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:15-00:20",
        "transcript": "Great, thank you. Um, and last but not least, uh Lingyan.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 60.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:15",
        "end_time": "20:20",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi",
        "timestamp": "00:21-02:33",
        "transcript": "Hello? Yes. Hi, everyone. Uh my name is Lingyan Shi. Uh I'm from bioengineering department at UCSD. Uh I just established my lab in 2019. Uh basically we are developing, we are developing the optical imaging platform and we integrate the Raman based microscopy such as stimulated Raman microscopy and with the multiphoton fluorescence microscopy together. So this is a multimodality imaging system not only allow us to visualize the metabolic activities such as those small metabolites like glucose, amino acids or fatty acids, we can directly visualize them because the isotope we add onto those small metabolites will form the new chemical bond, which is uh for example carbon deuterium bond, so we don't need to do click chemistry to add the bulky fluorescence probe anymore. So this layer of metabolic information uh can be visualized at the same time we want to see for example the calcium fluorescence signal in the same region of interest. So this uh combined imaging platform can be used to solve some biological questions such as neurovascular coupling system. Uh for example we we are so interested in how neuron talk to those other type of cells such as endothelial cells on the vasculature system like the the uh blood brain barrier for example. So uh another layer of information that we couldn't really uh image because of the technical limitation is how the endothelial cell from the vasculature system signaling back to the the neuron and uh how these like feedback uh feedbacks the circuits that work. So uh if we combine both the Raman based imaging with the multiphoton fluorescence imaging together then we can visualize both layers of information at the same time specially and temporarily for in vivo imaging.",
        "speaking duration": 132,
        "nods_others": 0,
        "smile_self": 20.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:21",
        "end_time": "22:33",
        "annotations": {
            "codes": [
                {
                    "code_name": "introduce self/research",
                    "definition": "The speaker introduces themselves and their research background.",
                    "justification": "Hello? Yes. Hi, everyone. Uh my name is Lingyan Shi. Uh I'm from bioengineering department at UCSD. Uh I just established my lab in 2019."
                },
                {
                    "code_name": "share knowledge",
                    "definition": "The speaker shares information about their work or expertise.",
                    "justification": "The entire utterance is about sharing her research focus, methodology, and potential applications."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or perspective.",
                    "justification": "if we combine both the Raman based imaging with the multiphoton fluorescence imaging together then we can visualize both layers of information at the same time specially and temporarily for in vivo imaging."
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:33-02:35",
        "transcript": "Great, thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:33",
        "end_time": "22:35",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "02:57-03:28",
        "transcript": "I'm interested uh if you don't mind I'm interested to hear a little bit more about Nick's application looking at cilia because it seems like for a lot of us we have this issue of of looking at things with fluorescence microscopes and as a consequence it's a lot about the signal to noise of the sensor and so forth. But I mean it seems like Nick has this interesting um system where he's able to look at cilia uh that maybe doesn't require those sorts of labeling so I'm curious what maybe that would be an an easier one to scale up speed with some kind of camera based method.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:57",
        "end_time": "23:28",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "Seeking more information or clarification on a specific topic.",
                    "justification": "The speaker says, 'I'm interested uh if you don't mind I'm interested to hear a little bit more about Nick's application looking at cilia,' showing a clear desire for more information."
                },
                {
                    "code_name": "show interest",
                    "definition": "Expressing interest in another's work or idea.",
                    "justification": "The speaker mentions, 'it seems like Nick has this interesting um system where he's able to look at cilia uh that maybe doesn't require those sorts of labeling,' showing interest in Nick's work."
                },
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a potential solution or approach.",
                    "justification": "The speaker suggests, 'what maybe that would be an an easier one to scale up speed with some kind of camera based method,' indicating a possible solution."
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "03:28-04:43",
        "transcript": "Yeah, so so thanks for showing some interest in it. to traditionally if you need to image cilia that are beating, which is the most challenging situation, they're beating at anywhere from 20 hertz to some extreme protest that live in the sea can beat up to 150 hertz. So that's that's a different story. And typically you're imaging them if you if you need to do temporal imaging, you need to image them at around 100 hertz to get reliable, you know, wave forms. And so we do that with DIC. So DIC microscopy with just a camera is the best way to track the ciliary wave form. Um, but then if you want to track trafficking within this bending whip like wave form, that's where you need to do fluorescence. And so what the field has done is that they've either taken cilia that are beating and immobilized them pharmacologically so that they're not beating and then track protein trafficking within them, but that's such a major perturbation that, you know, we still don't know what protein trafficking within a beating cilium looks like because of that. So one thing, yeah, I don't know, you know, now you can do the combined DIC fluorescence, you know, that's not a challenging technique, but getting enough signal is then that becomes the challenge. So getting enough signal from what could be one to five proteins and part of like a particle train, um, to get enough signal from that to reliably track it within the wave form would seem to be what would be needed.",
        "speaking duration": 75,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:28",
        "end_time": "24:43",
        "annotations": {
            "codes": [
                {
                    "code_name": "explain",
                    "definition": "The speaker provides an explanation or describes a research challenge.",
                    "justification": "The speaker describes the challenge of imaging cilia that are beating. Evidence: 'Yeah, so so thanks for showing some interest in it. to traditionally if you need to image cilia that are beating, which is the most challenging situation, they're beating at anywhere from 20 hertz to some extreme protest that live in the sea can beat up to 150 hertz.'"
                },
                {
                    "code_name": "propose method",
                    "definition": "The speaker suggests a method or technique.",
                    "justification": "The speaker mentions using combined DIC fluorescence. Evidence: 'So one thing, yeah, I don't know, you know, now you can do the combined DIC fluorescence, you know, that's not a challenging technique, but getting enough signal is then that becomes the challenge.'"
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "04:48-04:57",
        "transcript": "So I mean with today's cameras like you know scientific cameras those frame rates are not out of reach, right? 100 hertz um is not out of reach of an SCM.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:48",
        "end_time": "24:57",
        "annotations": {
            "codes": [
                {
                    "code_name": "express feasibility",
                    "definition": "The speaker mentions that something is possible or feasible with current technology or methods.",
                    "justification": "The speaker says, 'with today's cameras... those frame rates are not out of reach,' which directly expresses the feasibility of achieving certain frame rates with current technology."
                },
                {
                    "code_name": "seek agreement",
                    "definition": "The speaker seeks confirmation or agreement from others regarding a statement.",
                    "justification": "The speaker ends the statement with 'right?' which is a clear attempt to seek agreement or confirmation from the listeners."
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "05:57-06:07",
        "transcript": "And can I ask how you're uh how are you looking at the cilia such that like where's your optical plane? Is it that you're looking through a bunch of cilia or you're looking along the length of some of them?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:57",
        "end_time": "26:07",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker asks a question to seek clarification or information.",
                    "justification": "The utterance starts with 'And can I ask' and proceeds to ask a question about the optical plane for imaging cilia. Evidence: 'And can I ask how you're uh how are you looking at the cilia such that like where's your optical plane?'"
                },
                {
                    "code_name": "show interest",
                    "definition": "The speaker expresses interest in the topic or another person's work.",
                    "justification": "The speaker mentions being interested in the method. Evidence: 'I'm interested uh if you don't mind I'm interested to hear a little bit more about Nick's application looking at cilia'"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "06:28-07:53",
        "transcript": "So yeah, they're going to depending on the organism. So like one one rapid prototyping approach would be to use tetrahymena, which have a thousand cilia and they're easy to manipulate and they're genetic and you can you can either immobilize them so they're because the other side of this is that if it's happening in a moving cell, there's another set of translation. So it's a beating cilia on a moving cell, so that would be a different thing. So you can immobilize them, um, the the cells, not the cilia. And then if you do that, you can get a glancing blow of the side cilia where you can image just through an individual one. Um, I can show an example if if you'd like, uh, I can I can share screen.",
        "speaking duration": 85,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:28",
        "end_time": "27:53",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a potential approach or method for addressing a problem.",
                    "justification": "The speaker proposes using 'tetrahymena, which have a thousand cilia' as a 'rapid prototyping approach.' Evidence: 'So like one one rapid prototyping approach would be to use tetrahymena, which have a thousand cilia and they're easy to manipulate and they're genetic...'"
                },
                {
                    "code_name": "offer to share resources",
                    "definition": "The speaker offers to share materials, data, or tools that could be useful for the discussion or project.",
                    "justification": "The speaker offers to share an example or demonstrate something on their screen. Evidence: 'Um, I can show an example if if you'd like, uh, I can I can share screen.'"
                },
                {
                    "code_name": "provide information",
                    "definition": "The speaker shares relevant information that could help in understanding a problem or approach.",
                    "justification": "The speaker explains the characteristics of tetrahymena and how they can be manipulated or used for imaging. Evidence: 'So yeah, they're going to depending on the organism. So like one one rapid prototyping approach would be to use tetrahymena, which have a thousand cilia and they're easy to manipulate and they're genetic...'"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "08:44-09:46",
        "transcript": "See here. So I guess this this is a a bunch of cilliates swimming around, but that's not what we're talking about. So here is an example of of the DIC type images that you can get and these this is acquired at 600 frames per second. And so we can slow down the wave form and we can track it, but now imagine trying to track a particle moving within that. Um, that's that seems to be the the the problem and I haven't seen anybody even come close to doing it. Again, one thing that people would do is they would maybe treat this with a drug that makes the cilia stop beating and then track them, but you know, that's that's the barrier. So some way to combine the DIC with fluorescence at the 100 to 200 hertz imaging frame would seem to be what would be needed.",
        "speaking duration": 62,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "Domenico (Nick) Galati shared his screen to show his lab website. He navigated to the microscopy section and showed a video of cilliates swimming around. He explained that the video was acquired at 600 frames per second.",
        "start_time": "28:44",
        "end_time": "29:46",
        "annotations": {
            "codes": [
                {
                    "code_name": "Propose Idea",
                    "definition": "The speaker suggests a potential solution or approach to a problem.",
                    "justification": "The speaker proposes combining DIC with fluorescence at a specific imaging frame rate. Evidence: \"So some way to combine the DIC with fluorescence at the 100 to 200 hertz imaging frame would seem to be what would be needed.\""
                },
                {
                    "code_name": "Identify Challenge",
                    "definition": "The speaker highlights a difficulty or obstacle in the current research or approach.",
                    "justification": "The speaker points out the challenge of tracking a particle moving within a waveform. Evidence: \"Um, that's that seems to be the the the problem and I haven't seen anybody even come close to doing it.\""
                },
                {
                    "code_name": "Describe Methodology",
                    "definition": "The speaker explains a research method or approach.",
                    "justification": "The speaker describes acquiring images at 600 frames per second and tracking waveforms. Evidence: \"So here is an example of of the DIC type images that you can get and these this is acquired at 600 frames per second.\""
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "09:47-09:58",
        "transcript": "So I mean with today's cameras like you know scientific cameras those frame rates are not out of reach, right? 100 hertz um is not out of reach of an SCM.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "29:47",
        "end_time": "29:58",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Making a statement that presents information as a fact or suggesting an idea for consideration.",
                    "justification": "The speaker says, 'So I mean with today's cameras like you know scientific cameras those frame rates are not out of reach, right?' This indicates presenting information as a fact and seeking agreement."
                },
                {
                    "code_name": "ask question",
                    "definition": "Seeking agreement or confirmation about a statement.",
                    "justification": "The use of 'right?' at the end of the utterance is evidence of this, as it seeks affirmation from others."
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "00:00-00:31",
        "transcript": "cameras frame rate. And so then the question is like, can you correct for that motion, right? Um, because when you're tracking your protein, you're going to have to um, um, find a way to to subtract the motion of the cilium, uh, from the motion of the protein itself. Um, is that motion of the cilium very stereotypical, like can you sort of characterize and and and correct for it?",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:31",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker asks a question to seek clarification or information.",
                    "justification": "The speaker asks 'can you correct for that motion, right?' and 'is that motion of the cilium very stereotypical, like can you sort of characterize and and and correct for it?' These questions show that the speaker is seeking information or clarification on a specific topic. "
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "00:32-01:13",
        "transcript": "I believe I I can't personally. I think the computational folks can. Um, certainly, I think that they can do it. Um, and but but I don't I can't do it. So that would be that that's a barrier right there is that trying to, you know, I think correct and straighten would be one way to do it so that you could, you know, take that curve waveform, turn it into a linear rod and then correct for it. So that's a that's an interesting idea. Um, so that would definitely be a computational approach. And then with the C stuff, that yeah, I use a a prime 95B scientific C and the frame rates aren't the issue. It's it is definitely getting the the signal for the protein of interest.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 33,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:32",
        "end_time": "31:13",
        "annotations": {
            "codes": [
                {
                    "code_name": "Propose Idea",
                    "definition": "The speaker suggests a new method or approach to solve a problem.",
                    "justification": "The speaker proposes a computational approach to correct and straighten a waveform. Quote: 'I think correct and straighten would be one way to do it so that you could, you know, take that curve waveform, turn it into a linear rod and then correct for it.'"
                },
                {
                    "code_name": "Offer Expertise",
                    "definition": "The speaker offers their expertise or mentions their experience with a particular tool or method.",
                    "justification": "The speaker mentions their experience with a specific camera model. Quote: 'And then with the C stuff, that yeah, I use a a prime 95B scientific C'"
                },
                {
                    "code_name": "Identify Barrier",
                    "definition": "The speaker points out an obstacle or challenge that needs to be addressed.",
                    "justification": "The speaker identifies a barrier to their approach, which is their personal inability to perform certain tasks. Quote: 'So that would be that that's a barrier right there'"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "01:14-01:19",
        "transcript": "Is there any way to have a non fluorescence contrast agent against some of these proteins of interest?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:14",
        "end_time": "31:19",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is seeking information or clarification.",
                    "justification": "The utterance starts with 'Is there any way,' which is a clear indicator of seeking information. Evidence: 'Is there any way to have a non fluorescence contrast agent against some of these proteins of interest?'"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "01:20-01:44",
        "transcript": "Good thought. I don't know. That's a good thought. Um, you know, one thing that potentially maybe, I don't know. I don't know much about this quantitative phase imaging. But QPI might be one way to to kill two birds with one stone and that just avoid we wouldn't have molecular specificity, but even tracking one of the granules moving within that structure, maybe that would be a good QPI type approach.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 25,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:20",
        "end_time": "31:44",
        "annotations": {
            "codes": [
                {
                    "code_name": "acknowledge idea",
                    "definition": "The speaker acknowledges or builds upon an idea proposed by someone else, showing engagement and potential for collaboration.",
                    "justification": "The utterance starts with 'Good thought. I don't know. That's a good thought,' which directly acknowledges a previous idea."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or approach to solving a problem.",
                    "justification": "The speaker proposes using 'QPI' as a potential approach, stating, 'But QPI might be one way to to kill two birds with one stone and that just avoid we wouldn't have molecular specificity, but even tracking one of the granules moving within that structure, maybe that would be a good QPI type approach.'"
                },
                {
                    "code_name": "express uncertainty",
                    "definition": "The speaker expresses a lack of knowledge or uncertainty about a topic or idea.",
                    "justification": "The speaker expresses uncertainty multiple times, 'I don't know. That's a good thought. Um, you know, one thing that potentially maybe, I don't know. I don't know much about this quantitative phase imaging.'"
                }
            ]
        }
    },
    {
        "speaker": "Doug Shepherd",
        "timestamp": "01:45-02:58",
        "transcript": "So one issue with a lot of QPIs is it's multiple images. I mean there are ones that aren't, but um, typically you need to introduce some sort of diversity in the phase so then you can extract, you know, what the refracted index was. So you need to look at the image somehow in with multiple views. So this can be pretty low though for certain techniques and so the frame rate can still get pretty high. Um, the you know, one the issue is how much is it moving in 3D in like one sort of time step, right? So that that also so let's say you needed minimum three views, I'm just guessing, you know, you could make some technique, you know, how far is it going to displace between each of those three shots or do you need to come up with some sort of simultaneous multifocal technique, which exists. But you keep every time you do that you split the light, so you're really going to need transmitted light measurements, right where your photon, your excitation photons are doing the work, not your emission photons. Um, so I do think the QPA stuff is is definitely a really promising way to go there, but it does typically require some sort of re computational recombination of multiple views.",
        "speaking duration": 73,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:45",
        "end_time": "32:58",
        "annotations": {
            "codes": [
                {
                    "code_name": "Propose Idea",
                    "definition": "The speaker suggests a potential approach or solution to a problem.",
                    "justification": "The speaker discusses introducing \"some sort of diversity in the phase\" and mentions the possibility of using a \"simultaneous multifocal technique\" or needing \"transmitted light measurements.\" "
                },
                {
                    "code_name": "Discuss Challenges",
                    "definition": "The speaker outlines difficulties or limitations related to the research or technique.",
                    "justification": "The speaker mentions that \"one issue with a lot of QPIs is it's multiple images\" and discusses the challenge of dealing with movement in 3D."
                },
                {
                    "code_name": "Suggest Future Directions",
                    "definition": "The speaker indicates potential future paths or applications for the research.",
                    "justification": "The speaker states that \"I do think the QPA stuff is is definitely a really promising way to go there,\" indicating a suggested direction for future research."
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "02:59-03:11",
        "transcript": "No, that makes sense. And so yeah, there there is also it's not a totally planar waveform. There is a three-dimensional rotary aspect to it as well. Um, the the most substantial translation is is planar, but then there is this little twist along with it.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:59",
        "end_time": "33:11",
        "annotations": {
            "codes": [
                {
                    "code_name": "acknowledge",
                    "definition": "The speaker is acknowledging or agreeing with a previous statement.",
                    "justification": "The speaker starts with 'No, that makes sense.' which indicates agreement."
                },
                {
                    "code_name": "provide information",
                    "definition": "The speaker is providing additional information about a topic.",
                    "justification": "The speaker provides details about the waveform, 'there there is also it's not a totally planar waveform. There is a three-dimensional rotary aspect to it as well.'"
                },
                {
                    "code_name": "describe",
                    "definition": "The speaker is describing a characteristic of something.",
                    "justification": "The speaker describes the waveform as having 'a three-dimensional rotary aspect to it as well' and mentions 'this little twist along with it.'"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "03:11-03:22",
        "transcript": "And so the maybe the multifocal approach where I assume then you can use optics to get multiple focal planes simultaneously on the same camera or do you need different cameras?",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:11",
        "end_time": "33:22",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is seeking information or clarification on a topic.",
                    "justification": "The utterance ends with a question, 'or do you need different cameras?' which is a direct inquiry about the necessity of different cameras for a multifocal approach."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a potential solution or approach.",
                    "justification": "The utterance begins with suggesting an approach, 'And so the maybe the multifocal approach', indicating a proposal."
                }
            ]
        }
    },
    {
        "speaker": "Doug Shepherd",
        "timestamp": "03:23-03:57",
        "transcript": "There's there's multiple approaches. Um, the most rigorously optically corrected way would would sort of do it with some tricks in 4A space and then you would get different views on the same camera. You can also do a port a less sophisticated version where you literally just use a couple cameras and displace where the image is being formed out of each of them, but this has some aberration cost. And so there's a couple ways to do this. Um, and so, you know, the simplest one to build is this one where you just displace a couple cheap cameras, you know, so that they're looking at different positions. So,",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:23",
        "end_time": "33:57",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a potential solution or approach to a problem.",
                    "justification": "The speaker proposes multiple approaches, e.g., 'There's there's multiple approaches. Um, the most rigorously optically corrected way...'."
                },
                {
                    "code_name": "compare approaches",
                    "definition": "The speaker compares different methods or solutions.",
                    "justification": "Doug compares approaches by saying, 'You can also do a port a less sophisticated version... but this has some aberration cost.'"
                },
                {
                    "code_name": "elaborate",
                    "definition": "The speaker provides more details or explanations about a topic or idea.",
                    "justification": "The detailed explanation of how the approaches work, such as 'the most rigorously optically corrected way would would sort of do it with some tricks in 4A space and then you would get different views on the same camera,' shows elaboration."
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "03:58-04:17",
        "transcript": "What about um, uh, I used to do a little bit of light field microscopy where you put a lenslet array, uh, so that you can get kind of multiple views in the same camera frame. But the issue is then it's really computationally expensive to deconvolve into an image and resolution is only so so.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:58",
        "end_time": "34:17",
        "annotations": {
            "codes": [
                {
                    "code_name": "share knowledge",
                    "definition": "The speaker shares their expertise or knowledge on a specific topic.",
                    "justification": "The speaker mentions their experience with light field microscopy, 'I used to do a little bit of light field microscopy...'. This shows they are sharing their knowledge with the group."
                },
                {
                    "code_name": "identify challenge",
                    "definition": "The speaker points out a difficulty or limitation in a particular approach.",
                    "justification": "The speaker notes that light field microscopy is 'really computationally expensive to deconvolve into an image and resolution is only so so.' This highlights a challenge in using this approach."
                }
            ]
        }
    },
    {
        "speaker": "Doug Shepherd",
        "timestamp": "04:19-04:44",
        "transcript": "I mean, I think those methods are getting a lot better. Um, they're very similar in spirit to the also different views for QPI. So, so either way you're talking about somehow combining something that has a different view of the image to then try and reconstruct it in 3D, right? The nice part about the QPI is it gets the refractive index and that's still a bit tricky to get with a light field setup. So, um, yeah.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:19",
        "end_time": "34:44",
        "annotations": {
            "codes": [
                {
                    "code_name": "Compare Methods",
                    "definition": "The speaker is comparing different methods or techniques, highlighting their similarities and differences.",
                    "justification": "The speaker compares methods by stating, 'I think those methods are getting a lot better. Um, they're very similar in spirit to the also different views for QPI.'"
                },
                {
                    "code_name": "Explain Concept",
                    "definition": "The speaker is explaining a concept or technique, providing information about how it works or its advantages.",
                    "justification": "The speaker explains, 'So, so either way you're talking about somehow combining something that has a different view of the image to then try and reconstruct it in 3D, right? The nice part about the QPI is it gets the refractive index and that's still a bit tricky to get with a light field setup.'"
                },
                {
                    "code_name": "Show Optimism",
                    "definition": "The speaker expresses a positive outlook or optimism towards a method or technique.",
                    "justification": "The speaker mentions, 'I mean, I think those methods are getting a lot better.'"
                }
            ]
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "04:49-05:00",
        "transcript": "Can I ask a question about the the transport phenomenon that you're interested in looking at inside the cilia? Is that motor based transport vesicular or free diffusion? That might also be important for for the speed that you need to have in order to pick up the movement.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:49",
        "end_time": "35:00",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker asks a question to seek clarification or information.",
                    "justification": "The utterance starts with 'Can I ask a question' and then proceeds to ask a specific question about the transport phenomenon. Evidence: 'Can I ask a question about the the transport phenomenon that you're interested in looking at inside the cilia?'"
                },
                {
                    "code_name": "seek clarification",
                    "definition": "The speaker seeks clarification on a specific topic or detail.",
                    "justification": "The speaker asks for specific details about the transport phenomenon, indicating a desire for clarification. Evidence: 'Is that motor based transport vesicular or free diffusion?'"
                },
                {
                    "code_name": "provide reasoning",
                    "definition": "The speaker provides a rationale or explanation for their question or idea.",
                    "justification": "The speaker explains why the information is important, providing a rationale for their question. Evidence: 'That might also be important for for the speed that you need to have in order to pick up the movement.'"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "05:05-05:11",
        "transcript": "Yeah, it's microtubial motor based and so it's thought to occur around the micron per second type range.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:05",
        "end_time": "35:11",
        "annotations": {
            "codes": [
                {
                    "code_name": "provide information",
                    "definition": "The speaker is providing factual information or data.",
                    "justification": "The utterance provides specific details about the phenomenon being microtubial motor-based and its speed. Evidence: 'Yeah, it's microtubial motor based and so it's thought to occur around the micron per second type range.'"
                },
                {
                    "code_name": "answer question",
                    "definition": "The speaker is directly responding to a question posed by another participant.",
                    "justification": "The utterance serves as a direct response to a query. Evidence: The entire utterance."
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "05:11-06:17",
        "transcript": "And it's it's it's kind of fascinating. So cryo EM has actually resolved. So there's two microtubules. There's there's 18 microtubules within the cilium and they're arranged in this really beautiful structure called an axoneme. And what people have figured out with cryo EM with just static snapshots of frozen cilia is that one set of motors walk up the A microtubule and another set of motors walk down the B microtubule. Um, and so that's what we have at the electron microscopy level is that there's actually a highway and you know, the plus end directed ones are going on the A tubule and the minus end directed ones are going down the B tubule.",
        "speaking duration": 66,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:11",
        "end_time": "36:17",
        "annotations": {
            "codes": [
                {
                    "code_name": "share knowledge",
                    "definition": "The speaker shares relevant information or expertise with the group.",
                    "justification": "The speaker provides detailed information about cryo EM and microtubules, 'So cryo EM has actually resolved. So there's two microtubules. There's there's 18 microtubules within the cilium and they're arranged in this really beautiful structure called an axoneme.'"
                },
                {
                    "code_name": "explain technical concept",
                    "definition": "The speaker attempts to clarify a technical concept or process.",
                    "justification": "The speaker explains the process of motors walking on microtubules, 'what people have figured out with cryo EM with just static snapshots of frozen cilia is that one set of motors walk up the A microtubule and another set of motors walk down the B microtubule.'"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "06:17-06:43",
        "transcript": "Can I ask a quick question? Um, so you had mentioned previously that a lot of your issue is um, kind of being photon starved and not being able to get enough light in the end of the day. Is that because of the labeling or is it because of the optical system and somewhere you're throwing out a lot of the light? What would what is the kind of cause?",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:43",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is inquiring about something previously mentioned or a specific issue.",
                    "justification": "The utterance starts with 'Can I ask a quick question?' and proceeds to ask about the cause of being 'photon starved,' which is a direct question seeking information."
                },
                {
                    "code_name": "seek clarification",
                    "definition": "The speaker is seeking further explanation or details about a topic.",
                    "justification": "The speaker is asking for the cause of a problem ('What would what is the kind of cause?'), indicating a desire for more detailed understanding."
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati",
        "timestamp": "06:44-07:27",
        "transcript": "Yeah, so I mean it's a good I I I don't quite know the answer. My assumption is is that it's a little bit of both. And so like people have only really tried to do this because with with wide field, right? I think it's it's generally like a wide field approach because we do want the most number of photons and we want speed. So camera based wide field analysis is kind of the standard approach. And so, you know, we're we're we could label brighter, we could try to, you know, you know, I guess wide field with deconvolution would probably be the next step. So just to do simple deconvolution would probably be the next step, but beyond that, I I don't know where the photons. I don't know, you know, we can try just going brighter. We're using typical FPs like GFP and and neon, which is pretty bright, but so could be a combination of both.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:44",
        "end_time": "37:27",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a potential solution or approach.",
                    "justification": "The speaker suggests trying 'wide field with deconvolution' as a next step. Quote: 'I guess wide field with deconvolution would probably be the next step.'"
                },
                {
                    "code_name": "suggest improvement",
                    "definition": "Proposing a way to improve a current approach or method.",
                    "justification": "The speaker mentions trying to 'label brighter' or 'go brighter' to improve the current approach. Quote: 'we could label brighter, we could try to, you know, you know, I guess wide field with deconvolution would probably be the next step... we can try just going brighter.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:27-07:44",
        "transcript": "Maybe I'll add the other factor is you can't just blast it with more light because it's not good for the cell or the, you know, so you have the issues there. It's the tradeoff of illumination without damage, collection of signal very fast, so you're limiting the time that you can capture those photons coming out.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:27",
        "end_time": "37:44",
        "annotations": {
            "codes": [
                {
                    "code_name": "highlight challenge",
                    "definition": "The speaker identifies a difficulty or obstacle in their research.",
                    "justification": "The utterance mentions 'so you have the issues there' and 'It's the tradeoff of illumination without damage,' which highlight challenges. Exact quote: 'so you have the issues there.'"
                },
                {
                    "code_name": "offer caution",
                    "definition": "The speaker warns about a potential problem or advises against a certain action.",
                    "justification": "The utterance advises against 'blast[ing] it with more light because it's not good for the cell,' which serves as a caution. Exact quote: 'you can't just blast it with more light because it's not good for the cell.'"
                },
                {
                    "code_name": "propose tradeoff",
                    "definition": "The speaker discusses a balance or compromise between two factors.",
                    "justification": "The utterance explains 'It's the tradeoff of illumination without damage, collection of signal very fast,' which outlines a tradeoff. Exact quote: 'It's the tradeoff of illumination without damage, collection of signal very fast.'"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "07:45-09:52",
        "transcript": "So it's like we almost had a case study, right? Nick's uh um Celia tracking and uh molecular molecule or or granular tracking within the Celia. Uh I wanted to um go back to there's a little bit of a shared theme between uh Arnold uh and Melika's um introduction, right? In both cases, I think um they talked about for example, Arnold talk about um uh temporarily, you know, you do slow imaging and then uh zoom in. You you you know, get something you're interested and you do fast imaging focusing on uh the processes that you really want to study in detail. And Melika talked about spatially, uh maybe lower resolution imaging and then you find something interesting and zoom in do uh super resolution that really high resolution imaging. I found that that shared theme very interesting. Um, do we want to um as a group talk a little bit about that what are the challenges um and and um there's a little bit of a right? uh AI guided uh automatic zooming in uh that's already been done what what's people uh experience?",
        "speaking duration": 127,
        "nods_others": 0,
        "smile_self": 75,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:45",
        "end_time": "39:52",
        "annotations": {
            "codes": [
                {
                    "code_name": "Propose Discussion",
                    "definition": "The speaker suggests having a group discussion about a specific topic or idea.",
                    "justification": "The speaker explicitly asks, 'Um, do we want to um as a group talk a little bit about that what are the challenges um and and um there's a little bit of a right?'"
                },
                {
                    "code_name": "Identify Common Theme",
                    "definition": "The speaker points out a common theme or connection between different ideas or presentations.",
                    "justification": "The speaker mentions, 'I wanted to um go back to there's a little bit of a shared theme between uh Arnold uh and Melika's um introduction,'"
                },
                {
                    "code_name": "Ask for Experiences",
                    "definition": "The speaker inquires about others' experiences or knowledge on a particular topic.",
                    "justification": "The speaker asks, 'what's people uh experience?'"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "00:00-00:03",
        "transcript": "and um we want to discuss a little bit more about that.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:03",
        "annotations": {
            "codes": [
                {
                    "code_name": "request discussion",
                    "definition": "Requesting to discuss or explore a topic further.",
                    "justification": "The utterance 'and um we want to discuss a little bit more about that.' indicates a desire to delve deeper into a previously mentioned topic. Evidence: 'we want to discuss a little bit more about that.'"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "00:03-00:34",
        "transcript": "Yeah, I put that in. I I agree. I put that into the shared Google Doc because I thought that did seem like a common uh approach. Yeah, so is that does that end up being more of a discussion of how to design um a microscope that integrates its hardware with with uh like a machine learning online approach or or just a user guided approach. I mean, I I I don't know if uh the others have ideas about that.",
        "speaking duration": 31,
        "nods_others": 1,
        "smile_self": 32.25,
        "smile_other": 3.22,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:03",
        "end_time": "40:34",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker asks a question to seek clarification or information.",
                    "justification": "The speaker asks 'so is that does that end up being more of a discussion of how to design um a microscope that integrates its hardware with with uh like a machine learning online approach or or just a user guided approach.' This indicates they are seeking input or clarification on the approach. The exact quote is 'so is that does that end up being more of a discussion of how to design um a microscope that integrates its hardware with with uh like a machine learning online approach or or just a user guided approach.'"
                },
                {
                    "code_name": "seek input",
                    "definition": "The speaker invites others to share their thoughts or ideas.",
                    "justification": "The speaker says 'I mean, I I I don't know if uh the others have ideas about that.' This indicates they are seeking input from others. The exact quote is 'I mean, I I I don't know if uh the others have ideas about that.'"
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "00:34-01:34",
        "transcript": "I mean, for what I mentioned, I think you do need an automated sort of machine learning guided approach. A user guided approach is usually too time consuming and you know, um low throughput again. Um and so you need something that um, you know, can integrate hardware with like recognition of what the image is telling you to guide the hardware um to the right field of view to the right focal plane. Um and change between objectives, right? Going from low magnification, low NA to high mag, high NA. Um and and then, you know, focusing and zooming into the right spot and changing modalities of imaging.",
        "speaking duration": 60,
        "nods_others": 1,
        "smile_self": 15.0,
        "smile_other": 1.67,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:34",
        "end_time": "41:34",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a new method or approach.",
                    "justification": "The speaker proposes an automated machine learning-guided approach with the phrase 'I think you do need an automated sort of machine learning guided approach.'"
                },
                {
                    "code_name": "compare approaches",
                    "definition": "Discussing advantages and disadvantages of multiple approaches.",
                    "justification": "The speaker compares automated and user-guided approaches, stating 'A user guided approach is usually too time consuming and you know, um low throughput again.'"
                },
                {
                    "code_name": "describe technical specifications",
                    "definition": "Elaborating on the technical details of a method.",
                    "justification": "The speaker provides technical details, 'Um and so you need something that um, you know, can integrate hardware with like recognition of what the image is telling you to guide the hardware um to the right field of view to the right focal plane.'"
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "01:34-01:34",
        "transcript": "I'm back.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:34",
        "end_time": "41:34",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "01:37-02:02",
        "transcript": "I guess the feature detection is something that one could not develop as a universal tool because the features might very context and question be question dependent. So one would have to develop algorithms of being able to detect those rare events or you know, structural arrangements of signals and uh feed that back into into a response of the microscope.",
        "speaking duration": 25,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:37",
        "end_time": "42:02",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Proposing a concept or suggestion for consideration.",
                    "justification": "The speaker proposes that 'feature detection is something that one could not develop as a universal tool' as evidence."
                },
                {
                    "code_name": "explain concept",
                    "definition": "Providing more details or elaboration about a concept or idea.",
                    "justification": "The speaker explains the necessity of 'developing algorithms of being able to detect those rare events' as a solution."
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "02:03-02:17",
        "transcript": "Yeah, may be very application dependent, right? But maybe could be something you could train, right? For your specific application.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:03",
        "end_time": "42:17",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Proposing a potential solution or approach.",
                    "justification": "The speaker suggests that something could be trained for a specific application. Evidence: 'But maybe could be something you could train, right? For your specific application.'"
                },
                {
                    "code_name": "acknowledge complexity",
                    "definition": "Recognizing that an issue may be complex or dependent on various factors.",
                    "justification": "The speaker notes that something may be 'very application dependent'. Evidence: 'Yeah, may be very application dependent, right?'"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "02:19-02:21",
        "transcript": "Is this is Oh sorry, go ahead please.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:19",
        "end_time": "42:21",
        "annotations": {
            "codes": [
                {
                    "code_name": "show deference",
                    "definition": "Showing respect or deference to others, often by yielding the floor or acknowledging their priority.",
                    "justification": "The speaker, Matt Lovett-Barron, says 'Is this is Oh sorry, go ahead please.' which indicates that he is yielding the floor to someone else and showing deference to their turn in the conversation."
                }
            ]
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "02:22-02:41",
        "transcript": "Is there any value in um kind of like sparsely randomly checking super high resolution and then, you know, you get a feel for what's going on on the large scale. I mean, I'm not sure for your applications, but that could be an approach as well.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 78.95,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:22",
        "end_time": "42:41",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is inquiring about the value or feasibility of a particular approach or idea.",
                    "justification": "The exact quote is 'Is there any value in um kind of like sparsely randomly checking super high resolution and then, you know, you get a feel for what's going on on the large scale.' This directly shows Aseema asking for opinions or insights on a specific methodological approach."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker is suggesting a potential approach or solution.",
                    "justification": "The quote 'that could be an approach as well' indicates Aseema is proposing or suggesting an alternative method for consideration."
                }
            ]
        }
    },
    {
        "speaker": "Melike Lakadamyali",
        "timestamp": "02:42-04:14",
        "transcript": "So, I mean, I guess just to give you an idea, right? When we do high resolution imaging because we're using 100x objective, um our field of view is very limited, right? Um, and so the throughput is very low. We image one cell at a time. Um, now with a CMOS camera is again very increasing a bit the field of view and the throughput, um but it's a couple of cells at a time. And that um, you know, limits you in terms of um, you know, if you have rare populations in your sample, will you ever sample them um in your imaging if you're only imaging 10 cells in and again it's a slow imaging modality, you image one cell in every uh, you know, 20 minutes, 15 minutes, um something like that. And so, um, you know, one approach is again like make it automated so that you can image um thousands of cells um automatically. Um, and again randomly sample or maybe a more sort of intelligent approach would be uh maybe there are low resolution features that, you know, um mark those rare populations that you can um find um with a higher throughput approach then you can assume it to those with high resolution uh right rather than just randomly sampling and hoping you will find one of those cells in your in your image. I don't know if that uh answers your question.",
        "speaking duration": 92,
        "nods_others": 0,
        "smile_self": 10.87,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:42",
        "end_time": "44:14",
        "annotations": {
            "codes": [
                {
                    "code_name": "explain methodology",
                    "definition": "The speaker describes their current methods or approaches in detail, including limitations and potential improvements.",
                    "justification": "The utterance explains the current methodology used for high-resolution imaging, including specifics about the limitations."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new approach or solution to a problem mentioned.",
                    "justification": "The speaker proposes automating the imaging process to increase throughput."
                },
                {
                    "code_name": "suggest future direction",
                    "definition": "The speaker indicates a potential future path for research or investigation.",
                    "justification": "The speaker mentions the possibility of using low-resolution features to identify rare populations for higher resolution imaging."
                }
            ]
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "04:14-04:14",
        "transcript": "Yeah, absolutely.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:14",
        "end_time": "44:14",
        "annotations": {
            "codes": [
                {
                    "code_name": "agree",
                    "definition": "Expressing agreement or confirmation.",
                    "justification": "The utterance 'Yeah, absolutely. ' directly agrees with a preceding statement, indicating confirmation or concurrence."
                }
            ]
        }
    },
    {
        "speaker": "Doug Shepherd",
        "timestamp": "04:18-05:07",
        "transcript": "So, one thing I'm curious about for these applications is we just had the a bit of the label free discussion. And so these tend to be much less phototoxic, but you lack specificity. You don't have molecular labeling. So, how hard is it to know if the event in your case, I guess specifically, I know generalizing is difficult, um that the event would have started occurring if you had a label free measurement that was lower resolution and then you could switch over to doing some sort of super res. I mean that requires integrating across data modalities, but it's it's pretty easy to integrate some of these label free methods in an opposing arm on the microscope. And so then you could try and image that way and then switch over. So, but the question is, will you actually know it's happening with a label free method if you don't have the molecular readout and I don't know if that's the case or not.",
        "speaking duration": 49,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:18",
        "end_time": "45:07",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker asks a question to seek information or clarification.",
                    "justification": "The speaker asks 'So, how hard is it to know if the event...'. The question is seeking information about the difficulty of knowing if an event occurred using a label-free measurement. "
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a potential approach or solution.",
                    "justification": "The speaker suggests 'you could try and image that way and then switch over' to integrate label-free methods with super-resolution imaging. "
                },
                {
                    "code_name": "express uncertainty",
                    "definition": "The speaker expresses uncertainty or doubt about something.",
                    "justification": "The speaker says 'I don't know if that's the case or not' indicating uncertainty about the effectiveness of label-free methods. "
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "05:11-05:30",
        "transcript": "Couldn't you in principle just um, I mean if you're training a model to be able to identify these things, you could just collect enough data where you could predict at least with some reasonable degree of accuracy, you could predict something from a label free method based on fluorescence detection as well and then use that to guide further experiments.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:11",
        "end_time": "45:30",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker is suggesting a potential approach or method to solve a problem.",
                    "justification": "The speaker proposes using a model trained on enough data to predict outcomes from label-free methods based on fluorescence detection. Evidence: 'Couldn't you in principle just um, I mean if you're training a model to be able to identify these things, you could just collect enough data...'"
                }
            ]
        }
    },
    {
        "speaker": "Doug Shepherd",
        "timestamp": "05:30-06:07",
        "transcript": "Yeah, I think I in principle I agree with that, but let's say that you're interested in, you know, transcription factor searching, right? You're never going to know if like a certain transcription factor has been shuttled to the nucleus most of the time from a label free measurement from a stimuli. So I I think there's cases it'll work, there's cases it won't work and I guess this is where I'm trying to figure out kind of, you know, where the value in it is.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:30",
        "end_time": "46:07",
        "annotations": {
            "codes": [
                {
                    "code_name": "express agreement",
                    "definition": "The speaker explicitly agrees with a previous statement.",
                    "justification": "The speaker says 'Yeah, I think I in principle I agree with that', showing agreement with a previous statement."
                },
                {
                    "code_name": "raise concern",
                    "definition": "The speaker raises a concern or a limitation about a method or approach.",
                    "justification": "The speaker says 'You're never going to know if like a certain transcription factor has been shuttled to the nucleus most of the time from a label free measurement from a stimuli', raising a concern about the limitations of label-free measurements."
                },
                {
                    "code_name": "seek clarification",
                    "definition": "The speaker seeks clarification or tries to understand the value or application of a method or approach.",
                    "justification": "The speaker says 'I guess this is where I'm trying to figure out kind of, you know, where the value in it is', seeking to understand the value or application of a method."
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "06:08-07:02",
        "transcript": "I think that may actually um, you know, perhaps this is where we could go into the multi, you know, modality um discussion, right? Uh for a label free based modality uh and um optical and some of the other modalities uh can they be um integrated uh and if so um computationally or experimentally uh do we, you know, have um, you know, sort of a registration or internal reference uh or do we need to have that uh to connect and integrate imaging data from different modalities. And from live cells versus fixed cells as well. Um this is a question.",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 33.33,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:08",
        "end_time": "47:02",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or direction for discussion.",
                    "justification": "The utterance starts with 'I think that may actually um, you know, perhaps this is where we could go into the multi, you know, modality um discussion,' which indicates proposing a new idea for discussion."
                },
                {
                    "code_name": "ask question",
                    "definition": "The speaker poses a question to seek information or clarification.",
                    "justification": "The speaker asks if different modalities can be integrated and about the need for registration or internal reference, which are clear questions."
                },
                {
                    "code_name": "seek input/feedback",
                    "definition": "The speaker invites others to contribute their thoughts or opinions.",
                    "justification": "By stating 'Um this is a question,' the speaker is implicitly seeking input or feedback from others."
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "07:05-07:50",
        "transcript": "this is yeah, as I mentioned earlier, this has worked really well for me to move from live tissue where we look at neural activity during behavior to fixed samples where we can do single molecule fish even in different microscopes. It's as long as we can find the same cells, we can register back and forth between the two data sets. And some of that is by virtue of the fact that the larval zebrafish is small and it's easy to get gross level registration and then um the fine cellular level registration isn't such a problem when things are broadly overlapped.",
        "speaking duration": 45,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:05",
        "end_time": "47:50",
        "annotations": {
            "codes": [
                {
                    "code_name": "provide technical explanation",
                    "definition": "The speaker provides a detailed technical explanation of a method or process.",
                    "justification": "The speaker explains how they can move from live tissue to fixed samples and register data between the two, quoting 'as long as we can find the same cells, we can register back and forth between the two data sets.'"
                },
                {
                    "code_name": "describe methodology",
                    "definition": "The speaker describes a specific methodology or technique they have used.",
                    "justification": "The speaker describes their experience with 'live tissue where we look at neural activity during behavior to fixed samples where we can do single molecule fish even in different microscopes.'"
                }
            ]
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "07:50-08:57",
        "transcript": "So one challenge that we face and uh that is related to using biosensors reporters for subcellular activities in migrating cells is that usually we can't do more than one or two reporters um at the same time. But perhaps you would like to know what five or 10 different things are doing in a specific event. So what we've come up with is is try to make cells behave in a very stereotypic way. For example, move along a a track of extracellular matrix which then has a turn. So you can have a cell that migrates along that track and then it has to turn and then you can especially temporarily analyze what's happening during this specific turning process. And then you have different cells, you you don't use the same cell but you use different cells in a stereotypical behavior um to register the different molecular events uh over time. So that's that's something that, you know, we're we're trying to um establish more and there there certainly with with microfabrication there's there ways of of uh forcing cells into specific behaviors and and helping with that issue. goes back to this multiplexing uh problem of spatial temporal analysis.",
        "speaking duration": 67,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:50",
        "end_time": "48:57",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new method, approach, or solution to a problem.",
                    "justification": "The speaker proposes making cells behave in a stereotypic way to analyze different molecular events over time. \"So what we've come up with is is try to make cells behave in a very stereotypic way.\""
                },
                {
                    "code_name": "describe method",
                    "definition": "The speaker explains or describes a research method, approach, or technique.",
                    "justification": "The speaker describes a method involving cells moving along a track of extracellular matrix to analyze molecular events. \"For example, move along a a track of extracellular matrix which then has a turn.\""
                },
                {
                    "code_name": "reference previous work",
                    "definition": "The speaker mentions or refers to previous work, techniques, or findings.",
                    "justification": "The speaker references the use of microfabrication as a way to force cells into specific behaviors. \"there there certainly with with microfabrication there's there ways of of uh forcing cells into specific behaviors\""
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "09:08-09:39",
        "transcript": "Could you uh could you also have something where, you know, you have a bunch of different sensors at once in the same cell, but they may be somewhat broadly distributed and then they are each tagged with a barcode and even if they're all in the same color, then afterwards you could fix the sample and do some kind of uh fixed tissue labeling or multi round fixed tissue labeling to identify based on the barcode what what what sensor it was even though they were all, you know, green at the time or something like that.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:08",
        "end_time": "49:39",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a new method or idea for addressing a problem.",
                    "justification": "The speaker proposes using barcodes with sensors in cells to identify them later through fixed tissue labeling: 'Could you uh could you also have something where...to identify based on the barcode what what what sensor it was'."
                },
                {
                    "code_name": "suggest solution",
                    "definition": "Offering a specific solution to a problem.",
                    "justification": "The speaker suggests a solution involving barcodes and fixed tissue labeling for identifying sensors: 'Could you uh could you also have something where...to identify based on the barcode what what what sensor it was'."
                }
            ]
        }
    },
    {
        "speaker": "Arnold Hayer",
        "timestamp": "09:39-09:56",
        "transcript": "Okay, okay. Yeah, yeah, I see I see what you mean. So you would have you would multiplex the uh the acquisition and then later basically deconvolve and decide who was who was who in the end. Yeah, that's an interesting idea. We haven't we haven't thought about that yet, but that could could definitely work.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:39",
        "end_time": "49:56",
        "annotations": {
            "codes": [
                {
                    "code_name": "acknowledge",
                    "definition": "The speaker acknowledges or shows understanding of the previous speaker's idea.",
                    "justification": "The speaker says 'Okay, okay. Yeah, yeah, I see I see what you mean.' to show understanding."
                },
                {
                    "code_name": "express interest",
                    "definition": "The speaker expresses interest or enthusiasm for the idea.",
                    "justification": "The speaker says 'Yeah, that's an interesting idea.' to show interest."
                },
                {
                    "code_name": "consider possibility",
                    "definition": "The speaker considers the possibility of an idea.",
                    "justification": "The speaker says 'that could could definitely work.' to consider the possibility."
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "09:56-10:01",
        "transcript": "I guess you need to sort of link that that read out to that barcode.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 40.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:56",
        "end_time": "50:01",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a new idea or approach.",
                    "justification": "The utterance explicitly mentions 'I guess you need to sort of link that that read out to that barcode,' which indicates proposing a potential solution or approach."
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "00:00-00:01",
        "transcript": "code somehow.",
        "speaking duration": 1.0,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:01",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "00:05-00:27",
        "transcript": "Yeah, I was thinking again, I mean based just on my own experience of doing it with an in situ hybridization approach afterwards once the cells are fixed, but it would it assumes that you can register between the live data where everything is green and the fixed data where you can disaggregate who's who. Um and I I mean yeah, I don't know how how feasible that would be within that type of cell.",
        "speaking duration": 22.0,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 13.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:05",
        "end_time": "50:27",
        "annotations": {
            "codes": [
                {
                    "code_name": "share experience",
                    "definition": "The speaker shares their personal experience or previous work to contribute to the discussion.",
                    "justification": "The speaker mentions 'based just on my own experience of doing it with an in situ hybridization approach,' which indicates they are sharing their personal experience to inform the discussion."
                },
                {
                    "code_name": "discuss methodology",
                    "definition": "The speaker discusses or suggests a methodological approach or consideration.",
                    "justification": "The speaker talks about 'register between the live data where everything is green and the fixed data where you can disaggregate who's who,' which is a methodological consideration for their proposed approach."
                },
                {
                    "code_name": "express uncertainty",
                    "definition": "The speaker expresses doubt or uncertainty about a particular aspect of their proposal or idea.",
                    "justification": "The speaker says 'I don't know how how feasible that would be within that type of cell,' which directly expresses uncertainty about the feasibility of their suggested approach."
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "00:28-01:22",
        "transcript": "So uh Andrew actually put uh something in the chat. Uh so there are perhaps uh optogenetic tools that could uh tattoo a cell. That's uh that's an idea as well. Uh related to Arnold um comment the the computational multiplexing or kind of an internal reference. I think that has been used also in a lot of other settings, for example, in cell migration, right? Like the the rather than turn like the the the edge of the cell could serve as a internal reference in some context as well. So I guess related to uh either the optogenetic tattooing or some cell features that serve as internal reference. Um can we think about linking different modalities? Uh I think Lingyan has something to say.",
        "speaking duration": 54.0,
        "nods_others": 2,
        "smile_self": 70.0,
        "smile_other": 10.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:28",
        "end_time": "51:22",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Presenting a new idea or suggestion for consideration.",
                    "justification": "The speaker proposes using optogenetic tools to 'tattoo a cell' and suggests linking different modalities. Evidence: 'So uh Andrew actually put uh something in the chat. Uh so there are perhaps uh optogenetic tools that could uh tattoo a cell. That's uh that's an idea as well.' and 'Um can we think about linking different modalities?'"
                },
                {
                    "code_name": "reference previous comment",
                    "definition": "Referring to a previous statement or idea to connect or build upon it.",
                    "justification": "The speaker references Arnold's comment. Evidence: 'Uh related to Arnold um comment the the computational multiplexing or kind of an internal reference.'"
                },
                {
                    "code_name": "suggest future direction",
                    "definition": "Indicating a potential future direction or action.",
                    "justification": "The speaker suggests considering linking different modalities. Evidence: 'Um can we think about linking different modalities?'"
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "01:23-01:53",
        "transcript": "Yes, yes. Uh I think another modality, actually I like Matt idea about the barcoding. But the barcoding you mentioned maybe it's fluorescence fluorescence related. And I think there is a possibility that we do barcoding with Raman Raman based technique.",
        "speaking duration": 30.0,
        "nods_others": 1,
        "smile_self": 90.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:23",
        "end_time": "51:53",
        "annotations": {
            "codes": [
                {
                    "code_name": "build on others' ideas",
                    "definition": "The speaker is developing or adding to an idea previously mentioned by someone else.",
                    "justification": "The speaker says 'I like Matt idea about the barcoding' and then further discusses the idea, showing they are building on Matt's idea. Quote: 'I like Matt idea about the barcoding'."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker is suggesting a new idea or approach.",
                    "justification": "The speaker suggests using 'Raman based technique' for barcoding, which is a new idea. Quote: 'I think there is a possibility that we do barcoding with Raman Raman based technique'."
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "01:53-02:42",
        "transcript": "Oh, even without the barcoding technique, we can do hyperspectral hyper hyperspectral imaging with the Raman based technology. So that means if we can speed up the imaging collection, then we have a stack of image that covers a certain spectrum. So each molecule, each molecule that we want to look at have its own spectrum profile.",
        "speaking duration": 49.0,
        "nods_others": 1,
        "smile_self": 90.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:53",
        "end_time": "52:42",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Proposing a new idea or method.",
                    "justification": "The speaker suggests an alternative approach: 'Oh, even without the barcoding technique, we can do hyperspectral hyper hyperspectral imaging with the Raman based technology.'"
                },
                {
                    "code_name": "explain method",
                    "definition": "Describing a method or process in detail.",
                    "justification": "The speaker elaborates on the method: 'So that means if we can speed up the imaging collection, then we have a stack of image that covers a certain spectrum. So each molecule... have its own spectrum profile.'"
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "02:42-03:54",
        "transcript": "So if the the image stack, the hyperspectral image stack have for example uh 512 multiplied by 512 pixels and each pixel have its own spectrum information covered. And that allow us to do computational algorithm to do clustering, clustering out the same similar spectrum groups of the pixels. So if group one have this same Raman spectrum, then these pixels will be assigned to uh for example red color, one color. And group two, we we cluster out again and we assign different second color. Uh then there's no limitation as long as we can group out uh a group of of spectrum profile, we can assign a color for that specific group of molecule. So the the in the end, each pixel, there is a dominating molecule signal. Dominating molecule signal is um the the the final assigned color.",
        "speaking duration": 72.0,
        "nods_others": 0,
        "smile_self": 90.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:42",
        "end_time": "53:54",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Proposing a new idea or method for addressing a problem or question.",
                    "justification": "The speaker outlines a specific method for analyzing image stacks and assigning colors based on Raman spectra. Quote: 'So if the the image stack, the hyperspectral image stack have for example uh 512 multiplied by 512 pixels and each pixel have its own spectrum information covered.'"
                },
                {
                    "code_name": "explain method",
                    "definition": "Describing a procedure or technique in detail.",
                    "justification": "The speaker details a step-by-step approach to analyzing hyperspectral image stacks. Quote: 'And that allow us to do computational algorithm to do clustering, clustering out the same similar spectrum groups of the pixels.'"
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
        "timestamp": "03:55-03:56",
        "transcript": "Can I ask a question about that?",
        "speaking duration": 1.0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:55",
        "end_time": "53:56",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "Seeking permission to pose a question, indicating an interest in gaining more information.",
                    "justification": "The speaker says 'Can I ask a question about that?' to seek permission to inquire about a previous topic."
                }
            ]
        }
    },
    {
        "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
        "timestamp": "03:56-04:42",
        "transcript": "I I was wondering because because we I've started looking into doing a little bit of Raman for another project because we have a spectroscopist and we just got a new Renishaw imaging Raman. And I'm curious, is there a way to if you wanted to label so that you could mark a subcellular compartment with fluorescence, right? Because maybe, you know, you're you're you know, I know you can you can you can separate mitochondria and nucleus, you know, things big structures really well. But if you wanted to label something like say a cilium so that you could identify it with fluorescence and then image the cilium with Raman, how can you separate out the fluorescence from the Raman signal? And if so, like that that seems like a really cool multimodal approach to be able to say here's a cellular compartment. Now what is the biochemical makeup of this compartment would be something that could be really interesting.",
        "speaking duration": 46.0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:56",
        "end_time": "54:42",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is inquiring about a specific topic or seeking information.",
                    "justification": "The speaker asks, 'is there a way to if you wanted to label so that you could mark a subcellular compartment with fluorescence... how can you separate out the fluorescence from the Raman signal?' This shows a clear inquiry about a specific technical challenge."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a potential approach or concept.",
                    "justification": "The speaker proposes a 'multimodal approach to be able to say here's a cellular compartment. Now what is the biochemical makeup of this compartment would be something that could be really interesting.' This indicates a suggestion for a research approach."
                },
                {
                    "code_name": "show enthusiasm",
                    "definition": "The speaker expresses excitement or interest in an idea.",
                    "justification": "The speaker says, 'like that that seems like a really cool multimodal approach.' This expresses enthusiasm for the proposed idea."
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "04:42-06:14",
        "transcript": "Yeah, so that is exactly what what I just talked about in the beginning. Uh for example the the neuro neurovascular coupling system that I was talking about, you have the calcium signal which is fluorescence based. So it's a photon that emitted from the molecule. But at the same time, we look at the same region of interest with Raman signal. So that is chemical bound vibrational modes. So we can collect different modalities in the same you know even same region of interest and it doesn't influence each other because it's it's different imaging modality. So then for for that do you do you use like the regular 488 laser for Gcamp excitation and then you use like an infrared laser for the Raman signal? Is that what you do?",
        "speaking duration": 92.0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:42",
        "end_time": "56:14",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is inquiring about another person's method or viewpoint.",
                    "justification": "The utterance ends with a direct question inquiring about the specifics of another's method, \"So then for for that do you do you use like the regular 488 laser for Gcamp excitation and then you use like an infrared laser for the Raman signal? Is that what you do?\"."
                },
                {
                    "code_name": "share knowledge",
                    "definition": "The speaker is providing information or explaining a concept.",
                    "justification": "The speaker explains a concept related to their research, \"Yeah, so that is exactly what what I just talked about in the beginning. Uh for example the the neuro neurovascular coupling system that I was talking about, you have the calcium signal which is fluorescence based.\", showing they are sharing their expertise."
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "06:14-06:15",
        "transcript": "Uh I do two photon fluorescence.",
        "speaking duration": 1.0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:14",
        "end_time": "56:15",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "06:15-06:15",
        "transcript": "Lingyan Shi_UCSD has started screen sharing",
        "speaking duration": 0.0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "None",
        "start_time": "56:15",
        "end_time": "56:15",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "06:16-08:24",
        "transcript": "So which means that because the focus plan will be a little bit different if you use visible laser instead of near infrared laser. So I use the same laser to do the the pump for the size imaging, but use the same wavelength to do the two photon fluorescence for for Gcamp or for other fluorescence signal. So other fluorescence signal can be uh can be imaged by two photon fluorescence very well. For example the the the one that we usually talk about like label free NADH or flavor molecules and we can quickly just image with two photon fluorescence in the same you know even same region of interest. And it doesn't influence each other because it's it's different imaging modality.",
        "speaking duration": 128.0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a PowerPoint presentation titled \"Aging La Jolla (Autosaved)\". The current slide is titled \"Label Free SRS hyperspectral image\" and contains a diagram illustrating the hyperspectral imaging process, an intensity plot of a highlighted pixel, and several images showing different Raman shifts.",
        "start_time": "56:16",
        "end_time": "58:24",
        "annotations": {
            "codes": [
                {
                    "code_name": "explain methodology",
                    "definition": "The speaker is describing their approach or method used in their research.",
                    "justification": "The speaker explains how they use the same laser for different imaging techniques, \"So I use the same laser to do the the pump for the size imaging, but use the same wavelength to do the two photon fluorescence for for Gcamp or for other fluorescence signal.\""
                },
                {
                    "code_name": "provide example",
                    "definition": "The speaker provides an example to illustrate a point or concept.",
                    "justification": "The speaker gives an example of label-free NADH or flavor molecules, \"For example the the the one that we usually talk about like label free NADH or flavor molecules and we can quickly just image with two photon fluorescence in the same you know even same region of interest.\""
                },
                {
                    "code_name": "highlight advantage",
                    "definition": "The speaker points out a benefit or advantage of their approach.",
                    "justification": "The speaker mentions that using two-photon fluorescence does not interfere with other imaging modalities, \"And it doesn't influence each other because it's it's different imaging modality.\""
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "09:24-09:59",
        "transcript": "Do we have a two minutes to discuss another quick idea? I want to ask Dr. uh Somarco, Dr. Mimi. Yes, so uh I have a little bit of experience with tumor modeling with ODE, you know, advective reactive equations and I have incorporated with that, you know, necrosis um and also uh partial oxygen oxygen partial pressure.",
        "speaking duration": 35.0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "59:24",
        "end_time": "59:59",
        "annotations": {
            "codes": [
                {
                    "code_name": "request discussion time",
                    "definition": "The speaker is asking for a short period of time to discuss an additional idea.",
                    "justification": "The utterance starts with 'Do we have a two minutes to discuss another quick idea?'"
                },
                {
                    "code_name": "seek expertise",
                    "definition": "The speaker is seeking input or expertise from specific individuals.",
                    "justification": "The speaker mentions wanting to ask Dr. Somarco and Dr. Mimi, indicating they are seeking expertise from these individuals."
                },
                {
                    "code_name": "share expertise",
                    "definition": "The speaker is sharing their own knowledge or experience on a specific topic.",
                    "justification": "The speaker shares their experience with tumor modeling using ODE, mentioning specifics like advective reactive equations, necrosis, and partial oxygen pressure."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "00:00-00:01",
        "transcript": "model will help.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:00",
        "end_time": "60:01",
        "annotations": {
            "codes": [
                {
                    "code_name": "express support",
                    "definition": "The speaker is showing agreement or a positive stance towards an idea or proposal.",
                    "justification": "The utterance 'model will help' directly supports the use of a model. Quote: 'model will help.'"
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or concept.",
                    "justification": "Although minimal, suggesting that 'model will help' implies proposing the idea of using a model. Quote: 'model will help.'"
                }
            ]
        }
    },
    {
        "speaker": "Mimi Sammarco",
        "timestamp": "00:01-00:07",
        "transcript": "Yeah, that would be super helpful. Um, I I'm do you want to",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:01",
        "end_time": "60:07",
        "annotations": {
            "codes": [
                {
                    "code_name": "express agreement",
                    "definition": "The speaker shows concurrence or acceptance of a previous statement.",
                    "justification": "The phrase 'Yeah, that would be super helpful' indicates agreement and appreciation for the help offered."
                },
                {
                    "code_name": "seek clarification",
                    "definition": "The speaker seeks more information or direction on what to do next.",
                    "justification": "The phrase 'Um, I I'm do you want to' suggests the speaker is looking for guidance or an invitation to proceed with something."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "00:07-00:11",
        "transcript": "Yeah, we can talk offline. We can talk offline and not derail it. Yeah.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 25.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:07",
        "end_time": "60:11",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose discussion",
                    "definition": "Suggesting a conversation outside of the current setting.",
                    "justification": "The speaker suggests talking offline with the quote 'Yeah, we can talk offline.'"
                },
                {
                    "code_name": "show consideration for group time",
                    "definition": "Expressing concern for not disrupting the group's discussion or agenda.",
                    "justification": "The speaker shows consideration with the quote 'and not derail it.'"
                }
            ]
        }
    },
    {
        "speaker": "Mimi Sammarco",
        "timestamp": "00:11-00:14",
        "transcript": "I I don't want to interrupt uh",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 25.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:11",
        "end_time": "60:14",
        "annotations": {
            "codes": [
                {
                    "code_name": "show consideration",
                    "definition": "The speaker shows consideration for others, in this case, not wanting to interrupt them.",
                    "justification": "The utterance 'I I don't want to interrupt uh' directly shows Mimi's consideration for not interrupting others. The verbatim quote is 'I I don't want to interrupt uh'."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "00:14-00:23",
        "transcript": "you know, the other discussions was very exciting and interesting. So I didn't want to interrupt. But we can write a line in that and we can talk offline.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 55.0,
        "smile_other": 22.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:14",
        "end_time": "60:23",
        "annotations": {
            "codes": [
                {
                    "code_name": "show respect",
                    "definition": "The speaker shows consideration for others by not wanting to interrupt their discussions.",
                    "justification": "So I didn't want to interrupt."
                },
                {
                    "code_name": "suggest future discussion",
                    "definition": "The speaker suggests continuing the conversation at a later time.",
                    "justification": "But we can write a line in that and we can talk offline."
                }
            ]
        }
    },
    {
        "speaker": "Mimi Sammarco",
        "timestamp": "00:23-00:25",
        "transcript": "Okay. I'll message you offline then. Okay, thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:23",
        "end_time": "60:25",
        "annotations": {
            "codes": [
                {
                    "code_name": "agree to follow up",
                    "definition": "Agree to take an action or communicate outside of the current setting.",
                    "justification": "The phrase 'I'll message you offline then' indicates an agreement to follow up or communicate privately."
                },
                {
                    "code_name": "express gratitude",
                    "definition": "Express thanks or appreciation.",
                    "justification": "The phrase 'Okay, thank you' shows gratitude."
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:26-01:10",
        "transcript": "Actually, I do think that that, you know, the previous discussion was really great and already, you know, indicates a great idea for a, you know, a project proposal. Um, I do think that both Joyoni and Mimi might have some um input on this kind of multimodal approach because you're working generally at larger scales and especially Mimi with um doing kind of like the I think you do microCT with then the spatial transmic and I think that um, you know, just using using structural information at larger scales and then kind of how you would um either multimodal to get different information and or then use that spatial information to decide where to sample with high resolution. I think either of you might be able to contribute um some ideas here.",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:26",
        "end_time": "61:10",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a potential project idea or approach.",
                    "justification": "The speaker mentions that the previous discussion 'already indicates a great idea for a project proposal.'"
                },
                {
                    "code_name": "seek input",
                    "definition": "The speaker asks for contributions or ideas from others.",
                    "justification": "The speaker explicitly states that Joyoni and Mimi 'might be able to contribute some ideas here.'"
                },
                {
                    "code_name": "reference others' work",
                    "definition": "The speaker mentions or builds upon the work of others.",
                    "justification": "The speaker references Joyoni and Mimi's work, specifically mentioning 'microCT with then the spatial transmic.'"
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "01:10-01:44",
        "transcript": "Yeah, I have worked on region based reconstruction as well, MLM regional reconstruction, you know, like the challenge is that you won't have artifacts from taking only a region, you know, so um, so there are some iterative reconstructions that can help there.",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 35.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:10",
        "end_time": "61:44",
        "annotations": {
            "codes": [
                {
                    "code_name": "share_expertise",
                    "definition": "The speaker provides information about their background or experience in a relevant field.",
                    "justification": "The speaker shares their experience with region-based reconstruction: 'Yeah, I have worked on region based reconstruction as well, MLM regional reconstruction'."
                },
                {
                    "code_name": "identify_challenge",
                    "definition": "The speaker highlights a difficulty or issue related to the topic of discussion.",
                    "justification": "The speaker identifies a challenge: 'like the challenge is that you won't have artifacts from taking only a region'."
                },
                {
                    "code_name": "propose_solution",
                    "definition": "The speaker offers a potential way to address a challenge or problem.",
                    "justification": "The speaker suggests a solution: 'so there are some iterative reconstructions that can help there'."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "01:44-02:01",
        "transcript": "So do one would only one idea go from each of these breakout session or we can discuss some other ones too for later, you know, it doesn't need to be for this cycle or we can I can still discuss with Dr. um Sammarco.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:44",
        "end_time": "62:01",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask_question",
                    "definition": "The speaker is seeking information or clarification on a particular topic.",
                    "justification": "The exact quote 'So do one would only one idea go from each of these breakout session or we can discuss some other ones too for later' shows Joyoni Dey is asking about the process for idea discussion, seeking clarification on whether they can discuss ideas beyond the current cycle."
                },
                {
                    "code_name": "propose_process",
                    "definition": "The speaker suggests a way to proceed or organize discussions/tasks.",
                    "justification": "The phrase 'or we can I can still discuss with Dr. um Sammarco' suggests an alternative process for discussing ideas, implying a proposal for how to move forward with the discussion."
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:01-02:27",
        "transcript": "Yes, I think that these breakout rooms are really meant to just seed ideas and learn about each other. And then, you know, really find the time outside of these structured times to be able to talk about um potential collaborations for the project proposals or even beyond that. And you will have, you know, future years to discuss as well, but I think if you have a seed that you're willing to both work on for for a project proposal that this is, you know, where that starts.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:01",
        "end_time": "62:27",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Propose a idea or suggestion for discussion or consideration.",
                    "justification": "The speaker suggests that the breakout rooms are meant to 'seed ideas and learn about each other' and that potential collaborations can start from these interactions. Evidence: 'I think that these breakout rooms are really meant to just seed ideas and learn about each other.'"
                },
                {
                    "code_name": "facilitate collaboration",
                    "definition": "Encourage or facilitate collaboration among participants.",
                    "justification": "The speaker encourages finding time outside of structured sessions to discuss potential collaborations. Evidence: 'And then, you know, really find the time outside of these structured times to be able to talk about um potential collaborations for the project proposals or even beyond that.'"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "02:30-03:13",
        "transcript": "Uh, can I ask so for to summarize what we'll uh talk about in the report out, we'll kind of try and focus on those two, these two ideas of that we discussed this concept of uh, you know, a smart microscope kind of thing that would be able to screen with low res data and then um ideally without user guided um input to then uh find things for higher res field of views. And then the second point about, you know, various ideas for combining things across modalities to um to to take advantage and and limit uh the downsides of each of these different modalities and stuff like that. That's essentially how we should summarize, I think.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:30",
        "end_time": "63:13",
        "annotations": {
            "codes": [
                {
                    "code_name": "summarize",
                    "definition": "The speaker is summarizing the discussion points or ideas presented.",
                    "justification": "The speaker says 'can I ask so for to summarize what we'll uh talk about in the report out' indicating an attempt to summarize."
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or concept for discussion or consideration.",
                    "justification": "The speaker mentions 'this concept of uh, you know, a smart microscope kind of thing' and 'various ideas for combining things across modalities' as ideas to focus on."
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "03:13-03:21",
        "transcript": "Okay. Is any if anyone wants to add to the doc, I've just been taking notes on these things, but um please go ahead.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:13",
        "end_time": "63:21",
        "annotations": {
            "codes": [
                {
                    "code_name": "invite contribution",
                    "definition": "The speaker invites others to contribute or add to a discussion, document, or idea.",
                    "justification": "The exact quote 'Is any if anyone wants to add to the doc, I've just been taking notes on these things, but um please go ahead' shows that Matt Lovett-Barron is explicitly inviting others to contribute to the document, indicating an openness to collaboration and input from others."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "03:35-03:41",
        "transcript": "So um if it's okay, I'm adding so if it's okay, I'm adding the third idea of a",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:35",
        "end_time": "63:41",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask permission",
                    "definition": "The speaker is seeking approval or permission to perform an action.",
                    "justification": "The speaker says 'So um if it's okay, I'm adding,' which directly indicates seeking permission. The exact quote is 'if it's okay.'"
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker is suggesting or introducing a new idea.",
                    "justification": "Although the utterance is incomplete and does not fully articulate the idea, the speaker mentions 'I'm adding the third idea,' which implies the introduction of a new idea. The exact quote is 'I'm adding the third idea.'"
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "03:41-03:56",
        "transcript": "model based approach with Dr. Sammarco, you know, like modeling like using a OD equation.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:41",
        "end_time": "63:56",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or approach.",
                    "justification": "The utterance mentions a 'model based approach with Dr. Sammarco' and 'like modeling like using a OD equation,' which indicates the proposal of a specific idea or method."
                },
                {
                    "code_name": "mention collaboration",
                    "definition": "The speaker mentions working with someone else.",
                    "justification": "The mention of 'with Dr. Sammarco' directly implies collaboration or the intention to collaborate."
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "03:56-04:00",
        "transcript": "Yeah, I think that's a that's a um important point.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:56",
        "end_time": "64:00",
        "annotations": {
            "codes": [
                {
                    "code_name": "acknowledge",
                    "definition": "Express agreement or confirmation.",
                    "justification": "The utterance 'Yeah, I think that's a that's a um important point.' acknowledges a previous statement. The verbatim quote is 'Yeah, I think that's a that's a um important point.'"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "04:00-04:32",
        "transcript": "Um, perhaps uh, you know, in terms of in addition to experimentally uh trying to integrate different uh information across different scales using modeling approach um to connect data uh from different experiments and then uh make them coherent and integrate that information is is also uh an another approach and um",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:00",
        "end_time": "64:32",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or approach to a problem.",
                    "justification": "The utterance proposes an approach of integrating different information across different scales using a modeling approach. Evidence: 'in addition to experimentally uh trying to integrate different uh information across different scales using modeling approach um to connect data uh from different experiments and then uh make them coherent and integrate that information'"
                },
                {
                    "code_name": "build on others' work",
                    "definition": "The speaker indicates that their idea or approach can complement or build upon what others have discussed or researched.",
                    "justification": "Although not directly referencing another's work, the context suggests a build-up or addition to previously discussed ideas, implying potential for building on others' work. Evidence: 'in addition to experimentally uh trying to integrate...is is also uh an another approach'"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "04:32-04:32",
        "transcript": "So maybe we can uh you know, you want to elaborate a little bit on that?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:32",
        "end_time": "64:32",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is asking for clarification or more information.",
                    "justification": "The speaker says 'So maybe we can uh you know, you want to elaborate a little bit on that?' which is a clear request for more information. The exact quote is 'you want to elaborate a little bit on that'."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey",
        "timestamp": "04:32-05:54",
        "transcript": "Uh what I have worked on is um for tumor models uh is uh you know, there are the um uh one set of equations where you describe the tumor population growth and the death like say natural apoptosis and there are these advective reactive equations OD equations describing that and then um what I have done is that didn't describe how the necrosis starts, okay? So what I had contributed was that I also have have another simultaneous equation where um I describe the oxygen partial pressure. I would get that from the spec imaging, okay? And then uh where the axial partial pressure pressure goes down to zero is where the necrosis will start in the tumor. So uh so that I can now start evolving this tumor equation with time and now the necrosis will start. So there is like I thought that that might easily translate to something that Dr.",
        "speaking duration": 82,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:32",
        "end_time": "65:54",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker presents a concept or method they have worked on or suggest a way to approach a problem.",
                    "justification": "The speaker describes their work on tumor models, including a set of equations for tumor population growth and death, and an additional equation for oxygen partial pressure to describe necrosis. Evidence: 'what I have worked on is um for tumor models...there are the um uh one set of equations where you describe the tumor population growth and the death...I also have have another simultaneous equation where um I describe the oxygen partial pressure.'"
                },
                {
                    "code_name": "share research",
                    "definition": "The speaker shares their research findings or methods with the group.",
                    "justification": "The speaker elaborates on their specific contributions to tumor models, including the equations and the role of oxygen partial pressure in describing necrosis. Evidence: 'So what I had contributed was that I also have have another simultaneous equation where um I describe the oxygen partial pressure.'"
                },
                {
                    "code_name": "seek connection with others' work",
                    "definition": "The speaker attempts to link their work with that of others in the field or in the room.",
                    "justification": "The speaker hints at the potential for their work to translate to something Dr. [presumably someone in the room or a known figure] might be interested in. Evidence: 'So there is like I thought that that might easily translate to something that Dr. '"
                }
            ]
        }
    },
    {
        "speaker": "Mimi Sammarco",
        "timestamp": "05:54-05:55",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:54",
        "end_time": "65:55",
        "annotations": {
            "codes": [
                {
                    "code_name": "acknowledge",
                    "definition": "Acknowledge or express agreement with what has been said.",
                    "justification": "The utterance 'Yeah.' is a clear acknowledgment of previous statements, showing agreement or understanding."
                }
            ]
        }
    },
    {
        "speaker": "Mimi Sammarco",
        "timestamp": "05:55-07:31",
        "transcript": "Sammarco was saying because I can describe the cellular metabolism and the physical structures of the uh osteoblast and osteocytes, you know, population and I could apply it to the anybody else's cellular um like, you know, all the things other things that we discussed. Yeah, we that would actually be perfect um for some of the stuff we work on. We there's we have this inexplicable we're working on an aged mouse model and so I think the the pictures up on the on the picture board or whatever, but you know, I get this higher bone mineral density and the regenerated bone. It's direct ossification. There's no cartilage intermediate. I get this um really high bone mineral density and it's in very specific places. And so the man handle or the woman handling of the microCT stacks and trying to actually align um where that is in relation to the histology, I can sort of reverse the spaces and then do CD31 and and say okay, that's an endothelial space but being able to correlate some of this high bone mineral density to what's around it, which presumably is either nerve or vascular space, um would actually lead to what the mechanism is that's underlying that, particularly if I can go in and sort of um look at that in terms of spatial transcriptomics and be able to say like, yeah, there's my you know, there's my vasculature and there's my osteoblast and you can see that it correlates like when we look at this in 2D. But um, we haven't been able to successfully take these CT stacks and be able to mathematically show it. I mean, I think the field hasn't really either because you end up with all these figures are just like, hey, it kind of looks like this. And then just hope somebody doesn't ask for some sort of quantification for it. You just sort of go, oh, we can't do it. Um, so but but I I think that's really needed um to be able to, you know, find out better ways to if you could do that, I mean, you could basically target where you where you want to interosseous growth for like prosthetic integration and stuff, which would be really nice.",
        "speaking duration": 96,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:55",
        "end_time": "67:31",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a new idea or approach that could be used to solve a problem or advance a field.",
                    "justification": "The speaker suggests targeting interosseous growth for prosthetic integration, indicating a new approach: 'I think that's really needed um to be able to, you know, find out better ways to if you could do that, I mean, you could basically target where you where you want to interosseous growth for like prosthetic integration and stuff, which would be really nice.'"
                },
                {
                    "code_name": "share research findings",
                    "definition": "Presenting data or findings from one's own research.",
                    "justification": "The speaker shares their research findings on bone mineral density: 'I get this higher bone mineral density and the regenerated bone. It's direct ossification. There's no cartilage intermediate.'"
                },
                {
                    "code_name": "express interest in collaboration",
                    "definition": "Expressing interest in working together or applying another's work to one's own research.",
                    "justification": "The speaker indicates another's approach could be applied to their work: 'Yeah, we that would actually be perfect um for some of the stuff we work on.'"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "07:46-07:55",
        "transcript": "Uh, could I ask Kristen, as we're getting uh close to finishing up, how do I put this into that the slide deck?",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "67:46",
        "end_time": "67:55",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker seeks information or clarification on a particular topic or task.",
                    "justification": "The utterance contains a direct question seeking help, 'how do I put this into that the slide deck?' The speaker is specifically asking Kristen for assistance, which is evident from 'could I ask Kristen'."
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:55-08:05",
        "transcript": "Um, so I would say that you should be able to copy and paste into the power the the the PowerPoint, whatever Google slides version.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "67:55",
        "end_time": "68:05",
        "annotations": {
            "codes": [
                {
                    "code_name": "offer help",
                    "definition": "Providing assistance or a solution to someone's problem or question.",
                    "justification": "The utterance 'Um, so I would say that you should be able to copy and paste into the power the the the PowerPoint, whatever Google slides version.' shows Kristen providing a specific action to take, which is offering help."
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:05-08:05",
        "transcript": "Are you unable to do that?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "68:05",
        "end_time": "68:05",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is seeking information or clarification by asking a question.",
                    "justification": "The utterance 'Are you unable to do that?' is a direct question, and its purpose is to inquire about someone's capability to perform an action mentioned previously."
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "08:06-08:17",
        "transcript": "I can do that and then do I just put it back in the drive? Like I copy it, save it and then drag it into the drive because I don't seem to have online access to edit uh what's on the drive.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "68:06",
        "end_time": "68:17",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is seeking clarification or information about a specific topic or process.",
                    "justification": "The utterance contains a direct question about how to perform a task ('do I just put it back in the drive?'), and the speaker is seeking technical help."
                },
                {
                    "code_name": "express limitation",
                    "definition": "The speaker is stating a constraint or limitation they are experiencing.",
                    "justification": "The speaker mentions not having online access to edit something. Evidence: 'I don't seem to have online access to edit uh what's on the drive.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:17-08:20",
        "transcript": "Maybe Richard can help us with that. I um",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "68:17",
        "end_time": "68:20",
        "annotations": {
            "codes": [
                {
                    "code_name": "suggest help from others",
                    "definition": "Suggesting that someone else might be able to assist with a task or problem.",
                    "justification": "The utterance 'Maybe Richard can help us with that' directly supports this code. It shows Kristen Maitland recognizing that Richard might have the necessary expertise or ability to assist with the issue at hand."
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "08:20-08:26",
        "transcript": "Or I mean we could also paste uh just what we've written here in there as well. I mean that's also uh an approach.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "68:20",
        "end_time": "68:26",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new idea or approach to solve a problem or move forward.",
                    "justification": "The speaker suggests an alternative approach by saying, 'Or I mean we could also paste uh just what we've written here in there as well. I mean that's also uh an approach.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:27-08:31",
        "transcript": "Yes, I I think just paste into the um the field.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "68:27",
        "end_time": "68:31",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose_idea",
                    "definition": "Suggesting a course of action or an idea.",
                    "justification": "The utterance 'just paste into the um the field.' is a suggestion for how to proceed, proposed by Kristen Maitland."
                }
            ]
        }
    },
    {
        "speaker": "Richard Wiener",
        "timestamp": "08:31-09:25",
        "transcript": "Yeah, you can paste it into the PowerPoint. When you get when you have it at the point that you want to have it in in uh what you want to present, when it's edited down, the easiest thing is just paste it in. That should work. Uh yeah, I I don't seem to have access to it. It says that it it won't preview the file and I can't load it. the same thing happened yesterday. so Oh, maybe we're having maybe it's there's so many people trying to put stuff in. Uh wait for a couple minutes or uh share it with someone else and another person can try. I I I haven't seen this problem in the previously, but it looks like we're getting enough people working in the document that it's um it's not making it as easy as we as it usually is or what we hoped for. So uh bear with us for a little bit. Don't if you if you're ready to paste something in but you guys want to talk some more, don't waste the time, please please do that.",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the logo of the Research Corporation for Science Advancement.",
        "start_time": "68:31",
        "end_time": "69:25",
        "annotations": {
            "codes": [
                {
                    "code_name": "offer solution",
                    "definition": "Providing a potential solution or workaround to a problem.",
                    "justification": "The speaker offers to solve a problem by suggesting to 'paste it into the PowerPoint' or 'wait for a couple minutes or uh share it with someone else and another person can try.' Exact quote: 'Yeah, you can paste it into the PowerPoint... Uh wait for a couple minutes or uh share it with someone else and another person can try.'"
                },
                {
                    "code_name": "explain problem",
                    "definition": "Describing an issue or challenge being faced.",
                    "justification": "The speaker describes a technical issue they're experiencing: 'I don't seem to have access to it. It says that it it won't preview the file and I can't load it.' Exact quote: 'Uh yeah, I I don't seem to have access to it. It says that it it won't preview the file and I can't load it.'"
                },
                {
                    "code_name": "facilitate collaboration",
                    "definition": "Encouraging or facilitating teamwork and communication among participants.",
                    "justification": "The speaker encourages participants to prioritize discussion over immediate contribution: 'So uh bear with us for a little bit. Don't if you if you're ready to paste something in but you guys want to talk some more, don't waste the time, please please do that.' Exact quote: 'So uh bear with us for a little bit. Don't if you if you're ready to paste something in but you guys want to talk some more, don't waste the time, please please do that.'"
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron",
        "timestamp": "09:26-09:31",
        "transcript": "And I'm I'm going to bug out but uh what parts of the discussion I've heard have been really interesting.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the logo of the Research Corporation for Science Advancement.",
        "start_time": "69:26",
        "end_time": "69:31",
        "annotations": {
            "codes": [
                {
                    "code_name": "exit discussion",
                    "definition": "The speaker announces their departure from the conversation or meeting.",
                    "justification": "The speaker says 'I'm going to bug out,' which directly indicates they are leaving the discussion."
                },
                {
                    "code_name": "express interest",
                    "definition": "The speaker shows interest in certain aspects of the discussion.",
                    "justification": "The speaker mentions 'what parts of the discussion I've heard have been really interesting,' which shows they are interested in specific parts of the conversation."
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "09:31-09:32",
        "transcript": "Thank you, Richard.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the logo of the Research Corporation for Science Advancement.",
        "start_time": "69:31",
        "end_time": "69:32",
        "annotations": {
            "codes": [
                {
                    "code_name": "express gratitude",
                    "definition": "The speaker is thanking someone for something they have done or provided.",
                    "justification": "The utterance directly expresses thanks, as evidenced by 'Thank you, Richard.'"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang",
        "timestamp": "09:32-09:59",
        "transcript": "Can I ask uh the the modeling based integration, can that be extended to uh, you know, other cross scales, single molecule to subcellular uh subcellular to um, you know, multicellular collective uh migration uh, you know, and then multi the multi tissue level, anything um along",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the logo of the Research Corporation for Science Advancement.",
        "start_time": "69:32",
        "end_time": "69:59",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is seeking information or clarification on a specific topic.",
                    "justification": "The utterance starts with 'Can I ask' and proceeds with a direct question about extending 'modeling based integration' to other scales. Evidence: 'Can I ask uh the the modeling based integration, can that be extended...'"
                },
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a potential idea or future direction for research or collaboration.",
                    "justification": "By asking about extending the modeling integration to other scales, Jin Zhang is suggesting a future direction or potential area of collaboration. Evidence: '...to uh, you know, other cross scales, single molecule to subcellular uh subcellular to um, you know, multicellular collective uh migration uh, you know, and then multi the multi tissue level, anything um along'"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "00:00-00:03",
        "transcript": "Those line has have people thought about that aspect?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 33.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:00",
        "end_time": "70:03",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is asking if others have thought about a particular aspect or idea.",
                    "justification": "The utterance 'Those line has have people thought about that aspect?' is a clear question asking if others have considered a specific aspect. The verbatim quote 'have people thought about that aspect' indicates a inquiry about others' thoughts."
                }
            ]
        }
    },
    {
        "speaker": "Arnold Hayer, McGill",
        "timestamp": "00:07-00:50",
        "transcript": "I think I think yes. I think I think it could be so like the the example that I I said about cells, you know, turning forcing cells into specific turning thing. One could also say, okay, let's just look at what cells naturally do and then identify particular um for example, movement patterns and during specific movement patterns make that as a detection um point of detection where you say like, okay, this is the this is the event. So that's more more like using using a a set of features that have that have to happen in order to to detect the event and then and then focus focus in um",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:07",
        "end_time": "70:50",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Proposing a new idea or approach to a problem.",
                    "justification": "The speaker suggests looking at what cells naturally do and identifying movement patterns as a detection point. Evidence: \"One could also say, okay, let's just look at what cells naturally do and then identify particular um for example, movement patterns...\""
                },
                {
                    "code_name": "provide example",
                    "definition": "Offering a specific example to clarify or support an idea.",
                    "justification": "The speaker mentions an example about cells and turning. Evidence: \"like the the example that I I said about cells, you know, turning forcing cells into specific turning thing.\""
                },
                {
                    "code_name": "suggest methodology",
                    "definition": "Proposing a specific method or approach to achieve a goal.",
                    "justification": "The speaker talks about using a set of features to detect an event. Evidence: \"So that's more more like using using a a set of features that have that have to happen in order to to detect the event and then and then focus focus in um .\""
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "00:50-01:13",
        "transcript": "The modeling work that I have worked on is mostly on the tissue level. But I guess you can do transportation models and you know, it's a matter of learning the math and I don't think I can do it by next week, but but you know, uh yeah, in the future definitely uh I'll be at least very interested in doing something like that.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 65.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:50",
        "end_time": "71:13",
        "annotations": {
            "codes": [
                {
                    "code_name": "share personal experience",
                    "definition": "The speaker shares their personal or professional experience related to the topic.",
                    "justification": "The speaker mentions their experience with modeling work on the tissue level. Quote: 'The modeling work that I have worked on is mostly on the tissue level.'"
                },
                {
                    "code_name": "suggest possibility",
                    "definition": "The speaker suggests a possibility or an idea related to the discussion.",
                    "justification": "The speaker suggests the possibility of doing transportation models. Quote: 'But I guess you can do transportation models'"
                },
                {
                    "code_name": "express future interest",
                    "definition": "The speaker expresses interest in doing something in the future.",
                    "justification": "The speaker expresses interest in doing something like transportation models in the future. Quote: 'in the future definitely uh I'll be at least very interested in doing something like that.'"
                }
            ]
        }
    },
    {
        "speaker": "Douglas Shepherd",
        "timestamp": "01:13-02:57",
        "transcript": "So we've done this with snapshot RNA fish data. So the problem with RNA fish strategy is you have to kill the sample. But often the if you measure say 100 cells and you perturb them and then you measure them at similar time points, you actually get very repeatable behavior often for certain gene networks. So it turns out you can actually link the snapshot data using some modeling ideas. So these come more from control theory, so they're things like chemical master equation and these other things. What's really interesting about them is you can actually predict if you take enough data what the cells might do under a new stimuli or you can predict which time points you should then measure to reduce your uncertainty. So you can do sort of a coarser set of experiments and then predict like where do I need to fill in to understand the dynamics in my system better. And we actually showed that you can do this well enough where you can extract say um elongation rates of RNA from these snapshot data. So then we went back into the line system and actually measured the elongation rate and actually showed we got it right from the computational inference. The the problem we run into there again is we just started with an overwhelming amount of data. So we're stuck to this idea of like, can we it's really easy to start from this overwhelming data, specify a model and say I should have measured here. I think it gets much harder to start from a sort of first principles modeling and say this is where I need to be doing my measurements to learn the most over space and time and that problem I think is is still really challenging and I don't have a good handle on the best way to approach it. So.",
        "speaking duration": 104,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:13",
        "end_time": "72:57",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "Presenting a suggestion or approach for solving a problem or analyzing data.",
                    "justification": "The speaker proposes using modeling ideas from control theory to link snapshot data. \"So it turns out you can actually link the snapshot data using some modeling ideas.\""
                },
                {
                    "code_name": "share results",
                    "definition": "Presenting findings or outcomes from conducted experiments or analyses.",
                    "justification": "The speaker shares specific outcomes, \"And we actually showed that you can do this well enough where you can extract say um elongation rates of RNA from these snapshot data.\""
                },
                {
                    "code_name": "identify challenge",
                    "definition": "Pointing out obstacles or difficulties encountered in a project or analysis.",
                    "justification": "The speaker discusses a challenge, \"The the problem we run into there again is we just started with an overwhelming amount of data.\""
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "02:57-03:11",
        "transcript": "Related to an earlier comment America made, this also almost you know, we can go back link back to our case study at the the beginning. If you can model uh the behaviors of the the the cilia.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "72:57",
        "end_time": "73:11",
        "annotations": {
            "codes": [
                {
                    "code_name": "reference earlier comment",
                    "definition": "Referencing a previous comment or idea to connect or build upon it.",
                    "justification": "The speaker says 'Related to an earlier comment America made,' which directly references a previous comment."
                },
                {
                    "code_name": "propose idea",
                    "definition": "Suggesting a new idea or research direction.",
                    "justification": "The speaker suggests, 'If you can model uh the behaviors of the the the cilia,' which proposes a specific research direction."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:11-03:12",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:11",
        "end_time": "73:12",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "03:12-03:21",
        "transcript": "Um that could also provide uh some you know, some possibilities of linking those different scales.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:12",
        "end_time": "73:21",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose_idea",
                    "definition": "The speaker suggests a new idea or approach to a problem.",
                    "justification": "The utterance 'Um that could also provide uh some you know, some possibilities of linking those different scales' indicates that Jin Zhang is suggesting a potential method for integrating or connecting different scales, which is a clear proposal of an idea."
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "03:21-03:22",
        "transcript": "USD.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:21",
        "end_time": "73:22",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Vivian Qian Liu, McGill",
        "timestamp": "03:22-04:56",
        "transcript": "Yes, uh I think a lot of the discussion we made so far are applied to my research. So the the case study for the cilia, having a lot of approaches would apply to viruses as well because they are the cilia is like uh uh the little filaments on the cell. So the virus would attach on those. So the movement of the cilia kind of reflects uh sort of the movement of the virus particle on the cell before they enter. Uh and also the uh I think the uh user guided imaging where where you uh you focus where with a with a bigger field and then you zoom in on a smaller field. That's exactly what I would looking for. And I think if we can I think that it it it definitely would help with the uh photo bleaching or photo toxicity uh problem so that with a uh bigger field we don't need we uh we kind of spread out the intensity of the of the lasers. But uh once we find an interesting field, we can zoom it in then we only look at that small part and look at it at super resolution and that way we can keep the cell alive while we're imaging. So yes, that was the thing I found most interesting from that from this discussion.",
        "speaking duration": 94,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Aurora Borealis, also known as the Northern Lights. The image remains static throughout the segment.",
        "start_time": "73:22",
        "end_time": "74:56",
        "annotations": {
            "codes": [
                {
                    "code_name": "Connect Research",
                    "definition": "The speaker connects their research to the discussion, indicating potential applications or relevance.",
                    "justification": "The speaker explicitly states, \"I think a lot of the discussion we made so far are applied to my research.\" This shows a direct connection between their research and the discussion topics."
                },
                {
                    "code_name": "Share Knowledge",
                    "definition": "The speaker shares their knowledge or insights that could be beneficial to the discussion or project.",
                    "justification": "The speaker explains how approaches for studying cilia could apply to viruses, stating, \"So the case study for the cilia, having a lot of approaches would apply to viruses as well...\" They also discuss the benefits of user-guided imaging in their research."
                },
                {
                    "code_name": "Express Interest",
                    "definition": "The speaker expresses interest in a method, approach, or idea discussed.",
                    "justification": "The speaker mentions, \"That's exactly what I would looking for,\" referring to user-guided imaging. This indicates their interest in a specific approach."
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "05:19-05:25",
        "transcript": "Great. Uh I think uh any any other comments um thoughts?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 66.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Aurora Borealis, also known as the Northern Lights. The image remains static throughout the segment.",
        "start_time": "75:19",
        "end_time": "75:25",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask_question",
                    "definition": "The speaker is seeking input or feedback from others.",
                    "justification": "The utterance 'any any other comments um thoughts?' is a clear request for input."
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "05:26-06:11",
        "transcript": "I just have a quick uh last comment on the on the um RNA in situ fish for spatial information. Just just idea that how we can combine the hyper spectrum Raman imaging uh since we just discussed that each pixel will be belong to a certain molecule uh that is the metabolic actually the mapping the metabolic activity. So we can also uh validate by the fish in situ fish multiplex imaging to do the label free fish in the in the future. That's just my my idea on on that direction. A quick comments on that. Yeah.",
        "speaking duration": 45,
        "nods_others": 0,
        "smile_self": 75.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "75:26",
        "end_time": "76:11",
        "annotations": {
            "codes": [
                {
                    "code_name": "propose idea",
                    "definition": "The speaker suggests a new plan or method for approaching a problem or topic of discussion.",
                    "justification": "The speaker proposes combining 'hyper spectrum Raman imaging' with 'RNA in situ fish for spatial information' to validate metabolic activity mapping. Evidence: 'Just just idea that how we can combine the hyper spectrum Raman imaging uh since we just discussed that each pixel will be belong to a certain molecule uh that is the metabolic actually the mapping the metabolic activity.'"
                },
                {
                    "code_name": "build on previous discussion",
                    "definition": "The speaker references or builds upon a previous topic or discussion point.",
                    "justification": "The speaker mentions 'since we just discussed that each pixel will be belong to a certain molecule,' indicating they are building on a previous discussion. Evidence: 'since we just discussed that each pixel will be belong to a certain molecule'"
                },
                {
                    "code_name": "suggest future action",
                    "definition": "The speaker suggests a potential future action or direction for research or collaboration.",
                    "justification": "The speaker suggests validating by 'fish in situ fish multiplex imaging to do the label free fish in the in the future.' Evidence: 'So we can also uh validate by the fish in situ fish multiplex imaging to do the label free fish in the in the future.'"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "06:12-06:21",
        "transcript": "Sounds like that's an idea that you guys can explore it a little bit Matt and Lingyan. that's also close in terms of collaboration for you guys.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 77.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:12",
        "end_time": "76:21",
        "annotations": {
            "codes": [
                {
                    "code_name": "suggest collaboration",
                    "definition": "Suggesting potential collaboration or teamwork between individuals or groups.",
                    "justification": "The speaker suggests that Matt and Lingyan can explore an idea together, indicating potential collaboration. Evidence: 'Sounds like that's an idea that you guys can explore it a little bit Matt and Lingyan.'"
                },
                {
                    "code_name": "facilitate discussion",
                    "definition": "Facilitating or trying to move the discussion forward.",
                    "justification": "The speaker is trying to facilitate the discussion by suggesting a potential collaboration. Evidence: 'Sounds like that's an idea that you guys can explore it a little bit Matt and Lingyan. that's also close in terms of collaboration for you guys.'"
                }
            ]
        }
    },
    {
        "speaker": "Joyoni Dey, LSU, Physics",
        "timestamp": "06:21-06:23",
        "transcript": "Yeah, USD.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:21",
        "end_time": "76:23",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "06:23-06:27",
        "transcript": "We have 30 seconds 30 seconds left.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 75.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:23",
        "end_time": "76:27",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Lingyan Shi, UCSD",
        "timestamp": "06:27-06:30",
        "transcript": "Great discussions uh everyone.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:27",
        "end_time": "76:30",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "06:30-06:34",
        "transcript": "We're counting to end it.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:30",
        "end_time": "76:34",
        "annotations": {
            "codes": [
                {
                    "code_name": "none"
                }
            ]
        }
    },
    {
        "speaker": "Jin Zhang (UCSD)",
        "timestamp": "06:37-06:40",
        "transcript": "Kristen, you have any last comment?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:37",
        "end_time": "76:40",
        "annotations": {
            "codes": [
                {
                    "code_name": "ask question",
                    "definition": "The speaker is asking another person if they have any final comments or thoughts.",
                    "justification": "The utterance ends with '?', indicating a question, and the phrase 'any last comment' suggests the speaker is soliciting input. Evidence: 'Kristen, you have any last comment?'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "06:40-06:47",
        "transcript": "No, I'm trying to squeeze all of our discussion into our box on the on the presentation.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 57.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:40",
        "end_time": "76:47",
        "annotations": {
            "codes": [
                {
                    "code_name": "manage discussion",
                    "definition": "The speaker is indicating an effort to organize or fit discussion points into a limited space or format, in this case, a presentation.",
                    "justification": "The utterance 'I'm trying to squeeze all of our discussion into our box on the on the presentation' directly shows this effort."
                },
                {
                    "code_name": "acknowledge limitation",
                    "definition": "The speaker acknowledges a constraint or limitation, in this case, space or time in the presentation.",
                    "justification": "The need to 'squeeze' implies there's a limitation in how much can be included."
                }
            ]
        }
    },
    {
        "speaker": "Matt Lovett-Barron, UCSD",
        "timestamp": "06:47-06:52",
        "transcript": "Thank you. Please feel free to cut some things out and I'll just I'll I'll read from the breakout room doc. So.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:47",
        "end_time": "76:52",
        "annotations": {
            "codes": [
                {
                    "code_name": "acknowledge",
                    "definition": "Expressing gratitude or acknowledgment of others' work.",
                    "justification": "The speaker says 'Thank you' to acknowledge the previous speakers. "
                },
                {
                    "code_name": "offer_solution",
                    "definition": "Providing a solution or suggestion to a problem.",
                    "justification": "The speaker suggests that others can 'cut some things out' and offers to read from a document, showing a willingness to adapt and find a solution. Exact quote: 'Please feel free to cut some things out and I'll just I'll I'll read from the breakout room doc.'"
                }
            ]
        }
    },
    {
        "speaker": "Kristen Maitland (Texas A&M)",
        "timestamp": "06:52-06:54",
        "transcript": "Okay, sounds great.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a background image of the Geisel Library at UCSD. The image remains static throughout the segment.",
        "start_time": "76:52",
        "end_time": "76:54",
        "annotations": {
            "codes": [
                {
                    "code_name": "acknowledge",
                    "definition": "Acknowledge a previous statement or proposal.",
                    "justification": "The utterance 'Okay, sounds great.' acknowledges a previous statement, likely from Matt Lovett-Barron, and indicates agreement. Quote: 'Okay, sounds great.'"
                },
                {
                    "code_name": "show agreement",
                    "definition": "Indicate concurrence with a previous statement.",
                    "justification": "The utterance 'Okay, sounds great.' indicates agreement with a previous statement. Quote: 'Okay, sounds great.'"
                }
            ]
        }
    }
]