{
    "meeting_annotations": [
        {
            "speaker": "Melike Lakadamyali, UPenn",
            "timestamp": "00:00-00:18",
            "transcript": "interesting regions within your sample um that uh are are are actually interesting to further look at higher resolution sort of zoom up to those and do that in a fully automated way uh with a sort of intelligent type microscope. Um so those are my thoughts.",
            "speaking duration": 18,
            "nods_others": 2,
            "smile_self": 11,
            "smile_other": 22,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "00:18-00:23",
            "transcript": "Great, thank you. Vivian?",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 20,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Vivian Qian Liu, McGill",
            "timestamp": "00:24-03:11",
            "transcript": "Hello, uh I'm Vivian Liu. I'm from McGill University. Uh I'm at uh Institute of Cancer Technology and the McGill Center forology. I was trained as a molecularologist and uh worked in a biophysical lab on super resolution imaging on virus host interactions. So my lab uh I built a single molecule of polarization microscope to look at uh virus uh life cycle. Uh so far I have um so one of my question is uh when the virus replicates on the ER structure close to the nuclei uh nuclei and we uh by so our super resolution microscopy lose the ability to uh resolve those uh replication complex uh in 3D. So we can only do kind of turf. Uh so I'm hoping that uh if there's some methods that we can we can we can we can uh see those very small structures deep in the cell uh with high contrast. So I know that there are tradeoffs between um spatial resolution and the photo uh phototoxicity and as well as the floor for um you know, photon budget. So I think maybe a new floor for um uh that would be helpful and also uh adaptive imaging, for example, that you only uh activate the floor for that on your focal point will all the others uh you do not activate. So that's uh some uh some thoughts I have. Uh and also I am uh uh I really like to look at the dynamics of the virus moving um on the surface of the cells or moving from the inside to the out of the cells. So uh the challenge in here would be the temporal resolution. So um so far we use uh millisecond resolution to track the viruses, but I think there are some very tiny or detailed movements of these virus on the cell surface before they enter or before they enter the cells. So uh and also because virus are so small, they're like 100 to between 100 to 200 nanometers. So then that will require uh high spatial and temporal resolution to resolve those questions. So those are my thoughts on that.",
            "speaking duration": 167,
            "nods_others": 0,
            "smile_self": 1,
            "smile_other": 1,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "03:11-03:12",
            "transcript": "Great, thank you very much.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "03:12-03:15",
            "transcript": "Okay, Matt.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matt Lovett-Barron, UCSD",
            "timestamp": "03:15-05:12",
            "transcript": "Hi, Matt Love Baron. I'm in neurobiology at UC San Diego and in my lab uh we're really interested in how neural activity across the brain uh generates behaviors. And so I use microscopy because it's a great system to observe neural activity and I use small transgenic or small transparent fish species so that we can observe activity across the brain and uh without any kind of surgery using uh fluorescent sensors of neural activity like voltage or calcium. And one thing that I think is really important that neuroscience in general is trying to get at is how to link multiple levels of uh looking at the brain such as looking at the activity or the anatomy or what cells are connected to each other or what genes they express. And it's difficult to look at all these with the same method. So I've, you know, worked on some uh approaches to try and register different types of data together so we can look at the same cells under different conditions where we'll look at live uh neural activity imaging in an animal that's behaving and then we take the same animal, we fix it and we do, you know, multiple rounds of in situ hybridization to look at the genes expressed in those same cells using image registration to merge our live brain onto the fixed brain. And I'm really interested in kind of pushing that forward and seeing how many different types of data of imaging data we can merge together to try and link some of these different temporal and spatial domains. So using the tradeoffs of different types of microscopy in live tissue versus say fixed tissue where we can zoom in a lot more and look at, you know, single molecule gene expression and so forth. And so I'm I'm interested to see what what sorts of um imaging modalities we can apply to look at these other levels of organization in the brain and and what sorts of uh registration approaches would be best to merge very different types of data.",
            "speaking duration": 117,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "05:12-05:14",
            "transcript": "Great, thank you.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "05:14-05:16",
            "transcript": "Aseema?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Mohanty, Tufts U. (she/her)",
            "timestamp": "05:16-06:30",
            "transcript": "Hi everyone. Um I'm Aseema Mohanty. I'm an assistant professor at Toughs. Um just started this year um in the electrical engineering department and um I work on nanonics, so chip scale optical devices. And um a lot of my work focuses on how do we manipulate light in 3D from a chip. Um so uh what I've kind of primarily been using this for is um in implantable neural probes for optogenetic neural stimulation. And a lot of our problem is the same as what uh Matt said um is reaching across, you know, multiple different regions of the brain but being able to do high resolution stimulation um for optogenetics.",
            "speaking duration": 74,
            "nods_others": 0,
            "smile_self": 12,
            "smile_other": 12,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Mohanty, Tufts U. (she/her)",
            "timestamp": "06:30-06:31",
            "transcript": "Great.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "06:31-06:32",
            "transcript": "Thank you.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "06:32-06:34",
            "transcript": "Mimi?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Mimi Sammarco, Tulane",
            "timestamp": "06:35-08:07",
            "transcript": "I'm Mimi Smarco and I'm at T School of Medicine in New Orleans. I work um in the Department of Surgery and my field is um skeletal regeneration. Um we work in an adult model um and so a lot of what we do is sort of trying to overcome these phase specific um stages that you have where one is soft tissue and then that eventually develops into bone. Um so the imaging techniques um that we have to use are often really challenging. Um my lab specifically looks or has recently started to look at the effects of cell metabolism and how that actually drives um skeletal regeneration. Currently um it's fairly difficult to look at that in terms of we just started looking in terms of spatial transcriptomics and then um high plex proteomics, but really what you're looking at is um, you know, transcript before the enzyme or protein but not knowing if the enzyme is active. And so trying to look at different ways beyond Seahorse analytics, which is going to be an ex vivo analysis, um both spatially and over time in vivo would be incredibly useful to the field. Um and I think it would probably hold a lot of answers. So I'm really just here to see again what sort of imaging modalities which I think somebody else mentioned can be applied to the field. Um so looking at sort of what's here in these sorts of forums and then applying them back to my field.",
            "speaking duration": 92,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "08:07-08:09",
            "transcript": "Great, thank you.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland (Texas A&M)",
            "timestamp": "08:09-08:10",
            "transcript": "Doug?",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}