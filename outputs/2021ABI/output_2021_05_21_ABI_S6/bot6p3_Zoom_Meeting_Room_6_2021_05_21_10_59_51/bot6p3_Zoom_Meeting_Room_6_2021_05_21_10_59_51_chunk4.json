{
    "meeting_annotations": [
        {
            "speaker": "Allison Dennis (she/her)",
            "timestamp": "00:01-00:40",
            "transcript": "Uh I think one of the things that I uh heard yesterday that was really exciting to me was the um idea of combining aspects of the contrast agents in order to use uh genetically encoded elements to make sure that they're local to the cells that you're interested in. And of course, you know, in that context we're talking about pre clinical applications which uh you know, seems obvious, although it also occurs to me with the MRNA vaccines, does that not mean that we could make luciferase in people in theory if that were ever something that somebody wanted. I, you know, I don't I don't know, but um, you know, ethically or clinically. But um, this one one of the things",
            "speaking duration": 39,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Allison Dennis (she/her)",
            "timestamp": "00:40-01:24",
            "transcript": "we were talking about thinking of luciferase was you can have a set of cells that is expressing the luciferase we're excited about swear imaging and so the contrast agents you only see the swear emission from the contrast agents that are you know, adjacent to the the cells that are the cells of interest. And so with with specificity, you know, it could be that the contrast agent is actually effectively targeted where it's supposed to go, which would be ideal. Um, but the other half of it is that you if you only see some portion of the contrast agent, is that good enough? What is the you know, when does the off target contrast agent become a problem?",
            "speaking duration": 44,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Allison Dennis (she/her)",
            "timestamp": "01:24-01:25",
            "transcript": "Um",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Yevgenia Kozorovitskiy",
            "timestamp": "01:26-02:34",
            "transcript": "Since since Dylan isn't here, uh I just want to reinforce your point, Allison. I think the uh taking advantage of the exquisite our exquisite ability to express any protein in one of thousands of subsets uh of for example, neurons or other cell types, particularly in models like mice that are very broadly used. We can do anything now. We can, you know, turn on some particular uh gene on the basis of specific activity patterns and activation of transcription uh factors or some particular genetic and morphological and functional identity. And I think at the end of the day, right, some of the small molecule and nanoparticle approaches uh have opportunities for sensing that cannot be beat by genetically full genetically encoded probes. So this combination of a kind of a chemogenetic approach, I think is really, really significant and there's very creative work to be done in that area and it's only relatively recently been kind of tapped in over the last five years, I would say or so.",
            "speaking duration": 68,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Brad Smith, Notre Dame",
            "timestamp": "02:34-02:46",
            "transcript": "Genia, can you talk you do brain imaging. So so what what would be you you're working with model systems. for example, you don't you don't use this clearing technology or anything like that, do you? Or do you do living animals?",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Yevgenia Kozorovitskiy",
            "timestamp": "02:46-03:41",
            "transcript": "Uh, we do living animals. We do brain a lot of work that we do actually is in the brain slice, which has a kind of a combination of partially preserved circuit, but considerable access including for small molecule dye. And in fact, we also use photoactivatable uh agents as well where we make cleave off some tail on the molecule to make it, let's say selectively activate a single synapse. I think there's significant opportunity for kind of any sort of sensing that neurons do. And of course, neurons sense a very broad variety of, you know, fast neurotransmitters and also different kinds of neuromodulators. Um, there's very interesting questions in the space of sort of neuron interactions that I think uh one can explore uh potentially using some new types of probes as well. But essentially it's almost completely untapped. We don't really have chemogenetic small molecule sensors for essentially anything.",
            "speaking duration": 55,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Yevgenia Kozorovitskiy",
            "timestamp": "03:41-03:42",
            "transcript": "We have now is a little bit of a start of kind of work uh with directing some fluorescent dyes uh so I think",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Mini Das (U. Houston)",
            "timestamp": "04:10-05:25",
            "transcript": "I want to sort of drive the conversation a little bit uh to what we talked earlier, I think Dylan uh and Matt about um can we use multiple modalities um to generate contrast and think about relevant contrast agents. So photoacoustics is a really good example. You have light coming in and uh pressure waves are generated and which gets detected. Now if you think about uh suppose we could think about contrast agents that would tag to something and for example, create higher pressure wave uh with photon photo uh incidence. That's very interesting. I I would be interested in thinking about those kind of combinations uh where contrast agent",
            "speaking duration": 75,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Mini Das (U. Houston)",
            "timestamp": "05:25-05:37",
            "transcript": "uh is not not specifically for one modality but results from multiple modalities being used together. If anyone has thoughts on that, for example, thermal emission generation, uh it could be um related to magnetic you know, MRI.",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Brad Smith, Notre Dame",
            "timestamp": "05:38-06:39",
            "transcript": "Well I thank you uh you raised this is one of the real strengths of nanoparticles is that you can pack a lot of different things in and then you can also potentially pack therapeutics in there as well. So these are all the strengths. nanoparticles have obviously weaknesses sometimes because their size can get in the way, they can have their own kinetic properties or something like this. But but if you come back to that multimodality strength, then the question sort of becomes what are the things to match. So X-ray contrast agents are inherently insensitive. So you know, fluorescence or or a pet spec system incredibly sensitive.",
            "speaking duration": 61,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Brad Smith, Notre Dame",
            "timestamp": "06:39-06:40",
            "transcript": "Um",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Mini Das (U. Houston)",
            "timestamp": "06:40-07:34",
            "transcript": "So the X-ray fluorescence for example, uh we could think about materials that would emit some fluorescence in slightly lower energy but they're still in the X-ray regime uh because of the where the binding energies are. so you could think about exciting with some higher X-ray energy and emission is in slightly lower energy. But if you push it further down, uh it could be in a different regime and I don't know, I have no idea how one would make go about this. I'm just giving some ideas for people who know how to make materials. Uh on the other hand, I think well if you're in your excitement is in the X-ray regime, well you're you still have ionization. So one of the, you know, interest is in staying away from that.",
            "speaking duration": 54,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Yevgenia Kozorovitskiy",
            "timestamp": "07:34-08:28",
            "transcript": "I feel like multimodal imaging needs to be have a really clear justification because first of all, on the hardware side, if it's made to be some simultaneous, that's as someone that builds hardware, like that's a pretty tough problem for many kinds of combination of imaging modalities. So you need a really, really good question to motivate solving that problem. I mean, one way that's a little bit simpler conceptual, I guess is if you have the same probes, you can use for example, like X-ray fluorescence as a ground truth read out at the end stage of an experiment where you may have some kind of a temporal uh imaging or sensing ability over a time course. So and then you can kind of ground truth it at the end. So those combinations I think uh are probably a little bit simpler and easier to justify uh building those kinds of contrast agents.",
            "speaking duration": 54,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Girgis Obaid | UT Dallas",
            "timestamp": "08:28-08:29",
            "transcript": "I completely agree with you.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Fanny Chapelin, UKentucky",
            "timestamp": "08:31-08:31",
            "transcript": "Sorry, yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Girgis Obaid | UT Dallas",
            "timestamp": "08:31-08:31",
            "transcript": "Sorry, go ahead.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Fanny Chapelin, UKentucky",
            "timestamp": "08:32-09:00",
            "transcript": "Sorry, yeah, I completely agree with you. Multimodal is not really useful if you're sending the same nanoparticle in the same place uh to interrogate the same phenomenon. Um, having two two modalities to measure the same information is is not really productive. To me multimodal makes sense only if you have really two sort of different targets in uh in a given area to see their interaction or such things.",
            "speaking duration": 28,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Girgis Obaid | UT Dallas",
            "timestamp": "09:00-09:02",
            "transcript": "100% agree, 100% agree.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Girgis Obaid | UT Dallas",
            "timestamp": "09:02-09:03",
            "transcript": "But I think what Mini's referring to",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}