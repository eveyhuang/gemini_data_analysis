```json
{
  "meeting_annotations": [
    {
      "speaker": "Gokul Upadhyayula",
      "timestamp": "00:00-00:31",
      "transcript": "very dense network of of objects that we've detected and be able to assign, you know, the trajectories for merges or splits and things like that. The biggest challenge I think uh for tracking in a label free setting is being able to identify the object. To be able to segment the object first, to be able to classify the object because again it's a label free setting, right? So that means that you're picking up lots of uh non specific um um uh changes um within your detection or imaging method.",
      "speaking duration": 31,
      "nods_others": 0,
      "smile_self": 10,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Gokul Upadhyayula",
      "timestamp": "00:31-01:33",
      "transcript": "Um and then uh the other uh okay I just kind of noted down a couple of other points, right? Which is okay, well are we doing this in two dimensions or three dimensions because obviously the problem is much easier in three dimensions than it is in two dimensions. Um and what happens uh when you are using whatever modality you're using to to detect the object which changes um potentially the um uh it it's properties which now does not allow you to be able to record it. So for example when you're doing like QPI or some sort of phase imaging, you know, it's tracking the refractive index changes um in these in these images, but um uh even though the object is present, but it changes its kind of uh physical like bending properties, you're no longer able to detect it from a uh label free context. So how do you deal with these kinds of problems, right? So um yeah, so those are my general thoughts and and happy to kind of um uh work through and refine some of these things with you guys.",
      "speaking duration": 62,
      "nods_others": 0,
      "smile_self": 10,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "Raising Hand",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Melike Lakadamyali",
      "timestamp": "01:33-02:48",
      "transcript": "Yeah, I mean I see label free imaging as as a possibility if you're if you're trying to track things that are organelles or you know, larger structures within cells that are detectable and identifiable with label free methods. Um some of the questions that I'm most interested in involve tracking individual proteins, right? So when it comes to tracking individual proteins inside cells, how do you do that in a label free way? Um and and you know, have enough contrast or molecular specificity, how do you know which protein you're tracking? Uh even if you had the contrast, I think is the big challenge. Um but I I mean I just want to kind of maybe pull people about how perturbative do people think is labeling? Um is it really that big of a problem? I mean, Jin showed beautiful examples of, you know, biosensors that you all kinds of amazing information um about activity of um enzymes inside cells. Um uh and and we're using this type of modalities to to extract a lot of really, you know, uh deep information. Is it really that big of a problem the labeling?",
      "speaking duration": 75,
      "nods_others": 0,
      "smile_self": 20,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Nick Galati",
      "timestamp": "02:50-03:51",
      "transcript": "Yeah, I've always wondered and I don't know if this exists, but combining, I mean, you could probably really reduce the amount of light. I I agree with you. I don't see a way because I do single protein imaging as well and I I can't conceptualize how to do that without labeling. So it's just something that I can't envision. But with something like QPI, I mean, can you combine QPI with, you know, some of these new more sensitive reporters and just really go very, very low on the fluorescent side. So go low excitation, very, very fast detection times and then combine the QPI readout with fluorescence to facilitate some of these things. So it's not really getting rid of labeling, it's just really minimizing labeling.",
      "speaking duration": 61,
      "nods_others": 0,
      "smile_self": 10,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "Open Palms",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Nick Galati",
      "timestamp": "03:51-04:11",
      "transcript": "Um, and the other thing I I I I I I just I don't have the computational brain to think about it, but I see particle tracking going down the path of like the genome sciences where it's like, okay, first we, you know, we sequence one gene and now we sequence everything and we wind up with these huge data sets, how do you ever infer that two different networks of particles are interacting with one another or constraining the movement of one another? Um, because you know, you have a homogeneous population of like this is all the GFP particles and they're all moving and we get beautiful tracks.",
      "speaking duration": 20,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "Open Palms",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Melike Lakadamyali",
      "timestamp": "04:12-05:14",
      "transcript": "Yeah, I agree with you on that. I was actually thinking about when Gokul mentioned AI based, you know, high density tracking. I feel like and this was one of the original questions I think in the PowerPoint, how do how many things do we need to track to be able to, you know, extract information about interactions. But the challenge there is again, I'm thinking from like the bias of tracking individual proteins, um this relies on sparse labeling. So you're labeling maybe 1% of the proteins that you're tracking. Um and then you label 1% of one protein in red and 1% of another protein in green, even if they're interacting, how do you really know they're interacting if you only label 1% of each um population.",
      "speaking duration": 62,
      "nods_others": 0,
      "smile_self": 10,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Melike Lakadamyali",
      "timestamp": "05:14-05:15",
      "transcript": "Um",
      "speaking duration": 1,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Yevgenia/Genia Kozorovitsky",
      "timestamp": "05:16-06:04",
      "transcript": "Building upon what uh Melika said, I think this question of real time analysis is really important, right? And it also may allow if you're able, it may solve some of Catherine's problems, I think, because if you are able to identify interesting interactions efficiently using some kind of uh you know, less perturbative imaging modalities that do not bleed bleach your let's say fluorescent based probes, then you're able to kind of zoom in and track those specific things, you know, with your higher power applications.",
      "speaking duration": 48,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Gokul Upadhyayula",
      "timestamp": "06:06-06:35",
      "transcript": "The awesome part is that I feel like I really believe that we're really right now at the perfect moment in time to be able to address all of these things, right? Because over the past decades, you know, the math and the computational algorithms have have been developed and implemented and it's only recently that it's becoming more and more accessible um or accessible in the sense sense of computationally accessible to be able to do this in real time in um um in a robust way, especially the robustness comes from the fact that, you know, your algorithms may be completely tunable.",
      "speaking duration": 29,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Gokul Upadhyayula",
      "timestamp": "06:35-06:59",
      "transcript": "But when and how to tune that is basically still a human endeavor at this moment, right? And that's basically where the these massive, you know, you know, either white neural nets or deep neural nets are kind of, you know, uh basically going to make my job obsolete, I think. Well, I hope. So.",
      "speaking duration": 24,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Ellen Sletten",
      "timestamp": "07:03-08:00",
      "transcript": "Because coming back to this like do we need a label how perturbating how much perturbation is a label? I mean I'm definitely in the label camp um and you know what we're working with in terms of our floor force are really big right now and that does give us some limitations. So I do think that there is a need for how small of a label can we go and there have been some papers out about uniquely fluorescent biomolecules like really thinking about what is that autofluorescence, you know, can we you know start to decipher specific molecular identities. I think some carbohydrates in a certain orientations are going to be fluorescent.",
      "speaking duration": 57,
      "nods_others": 0,
      "smile_self": 10,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Ellen Sletten",
      "timestamp": "08:00-08:01",
      "transcript": "And",
      "speaking duration": 1,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Anna-Karin Gustavsson",
      "timestamp": "08:01-08:33",
      "transcript": "Yeah, because I feel like there's always this trade off. You want to have the label as small and you know, both the label and the floor for as small as possible and less the least perturbative as possible, but at the same time you want to have the long tracks and the bright bright labels. So like for chromatin tracking, you can, you know, consider maybe some arrays and you know, these different schemes where you have multiple floor force but for a single protein.",
      "speaking duration": 32,
      "nods_others": 0,
      "smile_self": 10,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Anna-Karin Gustavsson",
      "timestamp": "08:33-08:34",
      "transcript": "Tracking, you know, you don't want to weigh that down with a a big brick, right?",
      "speaking duration": 1,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Anna-Karin Gustavsson",
      "timestamp": "08:34-08:41",
      "transcript": "Uh that would be very perturbative to the motion. Um, so yeah, it's um other ways of thinking kind of outside of those strategies are really interesting to see, you know, how can you actually get longer tracks.",
      "speaking duration": 7,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Gokul Upadhyayula",
      "timestamp": "08:53-09:00",
      "transcript": "Uh just out of curiosity, how many of us are in the label free camp versus the label camp? Just just curious.",
      "speaking duration": 7,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Gokul Upadhyayula",
      "timestamp": "09:03-09:05",
      "transcript": "I I'm definitely for label if that.",
      "speaking duration": 2,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "Raising Hand",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Katharine White",
      "timestamp": "09:08-09:10",
      "transcript": "For label?",
      "speaking duration": 2,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Katharine White",
      "timestamp": "09:10-09:11",
      "transcript": "Do we have to be in one?",
      "speaking duration": 1,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Jin Zhang",
      "timestamp": "09:11-09:12",
      "transcript": "I mean, my opinion is is that",
      "speaking duration": 1,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    },
    {
      "speaker": "Katharine White",
      "timestamp": "09:14-09:57",
      "transcript": "The label needs to be as small as it needs to be to study the biology. And so if and it needs to be as bright as it needs to be in order for you to track whatever phenotype or whatever behavior you're you're looking for. Um, I mean, I I did my PhD in a lab that was developing new approaches to fluorescently tagging proteins inside cells and we I still remember I was presenting for my postdoc interview and I said, you know, GFP is too bulky, it's too large, it affects biology. And then, you know, later on in the day I hear, oh, we tagged it with three GFPs because it doesn't affect the protein and it's really bright and everything works. And so, you know, it needs to be as as as as good as it needs to be for the biology you're studying and so for some people label free is going to be a requirement.",
      "speaking duration": 43,
      "nods_others": 0,
      "smile_self": 0,
      "smile_other": 0,
      "distracted_others": 0,
      "hand_gesture": "None",
      "interuption": "No",
      "overlap": "No",
      "screenshare": "Yes",
      "screenshare_content": "The screen shows a document with the title \"Team 2.1: Key Questions\". The document contains a list of questions related to the project. [low confidence]"
    }
  ]
}
```