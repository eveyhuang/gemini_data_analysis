[
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:00-00:05",
        "transcript": "about 40 seconds more. So jot them down, type them.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 40,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:00",
        "end_time": "00:05",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by instructing the group to take a bit more time to jot down and type their ideas."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:54-01:24",
        "transcript": "Okay, so that was our minute of jotting down our own thoughts for use later in this conversation. So why don't we start with you've heard Sam and me tell you who we are. So maybe um and Sam, do you want to start since you oh you're going to sign off now. Okay, I just saw.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:54",
        "end_time": "01:24",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by transitioning to the next step of the conversation.",
            "encourage participation": "The speaker is inviting Sam to contribute to the conversation, encouraging participation."
        }
    },
    {
        "speaker": "Ulugbek Kamilov (WashU)",
        "timestamp": "01:25-01:31",
        "transcript": "Yes, and you can call me Beck. Uh let me change my name because they asked to put our full names there. So I put my full name.",
        "speaking duration": 6,
        "nods_others": 1,
        "smile_self": 100,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:25",
        "end_time": "01:31",
        "annotations": {
            "None": "No relevant code strongly applies to this utterance as it seems to be a personal introduction and statement about name preference."
        }
    },
    {
        "speaker": "Ulugbek Kamilov (WashU)",
        "timestamp": "01:32-02:08",
        "transcript": "Hi everyone. So I'm at Washington University in St. Louis or she, I'm in the Department of Computer Science, engineering, electrical systems engineering. Uh my focus is computational imaging, um which is essentially um with focus on biomedical imaging where um the goal is to use optimization and uh machine learning uh to process imaging data, so it's spatial temporal data. I'm pretty much modality agnostic, but I have worked with MRI, PET, uh light microscopy, fluorescence microscopy with many different modalities.",
        "speaking duration": 36,
        "nods_others": 2,
        "smile_self": 83,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:32",
        "end_time": "02:08",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise and qualifications related to computational imaging, biomedical imaging, optimization, and machine learning."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:08-02:12",
        "transcript": "Thank you. Um Ellen, I'm just going along the the squares.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 75,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:08",
        "end_time": "02:12",
        "annotations": {
            "process management": "The speaker is describing her action of going along the squares, indicating management of the meeting flow or organizing group activities."
        }
    },
    {
        "speaker": "Ellen Sletten (UCLA)",
        "timestamp": "02:13-02:38",
        "transcript": "My name is Ellen Sletten. I'm an assistant professor in chemistry and biochemistry at UCLA. Uh we work on optical imaging particularly focused on 1000 nanometers and above, so we call it the shortwave infrared, some people call it the near infrared too. Um and we've done a lot of probe development uh for this region and developed a excitation multiplexing based approach so we can do four color real time optical imaging in the mouse.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:13",
        "end_time": "02:38",
        "annotations": {
            "signal expertise": "The speaker explicitly states her own expertise and qualifications related to her work in optical imaging.",
            "develop idea": "The speaker expands on her existing introduction by detailing her work in optical imaging, including specific areas of focus and research approaches."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:38-02:40",
        "transcript": "Thank you. Candace.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:38",
        "end_time": "02:40",
        "annotations": {
            "acknowledge contribution": "Maryellen Giger is verbally recognizing someone's input.",
            "encourage participation": "By mentioning Candace, Maryellen Giger is inviting or encouraging Candace to contribute."
        }
    },
    {
        "speaker": "Candace Fleischer (Emory, she/her)",
        "timestamp": "02:41-03:01",
        "transcript": "Hi, I'm Candace Fleischer at Emory University um in Atlanta. Um my group primarily does in vivo MR spectroscopy and thermometry of the brain. Um so most of our models are in humans. We do some technical development work as well but primarily um applications of chemical and metabolic imaging in the brain.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:41",
        "end_time": "03:01",
        "annotations": {
            "signal expertise": "The speaker explicitly states their affiliation with Emory University and describes their group's focus, indicating their expertise area."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:01-03:03",
        "transcript": "Thank you. Ping.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:01",
        "end_time": "03:03",
        "annotations": {
            "acknowledge contribution": "Maryellen Giger verbally recognizes someone (Ping), which can be seen as acknowledging their presence or contribution to the conversation."
        }
    },
    {
        "speaker": "Ping Wang (MSU)",
        "timestamp": "03:05-04:07",
        "transcript": "Hi, um everyone. Uh I'm Ping Wang from uh Michigan State University. Um I was trained um as interventional radiologist and develop um interest in uh molecular imaging uh especially uh in diabetes area. Uh the research work uh in our uh lab focus on um uh using imaging method to check the uh transplanted eyelids or stem cell uh differentiate eyelid organoids for the type one diabetes. We also uh do um some work for the nano drug delivery uh targeting uh endogenous beta cells. The uh imaging modalities we uh use uh include um MRI, PET MRI, uh we use optical imaging a lot and uh uh recently we started use a new imaging modality um magnetic particle imaging. I look forward to talk to um everyone and work together on some uh great uh proposals.",
        "speaking duration": 62,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:05",
        "end_time": "04:07",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own background and expertise related to the task, detailing his training as an interventional radiologist and his interest in molecular imaging.",
            "develop idea": "The speaker elaborates on his research work and interests, providing context for potential collaboration and discussion."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:07-04:09",
        "transcript": "Thank you. Shiva.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:07",
        "end_time": "04:09",
        "annotations": {
            "acknowledge contribution": "Maryellen Giger verbally recognizes previous contributors before moving on.",
            "encourage participation": "Maryellen Giger invites Shiva to contribute by saying 'Shiva.'"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSC",
        "timestamp": "04:10-04:39",
        "transcript": "Hi, this is Shiva. I'm assistant professor in University of California, Santa Cruz. My background is electrical engineering. I do work on radiation detection for um um X-ray, CT and positron emission tomography, how to improve their time resolution, energy resolution and depth of interaction. And then I do work on signal processing to improve the um image quality.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:10",
        "end_time": "04:39",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise and qualifications related to electrical engineering and his work on radiation detection and signal processing."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:39-04:43",
        "transcript": "Thank you. Ferdinand. Uh yeah.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:39",
        "end_time": "04:43",
        "annotations": {
            "Acknowledge contribution": "Maryellen Giger verbally recognizes someone's input by saying 'Thank you'.",
            "None": "The 'Uh yeah' does not strongly fit into any category but is an acknowledgment."
        }
    },
    {
        "speaker": "Ferdinand Schweser, SUNY UB",
        "timestamp": "04:43-05:17",
        "transcript": "Uh yeah, I'm Ferdinand Schweser. Um I'm assistant professor in Department of Neurology at the University at Buffalo. But my training is in physics and uh I do I use physical models um to develop uh uh MRI methods that quantify tissue uh properties. and then we do a lot of translation of these techniques um into uh early clinical studies.",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:43",
        "end_time": "05:17",
        "annotations": {
            "develop idea": "The speaker expands on their research work, detailing the use of physical models for developing MRI methods and their translation into clinical studies."
        }
    },
    {
        "speaker": "Ferdinand Schweser, SUNY UB",
        "timestamp": "05:17-05:38",
        "transcript": "And uh my more neuroscience based research interest is in brain iron homeostasis. So I really focus on techniques that uh can specifically quantify brain iron. Uh I also have a second head I'm technical director for the imaging center um and there we develop um PET MRI hybrid techniques for pre clinical world and uh pre clinical MRI uh cell tracking and um and clinical MRI too.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:17",
        "end_time": "05:38",
        "annotations": {
            "signal expertise": "The speaker explicitly states their research focus and role, indicating their expertise.",
            "develop idea": "The speaker is elaborating on their research interests and providing more details about their work."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:39-05:41",
        "transcript": "Thank you. Anna Karen.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:39",
        "end_time": "05:41",
        "annotations": {
            "process management": "This code applies because Maryellen is managing the meeting flow by transitioning between speakers and inviting another participant to contribute.",
            "encourage participation": "This code applies as Maryellen is inviting Anna Karen to participate or share something by mentioning her name."
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson (Rice)",
        "timestamp": "05:42-06:27",
        "transcript": "So hi. Um my name is Anna Karen and I'm an assistant professor at Rice University. Um in the chemistry department there, but I have a background in physics with optics and microscopy. So in our lab we are developing um microscopy techniques when it comes to fluorescence imaging, uh single molecule tracking and super resolution imaging. and our expertise is 3D tracking, 3D super resolution imaging uh by combining point function engineering, light sheet illumination and now we're starting to implement also microfluidics in the mix as well.",
        "speaking duration": 45,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:42",
        "end_time": "06:27",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise in physics, optics, microscopy, and specific techniques like fluorescence imaging, single molecule tracking, and super resolution imaging."
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson (Rice)",
        "timestamp": "06:27-06:29",
        "transcript": "Uh so a lot of the work is on the methods development side.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:27",
        "end_time": "06:29",
        "annotations": {
            "develop idea": "The speaker is elaborating on her current work, specifically mentioning that a significant portion of it is focused on methods development."
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson (Rice)",
        "timestamp": "06:29-06:30",
        "transcript": "Um but also working on various applications.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:29",
        "end_time": "06:30",
        "annotations": {
            "develop idea": "Anna-Karin is expanding on her previous statement about developing microscopy techniques by mentioning they are also working on various applications."
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson (Rice)",
        "timestamp": "06:30-06:32",
        "transcript": "In collaboration with biologist and biomedicine.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:30",
        "end_time": "06:32",
        "annotations": {
            "develop idea": "The speaker is expanding on her existing idea about the work in her lab, specifically mentioning collaborations with biologists and biomedicine."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:32-06:33",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:32",
        "end_time": "06:33",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging the contributions (self-introductions) made by the participants."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:33-06:33",
        "transcript": "Uh uh.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:33",
        "end_time": "06:33",
        "annotations": {
            "None": "No relevant code applies to this utterance or it could be considered a minimal form of process management, but given the brevity and lack of clear intent, 'None' seems most appropriate."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "06:34-07:17",
        "transcript": "Yeah, uh but something but quick close. Um yeah, so I'm at UT Austin here. Professor in biomedical engineering and my lab works mostly on chemical imaging and non linear fluorescence. So we do a lot of vibrational scopic imaging to look at how molecules interact and how that is perturbed particularly in protein protein interactions and networks that are related to cancer for extra cellular matrices and bio polymer networks like um skeletal filaments in cells.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:34",
        "end_time": "07:17",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own expertise and qualifications related to his work in biomedical engineering and his lab's focus areas.",
            "develop idea": "The speaker is providing more details about his work, elaborating on the focus of his lab in chemical imaging and non-linear fluorescence."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "07:17-07:18",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:17",
        "end_time": "07:18",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing Maryellen Giger's introduction."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:18-07:21",
        "transcript": "And you say, did I say that right?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:18",
        "end_time": "07:21",
        "annotations": {
            "ask question": "The speaker is seeking clarification or confirmation on a previous statement, which aligns with the definition of asking a question."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "07:22-07:23",
        "transcript": "Uzay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:22",
        "end_time": "07:23",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "07:24-07:58",
        "transcript": "Thank you so much. So my name is Uzay and I'm assistant professor at the School of Health Science at University. And I'm I'm electrical engineer but I have been doing biomedical imaging since I graduated. So and I'm MRI physicist so I am developing new techniques to answer questions, biological questions that my colleagues ask and try to translate them to clinical application. It starts from bench to bedside.",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:24",
        "end_time": "07:58",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise as an electrical engineer and an MRI physicist, and their position as an assistant professor.",
            "develop idea": "The speaker elaborates on their work in biomedical imaging, specifically mentioning the development of new techniques and their application in clinical settings."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:58-08:00",
        "transcript": "Thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:58",
        "end_time": "08:00",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing another group member's input with a simple 'Thank you.'"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:00-08:01",
        "transcript": "And",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:00",
        "end_time": "08:01",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Alexandra Basford",
        "timestamp": "08:08-08:17",
        "transcript": "I I'm a guest. I'm a program officer for the and group and very excited to hear um about what is exciting and new in bioimaging. Thanks.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:08",
        "end_time": "08:17",
        "annotations": {
            "None": "No relevant code applies to this utterance as it is primarily an introduction and expression of interest rather than engaging with the meeting's content."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:17-08:18",
        "transcript": "Okay. Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:17",
        "end_time": "08:18",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:18-08:25",
        "transcript": "And we also have Ed and Megan, but we I know yesterday we didn't go through introductions if you think we should, jump in.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:18",
        "end_time": "08:25",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting that Ed and Megan introduce themselves if the group thinks it's appropriate.",
            "encourage participation": "The speaker is inviting Ed and Megan to participate by introducing themselves."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:25-08:25",
        "transcript": "Nope.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:25",
        "end_time": "08:25",
        "annotations": {
            "process management": "This code applies because Maryellen Giger is managing the meeting flow by indicating that there is no need for introductions or further action as suggested."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:25-08:26",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:25",
        "end_time": "08:26",
        "annotations": {
            "None": "No relevant code applies to this utterance as it is a minimal acknowledgment without additional content."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:26-08:45",
        "transcript": "Um uh we're going to start with some of those questions, but if you have another idea and question, we can bring that in. Also, I'm pretty excited just hearing the the mix of folks here. We go from nano to micro to macro, we're stationary, we're temporal.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:26",
        "end_time": "08:45",
        "annotations": {
            "process management": "Maryellen Giger is managing the meeting flow by suggesting they start with some questions but also leaving room for additional ideas or questions.",
            "encourage participation": "Maryellen Giger invites participants to share any additional ideas or questions they might have.",
            "summarize conversation": "Maryellen Giger reflects on the introductions, expressing excitement about the group's diverse expertise."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:45-09:21",
        "transcript": "Um so I think we've got everything covered, but since this is multimodal, let's see where we can bring these two together. Usually when I hear multimodal, I think of PET CT or PET MR, but um we can also uh my dream is to have a multimodal but across scale type imaging where you could do the nano, the micro. um and the macro. But um how about um you all the experts um comments on um what do you think is the next wave for multimodal imaging? what's your dream with it?",
        "speaking duration": 36,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:45",
        "end_time": "09:21",
        "annotations": {
            "ask question": "Requesting the experts' opinions on the future of multimodal imaging and their dreams for it."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "09:21-09:23",
        "transcript": "Uh who can I start with?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:21",
        "end_time": "09:23",
        "annotations": {
            "encourage participation": "The speaker invites others to contribute to the discussion by asking 'who can I start with?', directly encouraging participation."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "09:24-09:24",
        "transcript": "Ellen looks like she's thinking there.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:24",
        "end_time": "09:24",
        "annotations": {
            "Encourage participation": "Maryellen Giger invites Ellen to contribute her thoughts, encouraging her participation in the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:00-00:25",
        "transcript": "with the group I we did yesterday, we opened up a Google Drive and they kept notes and then condensed it down to what would go on the slide. First I have to ask, I uh no one can do that twice, so if you did it before, don't raise your hand. And do I have a volunteer? Or I'll do the Hollywood squared blinded pick like I did yesterday. Okay.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 15,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:00",
        "end_time": "10:25",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by referring to a previous activity and suggesting a method for selecting someone for a task.",
            "assign task": "The speaker is suggesting a method for selecting someone for a task, indicating an attempt to organize the group's activities.",
            "encourage participation": "The speaker is inviting someone to contribute or participate in the task by asking for a volunteer."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:26-00:28",
        "transcript": "I can volunteer actually.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:26",
        "end_time": "10:28",
        "annotations": {
            "supportive response": "The speaker is offering help in response to a request, which is a supportive action.",
            "process management": "The speaker's offer to volunteer can be seen as contributing to the management of group tasks or processes."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:29-00:34",
        "transcript": "Great. Excellent Beck. Thank you. I was just going to um",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:29",
        "end_time": "10:34",
        "annotations": {
            "acknowledge contribution": "Maryellen Giger is verbally recognizing Beck's input (volunteering).",
            "process management": "She is managing the flow of the meeting or discussion.",
            "supportive response": "Because she is expressing agreement and appreciation."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "00:34-01:56",
        "transcript": "So I guess I I just want to I just want to make a comment uh because um I've been working with uh so we we're working on this pre clinical pet MRI and uh it it maybe a little bit uh cautious comment that uh there's always the hope that if you combine multiple techniques that you gain something out of it. But uh I think the key is to have an application where you really need to do both techniques at the same time where you get something out of doing it at the at the same time. For example, pet MRI uh there are not really many applications where you actually need pet MRI. Uh many applications you can do pet and then you do an MRI after that and combining the techniques always is linked to uh or most of the time is linked to a degradation of the performance of the involved techniques. So you really need I mean, I I found it personally to very challenging to find applications. And for example, we submitted a grant uh for uh uh photoacoustic tomography to be integrated into our MRI. already have preliminary data at the time we just couldn't find uh application, killer application. The grant was not funded because they said okay what do you want to do with it? I mean why do you need it? Why can't you do it sequential? So I think that's really important.",
        "speaking duration": 82,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:34",
        "end_time": "11:56",
        "annotations": {
            "develop idea": "The speaker is elaborating on his experience and thoughts on combining multiple imaging techniques.",
            "signal expertise": "The speaker is drawing from his experience and work in the field, signaling his expertise.",
            "critical response": "The speaker is providing a critical view of combining imaging techniques without a clear need.",
            "offer feedback": "The speaker is providing his experience as feedback on the challenges of combining techniques.",
            "clarify goal": "The speaker's discussion clarifies the goals or challenges in combining imaging techniques."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:57-02:04",
        "transcript": "That's a good point. Yeah, do we start with the hammer and find the application or do we look at the problem and find the new hammer?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:57",
        "end_time": "12:04",
        "annotations": {
            "Ask question": "The speaker is explicitly seeking opinions or insights from the group on how to approach the integration of different imaging techniques.",
            "Develop idea": "The speaker is expanding on a previous comment about the challenges of integrating multiple techniques by posing a fundamental question about the approach to research in this area."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "02:04-02:29",
        "transcript": "I very much agree with that. also I spend some time also in the super resolution thing as well and had a fair number of heated arguments with people who are really serious in that field about what are you doing, what are you learning? and same with my field often wondering like, you know, is the western blot enough or do you really need the sub cellular resolution that I'm providing you? You know, and I think that's a I struggle with that question a lot when I'm writing grants.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:04",
        "end_time": "12:29",
        "annotations": {
            "supportive response": "The speaker expresses agreement with a previous statement.",
            "identify gap": "The speaker recognizes challenges and questions the necessity of certain techniques in their field.",
            "develop idea": "The speaker expands on their perspective by sharing personal experiences and thoughts about their field."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "02:30-03:00",
        "transcript": "I I mean in case of pet MR though, I would say that there is a the big benefit of having uh them together is the co registration and that's going to be in multi modality that's going to be a problem that we're going to hit each time, especially when they're close close resolution instruments rather than, you know, super resolution microscopy versus MRI thing, right?",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:30",
        "end_time": "13:00",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of combining PET and MR imaging techniques by highlighting the benefit of co-registration.",
            "offer feedback": "The speaker is providing feedback on the concept of multi-modality imaging, discussing potential challenges and benefits."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "03:01-03:03",
        "transcript": "Yeah, that's a killer application, right? cardiac cardiac uh where you have movement.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:01",
        "end_time": "13:03",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement with a previous statement, supporting the idea of a specific application being a 'killer application' for cardiac imaging where movement is a factor."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:04-03:13",
        "transcript": "Exactly. So there are kind of killer apps for those where you can actually, you know, use MR for guiding pet, but not like joint fusion or something. Yeah.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:04",
        "end_time": "13:13",
        "annotations": {
            "Develop idea": "The speaker is expanding on the idea of using MRI for guiding PET, providing specific examples of applications.",
            "Offer feedback": "The speaker is offering insights into the applications and potential limitations of combining MRI and PET."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "03:14-03:42",
        "transcript": "Yeah. but billions went into the development of the technology. You have to pay $7 million or something to get such a technology and then the only application that you find is uh cardiac triggering basically or I mean I I'm there are not so many applications actually where it's essential. And and if you just think uh motion correction is the application for pet MRI, okay, maybe, but I think when people started integrating the technology, they had much higher hopes for it.",
        "speaking duration": 28,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:14",
        "end_time": "13:42",
        "annotations": {
            "Critical response": "The speaker is questioning and providing a negative evaluation of the technology's applications.",
            "Identify gap": "The speaker mentions that there are not many applications where the technology is essential.",
            "Offer feedback": "The speaker is providing their opinion on the technology's limitations and applications."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:43-03:45",
        "transcript": "So would you have to ask um",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:43",
        "end_time": "13:45",
        "annotations": {
            "process management": "The speaker is managing the conversation flow by prompting further discussion or clarification."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "03:45-03:47",
        "transcript": "I just want to add I just want to um some disc discussions.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:45",
        "end_time": "13:47",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "03:47-04:46",
        "transcript": "Um, I I do think there's uh applications. The bottleneck uh for pet MRI is um people use it like a sequential uh scanning because there's no uh probes actually can be detected simultaneously from pet and MRI. That's a problem. Uh, for the pet MRI because uh people put them together uh just because they're complimentary to each other. MRI has very high special resolution.",
        "speaking duration": 59,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:47",
        "end_time": "14:46",
        "annotations": {
            "develop idea": "Ping Wang is expanding on the existing ideas about PET MRI by discussing its limitations and challenges.",
            "identify gap": "Ping Wang explicitly identifies a gap in the current use of PET MRI, which is the lack of probes for simultaneous detection."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "04:46-04:46",
        "transcript": "Oh sorry.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:46",
        "end_time": "14:46",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "04:47-04:48",
        "transcript": "can I uh sorry.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:47",
        "end_time": "14:48",
        "annotations": {
            "process management": "The speaker is attempting to manage the conversation flow by seeking permission to speak."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:49-04:53",
        "transcript": "Yes. And I just want to make sure Beck is um getting all this down Beck. I don't know if you want to go open up",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:49",
        "end_time": "14:53",
        "annotations": {
            "process management": "The speaker is ensuring that Beck is capturing all the discussion points, managing the meeting's information flow."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:54-04:56",
        "transcript": "you guys want me to share the screen? I can share.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:54",
        "end_time": "14:56",
        "annotations": {
            "process management": "The speaker is offering to share his screen, which relates to managing how information is shared during the meeting.",
            "encourage participation": "The speaker asks for the group's preference, inviting their input."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:57-05:03",
        "transcript": "If you open you could are you type what are you typing into? Here. A Google Doc. Okay.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:57",
        "end_time": "15:03",
        "annotations": {
            "process management": "The speaker is asking about the process of sharing and working on a Google Doc, which involves managing how the group collaborates on a document."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:03-05:03",
        "transcript": "Here.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:03",
        "end_time": "15:03",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "05:04-05:07",
        "transcript": "I I just want I haven't finished. I'm sorry.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:04",
        "end_time": "15:07",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:07-05:07",
        "transcript": "Oh sorry.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:07",
        "end_time": "15:07",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:09-05:16",
        "transcript": "So we're going to get right back to you Ping but maybe Beck if you can share the link to the Google Drive and that way people can add stuff.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:09",
        "end_time": "15:16",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by instructing Beck to share the Google Drive link.",
            "encourage participation": "By asking Beck to share the link to the Google Drive, the speaker is enabling everyone to contribute by adding stuff."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:17-05:17",
        "transcript": "Yeah, definitely.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:17",
        "end_time": "15:17",
        "annotations": {
            "None": "No relevant code directly applies to this utterance as it's a simple agreement without adding content."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:18-05:28",
        "transcript": "Okay. Does that sound good? All right. And that way you don't have to share it because it's it I think it's harder to see but I can crunch up all of you on one side of my screen and open up the Google Drive.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:18",
        "end_time": "15:28",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting a way to share information and adjust the screen layout for better visibility."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "05:28-05:30",
        "transcript": "Should I go back?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:28",
        "end_time": "15:30",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on whether they should go back, indicating a need for guidance on their participation."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:31-05:34",
        "transcript": "Yes, put in yeah, if you put the link in the chat, that's probably easiest.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:31",
        "end_time": "15:34",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by instructing on how to share information efficiently."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:35-05:40",
        "transcript": "Thank you. And Ping we didn't forget about you. We're going back to you right now but I just needed to do some logistics. Okay.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:35",
        "end_time": "15:40",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by addressing the group, ensuring continuity of discussion, and handling logistical tasks before proceeding."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "05:41-07:01",
        "transcript": "Yeah, um for example for the cell transplantation and the nano drug delivery, we do need uh like uh for beta cell endogenous beta cell uh targeted uh drug delivery. We do need the high resolution. Also we want to have the higher uh sensitivity to detect the nano drugs and especially for the endogenous beta cells like only 2%, less than 2% of the whole uh pancreatic pancreatic tissue. So the problem now is like probably I think the chemist need to like work more on the synthesize and design for the nano particle or whatever probes or tracers, uh you can put together uh and can be detected by by both like MRI and pet. Now, um for example, we're trying to uh label the cells for the MRI and pet. I I work on the pre clinical uh scanner for pet MRI uh for tracing the tracking the cells. We give you an example, we label the cells with iron oxide nano particle, so it can can be detected by MRI. Um, we're trying to uh like also put some radio labeling on the nano particle or just direct label the cells. But it's kind of difficult um because because the pet um uh the the the the I mean the the limitation for the half lifetime also uh for the for the labeling uh because because um I mean that's some problem uh for the chemist. I do think there's applications and I I agree uh um for some comments uh it's it's very expensive if just use it for diagnosis uh in clinic. I mean, um people will just say why why don't you do the sequential scanning? What's the point to do it simultaneously? If you can co co register the images together anyway. Yeah.",
        "speaking duration": 80,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "15:41",
        "end_time": "17:01",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of using PET MRI for medical applications, discussing challenges and potential uses.",
            "identify gap": "The speaker highlights the need for better probes or tracers that can be detected by both MRI and PET.",
            "offer feedback": "The speaker provides insights into the challenges faced in labeling cells for MRI and PET and the limitations of current technology."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "07:01-07:01",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "17:01",
        "end_time": "17:01",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or validation with what was previously said."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "07:01-07:01",
        "transcript": "Yes.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "17:01",
        "end_time": "17:01",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:01-07:01",
        "transcript": "What?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "17:01",
        "end_time": "17:01",
        "annotations": {
            "ask question": "Maryellen Giger is seeking information or clarification as indicated by her question 'What?'."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "07:01-07:02",
        "transcript": "Yes.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "17:01",
        "end_time": "17:02",
        "annotations": {
            "supportive response": "The utterance 'Uzay Emir: Yes.' is a supportive response as it expresses agreement or validation."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "07:02-08:44",
        "transcript": "Thank you so much. So um I think I I was in a optical group yesterday and I was at the microscopic level imaging person and I couldn't find a channel to intervene to discussions here. I we do have the optical people. I think we are talking in the microscopic level and they might have the same problem. So I think we should try to think uh my mentor was always saying how we are going to do this mesoscopic scale to microscopic scale translation. So I think that is that is the even though we are doing MRI, we are far from anything that is come to the neurons and it cellular level. So they are indirect measurements at the end of the day, we will be far from anything that underlying physiology or what is happening in the cellular level. So that is going to be the eventual consequence of using MRI, pet and all those things. Yes, they are powerful, they are clinically useful, but uh we need to try to make the bridge between the very high resolution between the uh microscopic measurements that we do with the MRI. So the way how I do see that for example, try to use the optical imaging that might be so if we are going to think about the multi modality, we should do um small animal models and that we can try to figure out that for example, optical contrast that might generate us different contrast with MRI and and then we can use it to pinpoint the problems that we are looking for. For example, we can do I don't know so the iron they they cause scattering in optical imaging and they use this for example, we can inject those iron into the animal and try to use that iron contrast in the MRI modality and see what it is causing because all entire functional MRI is relying on uh paramagnetic effects of the deoxyhemoglobin which is very strictly iron contrast. So maybe we can amplify the uh signal intensity using this iron of the creative or insanity ideas so",
        "speaking duration": 102,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "17:02",
        "end_time": "18:44",
        "annotations": {
            "propose new idea": "The speaker proposes using small animal models and optical contrast agents that could also provide contrast in MRI, introducing a new approach.",
            "develop idea": "The speaker expands on existing ideas by suggesting the use of optical imaging and iron contrast in MRI for multi-modality imaging."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:44-08:45",
        "transcript": "So we",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
        "start_time": "18:44",
        "end_time": "18:45",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:40",
        "transcript": "of going from the nano to the micro to the macro. the other thing is seems to be we first need to identify some major use cases, some major problems that would benefit from going through the scales and then we have to ask the question, do we need to worry about spatial registration and temporal registration and how does that complicate it. So I'm thinking where in this Candace, do you see um uh your work fitting and where might it be expanded um if you had this capability.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:40",
        "annotations": {
            "develop idea": "The speaker is elaborating on the concept of multiscale imaging, discussing its potential and challenges.",
            "ask question": "The speaker asks Candace about her work and how it might fit into the multiscale imaging approach.",
            "encourage participation": "The speaker directly asks Candace for her thoughts, inviting her participation."
        }
    },
    {
        "speaker": "Candace Fleischer (Emory, she/her)",
        "timestamp": "00:40-02:30",
        "transcript": "Yeah, I guess um, I'm not sure about my specific work, but when I think of really big challenges in the field, um, I think of like just huge things, like if we could fix tomorrow we'd change medicine. So, you know, why why is medicine still not personalized? Why do we throw the same hammer at every patient and hope that we'll get something. And then related to that, we do so much imaging, especially in the clinical setting where we do, let's say we do a CT and we're like we're not sure, we better go back and do an MRI, we're not sure, maybe we need an intervention, we need to go back again. And related to that, we have a lot of data in in the clinical case that we throw away. So if we think about complementary imaging, um, you know, if I'm thinking of like huge ideas, what if we had every technique in a single instrument and we sample everything sparsely, so we take, you know, micro scale, nano scale, fluorescence, optical, whatever whatever your favorite technique is in in a modular way and we never needed to throw away data and if the MRI wasn't successful, we also had sparse CT data or we had sparse optical fluorescence data on the cellular level. And I guess it's not particularly, I mean it's related to what I do in in a clinical setting, but I think I think that's what I think of the big problem is we do so much extremely expensive, like prohibitively expensive imaging and we don't even get what we want most of the time and we don't even get cellular or microscopic data on what's actually going on in the diseases. So I I don't have a good application case, but I think if I'm thinking about big problems in the field, that those are the big problems that I see like I I wasn't sure how big we're supposed to be thinking, but if I'm thinking yeah, what do I want to push a button to change today, that would be it.",
        "speaking duration": 110,
        "nods_others": 1,
        "smile_self": 10.0,
        "smile_other": 10.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:40",
        "end_time": "22:30",
        "annotations": {
            "propose new idea": "The speaker introduces a new idea of combining multiple imaging techniques into one instrument.",
            "identify gap": "The speaker highlights the gaps in current medical practice, including the lack of personalized medicine and inefficiencies in imaging.",
            "critical response": "The speaker's comments imply criticism of current practices in a constructive manner."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:30-02:54",
        "transcript": "And I also you know, it's a minor point but using data from clinical scanners, sometimes you can't even get it because of proprietary software on that clinical scanner and if you could get to the raw data, you could do more of what you want to do. And so um uh so Ellen, what are you thinking about? I see your head shaking.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:30",
        "end_time": "22:54",
        "annotations": {
            "identify gap": "The speaker highlights a limitation in accessing clinical scanner data due to proprietary software, identifying a gap in current practice.",
            "encourage participation": "The speaker asks Ellen for her thoughts, inviting her participation and opinion."
        }
    },
    {
        "speaker": "ELLEN SLETTEN (UCLA)",
        "timestamp": "02:54-03:38",
        "transcript": "Yeah, I I really wanted to second essentially everything you said and that we have these beautiful tools to look at cellular processes and then we just really can't extend them even well into animal models. And if we could use multimodal approaches to take starting what already works so well in cells and be able to, you know, translate to mice, translate to, you know, maybe even some intermediate mammal before getting to humans. I think that that would be really impactful just from the basic science to get us to really understand molecular processes even in animal models before thinking about the clinic.",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:54",
        "end_time": "23:38",
        "annotations": {
            "supportive response": "Ellen agrees with previous statements, showing support for the ideas presented.",
            "develop idea": "She expands on the idea of using multimodal approaches for translating findings from cells to animal models, providing a specific direction for research."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:38-03:43",
        "transcript": "And I'm trying to make sure everyone has a chance to um bring their thoughts forward.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:38",
        "end_time": "23:43",
        "annotations": {
            "encourage participation": "The speaker is explicitly inviting others to contribute their thoughts and ideas, ensuring everyone has a chance to participate in the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:43-04:33",
        "transcript": "but at any of those who have already spoken, um, if you um, you know, kind of maybe use the hand or um, just start talking. But I think it's really important um to get all these aspects. I think we have key points forming. Um, uh, how about a more of a discussion on use cases? What are the use cases that, you know, let's say you someone said we'll go work on taking the molecular um cellular imaging and move it into mice. What use case pops out? What because sometimes the problem drives the next development. Um, Shiva, do you have a use case or Sampoon, what do you folks think?",
        "speaking duration": 50,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:43",
        "end_time": "24:33",
        "annotations": {
            "ask question": "She is explicitly asking for input and thoughts from the group, specifically about use cases.",
            "encourage participation": "She encourages participants to share their thoughts and ideas, using phrases like 'if you um, you know, kind of maybe use the hand or um, just start talking.'"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSC",
        "timestamp": "04:33-06:00",
        "transcript": "Uh, yeah, I totally second that that I like kind of almost every night I ask myself that why I'm doing what I'm doing because to me like working towards the problem statement especially from like for me developing hardware is really important and then like regarding that I wish that for example if I had a multimodal imaging modality that I could just like image a spiking of the neuron because you know like kind of this is like from before my father passed away like I got interested to learn about Alzheimer disease then I was like doing pit and then I was like oh maybe I should like now push the sensitivity of pit to be able to do more dynamic pits but then I was like okay still I'm not able to you know like image a spiking of the neuron and then now I'm just trying to learn about what kind of combination of other modality like I can leverage to like see how like to image functioning of the brain. So then like that that is kind of like as if a question for the group that what do you think guys if you wanted to like image a spiking of the neuron in the brain, what imaging modality or what are the combination that could be good.",
        "speaking duration": 87,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:33",
        "end_time": "26:00",
        "annotations": {
            "develop idea": "The speaker is elaborating on their personal motivation and interest in developing an imaging modality for neuronal spiking.",
            "ask question": "The speaker asks the group for their thoughts on what imaging modality or combination could be used to image neuronal spiking.",
            "encourage participation": "The speaker explicitly asks the group for their thoughts, encouraging participation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:00-06:01",
        "transcript": "Nick, that's great.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:00",
        "end_time": "26:01",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and validation for Nick's previous statement."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:01-06:02",
        "transcript": "Sorry, go ahead.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:01",
        "end_time": "26:02",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and allowing the conversation to continue, facilitating discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:02-06:05",
        "transcript": "No, no. I I'm more than happy for people to speak up.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:02",
        "end_time": "26:05",
        "annotations": {
            "supportive response": "The speaker is expressing a positive sentiment and encouraging someone to speak up.",
            "encourage participation": "The speaker is directly inviting someone to contribute to the discussion."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "06:05-06:52",
        "transcript": "I I think that the one the not necessarily exactly what I do. I mean, we do some of this, but not honestly a lot of it is I think that there's this intravital, you know, multiphoton microscopy that people do when they want to image exactly, you know, the functioning of the brain in a small animal like a a mouse or a rodent. I I I've even heard some people trying to do this now at the scale of a monkey. I don't know if somebody here is trying to do that. I don't know if they're going to get their protocol approved.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:05",
        "end_time": "26:52",
        "annotations": {
            "develop idea": "The speaker is discussing and elaborating on an existing idea related to intravital multiphoton microscopy for imaging brain function.",
            "ask question": "The speaker is asking if someone in the group is working on or planning to do this scale of imaging and if they have encountered issues with protocol approval."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "06:52-07:36",
        "transcript": "But I mean, you're always kind of limited with this sort of, let's call it a millimeter, right? Like it's not going to happen past a millimeter with visible radiation. And a millimeter is pushing it. Those are the world class research labs that can get to like 1.2 millimeters. But I think it's really hard to get that cellular level resolution at a centimeter deep and you might want to do that. Like when I think I don't know, when Candace was talking, I just had this weird, I don't know, imagination in my head where I'm like somebody on a bed and then they're in a scanner and you've got like 30 probes on them to get every sort of level of imaging that you want and how many of those are really feasible.",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:52",
        "end_time": "27:36",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes a limitation in current imaging capabilities, specifically the difficulty in achieving cellular level resolution at deeper tissue depths.",
            "critical response": "The speaker questions and provides a negative evaluation of current imaging techniques' ability to achieve certain goals, highlighting their limitations."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "07:36-07:48",
        "transcript": "Right? The clinical ones are definitely feasible because you can pay $5 million to go to a hospital tomorrow if you need to and and get imaging whether good, bad or ugly, it can be done at least.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:36",
        "end_time": "27:48",
        "annotations": {
            "supportive response": "The speaker expresses agreement that clinical imaging modalities are feasible, highlighting the role of financial resources.",
            "critical response": "The speaker also implies a critique by suggesting that feasibility is heavily dependent on financial capability, potentially limiting accessibility."
        }
    },
    {
        "speaker": "Sapun Parekh (UT Austin)",
        "timestamp": "07:48-08:48",
        "transcript": "But the optical ones I really think are challenged at that problem. We really do well at working at cover slips and single cells and subcellular things and nano domains like what Anika does and you know, so what I do, but we aren't really good at looking at really big samples. Like I got to be honest. Yeah, and can I add to Sapoon's am I pronounced right? Yeah. Okay. Um, I think I'm I'm really not limited about the resolution because right now there are laminar FMRIs they can go down to the sub millimeter resolution to get the laminar brain activation using seven Tesla scanners and it is getting very common in the occipital cortex using the advanced technology and even if you go to do even higher fields, you can reduce so there's reason uh I framed that mesoscopic to microscopic level so and at this level the functional activation can be detected from human brain is sub millimeter level. So that allows us to map the laminar levels of the brain activation.",
        "speaking duration": 60,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:48",
        "end_time": "28:48",
        "annotations": {
            "signal expertise": "The speaker is explicitly stating his own expertise and knowledge in optical imaging.",
            "develop idea": "The speaker is expanding on the idea of optical imaging's capabilities and limitations."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:00-00:25",
        "transcript": "that it is it is the it is it's providing unique opportunity to see these things at the same time with optical imaging and that provides useful information and MRI and you can pinpoint really important features together with that. So I I don't think the technical wise it is it is pretty open if we use the devices as appropriate as possible.",
        "speaking duration": 25,
        "nods_others": 1,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:25",
        "annotations": {
            "develop idea": "The speaker is elaborating on the idea of combining optical imaging and MRI, mentioning the benefits and feasibility.",
            "supportive response": "The speaker is expressing a positive view towards combining optical imaging and MRI.",
            "offer feedback": "The speaker is providing a viewpoint on the potential and feasibility of combining imaging modalities."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:25-00:26",
        "transcript": "Yeah, I would",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:25",
        "end_time": "30:26",
        "annotations": {
            "supportive response": "The utterance 'Yeah, I would' expresses agreement or validation for other group members' contributions without adding new content."
        }
    },
    {
        "speaker": "Ellen Sletten",
        "timestamp": "00:26-00:27",
        "transcript": "Anna, oh, go ahead.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:26",
        "end_time": "30:27",
        "annotations": {
            "encourage participation": "The speaker invites Anna to contribute to the discussion."
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson",
        "timestamp": "00:27-02:01",
        "transcript": "Yeah, I would like to chime in kind of coming from the other side of things, you know, going from the molecular nanoscale and our problem is really scaling up, right? How do we push that technology into tissues to make it, you know, we even starting with tissue slices from from patients from hospitals. Um, and there are a few different considerations, right? You have the scattering and the limitations from optics, you know, how how do we improve adaptive optics and combine that to be able to image with high resolution deeper and deeper into tissues. Um, and then you come to the other aspect of the field of you just, you know, becoming larger and larger when we're typically imaging a single cell, right? Even a single cell is large for us. How do you need higher throughput methods, data, you know, data analysis, online analysis to kind of zoom in on what aspects or what parts of the sample should we kind of zoom in on. Um, do you want to do tiling to really get, you know, all of it or is it enough to have other modalities guide, you know, take a close view at this particular section. So yeah, those are some thoughts, both the scaling up, high throughput, online image analysis, very fast acquisitions and data handling with the adaptive optics and really improving and pushing what can be done when it comes to how how deep, how thick can we image.",
        "speaking duration": 94,
        "nods_others": 0,
        "smile_self": 20.21,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:27",
        "end_time": "32:01",
        "annotations": {
            "identify gap": "The speaker highlights the gap in current technology for scaling up imaging from molecular nanoscale to tissues.",
            "develop idea": "The speaker is expanding on existing ideas and challenges in the field of imaging, discussing potential considerations and approaches.",
            "clarify goal": "The speaker is discussing the goals of improving imaging technology to scale up and image deeper into tissues with higher resolution."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:01-02:04",
        "transcript": "I like that I sorry.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 33.33,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:01",
        "end_time": "32:04",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or approval, indicating a positive evaluation of a previous contribution."
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson",
        "timestamp": "02:04-02:04",
        "transcript": "Yeah, please.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:04",
        "end_time": "32:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:04-02:06",
        "transcript": "in go ahead.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:04",
        "end_time": "32:06",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson",
        "timestamp": "02:07-02:28",
        "transcript": "No, yeah, it's just kind of at what point are we good enough so that we can switch over to a different modality that is better at the larger scale, right? How how far can we push it from from the smallest scale until it's good enough to kind of or that that can be guided by some other modalities.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 23.81,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:07",
        "end_time": "32:28",
        "annotations": {
            "develop idea": "The speaker is elaborating on the challenges and considerations of imaging at different scales.",
            "ask question": "The speaker is posing questions about the limitations and switchovers between different imaging modalities.",
            "clarify goal": "The speaker is discussing the goals and limitations of imaging techniques."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:28-03:25",
        "transcript": "Yeah, I think you bring up a really good point. A lot of times we look at multimodality so that we get two different two different types of characteristics say of a patient simultaneously where they're co-registered in time and and space. However, you you noted um tiling or um and we've looked at it even using AI to, you know, you find a suspicious area on at one spatial resolution, say MRI or X-ray or something, and you use AI on that to go down into your scale. So you're using either humans to go find that area or AI, but you're zooming down into the higher spatial resolution. So it's multimodality at two different scales, not simultaneous imaging, but having one guide the other. Uh I think that's that's that's one of the different ways of looking at multimodal. Are you using it simultaneously, you're using it one to get to the other. And I know Ellen has something to say.",
        "speaking duration": 57,
        "nods_others": 0,
        "smile_self": 10.53,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:28",
        "end_time": "33:25",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of multimodality and its applications.",
            "supportive response": "The speaker is providing a positive and furthering response to the discussion.",
            "summarize conversation": "The speaker is summarizing and reflecting on the conversation about multimodality."
        }
    },
    {
        "speaker": "Ellen Sletten",
        "timestamp": "03:26-04:07",
        "transcript": "Oh yeah, I was I was maybe going to make a more of a pitch for optical and I think that we can do beyond one millimeter and it's really all about kind of signal to noise and like what your background is and so thinking about imaging in regions where you have little background, thinking about, you know, probes that turn on um and you know, we haven't really talked about that that I feel like that is simplest maybe for optical, but it's definitely possible for MRI as well and you know, that will kind of been really enhance some of this sensitivity uh issues.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 12.2,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:26",
        "end_time": "34:07",
        "annotations": {
            "signal expertise": "Ellen is sharing her expertise in optical imaging.",
            "develop idea": "Ellen is expanding on the idea of using optical imaging beyond one millimeter, discussing challenges like signal-to-noise ratio and background.",
            "supportive response": "Ellen seems to be supportive of optical imaging as a method."
        }
    },
    {
        "speaker": "Ellen Sletten",
        "timestamp": "04:07-04:07",
        "transcript": "Um.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:07",
        "end_time": "34:07",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Ellen Sletten",
        "timestamp": "04:07-04:38",
        "transcript": "But in terms of what the discussion we were just having and like complementary aspects, I I think the temporal aspect of these imaging modalities is also very distinct and you know, optical is really fast and then you know, so if you wanted to look at things in in real time, you would be able to do that. Um, and then maybe if you really need better penetration at a later time point, you know, this would be another place where things like optical and MRI I think would be nice compliments.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:07",
        "end_time": "34:38",
        "annotations": {
            "Develop Idea": "Ellen discusses complementary aspects of imaging modalities, specifically how optical and MRI can be used together based on their characteristics."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:39-04:40",
        "transcript": "Can I also throw something in?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:39",
        "end_time": "34:40",
        "annotations": {
            "encourage participation": "The speaker is asking for permission to contribute to the discussion, which encourages participation."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:40-05:13",
        "transcript": "Uh I think one thing we can think about in the context of multimodality is uh so one thing we're the way we're thinking right now in this discussion is we're thinking about images, right? You get this image in very high nanoscale resolution, you get another one at millimeter scale and we're trying to bridge. Another way to think about the information content, right? Uh what I mean by this is that maybe when we work with multimodality, what we want to extract from the modalities are not necessarily images, right?",
        "speaking duration": 33,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:40",
        "end_time": "35:13",
        "annotations": {
            "develop idea": "The speaker expands on the concept of multimodality by suggesting a different perspective on approaching information content from various imaging modalities."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:13-05:46",
        "transcript": "But some kind of information that now can be correlated at a at a more abstract level. So I don't necessarily want to correlate pixels but say I want to use it for clinical diagnostics. So if I see something in a molecular level, can there be patterns that could be seen at uh say MRI level and then can we kind of bridge them at a more abstract level saying if I observe certain things.",
        "speaking duration": 33,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:13",
        "end_time": "35:46",
        "annotations": {
            "propose new idea": "The speaker introduces a new perspective on multimodality by suggesting to correlate information at a more abstract level.",
            "develop idea": "The speaker elaborates on the idea by discussing correlations between molecular and MRI levels for clinical diagnostics.",
            "offer feedback": "The speaker provides a suggestion for approaching multimodality by focusing on abstract correlations rather than direct image correlations."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:46-05:47",
        "transcript": "That's what humans do, right?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:46",
        "end_time": "35:47",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or alignment with the group's direction of thought."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:47-05:50",
        "transcript": "We look at those images and I go there is some issue.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:47",
        "end_time": "35:50",
        "annotations": {
            "Supportive response": "The speaker expresses a thought process on analyzing images to identify issues, contributing to the discussion in a supportive analytical manner."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:50-05:51",
        "transcript": "I correlated to something else there is some issue.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:50",
        "end_time": "35:51",
        "annotations": {
            "develop idea": "Beck Kamilov is expanding on the concept of correlating information from different imaging modalities to identify issues.",
            "critical response": "Beck points out that there is some issue when correlating information from different sources."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:51-05:51",
        "transcript": "And then I decide.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:51",
        "end_time": "35:51",
        "annotations": {
            "confirm decision": "The speaker concludes with 'And then I decide', indicating a decision or conclusion has been reached."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "05:51-05:55",
        "transcript": "But that's something in principle that could be done with AI ML.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:51",
        "end_time": "35:55",
        "annotations": {
            "propose new idea": "The speaker suggests using AI/ML as a potential solution."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:55-06:00",
        "transcript": "Yes, I I think it's like a third use case, general use case. I I I very very good um.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:55",
        "end_time": "36:00",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:00-06:11",
        "transcript": "you know, in fact that's I'm more of an AI imager than an imager. Um, I should say and you know, we merge.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:00",
        "end_time": "36:11",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:11-06:23",
        "transcript": "Where do you do the fusion? That's the question. Do you fuse when you're image? Do you fuse by um relating by um post imaging relating.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:11",
        "end_time": "36:23",
        "annotations": {
            "ask question": "The speaker is requesting information about the process of fusion in multimodal imaging, specifically when and how it is done."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:23-06:30",
        "transcript": "Or do you fuse at the feature level that you've brought out about something which you can do at multiple um things.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:23",
        "end_time": "36:30",
        "annotations": {
            "ask question": "The utterance explicitly asks a question about the level of data fusion, seeking clarification or information."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:30-06:31",
        "transcript": "I think um uh.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:30",
        "end_time": "36:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:31-06:33",
        "transcript": "fusion aspect might be.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:31",
        "end_time": "36:33",
        "annotations": {
            "propose new idea": "The speaker introduces the idea of considering a 'fusion aspect' in their discussion on multimodal imaging."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:33-06:34",
        "transcript": "Good to think about.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:33",
        "end_time": "36:34",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges a prior statement or idea without adding new content."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "06:34-06:35",
        "transcript": "Yeah, I think so.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:34",
        "end_time": "36:35",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous statement, which is a positive evaluation of the idea or suggestion."
        }
    },
    {
        "speaker": "Candace Fleischer",
        "timestamp": "06:41-07:48",
        "transcript": "back I really like that idea because I was going to suggest what if so we always train our AI models on our modality and then some outcome or disease or or cellular change. But what if we train our AI models using cellular or microscopic or nanoscale data to predict what we see with MR or microscopic images. So what if we actually train the models between modalities and I think that's a really broad thing. Actually that was something I would love to work on is for example, I get I I take an MRI image of a patient, then we do a biopsy. I take the sample, I send it to you, you train your image and can you predict my MR image? I think that would be a great use case. I would love to work on something like that. And I think that's really broadly impactful, right? Could we predict from what we see in the cell, which we do anyways, we do pathology on all of our patients, you know, especially if there's a tumor, what if we took that and then could predict and I don't even have to do a $2,000 MRI scan. Um, I don't know, this is one idea. I I would be interested in working on something like that. I'm not sure if we're supposed to be talking about really concrete proposal ideas, but",
        "speaking duration": 67,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:41",
        "end_time": "37:48",
        "annotations": {
            "propose new idea": "The speaker introduces a new idea of training AI models using cellular or microscopic or nanoscale data to predict what we see with MR or microscopic images.",
            "develop idea": "The speaker expands on the concept by providing a concrete example of taking an MRI image, doing a biopsy, and then using the biopsy sample to train an image to predict the MRI image.",
            "identify gap": "The speaker implicitly identifies a gap in current medical imaging practices by suggesting that predicting MRI images from cellular data could reduce the need for expensive MRI scans."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "07:49-07:51",
        "transcript": "I would like to build on that idea.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:49",
        "end_time": "37:51",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by expressing a desire to build on it."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "07:51-07:52",
        "transcript": "I'd like to move it one step further even.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:51",
        "end_time": "37:52",
        "annotations": {
            "supportive response": "The speaker is expressing a desire to continue and advance the discussion, showing engagement and support for further exploration of the idea."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "07:52-08:13",
        "transcript": "So assume you have some histopathological biopsy or something and you correlate that with the MRI that you also acquire in that region before or you train the model or whatever.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:52",
        "end_time": "38:13",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of combining histopathological biopsy data with MRI data for analysis or prediction.",
            "offer feedback": "The speaker is providing a suggestion for approaching the integration of different data types."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "08:13-08:57",
        "transcript": "And then you could use the MRI and look for the same pattern on a spatial scale and then basically predict from that again the pathology throughout the brain or see where you have a similar pattern in the brain. So you go basically across scales and combine really the methods um because if for example if you would do microscopic technique of whatever neuron firing or something, you could image only a certain a very small percentage of the brain and you can only relate you can only correlate MRI say uh with the microscopy technique at that special location.",
        "speaking duration": 44,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:13",
        "end_time": "38:57",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas about using MRI and microscopic techniques together across different scales to predict pathology.",
            "identify gap": "The speaker highlights the limitation of microscopic techniques in only being able to image a small percentage of the brain.",
            "offer feedback": "The speaker provides a suggestion for approaching the problem of predicting pathology throughout the brain by using MRI to look for patterns and correlate with microscopic findings."
        }
    },
    {
        "speaker": "Ferdinand Schweser",
        "timestamp": "08:57-08:57",
        "transcript": "Yeah, I",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:57",
        "end_time": "38:57",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "08:57-09:00",
        "transcript": "I I totally agree.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:57",
        "end_time": "39:00",
        "annotations": {
            "Supportive response": "The speaker expresses agreement with a previous statement, providing a positive evaluation without adding new content."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "09:00-09:31",
        "transcript": "I think in clinic actually as Candace said, um, you can get your, um, like a like histology, you don't need to do the MRI, but actually in clinic it's opposite. So patients get MRI, they want to get the histology because it's like a I mean invasive procedure.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 12.9,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:00",
        "end_time": "39:31",
        "annotations": {
            "develop idea": "The speaker is expanding on a previous idea about the use of MRI and histology in clinical settings.",
            "supportive response": "The speaker is providing additional thoughts that support and build upon previous discussions."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "09:31-09:35",
        "transcript": "So so if you can get MRI and predict the histology, that's going to be a",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:31",
        "end_time": "39:35",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of using MRI for predicting histology, building on previous discussions about multimodal imaging.",
            "identify gap": "The utterance implies a current limitation in directly predicting histology from MRI data."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "09:35-09:37",
        "transcript": "very brilliant, yeah, approach.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:35",
        "end_time": "39:37",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and a positive evaluation of a previously mentioned idea or approach."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "09:37-09:38",
        "transcript": "I totally agree.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:37",
        "end_time": "39:38",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a prior statement without adding new content."
        }
    },
    {
        "speaker": "Ping Wang",
        "timestamp": "09:38-09:38",
        "transcript": "I really like this idea.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:38",
        "end_time": "39:38",
        "annotations": {
            "Supportive Response": "The speaker is expressing agreement and a positive evaluation of a previously mentioned idea."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:01-00:28",
        "transcript": "we have this N dimensional plot of all the characteristics and limitations of all the modalities. I I want to point out that I I think you know one of the things we we use the term virtual biopsy where we hope to uh you know because you in for example in a screening situation, for example with breast cancer, you can't biopsy people in a screening situation, right?",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 11,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:01",
        "end_time": "40:28",
        "annotations": {
            "develop idea": "The speaker is elaborating on the concept of a 'virtual biopsy' and its relevance to screening situations, building on previous discussions.",
            "supportive response": "The speaker is expressing a positive view on the concept of virtual biopsy, supporting the idea of improving imaging techniques."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:28-00:42",
        "transcript": "But you can image. But if you can relate that to subsequent biopsies on a different population, then when you do the imaging, you can extract out features, you can predict if it's cancer or not and that's why it's called virtual biopsy.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:28",
        "end_time": "40:42",
        "annotations": {
            "clarify goal": "The speaker is defining and clarifying the objective of using imaging for cancer prediction, similar to what a biopsy would achieve.",
            "propose new idea": "The speaker introduces the concept of 'virtual biopsy' as a new approach for predicting cancer through imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:42-01:01",
        "transcript": "So I but it's it's um it's still slowly crossing over to um uh clinical use and that's I think a very important area and I just say one more thing and then I'm going to give it back to you is one of the features is heterogeneity. Cancer is very heterogeneous.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:42",
        "end_time": "41:01",
        "annotations": {
            "clarify goal": "The speaker highlights the importance of an area, specifically the transition into clinical use.",
            "develop idea": "The speaker expands on the concept of clinical use and its significance.",
            "process management": "The speaker manages the discussion flow by indicating she will give it back to the group."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:01-01:09",
        "transcript": "So in histopathology and and looking at the genomics, they look at the the heterogeneity within the tumor.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:01",
        "end_time": "41:09",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by providing more information about histopathology, genomics, and their relation to tumor heterogeneity."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:09-01:18",
        "transcript": "And we can look at the heterogeneity within a breast MRI. You can look at the heterogeneity of the uptake which is related to the angiogenesis.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:09",
        "end_time": "41:18",
        "annotations": {
            "clarify goal": "The speaker is also implicitly clarifying the goal of using MRI in this context, which is to understand tumor characteristics like heterogeneity."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:19-01:39",
        "transcript": "But and and so we know how to do both of those, but then to relate them to cross the scale needs a massive data set of patients that have both. And in fact in the histology instead of a tiny piece of tissue, you could actually do it's almost like a bread slice through the organ.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:19",
        "end_time": "41:39",
        "annotations": {
            "clarify goal": "The discussion aims to clarify the objective of relating different imaging scales and modalities."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:39-01:57",
        "transcript": "And you get this massive histology and I think the folks here who are doing microscopy do that, but now it's a big piece of tissue, you have the entire tumor, you can look at the heterogeneity of your um uh um tissue and relate it to the heterogeneity which you see in your MRI or.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:39",
        "end_time": "41:57",
        "annotations": {
            "develop idea": "The speaker is elaborating on the concept of massive histology and its relation to MRI, building upon previously discussed ideas.",
            "signal expertise": "The speaker is showing her expertise in the field, particularly in imaging and histology."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:57-02:13",
        "transcript": "ultrasound or something. There are different types of heterogeneity, but it's that heterogeneity keeps popping up across scales even though it's heterogeneity of different things. So I think you guys are on something here.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:57",
        "end_time": "42:13",
        "annotations": {
            "code name": "supportive response",
            "explanation": "The speaker is expressing agreement and a positive evaluation of the discussion, indicating that she thinks the group is on the right track."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:13-02:14",
        "transcript": "Okay, more thoughts.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:13",
        "end_time": "42:14",
        "annotations": {
            "encourage participation": "The speaker invites further discussion or thoughts from the group, encouraging participation.",
            "None": "No other code seems to directly apply to this utterance beyond encouraging participation."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:14-02:20",
        "transcript": "Um I would like to add a counter argument to this because what we are discussing all is the",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:14",
        "end_time": "42:20",
        "annotations": {
            "critical response": "The speaker is indicating a desire to present a counterargument to the current discussion, which involves questioning or challenging the prevailing views."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:20-02:25",
        "transcript": "structural deformation has already happened and you can see on the images.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:20",
        "end_time": "42:25",
        "annotations": {
            "critical response": "The speaker is providing a comment that could be seen as questioning or challenging the prevailing discussion by pointing out that structural deformation can already be observed in images."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:25-02:28",
        "transcript": "most of the time.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:25",
        "end_time": "42:28",
        "annotations": {
            "None": "No relevant code strongly applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:28-02:40",
        "transcript": "So because when you don't have any anatomical feature changes MRI becomes useless and then you need to go another uh opportunity.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:28",
        "end_time": "42:40",
        "annotations": {
            "identify gap": "Uzay highlights a limitation of MRI, indicating a gap in its capability when anatomical feature changes are not present.",
            "critical response": "Uzay critiques MRI by pointing out it becomes useless without anatomical feature changes, suggesting a need for another approach."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "02:40-03:03",
        "transcript": "So and then you do have the so it is still clinically useful. I am not saying this is what we need to do, but it is still really not helping us to early diagnostic or understanding what's happening at the beginning.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:40",
        "end_time": "43:03",
        "annotations": {
            "critical response": "The speaker is questioning the effectiveness of the approach for early diagnostics or understanding what's happening at the beginning.",
            "offer feedback": "The speaker is providing specific feedback on the limitations and usefulness of the approach."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "03:03-03:35",
        "transcript": "So that is that's I do find difficulties uh about this because for example I do have a glioma case which I was able to predict everything and I even though histology fails antibody tests for the glioma patients and then later on they do the DNA sequence and they always come back to confirm my results from the beginning.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:03",
        "end_time": "43:35",
        "annotations": {
            "signal expertise": "The speaker explicitly states his own experience and success in a specific case, showcasing his expertise in the field.",
            "offer feedback": "The speaker provides feedback based on his experience with a glioma case, implying challenges with current diagnostic methods."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "03:35-03:41",
        "transcript": "But this is really not exciting because there is already a chunk of tissue that is already deformed.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:35",
        "end_time": "43:41",
        "annotations": {
            "critical response": "Uzay Emir is questioning the excitement about a diagnostic approach by pointing out a limitation (tissue deformation),",
            "offer feedback": "Uzay Emir provides a critique that could be seen as feedback on the approach or situation being discussed."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "03:41-03:47",
        "transcript": "and I do localize it easily, but even there isn't anything so you will you will never be able to do the biopsy.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:41",
        "end_time": "43:47",
        "annotations": {
            "critical response": "The speaker questions the capability of imaging modalities in doing a biopsy when there's no significant anatomical change.",
            "offer feedback": "The speaker provides feedback on the limitations of imaging modalities for biopsy purposes."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "03:47-04:05",
        "transcript": "You will never be able to do histopathology because there isn't any clinical findings that confirms that only the symptoms the patient has and the clinician will never try to get let's try to sample it without having any additional confirmation. So and again we are getting far from the uh this optical imaging what helping us to understand uh and try to figure out early diagnostic features and try to change the treatment or try to intervene as quick as possible.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:47",
        "end_time": "44:05",
        "annotations": {
            "identify gap": "The speaker highlights challenges and limitations in current diagnostic practices, particularly in early diagnosis when there are no apparent anatomical changes.",
            "critical response": "The speaker critiques current practices by pointing out the limitations of imaging techniques like MRI in early diagnosis and the challenges of performing histopathology without clinical findings.",
            "offer feedback": "The speaker provides feedback based on their experience, emphasizing the difficulties in early diagnosis and the potential benefits of optical imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:05-04:15",
        "transcript": "Yes. And I I think we have to push optical imaging, you know, but we also have to accept that it's going to have its limitations and that's why we have",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:05",
        "end_time": "44:15",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and a balanced view regarding optical imaging, acknowledging its potential while also considering its limitations."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:15-04:24",
        "transcript": "radiographic x-ray, we have um pet, we have um spec, we have MRI, we have ultrasound and how do we link them together because um",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:15",
        "end_time": "44:24",
        "annotations": {
            "code name": "ask question",
            "explanation": "The speaker is asking a question about how to link different imaging modalities together.",
            "clarify goal": "The speaker is clarifying the objective of integrating different imaging modalities.",
            "develop idea": "The speaker is expanding on the idea of integrating different imaging modalities, previously discussed."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:24-04:34",
        "transcript": "in the end none of those will handle everything. Um at least my opinion.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:24",
        "end_time": "44:34",
        "annotations": {
            "None": "No relevant code directly applies, but it's closest to a summary or personal opinion. Given the options and the need for a precise fit, 'None' seems most appropriate as it doesn't directly summarize the conversation but is a concluding thought."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:34-04:40",
        "transcript": "But um um I uh and and I think everything is task based and disease based.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:34",
        "end_time": "44:40",
        "annotations": {
            "clarify goal": "The speaker is clarifying that the approach or method might depend on the specific task and disease being studied."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:40-04:51",
        "transcript": "Optical imaging may be great in diagnosing say say skin lesions, but it's not going to help in some of the deep tissue stuff.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:40",
        "end_time": "44:51",
        "annotations": {
            "identify gap": "The speaker highlights a limitation of optical imaging, specifically its inability to help with deep tissue issues.",
            "develop idea": "The speaker is expanding on the discussion about the applications and limitations of optical imaging in relation to other imaging modalities."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:51-05:01",
        "transcript": "So how do we how do we decide what's best for what organ, what disease and all that. Um but that's that's maybe pushing this too far.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:51",
        "end_time": "45:01",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:01-05:14",
        "transcript": "But maybe we should go back up um um back when you have time to I just don't want you to run out of time. I know we still have a half hour.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:01",
        "end_time": "45:14",
        "annotations": {
            "process management": "The speaker is managing the meeting time, ensuring that participants do not run out of time and are aware of the remaining time."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:14-05:23",
        "transcript": "But if you want to look at um you have your main points at the very start at the beginning of yours, your key. So you got two so far addressing.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:14",
        "end_time": "45:23",
        "annotations": {
            "process management": "The speaker is managing the discussion flow and how information is organized and viewed."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "05:23-05:26",
        "transcript": "Yeah, because we're kind of rolling over. I'm just summarizing the",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:23",
        "end_time": "45:26",
        "annotations": {
            "summarize conversation": "The speaker explicitly states they are summarizing the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:26-05:26",
        "transcript": "Okay, great, great.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:26",
        "end_time": "45:26",
        "annotations": {
            "Supportive response": "The utterance expresses agreement or confirmation, indicating a positive evaluation of the previous discussion."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "05:26-05:30",
        "transcript": "I'm doing clustering as we go along.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:26",
        "end_time": "45:30",
        "annotations": {
            "process management": "The speaker is explicitly stating that they are organizing or clustering information as the discussion progresses."
        }
    },
    {
        "speaker": "Candace Fleischer (Emory, she/her)",
        "timestamp": "05:30-05:31",
        "transcript": "No, excellent.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:30",
        "end_time": "45:31",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges a prior contribution.",
            "supportive response": "The utterance expresses a positive evaluation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:31-05:40",
        "transcript": "I think your two points are right on. Um folks, um is um is there a way of taking from all this discussion another point?",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:31",
        "end_time": "45:40",
        "annotations": {
            "supportive response": "The speaker explicitly agrees with previous points by saying 'I think your two points are right on.'",
            "ask question": "The speaker requests additional input or points from the discussion by asking 'is there a way of taking from all this discussion another point?'"
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "05:40-05:57",
        "transcript": "From me the question for me the important question I mean thinking big is is great uh but uh we for me the question is what is achievable really.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:40",
        "end_time": "45:57",
        "annotations": {
            "clarify goal": "The speaker is emphasizing the importance of determining what is achievable in the context of multimodal imaging discussions."
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "05:57-06:05",
        "transcript": "And uh of course I mean yeah, I would like to do uh microscopy in a living human uh throughout the brain and zoom in on every uh cell that I can do.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:57",
        "end_time": "46:05",
        "annotations": {
            "identify gap": "The speaker recognizes a current limitation in medical imaging technology, specifically the inability to perform microscopy in a living human throughout the brain."
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "06:05-06:11",
        "transcript": "That's the ultimate goal and maybe in a thousand years we can do that.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:05",
        "end_time": "46:11",
        "annotations": {
            "express humor": "The speaker makes a joke about the timeline for achieving a goal in imaging technology.",
            "supportive response": "The speaker expresses a positive outlook on the potential future achievements in the field of imaging technology."
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "06:11-06:29",
        "transcript": "But uh what is achievable? Because yeah, if you if we don't see anything on MRI, if there's no change, we can we can throw AI at it and correlate it with a pathology, the result will be nonsense.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:11",
        "end_time": "46:29",
        "annotations": {
            "critical response": "Ferdinand Schweser is questioning the effectiveness of using AI to correlate with pathology when no changes are seen on MRI, implying a critical view of an approach.",
            "ask question": "The utterance starts with 'But uh what is achievable?' which is a direct question about the feasibility of certain actions or expectations."
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "06:29-06:32",
        "transcript": "It may work in our cohort, but it will be nonsense.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:29",
        "end_time": "46:32",
        "annotations": {
            "critical response": "The speaker is questioning the validity of an approach, expressing concern that it may not work in a different cohort."
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "06:32-06:33",
        "transcript": "because if there's no change",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:32",
        "end_time": "46:33",
        "annotations": {
            "identify gap": "The speaker highlights a challenge or limitation in correlating MRI findings with pathological changes, emphasizing the need for actual changes to be present.",
            "critical response": "The speaker cautions against the potential for nonsensical results if correlations are attempted without actual changes being present."
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "06:33-06:35",
        "transcript": "on the MRI it's not going to work.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:33",
        "end_time": "46:35",
        "annotations": {
            "identify gap": "The speaker is highlighting a limitation or a gap in the capability of MRI technology for certain applications.",
            "critical response": "The speaker is providing a negative evaluation of the utility of MRI under certain conditions."
        }
    },
    {
        "speaker": "Ferdinand Schweser (SUNY UB)",
        "timestamp": "06:35-06:37",
        "transcript": "So what is an achievable goal here?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:35",
        "end_time": "46:37",
        "annotations": {
            "ask question": "Ferdinand Schweser is requesting information on what constitutes an achievable goal in the context of multimodal imaging discussions.",
            "clarify goal": "He is seeking to clarify or define what achievable goals look like in the specific context of their discussion on multimodal imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:37-06:37",
        "transcript": "Right.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:37",
        "end_time": "46:37",
        "annotations": {
            "None": "The utterance is a brief agreement or acknowledgment without adding new content."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "06:37-06:38",
        "transcript": "I would like to encourage.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:37",
        "end_time": "46:38",
        "annotations": {
            "encourage participation": "The speaker is encouraging others to participate or contribute to the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:38-06:38",
        "transcript": "Go ahead, you say.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:38",
        "end_time": "46:38",
        "annotations": {
            "encourage participation": "The speaker is inviting someone to contribute their thoughts or ideas."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "06:38-06:55",
        "transcript": "My padlets for cancer, there is one case I intentionally put that clinical scan failed and they come to me and can you do this seven Tesla spectroscopy on this patient. I did and the first scan I said this is IDH2 mutation patient based on the features.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:38",
        "end_time": "46:55",
        "annotations": {
            "develop idea": "The speaker is expanding on the discussion by providing a specific example of using seven Tesla spectroscopy in cancer diagnosis.",
            "signal expertise": "The speaker is explicitly stating his own expertise in performing and interpreting seven Tesla spectroscopy."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "06:55-07:05",
        "transcript": "And then they do the biopsy. The biopsy failed because lack of information, lack of sample and then the neurosurgeon took the extreme case and do the complete resection.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:55",
        "end_time": "47:05",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "07:05-07:12",
        "transcript": "And they do the DNA sequencing and it ended up IDH2 mutation and there weren't any anatomical changes.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:05",
        "end_time": "47:12",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "07:12-07:30",
        "transcript": "The only thing that uh the symptoms and the doctor told me that this temporal lobe might be the problem. So what I'm saying is we need to really the capacity and you need to use the right tool, right method and then to understand the physiology really well.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:12",
        "end_time": "47:30",
        "annotations": {
            "signal expertise": "The speaker shares a personal case experience, indicating their expertise.",
            "offer feedback": "The speaker provides general advice on approaching medical imaging and diagnosis.",
            "clarify goal": "The speaker emphasizes the importance of understanding physiology and using the right tools and methods."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "07:30-07:41",
        "transcript": "So that is I always try to share it. Yes, the tools are have really powerful, but this has to be driven by mesoscope mesoscopic scales.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:30",
        "end_time": "47:41",
        "annotations": {
            "identify gap": "The speaker implies a gap in current practices of using tools without proper consideration of mesoscopic scales.",
            "offer feedback": "The speaker provides feedback on the use of tools, suggesting they should be driven by mesoscopic scales."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:00-00:04",
        "transcript": "over the break, but I don't want anybody excluded in this this discussion.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:04",
        "annotations": {
            "encourage participation": "The speaker is inviting everyone to participate in the discussion, ensuring no one is excluded.",
            "process management": "The speaker is suggesting how to manage the discussion process, specifically over the break."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:04-00:13",
        "transcript": "A quick side information, not every country and not every city will be able to have 70 Tesla MRI scanners. So we have to keep that in mind.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 66.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:04",
        "end_time": "50:13",
        "annotations": {
            "identify gap": "The speaker points out that not every country or city can have 70 Tesla MRI scanners, highlighting a resource gap."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:13-00:13",
        "transcript": "Sure.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:13",
        "end_time": "50:13",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:13-00:17",
        "transcript": "Yes, we are in the middle of we are country.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:13",
        "end_time": "50:17",
        "annotations": {
            "express humor": "The speaker is making a humorous comment about their location."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:17-00:23",
        "transcript": "You'll have it in St. Louis where we have it, you'll have it in maybe Boston, but that's another thing to take into account.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:17",
        "end_time": "50:23",
        "annotations": {
            "process management": "The speaker is commenting on the practical considerations of technology availability in different locations, which affects the process of research or clinical work."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:23-00:30",
        "transcript": "But we need to be insane this group of people, right? So push the limits.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:23",
        "end_time": "50:30",
        "annotations": {
            "express humor": "The speaker uses a colloquial and humorous expression to encourage the group.",
            "encourage participation": "The speaker encourages the group to push limits, promoting active participation and boldness in their work."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:31-00:31",
        "transcript": "Right.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:31",
        "end_time": "50:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:31-00:31",
        "transcript": "So.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:31",
        "end_time": "50:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:31-00:31",
        "transcript": "So.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:31",
        "end_time": "50:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:31-00:31",
        "transcript": "So.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:31",
        "end_time": "50:31",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:31-00:34",
        "transcript": "So the reason I'm bringing up, what the reason I'm bringing it up.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:31",
        "end_time": "50:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:34-00:55",
        "transcript": "There might be a cheaper alternative that potentially can be correlated in somehow with seven Tesla Tesla but can be deployed in a countries that cannot have a seven Tesla Tesla scanner or in a region that cannot have a Tesla scanner. And you know, that's something to keep in mind for multimodality, the the cost and the invasiveness.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 33.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:34",
        "end_time": "50:55",
        "annotations": {
            "propose new idea": "Beck Kamilov introduces the idea of considering cheaper alternatives for imaging modalities, specifically in the context of multimodality and accessibility.",
            "develop idea": "He discusses how this cheaper alternative could potentially correlate with more expensive imaging techniques like seven Tesla MRI, in terms of application and deployment."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:55-01:36",
        "transcript": "So one of your key points might be all these aspects of imaging that um help create the next generation of imaging but also limit it and that, you know, there multiple um folks here have pointed out, you know, the spatial and temporal resolution, the the cost, the um um uh invasiveness.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:55",
        "end_time": "51:36",
        "annotations": {
            "summarize conversation": "The speaker summarizes the discussion by highlighting key aspects of imaging that both enable and limit the creation of the next generation of imaging technologies, including spatial and temporal resolution, cost, and invasiveness."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:36-01:45",
        "transcript": "And then there's also the um part on um uh which is related to the cost is the uh socio economic situation in which that uh imaging system uh might uh not be able to exist.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:36",
        "end_time": "51:45",
        "annotations": {
            "develop idea": "The speaker is expanding on previous thoughts about challenges or considerations in imaging, specifically mentioning socio-economic situations as a factor that might affect the existence of an imaging system."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:45-01:52",
        "transcript": "Um so but now I think we should just dream. You know, if we came up with the best one, um what could we do that?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:45",
        "end_time": "51:52",
        "annotations": {
            "Encourage participation": "The speaker invites the group to engage in a speculative discussion, encouraging them to contribute their thoughts.",
            "Process management": "The speaker is managing the discussion process by suggesting a new direction for the conversation."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:52-02:03",
        "transcript": "Uh should we work on your key points or keep going in the full discussion? Someone um do the key points summarize um all that um we've been talking about. And Beck, you've been doing a great job.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:52",
        "end_time": "52:03",
        "annotations": {
            "process management": "The speaker is managing the discussion by suggesting directions for the meeting to proceed.",
            "assign task": "The speaker assigns the task of summarizing key points to someone in the group.",
            "acknowledge contribution": "The speaker acknowledges Beck's contribution and provides positive feedback."
        }
    },
    {
        "speaker": "Anna-Karin Gustavsson",
        "timestamp": "02:04-02:22",
        "transcript": "Even though it's primarily mesoscopic to microscopic, but to some extent also microscopic to mesoscopic, um to bridging that gap as well. I don't know if we want to have that as a key point, but that's another consideration.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 33.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:04",
        "end_time": "52:22",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas about the relationship between mesoscopic and microscopic scales.",
            "identify gap": "The speaker mentions the consideration of bridging the gap between mesoscopic and microscopic scales.",
            "clarify goal": "The speaker questions whether to include this consideration as a key point, seeking clarity on focus."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "02:23-02:41",
        "transcript": "I think that general idea of fusion is a very nice one. It's it's quite quite prevalent actually even in within a modality. People take, you know, three different views and fuse them to get more information. I I guess actually people in have been doing that for quite some time, I think.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:23",
        "end_time": "52:41",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement and validation for the concept of fusion.",
            "Develop idea": "The speaker is expanding on the idea of fusion, providing examples and context."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:44-03:02",
        "transcript": "Right. and and actually the reason people do a lot of fusion is to merge structural morphology with um you know, physiology. Um and that's why people have pet CTs in a way. Um but you can I think you can fuse it at the image level um or at the uh feature level.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 11.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:44",
        "end_time": "53:02",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of fusion in imaging, providing examples and explanations.",
            "supportive response": "The speaker is providing a positive context for the use of multimodal imaging by explaining its rationale."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "03:06-03:15",
        "transcript": "Right. and then building a model for that that you know, could be equivalence like what a classifier would be would be, I don't know, that seems like it would have some value.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:06",
        "end_time": "53:15",
        "annotations": {
            "propose new idea": "The speaker suggests building a model for equivalence like what a classifier would be, proposing a new approach to integrating data across modalities.",
            "develop idea": "The utterance elaborates on the idea of fusing data and building models for comparison across different imaging modalities.",
            "offer feedback": "The speaker provides a suggestion or an idea about potentially valuable approaches to data modeling and fusion."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:19-03:47",
        "transcript": "I I really like thinking that direction. It's kind of, you know, you can extract certain characteristic, like interpretable characteristics from each image for that modality, right? You say, oh, you know, I'm trying to diagnose this, I have this structural information and you know, I can get features that tell me something about this diseases and later we can classify based on those features. Uh, for another modality, it could be a related type of features and and later you can kind of work in the feature level.",
        "speaking duration": 28,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:19",
        "end_time": "53:47",
        "annotations": {
            "develop idea": "The speaker is expanding on an existing idea by suggesting the extraction of characteristics from images for different modalities and potentially classifying based on those features.",
            "supportive response": "The speaker is expressing a positive evaluation of an idea by suggesting a potential approach.",
            "offer feedback": "The speaker is providing a suggestion for how to proceed with an idea."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:48-03:55",
        "transcript": "So let me ask Ellen, is this answering your big dream of multimodal?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:48",
        "end_time": "53:55",
        "annotations": {
            "ask question": "The speaker is directly asking Ellen about her thoughts on the discussion.",
            "encourage participation": "The speaker is engaging with Ellen, encouraging her to share her thoughts.",
            "clarify goal": "The speaker is checking if the current discussion aligns with Ellen's expectations or vision for multimodal imaging."
        }
    },
    {
        "speaker": "Ellen Sletten",
        "timestamp": "04:00-04:32",
        "transcript": "I think we're getting at a lot of them. Um, you know, ultimately, I would like to think on more of a diagnostic, you know, before a patient has symptoms and you know, I think that if we could get things at the molecular level and have a cheap diagnostic and maybe that does have to be multimodal, um that would allow more screening.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:00",
        "end_time": "54:32",
        "annotations": {
            "identify gap": "Implicitly identifying a gap in current diagnostic capabilities.",
            "clarify goal": "Explicitly stating a goal for future diagnostics.",
            "supportive response": "Showing support for the direction of research."
        }
    },
    {
        "speaker": "Ellen Sletten",
        "timestamp": "04:32-04:32",
        "transcript": "That's something that we haven't.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:32",
        "end_time": "54:32",
        "annotations": {
            "identify gap": "Ellen Sletten is pointing out that there is an aspect or idea that they have not considered yet."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:33-04:37",
        "transcript": "So getting molecular information at the screening time.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:33",
        "end_time": "54:37",
        "annotations": {
            "clarify goal": "The speaker is defining and clarifying the objective of getting molecular information at the screening time.",
            "summarize conversation": "The utterance attempts to crystallize a goal or objective discussed in the conversation."
        }
    },
    {
        "speaker": "Ellen Sletten",
        "timestamp": "04:38-04:54",
        "transcript": "Well, I think we've sort of touched upon it is the molecular information, right? That is the early signals that we're going to be able to read out on. So how can we think about doing that in a cheap, non-invasive way that would allow more screening.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:38",
        "end_time": "54:54",
        "annotations": {
            "Clarify goal": "Ellen is discussing and clarifying the goal of achieving early screening through molecular information in a cheap and non-invasive way.",
            "Identify gap": "She identifies a gap in current methods, which is the need for cheap, non-invasive techniques for early screening.",
            "Ask question": "Ellen asks how to think about doing this, which invites discussion and ideas."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:54-04:54",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:54",
        "end_time": "54:54",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "04:54-05:03",
        "transcript": "Yeah, I think that actually item like combination of the tree it could like solve what I I was getting at.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:54",
        "end_time": "55:03",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous statement, showing a positive evaluation without adding new content."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "05:03-05:17",
        "transcript": "It's just like I was thinking that how we are able to have access, you know, to that data set to be able to do like item two, but yeah.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 21.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:03",
        "end_time": "55:17",
        "annotations": {
            "ask question": "The speaker is seeking clarity or discussion about accessing a dataset.",
            "identify gap": "The speaker implies a gap in accessing a dataset.",
            "clarify goal": "The speaker's comment relates to understanding or discussing objectives or goals."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "05:17-05:17",
        "transcript": "we could, right?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:17",
        "end_time": "55:17",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or confirmation with a previous statement, indicating a positive evaluation without adding new content."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "05:17-05:18",
        "transcript": "Yes.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:17",
        "end_time": "55:18",
        "annotations": {
            "supportive response": "Sapun Parekh is expressing agreement with a previous statement, indicating a supportive response."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "05:18-05:18",
        "transcript": "That's the point of all of us.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:18",
        "end_time": "55:18",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or alignment with the previous discussion, emphasizing the collective purpose or goal."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "05:18-05:18",
        "transcript": "Yes.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:18",
        "end_time": "55:18",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous statement or suggestion."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:18-05:30",
        "transcript": "Yeah. That's why we we're quite a a diverse group here. I mean, there's some of us, I'm I'm an AI person. There seems to be some other folks here AI meaning merging of techniques using mathematical methods.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:18",
        "end_time": "55:30",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:30-05:36",
        "transcript": "Um and there's acquisition people both at the optical uh you know, across all scales.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:30",
        "end_time": "55:36",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:36-05:44",
        "transcript": "I I think that's the benefit of this uh group. Um so when on number two, you have multimodality by using AI to fuse.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:36",
        "end_time": "55:44",
        "annotations": {
            "summarize conversation": "The speaker is summarizing a point discussed, specifically about multimodality by using AI to fuse, which seems to be a key point (number two) from the conversation."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:44-05:53",
        "transcript": "What about where how about using multidata to guide the next layer? You know, I think how to zoom in. I think it was Anna Karin talked about that was that Ellen, someone. Okay.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:44",
        "end_time": "55:53",
        "annotations": {
            "propose new idea": "The speaker introduces a new idea of using multidata to guide the next layer of analysis or imaging.",
            "develop idea": "The speaker builds upon or elaborates on ideas previously discussed by others (Anna Karin, Ellen).",
            "ask question": "The speaker seeks clarification or further discussion on the proposed approach."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "05:54-06:16",
        "transcript": "Yeah, I think that actually item like combination of the tree it could like solve what I I was getting at. It's just like I was thinking that how we are able to have access, you know, to that data set to be able to do like item two, but yeah.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 18.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:54",
        "end_time": "56:16",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous statement and relating their thoughts to the discussion, showing support for the ideas presented."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "06:17-06:17",
        "transcript": "we could, right?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:17",
        "end_time": "56:17",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or acknowledgment of a preceding idea, indicating a positive evaluation or confirmation of the possibility discussed."
        }
    },
    {
        "speaker": "Sapun Parekh",
        "timestamp": "06:17-06:21",
        "transcript": "That's the point of all of us. Yes. Yeah.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:17",
        "end_time": "56:21",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging a point made by others, showing engagement.",
            "supportive response": "The speaker is expressing agreement and support for the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:21-06:33",
        "transcript": "That's why we we're quite a a diverse group here. I mean, there's some of us, I'm I'm an AI person. There seems to be some other folks here AI meaning merging of techniques using mathematical methods.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:21",
        "end_time": "56:33",
        "annotations": {
            "None": "No relevant code directly applies to this utterance as it primarily serves as a reflective statement on the group's diversity and expertise."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:33-06:40",
        "transcript": "Um and there's acquisition people both at the optical uh you know, across all scales.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:33",
        "end_time": "56:40",
        "annotations": {
            "acknowledge contribution": "Maryellen Giger acknowledges the role of acquisition people in optical imaging across various scales."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:40-06:52",
        "transcript": "I think that's the benefit of this uh group. Um So when on number two, you have multimodality by using AI to fuse.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:40",
        "end_time": "56:52",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and validation for the group's approach to multimodality, specifically mentioning the use of AI to fuse different modalities."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:52-07:01",
        "transcript": "What about where how about using multidata to guide the next layer? You know, I think how to zoom in. I think it was Anna Karin talked about that was that Ellen, someone. Okay.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:52",
        "end_time": "57:01",
        "annotations": {
            "propose new idea": "The speaker suggests using multidata to guide the next layer of imaging.",
            "develop idea": "The suggestion builds upon previous discussions about multimodal imaging.",
            "ask question": "The utterance contains a question about using multidata to guide the next layer."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:01-07:09",
        "transcript": "Uh how do we bring that in? Is that a is that additional one to number two to fuse or guide over here?",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:01",
        "end_time": "57:09",
        "annotations": {
            "code name": "develop idea",
            "explanation": "The speaker is trying to understand how an idea fits into their current framework, specifically if it relates to point number two about fusing or guiding."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:10-07:15",
        "transcript": "I think we should brought that by fuse or guide or make it separate.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:10",
        "end_time": "57:15",
        "annotations": {
            "propose new idea": "The speaker is introducing a suggestion on how to organize or relate different concepts.",
            "develop idea": "The speaker expands on the suggestion by providing specific options (fuse, guide, or make separate)."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:15-07:15",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:15",
        "end_time": "57:15",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or validation without adding new content."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:07",
        "transcript": "Well, for now it's too much, but in the future potentially it will be uh something we can handle.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:00",
        "end_time": "60:07",
        "annotations": {
            "None": "No relevant code directly applies to this utterance as it is a general comment about the future potential of handling something complex."
        }
    },
    {
        "speaker": "Ferdinand Schweser, SUNY UB",
        "timestamp": "00:07-00:23",
        "transcript": "But what I mean is on MRI we get one single number per scan for that voxel cube and then we are we know that on the microscopic level we have so much data. So and now we try to map these two, it's impossible.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:07",
        "end_time": "60:23",
        "annotations": {
            "identify gap": "The speaker is highlighting the gap between the data provided by MRI and the detailed data available at the microscopic level.",
            "critical response": "The speaker is pointing out a limitation and challenge, which can be seen as a critique of current MRI technology.",
            "signal expertise": "The speaker is drawing from their expertise in MRI and its limitations."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:23-00:26",
        "transcript": "So we need to restrict the by the way.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:23",
        "end_time": "60:26",
        "annotations": {
            "process management": "The speaker is trying to manage the discussion flow or focus.",
            "clarify goal": "The utterance attempts to refocus the discussion on a particular aspect or goal."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "00:26-00:39",
        "transcript": "You you're saying like even MRI, you do quantitative MRI, you don't get one scan, you do different, you know, I don't know, recall echoes and then you try to you try to get molecular information then by using some biophysical model on that MRI data. So you can explore it in a richer way too.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:26",
        "end_time": "60:39",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of quantitative MRI, explaining how it works and its benefits.",
            "offer feedback": "The speaker is providing an explanation on how to explore MRI data more effectively.",
            "supportive response": "The speaker is supporting the discussion by providing additional insights."
        }
    },
    {
        "speaker": "Ferdinand Schweser, SUNY UB",
        "timestamp": "00:39-01:06",
        "transcript": "I think the goal in the MRI field is really to acquire a very high set of parameters in a very short time and then fuse them to get to the high number of parameters and characterize the tissue. That's the that's the far goal for MRI, I think. But still you would have to figure out how to how to reduce the parameter space to predict the microscopic level somehow.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:39",
        "end_time": "61:06",
        "annotations": {
            "develop idea": "The speaker is elaborating on existing ideas in the MRI field.",
            "identify gap": "The speaker highlights a challenge in predicting the microscopic level.",
            "clarify goal": "The speaker discusses the goals in the MRI field."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:06-02:34",
        "transcript": "So we've had a lot of discussion on different limitations, you know, we're hearing some here, um, both in the actual acquisitions and then how do we map them? You say you brought up limitations, you know, and how do we push, you know, optical imaging more across the different scales, but all of this feeds into a dream. What what what would you want? You know, you have those limitations. Uh, for example, uh, uh, say in the old days we could only image um with say 1 millimeter pixels. But we could dream, we could say, but we really want to image at 0.2 millimeter pixels. And then we go back and we we push um the technology, the detector system or the sources or or the reconstruction or the AI part of the interpretation. So now take those limitations that you have in your mind, but convert them to I wish I had this. And I I think some of because this is a great team here of different modality, different scales and also different use. Some of you are right in the clinical area, other ones are at the bench. Um, and we're we're actually trying to do multi uh fusion of that. Um, so Ellen, where do you see this going? Help us here.",
        "speaking duration": 88,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:06",
        "end_time": "62:34",
        "annotations": {
            "summarize conversation": "The speaker summarizes the discussion on limitations and their implications for their work.",
            "encourage participation": "The speaker invites Ellen to share her thoughts on the direction of their work, encouraging participation."
        }
    },
    {
        "speaker": "ELLEN SLETTEN (UCLA)",
        "timestamp": "02:35-02:57",
        "transcript": "I mean, I'm in the in the probe making space and I feel like a lot of the discussions we're having can be solved by responsive probes. And if we can have responsive probes that work throughout all the modalities, then you're going to be able to get molecular information and then you can pick the time scale you want and you can pick the depth penetration you need.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:35",
        "end_time": "62:57",
        "annotations": {
            "propose new idea": "Ellen introduces the idea of using responsive probes that work across all modalities as a solution to the challenges in multimodal imaging.",
            "develop idea": "Ellen elaborates on the benefits of responsive probes, including their potential to provide molecular information, and flexibility in time scale and depth penetration."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:00-03:09",
        "transcript": "So Ellen is going to keep working on probes and then she's going to team up with people are going to be pushing the detector system. Um, how is that going to help?",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:00",
        "end_time": "63:09",
        "annotations": {
            "ask question": "The speaker is asking for clarification on how Ellen's work on probes and collaboration with others on the detector system will help.",
            "encourage participation": "The speaker is encouraging others to contribute their thoughts on the plan.",
            "clarify goal": "The speaker seeks to understand the goal or benefit of Ellen's work and its collaboration with others."
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "03:10-04:33",
        "transcript": "Yes, I will give you an example, for example, optical imaging. Raman spectroscopy is quite important for cancer detection during intraoperative scans. It is in place, people are using this Raman spectroscopy to identify the certain mutations during the operation with using the neuro navigators and you can get the same information from the MRI. And for example, you can figure out the Raman spectroscopy signal intensity. So that's all have so when when Ellen highlighted the probes, for example, this can be another probe to do to using the optical information of the tissue during the real time and you can merge it with different types of MRI contrast as as has been highlighted by the Ferdinand and the Lubec and and and that can be merged easily because you do have the all spatial information that comes from the clinical scan during the operation and you do have the optical information and and then you can merge the optical properties with with clinical findings and later on you can merge because it's going to be very well marked with the histopathological information as well. So then you can go back to histology and DNA sequencing and you can have the big data and go to do canonical analysis and find what is interesting.",
        "speaking duration": 83,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:10",
        "end_time": "64:33",
        "annotations": {
            "develop idea": "expanding on the idea of using optical imaging (Raman spectroscopy) and its potential for integration with MRI, providing examples and applications",
            "acknowledge contribution": "mentioning Ellen's highlighting of probes",
            "offer feedback": "suggesting the use of Raman spectroscopy signal intensity and its merge with MRI contrast"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:33-04:36",
        "transcript": "So you're actually talking to number two in in um the key points that um Beck has put up.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:33",
        "end_time": "64:36",
        "annotations": {
            "process management": "The speaker is managing the discussion by referencing specific points previously discussed."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:36-04:51",
        "transcript": "Of you're now we're fusing the knowledge that we have from the clinical scans with all their limitations with what we're seeing at the bench.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:36",
        "end_time": "64:51",
        "annotations": {
            "summarize conversation": "The speaker summarizes the discussion about integrating knowledge from clinical scans with their limitations and what is observed at the bench.",
            "acknowledge contribution": "The speaker acknowledges the contributions of both clinical scans and bench research by mentioning their knowledge and limitations.",
            "supportive response": "The speaker expresses a positive view towards combining different types of knowledge for multimodal imaging."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:51-04:56",
        "transcript": "And then trying to move those closer so the bench becomes clinical. Um.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:51",
        "end_time": "64:56",
        "annotations": {
            "clarify goal": "The speaker is discussing the objective of moving research from the bench to clinical applications, reflecting on the goal of making basic research findings applicable in clinical settings."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:56-04:58",
        "transcript": "What have we missed?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:56",
        "end_time": "64:58",
        "annotations": {
            "summarize conversation": "The speaker is asking for a review of what has been discussed in the meeting."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:58-05:00",
        "transcript": "Shiva.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:58",
        "end_time": "65:00",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:00-05:03",
        "transcript": "We missed anything or Ping.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:00",
        "end_time": "65:03",
        "annotations": {
            "encourage participation": "The speaker invites Ping to contribute to the discussion.",
            "process management": "The speaker checks if anything was missed in the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:03-05:05",
        "transcript": "You know, you guys have been a little quiet for a while.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:03",
        "end_time": "65:05",
        "annotations": {
            "encourage participation": "The speaker is inviting others to contribute their thoughts or ideas, encouraging participation in the discussion."
        }
    },
    {
        "speaker": "Ping Wang (MSU)",
        "timestamp": "05:53-05:59",
        "transcript": "Um I I totally agree on that um probe uh discussion.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:53",
        "end_time": "65:59",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous discussion about probes."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "05:59-06:00",
        "transcript": "I mean.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:59",
        "end_time": "66:00",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:00-06:01",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:00",
        "end_time": "66:01",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:01-06:07",
        "transcript": "Actually, you know what? Maybe we should put it as one of the key points, as a separate key point.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:01",
        "end_time": "66:07",
        "annotations": {
            "process management": "Suggesting to organize discussion points by putting an idea as a separate key point."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:07-06:10",
        "transcript": "Yeah, there's no one saying you only could have three key points. You can have a fourth one.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:07",
        "end_time": "66:10",
        "annotations": {
            "process management": "The speaker is discussing the organizational aspect of their discussion, specifically about not limiting the number of key points to three."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:10-06:11",
        "transcript": "It's just that likes the number three.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:10",
        "end_time": "66:11",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:11-06:17",
        "transcript": "Okay, well we're we're we're merge one. How about we merge two?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:11",
        "end_time": "66:17",
        "annotations": {
            "process management": "Managing the discussion flow by suggesting to merge certain points."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:17-06:20",
        "transcript": "No, I'm just joking. I put the four.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:17",
        "end_time": "66:20",
        "annotations": {
            "express humor": "The speaker is making a joke."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:23-06:27",
        "transcript": "Across scales, right? across scales and modalities.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:23",
        "end_time": "66:27",
        "annotations": {
            "summarize conversation": "The speaker is summarizing or reflecting on the discussion about working across different scales and modalities in imaging."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:27-06:30",
        "transcript": "Chemical probes, right? Or you know.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:27",
        "end_time": "66:30",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges a previous mention of chemical probes."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:30-06:31",
        "transcript": "Yes, right.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:30",
        "end_time": "66:31",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a prior statement, showing support without adding new content."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:31-06:33",
        "transcript": "Designer designer chemical probes to.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:31",
        "end_time": "66:33",
        "annotations": {
            "propose new idea": "The speaker introduces the concept of 'designer chemical probes' as a potential approach or solution."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:33-06:34",
        "transcript": "Data reduction.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:33",
        "end_time": "66:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:34-06:34",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:34",
        "end_time": "66:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:34-06:35",
        "transcript": "Which is.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:34",
        "end_time": "66:35",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:35-06:43",
        "transcript": "Which is um fusion too, you know, like the AI of tech what you find at one scale related to what you find at the other, but use data reduction and AI to do it.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:35",
        "end_time": "66:43",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of fusion and how AI and data reduction can relate findings across different scales."
        }
    },
    {
        "speaker": "Ping Wang (MSU)",
        "timestamp": "00:00-00:53",
        "transcript": "design the probe adapt to multiple imaging modality is equal important as like put the modality together like instrument together for the application for the new new modality imaging I can I can have example people trying to combine MRI and MPI together magnetic particle imaging actually they they are also very competitive to complementary to each other MRI has higher resolution has higher sensitivity.",
        "speaking duration": 53,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:00",
        "end_time": "70:53",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of combining imaging modalities and the importance of probe adaptability.",
            "signal expertise": "The speaker discusses their understanding of imaging modalities, specifically MRI and MPI.",
            "offer feedback": "The speaker provides a perspective on the importance of probe design for multimodal imaging."
        }
    },
    {
        "speaker": "Ping Wang (MSU)",
        "timestamp": "00:53-01:33",
        "transcript": "I talk to the CEO of the MPI producer in United States. Actually there there are two major company one is magnetic insight based in California and the other one in Europe broker. I mean they don't they don't do the hybrid now but there's a group in Europe they trying to combine these two together.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:53",
        "end_time": "71:33",
        "annotations": {
            "signal expertise": "The speaker is sharing specific information about MPI producers and technological developments, indicating their expertise in the area."
        }
    },
    {
        "speaker": "Ping Wang (MSU)",
        "timestamp": "01:33-01:33",
        "transcript": "Mhm.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:33",
        "end_time": "71:33",
        "annotations": {
            "None": "No relevant code explicitly applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "01:34-01:39",
        "transcript": "Okay, and and Shiva, did you want uh so are we on track?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:34",
        "end_time": "71:39",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification from Shiva about being on track with the discussion."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "01:42-01:43",
        "transcript": "Shiva, we don't hear you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:42",
        "end_time": "71:43",
        "annotations": {
            "encourage participation": "The speaker directly addresses Shiva to ensure Shiva can contribute to the discussion."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh-UCSC",
        "timestamp": "01:44-02:57",
        "transcript": "Yes, like part of the like my problem was like how we can go like non invasively for diagnostic purpose to deep tissue especially since mostly I do x-ray pets so then I was wondering like in order to go deeper in tissue so then like what the group is thinking for diagnostic is the pass to go like in human because still I think that so many of the signaling pathway as if you know you want to like like you know what is happening you know in human especially that I I have done some plant imaging that is just like the environment of like one root of the plant is really important how all the plants together like the the sphere of the root as a group how they work together so then as if I want to see still how brain as a whole not in a small area is functioning and I want to go deeper but then how can I see the brain deep in the tissue what is the best approach?",
        "speaking duration": 73,
        "nods_others": 0,
        "smile_self": 0.08,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "71:44",
        "end_time": "72:57",
        "annotations": {
            "ask question": "The speaker is asking for the best approach to image deep tissue, indicating a request for information.",
            "identify gap": "The speaker recognizes a limitation in current imaging capabilities, specifically for deep tissue imaging.",
            "encourage participation": "The speaker is seeking input from the group on the best approach."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:01-03:11",
        "transcript": "Right, all of these need to be then customized to specific anatomical parts, clinical questions. Um.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:01",
        "end_time": "73:11",
        "annotations": {
            "develop idea": "The speaker is elaborating on previous discussions, emphasizing the need for customization of imaging approaches to specific anatomical parts and clinical questions.",
            "supportive response": "The speaker is showing agreement or validation with the previous discussion by affirming the need for a tailored approach.",
            "clarify goal": "The speaker is reiterating the importance of customizing imaging approaches to specific anatomical parts and clinical questions, which relates to defining objectives."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:12-03:18",
        "transcript": "Uh Beck, are you um set for uh to read back with what you have there on the key points?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:12",
        "end_time": "73:18",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by checking Beck's readiness to share key points."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:18-03:19",
        "transcript": "Yes, so should I read?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:18",
        "end_time": "73:19",
        "annotations": {
            "ask question": "The speaker is seeking confirmation or instruction on whether they should proceed with reading or sharing something."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:19-03:20",
        "transcript": "They look good.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:19",
        "end_time": "73:20",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or validation of the key points presented."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:20-03:20",
        "transcript": "Yes.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:20",
        "end_time": "73:20",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:23-03:25",
        "transcript": "Yes, you well well in the next.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:23",
        "end_time": "73:25",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:25-03:26",
        "transcript": "But we have.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:25",
        "end_time": "73:26",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:26-03:29",
        "transcript": "I need to put it in the slides, right? I I'm going to put it in.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:26",
        "end_time": "73:29",
        "annotations": {
            "process management": "The speaker is discussing the practical aspect of including information in the slides, which relates to managing the meeting flow or organizing group activities."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:29-03:34",
        "transcript": "Right, so you've got three minutes to uh but I think your cut point, your key points up here.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:29",
        "end_time": "73:34",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by mentioning a time constraint and directing the discussion."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:34-03:35",
        "transcript": "Also, do I need to edit the same PowerPoint that's shared or do I?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:34",
        "end_time": "73:35",
        "annotations": {
            "process management": "The speaker is asking for clarification on the process of editing a shared PowerPoint document, which pertains to managing the meeting's workflow and document handling."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:38-03:39",
        "transcript": "Yeah, I need to edit the.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:38",
        "end_time": "73:39",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:39-03:43",
        "transcript": "I think it's the um it's on that um Google Drive and you go just go to slide whatever and paste it in there.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:39",
        "end_time": "73:43",
        "annotations": {
            "process management": "The speaker is instructing someone on how to access and edit a shared Google Drive document, which relates to managing meeting flow and organizing group activities."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:43-03:44",
        "transcript": "Yeah, I just.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:43",
        "end_time": "73:44",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "03:52-03:54",
        "transcript": "Sounds good. I'm going to do it right away.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:52",
        "end_time": "73:54",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and commitment to an action, showing a positive and supportive attitude towards the discussion outcome."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:55-03:57",
        "transcript": "I think it's around slide 42.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "73:55",
        "end_time": "73:57",
        "annotations": {
            "process management": "The speaker is referring to a specific slide, indicating an action related to managing the meeting flow or presentation."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "04:05-04:06",
        "transcript": "Yep, multimodal imaging. Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:05",
        "end_time": "74:06",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:08-04:14",
        "transcript": "Okay, so what he what Beck has as key points good for everyone?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:08",
        "end_time": "74:14",
        "annotations": {
            "confirm decision": "The speaker is seeking confirmation that the key points summarized by Beck are acceptable for everyone."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:15-04:17",
        "transcript": "Okay, I saw a thumbs up, excellent.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:15",
        "end_time": "74:17",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and a positive evaluation based on observed feedback from the group."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "04:17-04:22",
        "transcript": "Okay, if somebody needs to edit, feel do your edit now or stay quiet forever.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:17",
        "end_time": "74:22",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by setting a deadline for edits to be made to the slides."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:22-04:23",
        "transcript": "Yes.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:22",
        "end_time": "74:23",
        "annotations": {
            "supportive response": "The utterance 'Yes.' is a supportive response as it confirms agreement or understanding of a previous statement or question."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:23-04:51",
        "transcript": "Um you you you all should be able to get multiple proposals out of this discussion. That means it was a good I really wish we had a lot more time a lot in the same group to really think more about all the questions that came up uh I almost feel the time is too short to really carve out and and focus the discussions on something.",
        "speaking duration": 28,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:23",
        "end_time": "74:51",
        "annotations": {
            "process management": "The speaker is reflecting on the discussion process, specifically mentioning a wish for more time to explore the questions that came up, which relates to managing meeting flow and time."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:51-05:17",
        "transcript": "That's a good point. But you you the fellows have additional time where and you have your break you have you have your what's it called? You have your other sessions at night where you could just you do your mini breakout or you could also just create your own group. Um uh and and start a discussion.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "74:51",
        "end_time": "75:17",
        "annotations": {
            "encourage participation": "The speaker invites participants to engage in discussions during breaks or other sessions, encouraging them to participate.",
            "process management": "The speaker mentions the meeting's schedule and logistics, guiding participants on what they can do during their free time."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:17-05:17",
        "transcript": "And.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:17",
        "end_time": "75:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Ping Wang (MSU)",
        "timestamp": "05:32-05:33",
        "transcript": "I cannot see any uh.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:32",
        "end_time": "75:33",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:40-05:40",
        "transcript": "See what.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:40",
        "end_time": "75:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:41-05:43",
        "transcript": "We're we're about to close in 53 seconds.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:41",
        "end_time": "75:43",
        "annotations": {
            "process management": "The speaker is indicating that the meeting is about to close, managing the meeting flow and time."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:43-05:48",
        "transcript": "Oh, I think he pressed the button. He left the breakout. So we're 45 seconds.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:43",
        "end_time": "75:48",
        "annotations": {
            "code name": "process management",
            "explanation": "The speaker is commenting on the meeting flow and time, specifically noting that someone left a breakout session and that there are 45 seconds remaining."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "05:51-05:54",
        "transcript": "Do you guys see the edit on the slide?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:51",
        "end_time": "75:54",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:54-05:54",
        "transcript": "I do.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:54",
        "end_time": "75:54",
        "annotations": {
            "supportive response": "The speaker is confirming or agreeing with something previously stated, providing a supportive acknowledgment."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:56-06:01",
        "transcript": "Oh, on the slide I haven't checked but I've been on your Google. Let me let me.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "75:56",
        "end_time": "76:01",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:01-06:04",
        "transcript": "And somebody check on the slide, is it only me who sees it or?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:01",
        "end_time": "76:04",
        "annotations": {
            "process management": "Beck Kamilov is checking if others can see the edit on the slide, which relates to managing the sharing and verification of information during the meeting."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:04-06:04",
        "transcript": "Let me let me.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:04",
        "end_time": "76:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Bot 5",
        "timestamp": "06:06-06:07",
        "transcript": "I'm checking now.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:06",
        "end_time": "76:07",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:07-06:08",
        "transcript": "Uh yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:07",
        "end_time": "76:08",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Ellen Sletten (UCLA)",
        "timestamp": "06:08-06:11",
        "transcript": "Putting our names in, so.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:08",
        "end_time": "76:11",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Uzay Emir (Purdue)",
        "timestamp": "06:11-06:17",
        "transcript": "Okay guys, I'm leaving last 20. See you later.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:11",
        "end_time": "76:17",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by announcing his departure from the meeting."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:17-06:17",
        "transcript": "See you later.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "76:17",
        "end_time": "76:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    }
]