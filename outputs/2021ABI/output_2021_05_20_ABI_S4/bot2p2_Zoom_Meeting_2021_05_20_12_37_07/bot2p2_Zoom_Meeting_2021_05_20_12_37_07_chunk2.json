{
    "meeting_annotations": [
        {
            "speaker": "Beck Kamilov",
            "timestamp": "00:00-01:05",
            "transcript": "uh data or model adaptation to different data, right? So, uh what do I mean by this? So you train your data uh on one type of data set, say, you know, you do MRI scan, uh it has certain artifact patterns, you train the model on that. Now you apply to something else and we know that it doesn't work very well if, you know, you applied it to a configuration doesn't work. Now there are a bunch of ideas out there, uh you know, in in the computer vision community in the machine learning community where people try to bridge those things, but it's still not we don't yet have, you know, killer technology that allows us, you know, we don't understand both the limits of how we can adapt the models to different applications. At the same time, you know, what's the best way to do the adaptation of the models that we already pre-trained to a new application, right? So deep learning models are not traditional software in the sense that I can go and just edit it. It's all in the weights of the training thing. So how do we reuse, adapt uh those models.",
            "speaking duration": 65,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:06-01:22",
            "transcript": "So how do we use metrology to appropriately measure how we're doing in our development as well as in the end product so that it is generalizable? I think that's what you were getting at as well as say unbiased and fair.",
            "speaking duration": 16,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "01:23-01:23",
            "transcript": "Yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:24-01:24",
            "transcript": "Are those major topics that",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:32-01:52",
            "transcript": "I think we should add kind of explainability to it too because in order to like uh focus more about the second part that what data are required to effectively train as we try to model and then create kind of some explanation to take away from that black box of how the algorithm is working.",
            "speaking duration": 20,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board."
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:52-02:22",
            "transcript": "And then make it more explainable is going to help us to see what are the different information that the data is leading to give us our accurate output and then as we learn and as we try to make it more explainable, that's become a tools for us to just try to focus in the information that we need.",
            "speaking duration": 30,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board."
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:22-02:26",
            "transcript": "Okay, I I agree explainability and then to the end user interpretability.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board."
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:27-02:42",
            "transcript": "So, um Shannon, would you want to share your screen and we could all pull it over so we can still see each other, but that way we can give you is that useful or not? I don't know what notes you're taking, that's why.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board."
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:43-02:50",
            "transcript": "I'm I'm unfortunately on Zoom on an iPad and taking notes on a desktop with the monitors right behind it.",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:50-02:52",
            "transcript": "Ah.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:54-03:03",
            "transcript": "So, um I could turn it into a Google Doc that I can then share a link to with everybody in here if that would be preferable.",
            "speaking duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:03-03:22",
            "transcript": "Because I like seeing everyone while we're having a discussion and I know I can kind of make the slide part very small and still see you all. Um but I think we need that visual feedback.",
            "speaking duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:22-03:24",
            "transcript": "So do you do you all want to do a uh Google Drive?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:24-03:26",
            "transcript": "Or do you want someone to",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "03:26-03:30",
            "transcript": "I'm comfortable with the Google Drive, uh Google Doc, Google Doc.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:30-03:45",
            "transcript": "Right, Google Doc, I'm sorry. So if you send that link in the chat, we can just click on it and then it's as if we're viewing the screen. That would be useful because",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "03:45-03:45",
            "transcript": "Yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:45-03:46",
            "transcript": "Um",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:46-04:24",
            "transcript": "Does anyone have any other thoughts on the first bullet which is in a way kind of our discussion blended into the third bullet? You know, we talked about um what kind of errors, you know, if we think about errors that are acceptable, those are quantitated by the metrology of the system. how are you going to measure the performance? How are you going to measure the variation of your system? How will you measure how unbiased or general your system is?",
            "speaking duration": 38,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "04:25-04:56",
            "transcript": "Yeah, I think I feel like since we're often imaging biological processes and looking at clinical images, um really knowing what ground truth is, um can be very challenging. Um it's not, you know, often the result might be correlated to pathology for example, if you're looking at cancer, but you don't really know that that pathology is accurate either.",
            "speaking duration": 31,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred."
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "04:57-05:07",
            "transcript": "Um do you think Carolyn that it's like having uh the expert lead on it or are you um like what would make it more true?",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "05:08-05:15",
            "transcript": "Um probably better images, right? Like since we're we're all looking at it with the image lens, right?",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred."
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:19-05:25",
            "transcript": "Yeah, when I think of imaging, I think of both acquisition and interpretation.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred."
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:25-06:16",
            "transcript": "I think we have to go back to the application and what is the task? And I think the truth um I'm going to throw this out. So a lot of us probably do segmentation, right? And then you ask, well how do you evaluate it? Well, maybe you use a dice coefficient or something like that. But it there's also the more broader picture saying, well, my segment works depending on my final truth, which might be based on pathology.",
            "speaking duration": 51,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred."
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:16-06:23",
            "transcript": "Um, just what do you think?",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred."
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "06:24-07:38",
            "transcript": "Well, I kind of I kind of agree with Carolyn's point about the uh ground truth, like what really is the ground truth? Um the way I see it is multiplexing the uh final yes no answer. So the input, let's say for example if it was histology, getting the manual input of the pathologist as well as some maybe molecular markers of the histological sections could be, you know, proteomics in addition to some genomic data, multiplexing the ground truth, well, getting working closer towards a ground truth by multiplexing the outputs at the end in order to train the intermediate. In my opinion is the best because I don't really know if there really is going to be a ground truth at that point because everything to a certain extent is either uh subjective to the observer if there's a pathologist or to uh experimental bias or fluctuations if you're going to get false positives or false negatives in the in the markers or the genomics themselves. So yeah, I'm I'm a little bit I'm kind of leaning more towards having building up the information at the at the end first in order to then bridge that gap because if you don't have that then it doesn't really make sense.",
            "speaking duration": 74,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:38",
            "transcript": "Sounds good.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:39-07:40",
            "transcript": "Um",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:41-08:21",
            "transcript": "I maybe I want to also bring up one thing. There is an interesting thing, the concept, right? Um in the so if you have errors in your ground truth and those errors are not systematic, meaning if you average them out across the whole data set, right? And then they average out to be a very small quantity, you can in principle train still with this form of errors and your model will not learn. So there is an interesting technical question there, what kind of errors are tolerable in the training data.",
            "speaking duration": 40,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:21-08:21",
            "transcript": "Yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:22-08:55",
            "transcript": "Yeah, I think we need to train and test with messy data because that's what the real world is. And sometimes, you know, we can do initial development, it's we do initial development of a filter in continuous domain, um but then when we go to actual image domain is pixelated and quantized, it doesn't quite work, but it gets you maybe 80, 85% there. Um, you know, we start in the ideal world and then um make it work in the messy real world.",
            "speaking duration": 33,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "08:56-09:16",
            "transcript": "And by the way, anything like changes like this you just mentioned that pixelation changes. Those are the systematic things that you could in principle incorporate to this as non-trainable elements or adaptable elements of machine learning models.",
            "speaking duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "09:16-09:17",
            "transcript": "So",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}