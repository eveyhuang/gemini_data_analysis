[
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:00-00:16",
        "transcript": "Washington University in St. Louis. My area is computational imaging, but I focus on biomedical imaging. A lot of the things I do focuses on image reconstruction, restoration and sometimes data acquisition, but not hardware, just software.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 7,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:00",
        "end_time": "00:16",
        "annotations": {
            "signal expertise": "The speaker is explicitly stating his own expertise and qualifications related to computational imaging and biomedical imaging."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:16-00:17",
        "transcript": "Okay, thank you, Katie.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:16",
        "end_time": "00:17",
        "annotations": {
            "acknowledge contribution": "The speaker is verbally recognizing another group member's input without adding new content."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "00:21-00:53",
        "transcript": "Hi, I'm at the National Institute of Standards and Technology. NIST's first role in imaging was around for MRI and validating results across centers. So we try to use quantitative techniques. We don't always get the same answer when we try them places. And now we're expanding into more validation of some of these techniques and also exploring what's possible at lower magnetic field strengths.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:21",
        "end_time": "00:53",
        "annotations": {
            "signal expertise": "The speaker explicitly states their role and work in imaging, particularly in MRI and validation of results.",
            "identify gap": "The speaker mentions a challenge they face in getting consistent results across different centers."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:53-00:57",
        "transcript": "Thank you and Shiva, I'm going to cross my Hollywood squares here.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:53",
        "end_time": "00:57",
        "annotations": {
            "acknowledge contribution": "The speaker verbally recognizes another group member's input with 'Thank you'.",
            "express humor": "The speaker attempts to make a lighthearted comment with 'I'm going to cross my Hollywood squares here', possibly trying to express humor."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "00:58-01:04",
        "transcript": "Hi, this is Shiva. I'm from University of California, Santa Cruz. So I do work on instrumentation for positron emission tomography and x-ray imaging.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:58",
        "end_time": "01:04",
        "annotations": {
            "signal expertise": "The speaker explicitly states their own expertise and qualifications related to the task, mentioning their work on instrumentation for positron emission tomography and x-ray imaging."
        }
    },
    {
        "speaker": "Jim Mitchell",
        "timestamp": "01:04-01:20",
        "transcript": "And then I'm really interested in like improving sensitivity and then quantitative accuracy of these imaging modalities.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:04",
        "end_time": "01:20",
        "annotations": {
            "signal expertise": "The speaker is implicitly signaling his expertise or area of interest related to improving sensitivity and quantitative accuracy of imaging modalities."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:20-01:24",
        "transcript": "Thank you, Shayna.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:20",
        "end_time": "01:24",
        "annotations": {
            "acknowledge contribution": "The speaker, Maryellen Giger, verbally recognizes Shayna's input, even though it seems there might have been a mishearing of the name."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "01:28-01:30",
        "transcript": "You referring to me? I'm Shannon.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 50,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:28",
        "end_time": "01:30",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on who was being referred to."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:30-01:31",
        "transcript": "Shannon.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:30",
        "end_time": "01:31",
        "annotations": {
            "None": "No relevant code directly applies to this utterance as it is a very brief and simple acknowledgment/correction of a name."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "01:31-01:31",
        "transcript": "Yes.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:31",
        "end_time": "01:31",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging Maryellen's correction of her name, which is a form of recognizing another group member's input."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:31-01:34",
        "transcript": "I got a new floor. I'm Shannon.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 66,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:31",
        "end_time": "01:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "01:35-01:57",
        "transcript": "I'm Shannon Quinn, I'm an assistant professor in computer science and cell bio at University of Georgia. I work in biomedical imaging and computational modeling of cellular and subcellular systems. I develop new artificial intelligence techniques for a unified representation of spatial and temporal signals and I work in the construction of open source software for domain scientists.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:35",
        "end_time": "01:57",
        "annotations": {
            "signal expertise": "The speaker explicitly states her own expertise and qualifications related to the task."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:58-02:00",
        "transcript": "Gergis.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:58",
        "end_time": "02:00",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Gergis Obaid",
        "timestamp": "02:01-02:25",
        "transcript": "Hi yes, so I'm Gergis Obaid. I'm assistant professor at University of Texas at Dallas. Been here about a year. I work predominantly on molecular targeted nanoparticles for photodynamic cancer therapy.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:01",
        "end_time": "02:25",
        "annotations": {
            "signal expertise": "Gergis explicitly states his position, institution, and research area, which can be seen as signaling his expertise or background."
        }
    },
    {
        "speaker": "Gergis Obaid",
        "timestamp": "02:25-02:25",
        "transcript": "Thank you, Alex.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:25",
        "end_time": "02:25",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:25-02:29",
        "transcript": "Thank you, Alex.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:25",
        "end_time": "02:29",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Alex Walsh",
        "timestamp": "02:29-02:52",
        "transcript": "Hi, I'm Alex. I'm at Texas A&M University and I do optical microscopy. Mostly looking at label free stuff, so molecules that are already in your cells like NADH and FAD to study cellular metabolism. And we do that for a variety of applications including drug response in cancer and studying laser tissue interactions.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 8,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:29",
        "end_time": "02:52",
        "annotations": {
            "signal expertise": "Alex explicitly states their own expertise and area of work, which is optical microscopy and its applications."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:52-02:53",
        "transcript": "Thank you and Lou.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:52",
        "end_time": "02:53",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Lu Wei",
        "timestamp": "02:56-03:22",
        "transcript": "I am Lou Wei. I'm assistant professor of chemistry here at Caltech. We perform optical imaging, particular vibrational microscopy on biological cells and we're interested in small molecule imaging mostly understanding the metabolic activities.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "02:56",
        "end_time": "03:22",
        "annotations": {
            "signal expertise": "The speaker is explicitly stating his own expertise and qualifications related to the task."
        }
    },
    {
        "speaker": "Lu Wei",
        "timestamp": "03:22-03:22",
        "transcript": "Thank you and Paris.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:22",
        "end_time": "03:22",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:23-03:24",
        "transcript": "Thank you and Paris.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:23",
        "end_time": "03:24",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Paris Perdikaris",
        "timestamp": "03:25-03:40",
        "transcript": "Hello, I'm at the University of Pennsylvania. My expertise is in computational science and machine learning. And basically I'm developing computational methods for modeling and simulation of biological systems with a focus on cardiovascular flows.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:25",
        "end_time": "03:40",
        "annotations": {
            "signal expertise": "Paris explicitly states his own expertise in computational science and machine learning."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:40-03:51",
        "transcript": "Thank you and we have five visitors which I was told hop in and out. Um if you would mind to say something you can or else we're going to get right to the purpose.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:40",
        "end_time": "03:51",
        "annotations": {
            "encourage participation": "Maryellen Giger is inviting the visitors to contribute to the discussion by saying 'if you would mind to say something you can'."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:51-03:51",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:51",
        "end_time": "03:51",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:51-04:06",
        "transcript": "We'll get right to the purpose. So, we have um oh next order is we need a recorder and who would also then present in three minutes for the group.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:51",
        "end_time": "04:06",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by transitioning to the main purpose and outlining next steps.",
            "assign task": "The speaker is assigning tasks to group members, specifically for a recorder and a presenter."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:06-04:22",
        "transcript": "Um, I could do it randomly or we can have a volunteer. Um you you should be able to get to the Google Drive and um this is great training when you're facilitating in your senior career cycle.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:06",
        "end_time": "04:22",
        "annotations": {
            "encourage participation": "The speaker encourages group members to participate by suggesting a developmental opportunity."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:26-04:35",
        "transcript": "Okay, should I close my eyes and pick on the screen and I end up on Shannon. Congratulations.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 55,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:26",
        "end_time": "04:35",
        "annotations": {
            "process management": "Maryellen Giger is managing the meeting flow by suggesting a method to randomly select a person for a task.",
            "assign task": "Maryellen Giger assigns the task of recording and presenting to Shannon.",
            "express humor": "Maryellen Giger makes a joke about randomly selecting Shannon for the task."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "04:37-04:37",
        "transcript": "So we're looking at",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:37",
        "end_time": "04:37",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:37-04:40",
        "transcript": "So we're looking at",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:37",
        "end_time": "04:40",
        "annotations": {
            "process management": "The utterance is managing the meeting flow by transitioning to the next item or agenda."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "04:40-04:40",
        "transcript": "the PowerPoint deck?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:40",
        "end_time": "04:40",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on what is being referred to as 'the PowerPoint deck'."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:40-04:47",
        "transcript": "Yes, so if you go to the and it's the if you you continue to around slide 20 or so you should you should find it should say um",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:40",
        "end_time": "04:47",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by providing instructions on navigating the presentation."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "04:54-04:55",
        "transcript": "It's 17 right now.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:54",
        "end_time": "04:55",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:55-05:01",
        "transcript": "Um, no probably a little past 20. 23.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:55",
        "end_time": "05:01",
        "annotations": {
            "process management": "The speaker is guiding the meeting process by specifying the slide number."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "05:02-05:03",
        "transcript": "Ah, yes.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:02",
        "end_time": "05:03",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or acknowledgment of the previous statement, which aligns with the definition of a supportive response."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "05:03-05:06",
        "transcript": "Okay. 20, 24 in fact. So yeah.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:03",
        "end_time": "05:06",
        "annotations": {
            "acknowledge contribution": "Shannon Quinn acknowledges Maryellen Giger's direction and provides feedback on the task given.",
            "supportive response": "Shannon Quinn expresses agreement and confirmation of understanding regarding the task to locate a specific part of the presentation."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:07-05:10",
        "transcript": "Is it supposed to be a separate recorder and um reporter?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:07",
        "end_time": "05:10",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on whether the roles of recorder and reporter are supposed to be separate.",
            "process management": "The speaker is managing the meeting flow by asking about roles and responsibilities."
        }
    },
    {
        "speaker": "Sandra Laney",
        "timestamp": "05:11-05:14",
        "transcript": "So is one taking the notes and one reporting?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:11",
        "end_time": "05:14",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on the roles of note-taking and reporting.",
            "None": "No other relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Richard Wiener",
        "timestamp": "05:15-05:27",
        "transcript": "One one person can do it and one person can do both, I think. Yeah, and you can take the notes, you don't have to put the notes into the PowerPoint yet, you can take those, share it with people, they can add and then can condense them into the PowerPoint so that there's one slide.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:15",
        "end_time": "05:27",
        "annotations": {
            "process management": "The speaker is suggesting a method for organizing meeting tasks, specifically how to handle note-taking and presenting.",
            "assign task": "The speaker is assigning responsibility for taking notes and potentially presenting, suggesting that one person can do both tasks."
        }
    },
    {
        "speaker": "Richard Wiener",
        "timestamp": "05:27-05:27",
        "transcript": "Sounds good.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:27",
        "end_time": "05:27",
        "annotations": {
            "Supportive Response": "This code applies because Richard Wiener is expressing agreement with a previous suggestion regarding note-taking and reporting."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:27-05:33",
        "transcript": "Okay, are you are you okay with that, Shannon?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:27",
        "end_time": "05:33",
        "annotations": {
            "process management": "The speaker is seeking confirmation or agreement from Shannon regarding a procedural arrangement about note-taking and reporting.",
            "ask question": "The speaker is also asking a question to Shannon, seeking her agreement or confirmation."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "05:33-05:33",
        "transcript": "Yep.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:33",
        "end_time": "05:33",
        "annotations": {
            "None": "The utterance 'yep' is a brief acknowledgment or agreement that does not explicitly fit into another category, and per guidelines, such brief responses are coded as 'None'."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:33-05:36",
        "transcript": "Okay, great, thank you.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:33",
        "end_time": "05:36",
        "annotations": {
            "Supportive Response": "This utterance expresses agreement and gratitude, serving as a supportive response to Shannon's previous agreement to take notes and possibly report."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:36-06:15",
        "transcript": "So now let's go in the beginning of the session, you all had the one minute to kind of collect your thoughts on the topics and we will start with the three bullets that are listed, but if any of you think that there's a major other bullet that you think would be useful to look into, we can go there too. One thing I drew from listening to all your introductions, we all do computational science.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:36",
        "end_time": "06:15",
        "annotations": {
            "process management": "The speaker is guiding the group on how to proceed with the session, suggesting they start with listed topics and inviting suggestions for additional ones.",
            "clarify goal": "The speaker identifies a common theme among the group members' introductions, noting that 'we all do computational science.'"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:15-06:19",
        "transcript": "Um, uh and it seems that some are at more of a macro scale, some are at micro scale.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:15",
        "end_time": "06:19",
        "annotations": {
            "summarize conversation": "Maryellen Giger's statement summarizes an observation from the introductions that participants work at different scales (macro and micro)."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:19-06:24",
        "transcript": "Um, and probably some work in 2D and some in 3D. But we all do computational science of images at one point.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:19",
        "end_time": "06:24",
        "annotations": {
            "Summarize Conversation": "The speaker is summarizing a common theme among the group members' research focuses.",
            "Develop Idea": "The speaker is also developing the idea that despite diverse scales and dimensions they work with, there's a commonality in their focus on computational science of images."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:24-06:36",
        "transcript": "So I I think we're um all in this together. So let's start with the first one, um 3D imaging can yield massive data sets too large to quantitate and fully scrutinize manually.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:24",
        "end_time": "06:36",
        "annotations": {
            "summarize conversation": "The speaker summarizes the collective interest in computational science.",
            "process management": "The speaker manages the discussion process by suggesting where to start.",
            "clarify goal": "The speaker clarifies the goal or topic of discussion by stating the challenge of 3D imaging data sets."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:36-06:41",
        "transcript": "What data are required to effectively train AI ML algorithms to assess these data sets.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:36",
        "end_time": "06:41",
        "annotations": {
            "ask question": "The utterance is a clear request for information about the data required for training AI ML algorithms to assess large data sets generated by 3D imaging."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:41-06:45",
        "transcript": "So how many of you do work with massive data sets?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:41",
        "end_time": "06:45",
        "annotations": {
            "ask question": "The speaker is requesting information from team members about their experience working with massive data sets."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:46-06:49",
        "transcript": "I know I do. Big, yeah.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:46",
        "end_time": "06:49",
        "annotations": {
            "Supportive Response": "The speaker is expressing agreement with the premise of the question, validating that she indeed works with massive data sets."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:50-06:50",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:50",
        "end_time": "06:50",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "06:58-07:00",
        "transcript": "Um, I have well.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:58",
        "end_time": "07:00",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:00-01:05",
        "transcript": "uh data or model adaptation to different data, right? So, uh what do I mean by this? So you train your data uh on one type of data set, say, you know, you do MRI scan, uh it has certain artifact patterns, you train the model on that. Now you apply to something else and we know that it doesn't work very well if, you know, you applied it to a configuration doesn't work. Now there are a bunch of ideas out there, uh you know, in in the computer vision community in the machine learning community where people try to bridge those things, but it's still not we don't yet have, you know, killer technology that allows us, you know, we don't understand both the limits of how we can adapt the models to different applications. At the same time, you know, what's the best way to do the adaptation of the models that we already pre-trained to a new application, right? So deep learning models are not traditional software in the sense that I can go and just edit it. It's all in the weights of the training thing. So how do we reuse, adapt uh those models.",
        "speaking duration": 65,
        "nods_others": 1,
        "smile_self": 10,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:00",
        "end_time": "11:05",
        "annotations": {
            "propose new idea": "The utterance introduces the concept of adapting models to different data sets and discusses challenges and potential approaches.",
            "develop idea": "Beck Kamilov elaborates on the challenges of adapting pre-trained models to new applications.",
            "identify gap": "The utterance highlights the current limitations in adapting models to different applications."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:06-01:22",
        "transcript": "So how do we use metrology to appropriately measure how we're doing in our development as well as in the end product so that it is generalizable? I think that's what you were getting at as well as say unbiased and fair.",
        "speaking duration": 16,
        "nods_others": 1,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:06",
        "end_time": "11:22",
        "annotations": {
            "clarify goal": "The speaker is seeking to understand how to measure progress and ensure generalizability, which involves clarifying goals or objectives.",
            "ask question": "The speaker is requesting information on using metrology for measurement, which is a clear request for information."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "01:23-01:23",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:23",
        "end_time": "11:23",
        "annotations": {
            "None": "The utterance is a simple acknowledgment without adding new content or explicitly fitting into any other category."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:24-01:24",
        "transcript": "Are those major topics that",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:24",
        "end_time": "11:24",
        "annotations": {
            "ask question": "Maryellen Giger is requesting information or clarification on whether certain topics are major, seeking input from the group."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "01:32-01:52",
        "transcript": "I think we should add kind of explainability to it too because in order to like uh focus more about the second part that what data are required to effectively train as we try to model and then create kind of some explanation to take away from that black box of how the algorithm is working.",
        "speaking duration": 20,
        "nods_others": 1,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
        "start_time": "11:32",
        "end_time": "11:52",
        "annotations": {
            "propose new idea": "The speaker introduces a new idea to add 'explainability' to their discussion.",
            "develop idea": "The speaker elaborates on the new idea by explaining its importance in understanding algorithm workings and data requirements for effective training."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "01:52-02:22",
        "transcript": "And then make it more explainable is going to help us to see what are the different information that the data is leading to give us our accurate output and then as we learn and as we try to make it more explainable, that's become a tools for us to just try to focus in the information that we need.",
        "speaking duration": 30,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
        "start_time": "11:52",
        "end_time": "12:22",
        "annotations": {
            "propose new idea": "The speaker introduces the concept of explainability as a means to improve the transparency and effectiveness of AI/ML algorithms.",
            "develop idea": "The speaker elaborates on how explainability can help in understanding and improving the algorithm's performance.",
            "clarify goal": "The speaker helps clarify the goal of making algorithms more effective and understandable through explainability."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:22-02:26",
        "transcript": "Okay, I I agree explainability and then to the end user interpretability.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
        "start_time": "12:22",
        "end_time": "12:26",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement with a previous suggestion.",
            "Develop idea": "The speaker is expanding on the idea by mentioning 'explainability' and 'interpretability.'"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:27-02:42",
        "transcript": "So, um Shannon, would you want to share your screen and we could all pull it over so we can still see each other, but that way we can give you is that useful or not? I don't know what notes you're taking, that's why.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
        "start_time": "12:27",
        "end_time": "12:42",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting a way for participants to collaborate and share information.",
            "encourage participation": "The speaker is encouraging Shannon to participate by sharing her screen and making her work open for feedback."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "02:43-02:50",
        "transcript": "I'm I'm unfortunately on Zoom on an iPad and taking notes on a desktop with the monitors right behind it.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:43",
        "end_time": "12:50",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:50-02:52",
        "transcript": "Ah.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:50",
        "end_time": "12:52",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "02:54-03:03",
        "transcript": "So, um I could turn it into a Google Doc that I can then share a link to with everybody in here if that would be preferable.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:54",
        "end_time": "13:03",
        "annotations": {
            "Supportive response": "The speaker is providing a solution that could facilitate group work by offering to convert notes into a Google Doc.",
            "Process management": "The speaker is suggesting a method to facilitate sharing notes, which relates to managing the meeting process."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:03-03:22",
        "transcript": "Because I like seeing everyone while we're having a discussion and I know I can kind of make the slide part very small and still see you all. Um but I think we need that visual feedback.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:03",
        "end_time": "13:22",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by suggesting how to share screens and notes for better collaboration.",
            "encourage participation": "The speaker is encouraging participation by suggesting a way to see each other during the discussion."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:22-03:24",
        "transcript": "So do you do you all want to do a uh Google Drive?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:22",
        "end_time": "13:24",
        "annotations": {
            "process management": "The speaker is suggesting the use of Google Drive for collaborative work, which pertains to managing the group's workflow and organization."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:24-03:26",
        "transcript": "Or do you want someone to",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:24",
        "end_time": "13:26",
        "annotations": {
            "ask question": "The speaker is requesting input or a preference from the group.",
            "encourage participation": "By asking for input, the speaker is encouraging group members to participate.",
            "process management": "The question relates to managing the meeting process, specifically note-taking or reporting."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:26-03:30",
        "transcript": "I'm comfortable with the Google Drive, uh Google Doc, Google Doc.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:26",
        "end_time": "13:30",
        "annotations": {
            "supportive response": "Beck Kamilov is expressing agreement with the suggestion to use Google Drive or Google Doc."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:30-03:45",
        "transcript": "Right, Google Doc, I'm sorry. So if you send that link in the chat, we can just click on it and then it's as if we're viewing the screen. That would be useful because",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:30",
        "end_time": "13:45",
        "annotations": {}
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "03:45-03:45",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:45",
        "end_time": "13:45",
        "annotations": {
            "acknowledge contribution": "Beck Kamilov is acknowledging Maryellen Giger's suggestion about using a Google Doc.",
            "supportive response": "Beck Kamilov is expressing agreement with Maryellen Giger's suggestion."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:45-03:46",
        "transcript": "Um",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:45",
        "end_time": "13:46",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:46-04:24",
        "transcript": "Does anyone have any other thoughts on the first bullet which is in a way kind of our discussion blended into the third bullet? You know, we talked about um what kind of errors, you know, if we think about errors that are acceptable, those are quantitated by the metrology of the system. how are you going to measure the performance? How are you going to measure the variation of your system? How will you measure how unbiased or general your system is?",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:46",
        "end_time": "14:24",
        "annotations": {
            "ask question": "The speaker is requesting thoughts and ideas from the group, which is a direct question seeking information.",
            "encourage participation": "By asking 'Does anyone have any other thoughts', the speaker is inviting group members to contribute their ideas and opinions."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "04:25-04:56",
        "transcript": "Yeah, I think I feel like since we're often imaging biological processes and looking at clinical images, um really knowing what ground truth is, um can be very challenging. Um it's not, you know, often the result might be correlated to pathology for example, if you're looking at cancer, but you don't really know that that pathology is accurate either.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
        "start_time": "14:25",
        "end_time": "14:56",
        "annotations": {
            "identify gap": "The speaker explicitly recognizes the challenge of determining 'ground truth' in their work, indicating a gap in knowledge or a clear reference point.",
            "develop idea": "The speaker elaborates on the challenge by providing a specific example related to cancer pathology, building upon previous discussion."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "04:57-05:07",
        "transcript": "Um do you think Carolyn that it's like having uh the expert lead on it or are you um like what would make it more true?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:57",
        "end_time": "15:07",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification from another team member on a prior statement."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "05:08-05:15",
        "transcript": "Um probably better images, right? Like since we're we're all looking at it with the image lens, right?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
        "start_time": "15:08",
        "end_time": "15:15",
        "annotations": {
            "develop idea": "She is expanding on the idea that image quality is crucial for accurate assessment.",
            "ask question": "She seeks agreement or confirmation from others with 'right?'"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:19-05:25",
        "transcript": "Yeah, when I think of imaging, I think of both acquisition and interpretation.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
        "start_time": "15:19",
        "end_time": "15:25",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of imaging by breaking it down into acquisition and interpretation, which elaborates on existing ideas discussed in the meeting."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:25-06:16",
        "transcript": "I think we have to go back to the application and what is the task? And I think the truth um I'm going to throw this out. So a lot of us probably do segmentation, right? And then you ask, well how do you evaluate it? Well, maybe you use a dice coefficient or something like that. But it there's also the more broader picture saying, well, my segment works depending on my final truth, which might be based on pathology.",
        "speaking duration": 51,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
        "start_time": "15:25",
        "end_time": "16:16",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas and discussing how to evaluate the performance of AI/ML algorithms in imaging, specifically in the context of segmentation and ground truth.",
            "clarify goal": "The speaker is defining and clarifying the objectives and success criteria for the group, emphasizing the importance of understanding the application and task."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:16-06:23",
        "transcript": "Um, just what do you think?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
        "start_time": "16:16",
        "end_time": "16:23",
        "annotations": {
            "ask question": "The speaker is requesting opinions or thoughts from other group members.",
            "encourage participation": "The utterance invites others to contribute their thoughts or opinions."
        }
    },
    {
        "speaker": "Girgis Obaid",
        "timestamp": "06:24-07:38",
        "transcript": "Well, I kind of I kind of agree with Carolyn's point about the uh ground truth, like what really is the ground truth? Um the way I see it is multiplexing the uh final yes no answer. So the input, let's say for example if it was histology, getting the manual input of the pathologist as well as some maybe molecular markers of the histological sections could be, you know, proteomics in addition to some genomic data, multiplexing the ground truth, well, getting working closer towards a ground truth by multiplexing the outputs at the end in order to train the intermediate. In my opinion is the best because I don't really know if there really is going to be a ground truth at that point because everything to a certain extent is either uh subjective to the observer if there's a pathologist or to uh experimental bias or fluctuations if you're going to get false positives or false negatives in the in the markers or the genomics themselves. So yeah, I'm I'm a little bit I'm kind of leaning more towards having building up the information at the at the end first in order to then bridge that gap because if you don't have that then it doesn't really make sense.",
        "speaking duration": 74,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "16:24",
        "end_time": "17:38",
        "annotations": {
            "propose new idea": "Girgis Obaid introduces a specific approach to dealing with the issue of ground truth by suggesting 'multiplexing the ground truth' through various means.",
            "develop idea": "Girgis Obaid builds upon Carolyn's point about ground truth, expanding the discussion by suggesting a method to approach this issue.",
            "ask question": "The utterance contains a question about what ground truth really is, seeking clarification or information on the concept."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:38-07:38",
        "transcript": "Sounds good.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:38",
        "end_time": "17:38",
        "annotations": {
            "Supportive Response": "The utterance 'Sounds good.' expresses agreement with previous suggestions, making it a supportive response."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:39-07:40",
        "transcript": "Um",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:39",
        "end_time": "17:40",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:41-08:21",
        "transcript": "I maybe I want to also bring up one thing. There is an interesting thing, the concept, right? Um in the so if you have errors in your ground truth and those errors are not systematic, meaning if you average them out across the whole data set, right? And then they average out to be a very small quantity, you can in principle train still with this form of errors and your model will not learn. So there is an interesting technical question there, what kind of errors are tolerable in the training data.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "17:41",
        "end_time": "18:21",
        "annotations": {
            "propose new idea": "The speaker introduces a new idea about considering errors in ground truth data and their impact on model training.",
            "develop idea": "The speaker expands on existing ideas by detailing the concept of systematic vs. non-systematic errors in ground truth data.",
            "ask question": "The speaker asks for discussion on what kind of errors are tolerable in the training data."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:21-08:21",
        "transcript": "Yeah.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:21",
        "end_time": "18:21",
        "annotations": {
            "None": "The utterance is a brief acknowledgment without adding new content or explicitly fitting into another category."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:22-08:55",
        "transcript": "Yeah, I think we need to train and test with messy data because that's what the real world is. And sometimes, you know, we can do initial development, it's we do initial development of a filter in continuous domain, um but then when we go to actual image domain is pixelated and quantized, it doesn't quite work, but it gets you maybe 80, 85% there. Um, you know, we start in the ideal world and then um make it work in the messy real world.",
        "speaking duration": 33,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:22",
        "end_time": "18:55",
        "annotations": {
            "develop idea": "The speaker expands on the idea of working with messy data and adapting models from ideal to real-world conditions, providing a practical perspective.",
            "clarify goal": "The utterance helps in defining what needs to be accomplished by emphasizing the importance of working with messy data to ensure the model's applicability in real-world scenarios."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "08:56-09:16",
        "transcript": "And by the way, anything like changes like this you just mentioned that pixelation changes. Those are the systematic things that you could in principle incorporate to this as non-trainable elements or adaptable elements of machine learning models.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "18:56",
        "end_time": "19:16",
        "annotations": {
            "develop idea": "The speaker is expanding on previous ideas about adapting machine learning models to new applications, specifically mentioning how to incorporate systematic changes like pixelation.",
            "offer feedback": "The speaker is providing a specific technical suggestion for handling pixelation changes in machine learning models."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:16-09:17",
        "transcript": "So",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "19:16",
        "end_time": "19:17",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "00:00-00:41",
        "transcript": "This is a major problem. I mean this problem and even uh it um the aspects about um the generalizability, um the bias that biases an AI is is really important. Um, what would you need to make this dream work? And I'm going to ask Lou. What what would take uh well maybe um you're more imaging than AI, right? Yeah, so I I well, you could take a pass if you want, but go ahead if you want to.",
        "speaking duration": 41,
        "nods_others": 0,
        "smile_self": 15,
        "smile_other": 3,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:41",
        "annotations": {
            "ask question": "The speaker is requesting information or expertise from Lou.",
            "encourage participation": "The speaker is inviting Lou to contribute his thoughts or ideas.",
            "develop idea": "The speaker is elaborating on the challenges and aspects of AI, specifically generalizability and bias."
        }
    },
    {
        "speaker": "Lu Wei Caltech",
        "timestamp": "00:41-02:45",
        "transcript": "Right, yeah, so I I'm more of imaging than AI. I'm here actually um trying to learn some um questions or or abilities for AI that could help us to interpretate uh imaging and do imaging segmentation. So um I'm new to the AI field. We're trying to adopting uh different networks for um um training and uh one part of the research in my lab is we do uh label free imaging um such that there's um a ton of uh images but not so much specific contrast. So we're trying to use an AI to allow us to uh do specific imaging. Um so I guess the question I have is uh there are a lot of different networks out there. Um well with with or specifically with very fine um um um differences. Um but there's not much of the benchmark um to allow us to compare um unless we're trying to use our own data to train it and then um to compare with of course different uh um um basically to adopt each of the techniques and compare it with our own data. Um before that there's really no way to know specifically what would be the best candidate for us. Um and also another thing um related to um I guess the uh um um validity of the interpretation is uh what kind of signal noise ratios do we need as both training set and also the prediction set and um is there any uh limitations on resolutions um that we should be aware of um before we do the um training. So so I guess I'm here more of to uh looking to the possibilities and asking questions then then providing some of the insights. Sorry about that.",
        "speaking duration": 124,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 1,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:41",
        "end_time": "22:45",
        "annotations": {
            "Ask question": "Lu Wei is asking questions about the requirements for signal-to-noise ratios and resolution limitations for AI training.",
            "Identify gap": "Lu Wei identifies a gap in their knowledge regarding AI applications and benchmarks for comparing networks.",
            "Signal expertise": "Lu Wei mentions their background in imaging, signaling their expertise in the area."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "02:45-03:00",
        "transcript": "Well no, I think that's very useful. You're telling us what you want and some of us in it in AI research and development kind of have to um work to uh uh give that to you. We we need to understand the end user.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:45",
        "end_time": "23:00",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and validation for the previous speaker's contribution.",
            "develop idea": "The speaker is building upon the previous idea by emphasizing the need to understand the end user in AI research and development."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:00-03:43",
        "transcript": "Because you know, earlier we talked about this pipeline of the AI pipeline, we we talked about for example segmentation, do you measure it while you're segmenting it or you look at the end point and the end point depends on the end user. And even if um even if it's an autonomous AI system, there's an end user somewhere. Somewhere it's affecting it and I think uh this field is still very young because a lot of the work being done is very um very focused.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:00",
        "end_time": "23:43",
        "annotations": {
            "develop idea": "The speaker is expanding on previous ideas about AI pipelines and evaluation.",
            "ask question": "The speaker is asking about measuring performance in AI tasks.",
            "clarify goal": "The speaker aims to understand and discuss the goals and challenges in AI pipeline evaluation."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "03:43-04:56",
        "transcript": "You know, you'll read the papers it was for this task with this database, maybe from different institutions, but it's just the the needle in a in a big haystack of all the other questions going on in medicine and biology. Um, but we can but many of the techniques, many of the metrology, the way to evaluate them, you know, how do you get around ground truth? Those I think there's um, I don't want to say a menu, but there is I think a short list and for me, um, though I have a lot of things that I would like in the world, I would like everyone to have access to this really clear short list of how how do I do all these things. Um, oh one of the things um I I don't want to forget before time goes by is we should look at bullet number two. And to me can can we extend our AI pipeline so it's very long, so it starts with acquisition, starts with the patient. In fact, someone thing by us is called closed loop imaging where this is that this is the what the patient needs, the patient gets it all the way to getting it and then doing the interpretation. To me that's you have to extend your AI to go through that entire pipeline.",
        "speaking duration": 73,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:43",
        "end_time": "24:56",
        "annotations": {
            "propose new idea": "The speaker suggests extending the AI pipeline to include the entire process from acquisition to interpretation.",
            "develop idea": "The speaker elaborates on the concept of a long AI pipeline and mentions 'closed loop imaging' as an example.",
            "ask question": "The speaker inquires about how to get around 'ground truth' and implies a need for a clear list of evaluation methods."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:56-04:56",
        "transcript": "Yes.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:56",
        "end_time": "24:56",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh, UCSC",
        "timestamp": "04:56-04:57",
        "transcript": "Yes, that makes me so happy.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:56",
        "end_time": "24:57",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and a positive sentiment towards a previous discussion, specifically showing happiness with an idea presented.",
            "express humor": "The speaker explicitly states that something makes them happy, indicating a positive emotional response."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "04:57-05:03",
        "transcript": "Oh, okay. Interesting. Okay, we have a happy group here. Good.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "24:57",
        "end_time": "25:03",
        "annotations": {
            "supportive response": "The speaker is expressing a positive sentiment towards the group's interaction.",
            "express humor": "The speaker makes a lighthearted comment about the group being 'happy.'"
        }
    },
    {
        "speaker": "Shiva Abbaszadeh, UCSC",
        "timestamp": "05:03-05:50",
        "transcript": "Yeah, I'm very excited to read, you know, like papers and then there are different groups that now thinking about kind of uh reconstructing the image, you know, using AI directly. And then since I usually work on kind of limited angle problem, so then I really uh think about how AI can just like really give us more information and then how we can even to interpret data that they are low dose and then we get kind of the information of higher dose. So I think that's um regarding this part, the question number two, I I think it's a very exciting time in the field and I'm really happy to learn and then implement them in my like research.",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:03",
        "end_time": "25:50",
        "annotations": {
            "develop idea": "The speaker elaborates on existing ideas by discussing how AI can be used for image reconstruction, especially in limited angle problems and with low-dose data.",
            "supportive response": "The speaker expresses excitement and positivity towards the application of AI in the field.",
            "identify gap": "The speaker implies a gap in current capabilities, particularly in interpreting low-dose data and limited angle problems."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:50-05:54",
        "transcript": "Great. So maybe optimizing along the pipeline individually and then the whole item.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:50",
        "end_time": "25:54",
        "annotations": {
            "Supportive response": "The utterance expresses a positive sentiment and suggests a strategy for moving forward.",
            "Develop idea": "The utterance expands on the idea of optimizing the pipeline, which has been a topic of discussion."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "05:54-06:05",
        "transcript": "Which includes acquisition and interpretation and then interpretation is by AI or human or AI aided human. But so patient um coming in for an imaging exam all the way to deciding the treatment.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:54",
        "end_time": "26:05",
        "annotations": {
            "Develop idea": "The speaker is expanding on the concept of the AI pipeline, specifically mentioning acquisition, interpretation, and the involvement of AI or human in interpretation.",
            "Supportive response": "The speaker is expressing agreement or validation with the previous discussion.",
            "Clarify goal": "The speaker is defining and clarifying objectives related to the AI pipeline."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "06:05-06:17",
        "transcript": "We got to do all that together as opposed we got everyone doing little niches here and there. So um that would be good. So yes, back.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:05",
        "end_time": "26:17",
        "annotations": {
            "Process Management": "The speaker is advocating for a collaborative approach to work, suggesting that everyone should work together rather than in isolated niches.",
            "Summarize Conversation": "The utterance summarizes the discussion point about the need for a unified, collaborative approach in their work."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:20-06:43",
        "transcript": "Uh I think one thing to think about in that context and you know, I'm very excited about that problem as well about, you know, the whole pipeline doing, but we need to think also about fragility of the system. Again, it comes back to generalization.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:20",
        "end_time": "26:43",
        "annotations": {
            "develop idea": "The speaker is expanding on previous ideas by mentioning the need to consider the fragility of the system and relating it back to generalization.",
            "supportive response": "The speaker expresses agreement or validation by stating they are excited about the problem, showing a positive evaluation.",
            "offer feedback": "The speaker provides a suggestion or perspective on how to approach the problem (considering fragility and generalization), which can be seen as a form of feedback."
        }
    },
    {
        "speaker": "Beck Kamilov (WashU)",
        "timestamp": "06:43-06:43",
        "transcript": "Right.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:43",
        "end_time": "26:43",
        "annotations": {
            "Supportive response": "The utterance 'Right.' is a supportive response as it indicates agreement with the previous discussion or statement."
        }
    },
    {
        "speaker": "Katy Keenan, NIST (she/her)",
        "timestamp": "06:44-07:39",
        "transcript": "There's a question around like um there's kind of a high barrier to entry as far as solving those sorts of problems because you want to have access to all the data types in order to solve that sort of problem. And uh like when you operate at a single institution, you're limited to the vendor system that you have access to. Or uh you know, in medical imaging when the vendors develop something, they're pulling it off of all of their own image sets and then it's not generalizable to the other vendors. So when I was, you know, thinking about the first bullet point, it was like uh like what data is required? I mean, you kind of want all the things. Uh and so I think that's a big challenge is how to and then how do we get it to people? Um there's a lot of access issues.",
        "speaking duration": 55,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:44",
        "end_time": "27:39",
        "annotations": {
            "identify gap": "The speaker highlights the challenge of limited access to diverse data types and the issue of generalizability across different vendor systems.",
            "develop idea": "The speaker is expanding on the ideas presented, discussing the challenges and limitations in medical imaging.",
            "ask question": "The speaker implicitly asks for solutions or thoughts on overcoming the challenges of data access and generalizability."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:39-07:41",
        "transcript": "So we want all the data.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:39",
        "end_time": "27:41",
        "annotations": {
            "summarize conversation": "The speaker summarizes a collective sentiment towards needing comprehensive data, reflecting on the discussion.",
            "clarify goal": "The utterance touches on clarifying the goal of having comprehensive data for training AI/ML algorithms."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:41-07:54",
        "transcript": "That's one of the they asked us what do we want? We want all the data and we you you there technically we could do a lot. We are limited by data and culture I would say. The giving of data, the sharing of data even.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:41",
        "end_time": "27:54",
        "annotations": {
            "identify gap": "The speaker mentions being limited by data and culture, identifying a gap in data availability and sharing.",
            "develop idea": "The utterance expands on the idea that data is crucial and that there are limitations to how much can be achieved without sufficient data."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:54-07:54",
        "transcript": "Right.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:54",
        "end_time": "27:54",
        "annotations": {
            "Supportive response": "The utterance 'Right.' is a minimal response indicating agreement or acknowledgment, which aligns with the definition of a supportive response."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "07:54-08:04",
        "transcript": "But if we had a massive method or so we we can do that. I saw Paris shaking his head. I think big mistake. So what are you thinking about?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "27:54",
        "end_time": "28:04",
        "annotations": {
            "ask question": "The speaker requests information or thoughts from Paris.",
            "encourage participation": "The speaker invites Paris to contribute his thoughts or opinions."
        }
    },
    {
        "speaker": "Katy Keenan, NIST (she/her)",
        "timestamp": "08:04-08:04",
        "transcript": "Oh.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:04",
        "end_time": "28:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Paris Perdikaris (UPenn)",
        "timestamp": "08:09-09:01",
        "transcript": "Uh it's a great discussion so far. I mean I'm a little bit on the less optimistic side on the front that you know, data and AI by alone will address all those issues. And perhaps one thing to think about is how we integrate domain knowledge into this pipeline in a way that is informative and gives us the right sort of prior information we need.",
        "speaking duration": 52,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:09",
        "end_time": "29:01",
        "annotations": {
            "critical response": "The speaker expresses concerns about relying solely on data and AI, indicating a critical view.",
            "propose new idea": "The speaker suggests integrating domain knowledge into the pipeline as an alternative approach."
        }
    },
    {
        "speaker": "Paris Perdikaris (UPenn)",
        "timestamp": "09:01-09:01",
        "transcript": "Yes.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "29:01",
        "end_time": "29:01",
        "annotations": {
            "Supportive response": "The speaker is expressing agreement with a previous statement, which is a positive evaluation without adding new content."
        }
    },
    {
        "speaker": "Maryellen Giger UChicago",
        "timestamp": "09:02-09:14",
        "transcript": "Yes, I to me domain knowledge, domain expertise, what you know, all of us here if we're in imaging and AI in biology or medicine, we are working in an interdisciplinary field.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "29:02",
        "end_time": "29:14",
        "annotations": {
            "Supportive response": "The utterance expresses agreement and validation of the interdisciplinary nature of the field.",
            "Develop idea": "The speaker is elaborating on the importance of domain knowledge and expertise."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:00-00:20",
        "transcript": "have many you all are smart, you all have great AI technologies, but I think we're looking at the issues of how do we bring it all together? Um, um, to me, that's the challenge. Alex, I haven't put you on the spot. I'm sorry, you're right in the middle of my screen and I keep going.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:20",
        "annotations": {
            "encourage participation": "The speaker is encouraging Alex to participate by mentioning not wanting to put him on the spot.",
            "supportive response": "The speaker is expressing a positive sentiment towards the group's capabilities.",
            "summarize conversation": "The speaker is summarizing the challenge of integrating technologies discussed in the conversation."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:21-00:22",
        "transcript": "Zoom has a question, no, Jim?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:21",
        "end_time": "30:22",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification about a question from Zoom or Jim.",
            "process management": "The utterance may also involve managing the meeting flow, but it's less direct."
        }
    },
    {
        "speaker": "Jim Mitchell",
        "timestamp": "00:23-00:51",
        "transcript": "Yeah, I have I have a question quickly. I know in other domains, um, you know, I know a lot about the Tesla autopilot work. The crowd sourcing of images and and so on has helped them a lot to improve that. Is there crowd sourcing going on here and and and where do those images end up residing that everybody could have access to the same large set of images?",
        "speaking duration": 28,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Raising Hand",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:23",
        "end_time": "30:51",
        "annotations": {
            "ask question": "The speaker is requesting information about crowd-sourcing and image storage.",
            "identify gap": "The speaker's question implies a recognition of a gap in their current approach regarding crowd-sourcing and shared image access."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:51-01:47",
        "transcript": "Uh, there is crowd sourcing in radiology. They do it at radiology meetings and also across the web where they they recruit some one project had over 180 radiologists who did multiple annotations on uh chest images. So they can do it. So and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to",
        "speaking duration": 56,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:51",
        "end_time": "31:47",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of crowd sourcing and its applications.",
            "supportive response": "The speaker is providing a supportive response by offering examples and context.",
            "encourage participation": "The speaker is encouraging participation by asking about experiences in cellular images.",
            "identify gap": "The speaker mentions being hindered by data and culture, indicating an awareness of limitations."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:47-02:02",
        "transcript": "so and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to people sit and circle cells. crazy just to create data and that gets back to bullet one. How many cells do you have to circle to have enough data to algorithm. Um, but yes, the crowd sourcing it does it does exist, but it's it's not on a massive um scale. Good point, Jim. And sorry I didn't see your hand ready. So I'm used to this, not the stationary one that they have on. Alex.",
        "speaking duration": 75,
        "nods_others": 0,
        "smile_self": 30.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:47",
        "end_time": "32:02",
        "annotations": {
            "develop idea": "The speaker elaborates on previous discussions about data and technical limitations.",
            "ask question": "The speaker asks how many cells need to be circled to have enough data for the algorithm.",
            "supportive response": "The speaker agrees with Jim's point.",
            "express humor": "The speaker uses humor when mentioning 'crazy just to create data'.",
            "encourage participation": "The speaker invites Alex to share their experience."
        }
    },
    {
        "speaker": "Jim Mitchell",
        "timestamp": "02:03-02:04",
        "transcript": "Thank you back.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:03",
        "end_time": "32:04",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Alex Walsh",
        "timestamp": "02:04-03:35",
        "transcript": "Yeah, we do a lot of circling cells. Um, yeah, we do auto fluorescence imaging, so it's low very low signal to noise and that creates a challenge for automated ways to process our data. And so we can see the patterns, but it's very hard to train traditional pipelines to do the segmentation. So that's why we've been working with AI. And actually, I really like Paris's point and you worded that much better than I was going to. Um, but my first interactions with AI and microscopy was stuff to for noise removal and um improving resolution and lowering laser power and stuff and I was just blown away by that work. And but I have right the same we know we know physical and biological boundaries on these conditions and I would like to see more integration of that into AI like if I'm segmenting a cell and it puts the nucleus, you know, right up against the edge of the cell, that's probably not where the nucleus is, right? It's more in the center. So how can we incorporate these things that we know um are are biological or physical boundaries and have the AI say like flag that oh that can't be right. Let's try again. Um, I think that gets into your errors, you know, what errors do we tolerate and how can we improve and minimize those.",
        "speaking duration": 91,
        "nods_others": 0,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:04",
        "end_time": "33:35",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of integrating physical and biological boundaries into AI for better segmentation.",
            "offer feedback": "The speaker is providing feedback on how to improve AI by suggesting the integration of biological boundaries.",
            "ask question": "The speaker is asking how to incorporate these boundaries into AI."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:36-04:00",
        "transcript": "I that's a a very good point. Um, when when I find when training AI, you should take advantage of a priori knowledge as well as what image are you inputting? Yes, one could say if I have infinite amount of data, infinite amount of truth, I can train it if I I just let it chug away, right?",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:36",
        "end_time": "34:00",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas by emphasizing the importance of a priori knowledge and the type of input data when training AI models.",
            "supportive response": "The utterance expresses agreement and validation of a previous point.",
            "offer feedback": "The speaker provides suggestions for how to approach training AI."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:00-04:16",
        "transcript": "But we don't have that especially in um the medical biomedical field, you know, you know, for things like image net, there's lots of pictures of cats and dogs and cars and light poles and all, but we don't have a lot of that annotated in the medical field even though we're generating so many medical images per day.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:00",
        "end_time": "34:16",
        "annotations": {
            "identify gap": "The speaker is explicitly recognizing the lack of annotated data in the medical field as a gap.",
            "develop idea": "The speaker is elaborating on the challenge of lacking annotated medical data for AI training, building on previous discussion."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:16-04:30",
        "transcript": "Um, and I I I I appreciate um these comments on the a priori because we we need to help the AI. I you know, sometimes I tell my students think like a human because if you know that um image presentation A is better for the human to look at than image presentation B.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:16",
        "end_time": "34:30",
        "annotations": {
            "develop idea": "The speaker is elaborating on the necessity of helping AI by incorporating human-like thinking, specifically mentioning the importance of image presentation.",
            "acknowledge contribution": "The speaker is acknowledging and appreciating comments made by others.",
            "supportive response": "The speaker is expressing agreement and validation for the discussion on incorporating a priori knowledge into AI."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:30-05:13",
        "transcript": "Why give the AI raw data? In a way, you're you're training in files, the training of all these humans has they have been reading images for many, many years. So how many of you in a sense consider what image am I giving to the AI and do you sometimes do the preprocessing to help the AI learn because you have limited data?",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:30",
        "end_time": "35:13",
        "annotations": {
            "ask question": "The speaker is asking questions about the approach of giving raw data to AI and about preprocessing to help AI learn.",
            "develop idea": "The speaker is expanding on an idea by questioning and relating it to human training and data preprocessing.",
            "encourage participation": "The speaker is encouraging others to consider and discuss their approach to giving data to AI."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:13-05:13",
        "transcript": "Caroline, what do you think of that?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:13",
        "end_time": "35:13",
        "annotations": {
            "encourage participation": "The speaker is inviting Caroline to contribute her thoughts or opinions to the discussion."
        }
    },
    {
        "speaker": "Carolyn Bayer",
        "timestamp": "05:13-06:05",
        "transcript": "Yeah, no, so I was nodding because um so I I'm also focused more on the imaging and instrumentation side. Um, but I work with collaborators that um do more of the sort of machine learning or, you know, neural network development. And um, you know, that's that definitely resonates that you have sometimes picked a data set to show a specific thing, right? Um, and that data set obviously then may not be representative of what that algorithm is actually going to encounter.",
        "speaking duration": 52,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:13",
        "end_time": "36:05",
        "annotations": {
            "Supportive Response": "The utterance expresses agreement and validation of the previous discussion, indicating a supportive tone.",
            "Develop Idea": "The utterance expands on the speaker's experience and thoughts related to machine learning and data sets.",
            "Identify Gap": "The utterance points out that data sets may not be representative of what an algorithm will encounter, identifying a gap in the current approach."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:06-06:21",
        "transcript": "So if we had our database, our messy database, we could include both, we can include them of different spatial resolution, we can include AI to do the reconstruction. Um, so Shannon, how's this list coming? It looks good. Looks longer than three minutes. It looks really good.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:06",
        "end_time": "36:21",
        "annotations": {
            "propose new idea": "The speaker suggests including different spatial resolutions and using AI for reconstruction.",
            "develop idea": "The speaker builds upon previous discussions about the database and AI.",
            "ask question": "The speaker asks Shannon about the status of the list."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "06:31-06:34",
        "transcript": "I'm trying to get the main points.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:31",
        "end_time": "36:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:34-06:41",
        "transcript": "Okay. Um, do you want us to go through? Do you want to kind of summarize for us and then we can so so the topic here is",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:34",
        "end_time": "36:41",
        "annotations": {
            "process management": "The speaker is managing the meeting flow by asking if the group wants to go through some materials and summarize before proceeding to discuss a topic."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:41-07:01",
        "transcript": "um what's the next big thing for this field? How can you what would be your dream of where it would go and um uh near the and I'll tell you how I've been trying to do my dream models.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:41",
        "end_time": "37:01",
        "annotations": {
            "encourage participation": "The speaker invites others to share their dreams or ideas for the field's future.",
            "ask question": "The utterance is a question about future directions and dreams for the field.",
            "clarify goal": "The speaker starts to clarify their own goal or vision for the field."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:01-07:03",
        "transcript": "Is it the open question?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:01",
        "end_time": "37:03",
        "annotations": {
            "ask question": "The speaker is explicitly requesting information or clarification on whether something is considered an open question."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:03-07:07",
        "transcript": "That's is it a clinical question? What do you mean on the",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:03",
        "end_time": "37:07",
        "annotations": {
            "ask question": "The speaker is seeking clarification or further information on a previous statement, explicitly asking for more details."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:07-07:14",
        "transcript": "I'm sorry. like are we discussing big big should we kind of",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:07",
        "end_time": "37:14",
        "annotations": {
            "ask question": "Beck Kamilov is seeking clarification on the discussion topic, indicating a request for information or direction."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:14-07:34",
        "transcript": "I think one thing that just was coming to my mind while we're discussing is like it would be amazing to have a recipe of how much data we need for a task. There is no recipe, you know, like you come to a problem, you say, I want to segment this thing.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:14",
        "end_time": "37:34",
        "annotations": {
            "identify gap": "The speaker recognizes a gap in current methodologies or knowledge regarding determining the necessary amount of data for tasks.",
            "propose new idea": "The speaker implies the need for a 'recipe' or guideline, suggesting a potential new approach to solving data quantity challenges."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:34-07:44",
        "transcript": "So, your collaborator asks, how much should I measure? Yeah. How much should I collect? Can anybody here answer?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:34",
        "end_time": "37:44",
        "annotations": {
            "ask question": "The speaker is seeking advice or information on the quantity of data needed for a task."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:44-07:54",
        "transcript": "Okay, now, how about if you know some prior information about the problem, say nucleus is in that position or that. Now, can this help me cut the data and by how much?",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:44",
        "end_time": "37:54",
        "annotations": {
            "ask question": "The utterance is a direct question asking for information or clarification.",
            "develop idea": "The speaker is exploring an idea of using prior information to potentially reduce data collection."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:54-07:54",
        "transcript": "Well",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:54",
        "end_time": "37:54",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "07:54-07:54",
        "transcript": "Right.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:54",
        "end_time": "37:54",
        "annotations": {
            "Supportive response": "This utterance expresses agreement with a previous statement, indicating a supportive response."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:55-08:01",
        "transcript": "I guess I guess for me I actually want to take it one step further and almost",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:55",
        "end_time": "38:01",
        "annotations": {
            "propose new idea": "The speaker is indicating a desire to extend or move beyond the current discussion point, suggesting a potential new direction or idea.",
            "None": "No other codes seem directly applicable as the speaker does not explicitly develop an idea, ask a question, or signal expertise in this partial utterance."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "08:01-08:04",
        "transcript": "almost take data out of the equation entirely and",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:01",
        "end_time": "38:04",
        "annotations": {
            "Propose new idea": "The speaker introduces a novel suggestion about minimizing or eliminating data from the equation, potentially offering a new approach to solving problems in AI and imaging."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "08:04-08:10",
        "transcript": "let me let me explain a bit where we've been talking a lot about",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:04",
        "end_time": "38:10",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "08:10-09:54",
        "transcript": "you know, we need a lot of data, we need a lot of ground truth. Given an infinite amount of data, um that was an interesting point to me because I still wonder like would the model still learn what we wanted to learn? And I'm not I hesitate before answering and I feel like that hesitation by itself says that even our models aren't quite there yet and that maybe more data isn't exactly the problem that we're looking at. Maybe I just I keep I keep thinking of like these new methods involving self-supervised learning and few shot learning and anomaly detection where it's less about how much data you can throw at the problem and more about how we can build this architecture that without it becoming kind of a handcrafted algorithm has very specific features that it looks for. And so as a result, you don't need this lengthy training process, you don't need terabytes and terabytes of data, but what you can have to again sort of inform the end user if they don't have enough data is some sort of uncertainty quantification at the end. So for instance, if you're trying to do some kind of segmentation and you have your data set, you don't necessarily need to do a kind of calculation of how much data do I need, you just kind of give it to the algorithm, the algorithm does its few shot semi or self-supervised training and then at the end of that spits out, okay, here's the segmentation that I did and here's my certainty that it's correct.",
        "speaking duration": 104,
        "nods_others": 0,
        "smile_self": 20.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:10",
        "end_time": "39:54",
        "annotations": {
            "propose new idea": "Shannon suggests considering alternative approaches to traditional data-heavy model training methods.",
            "develop idea": "Shannon elaborates on the potential of new methods like self-supervised learning, few-shot learning, and anomaly detection.",
            "ask question": "Shannon questions if a model would still learn what is intended even with an infinite amount of data.",
            "identify gap": "Shannon notes that current models may not be adequate, indicating a gap in AI capabilities."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "09:54-09:58",
        "transcript": "Do do we also need the certainty on the certainty so that we can trust the certainty?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "39:54",
        "end_time": "39:58",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on the necessity of certainty about AI output certainty."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:00-00:18",
        "transcript": "actually talk about having, you know, let's say the algorithm says, uh, you have 65% chance of having cancer, I am 35% sure and I am a slightly biased algorithm. So those are the three outputs I usually like, um, because",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 11,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:18",
        "annotations": {
            "develop idea": "The speaker is expanding on the concept of algorithm output to include certainty and acknowledgment of bias.",
            "identify gap": "The speaker implies a gap in current algorithm capabilities regarding providing certainty and acknowledging potential bias."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:19-00:22",
        "transcript": "Well I agree with that but I don't trust the 35%. How would I trust that 35",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:19",
        "end_time": "40:22",
        "annotations": {
            "critical response": "The speaker is questioning the reliability of the algorithm's uncertainty measure, implying a need for more robust confidence metrics.",
            "offer feedback": "The speaker is indirectly suggesting that the algorithm should provide more trustworthy or understandable measures of uncertainty."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:22-00:23",
        "transcript": "All right, but that's what the 35",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:22",
        "end_time": "40:23",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "00:23-00:29",
        "transcript": "that's what the 35% except if it actually has a true statistical meaning that's non Gaussian and I don't know.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:23",
        "end_time": "40:29",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of interpreting statistical outputs from AI models.",
            "ask question": "The speaker is requesting clarification on the statistical meaning of a 35% confidence level.",
            "critical response": "The speaker is questioning the validity and interpretation of statistical outputs."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:29-00:52",
        "transcript": "Right. You have to do the reproducibility, repeatability studies to get that. But that's telling you that the computer is only 35%. It's like you go to the your doctor's office and he says like, you know, you got 85% sure chance you have a chipped tooth, but I'm only 20% sure. How do you feel? So that's what but the AI has to also kind of do that. I I agree.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:29",
        "end_time": "40:52",
        "annotations": {
            "Supportive response": "The speaker agrees and builds upon previous statements, providing a supportive response to the discussion.",
            "Develop idea": "The speaker elaborates on the concepts of reproducibility studies and uncertainty in AI outputs.",
            "Express humor": "The speaker uses a humorous analogy about a doctor's office to make a point about AI uncertainty."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:52-01:17",
        "transcript": "Uh Shannon, that's a um, uh, I I think that's definitely what kind of outputs do you want? And I think that will differ for if you're doing um AI on biological images for discovery or are you doing it for a patient output. I'm going to ask um, um, more folks to talk here. I don't know what when do we finish? I just want to make sure we're not running out of time.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:52",
        "end_time": "41:17",
        "annotations": {
            "ask question": "She asks for clarification on the kind of outputs desired.",
            "encourage participation": "She intends to ask more folks to talk.",
            "process management": "She is concerned about managing the meeting time."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "01:19-01:54",
        "transcript": "I always, you know, I mentioned I I like to think like a human and I think the inputs and the outputs should be very similar. I'm a big fan of handcrafted. In fact, I I think it's the world will not just be all deep learning. I grew up with handcrafted and I now incorporate deep learning and I merge them.",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:19",
        "end_time": "41:54",
        "annotations": {
            "develop idea": "She is elaborating on her perspective, developing ideas previously mentioned in the conversation.",
            "signal expertise": "Maryellen Giger is sharing her experience and perspective.",
            "clarify goal": "She is discussing her perspective on the goals or approaches in AI development."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "01:54-02:20",
        "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access, but then like we have to. We have to find a way to just get to that.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
        "start_time": "41:54",
        "end_time": "42:20",
        "annotations": {
            "identify gap": "Shiva recognizes a problem with accessing necessary information or resources.",
            "propose new idea": "Shiva suggests involving funding agencies or hospitals to solve the access problem.",
            "acknowledge contribution": "Shiva seconds Katie's point about the difficulty in accessing information."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:20-02:25",
        "transcript": "Okay, yes, and when I say think like a human, I'm thinking more of input and output.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:20",
        "end_time": "42:25",
        "annotations": {
            "clarify goal": "The speaker is clarifying her previous statement about thinking like a human, focusing on input and output."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:26-03:26",
        "transcript": "Um, but if you think how radiologist are that their job is to interpret medical images. And what how do they get trained? First as a resident, they have a textbook and they go through that textbook and they learn this is what a cancer looks like. This that's handcrafted. Get a little hand waving here. And then they sit with their attending radiologist and they read day in and day out and they're told, oh, you're wrong. No, that's a false positive. That's the deep learning and that's of the radiologist brain. And then we have different structures of the brain. Some are really good at finding Waldo and weirds Waldo and some aren't. Maybe they shouldn't have been radiologist. Just like there's probably computer vision AI algorithms that way.",
        "speaking duration": 60,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:26",
        "end_time": "43:26",
        "annotations": {
            "develop idea": "The speaker elaborates on how radiologists are trained, comparing it to the development of AI algorithms.",
            "express humor": "The speaker makes a humorous comparison between radiologists' varying skills and finding Waldo.",
            "signal expertise": "The speaker demonstrates her knowledge of radiology training and its parallels with AI."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:26-03:37",
        "transcript": "And I I think the example of giving the AI algorithm an image that radio humans find easier to read could save you a lot of training time and data when you're doing your AI. How many of you train on medical images? I think Katie does and Shannon and Shiva.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:26",
        "end_time": "43:37",
        "annotations": {
            "develop idea": "Maryellen Giger is expanding on a concept related to training AI algorithms with specific types of images.",
            "ask question": "She directly asks the group how many of them train on medical images.",
            "encourage participation": "By asking who trains on medical images, she is inviting group members to contribute their experiences."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "03:37-03:39",
        "transcript": "We're using like a DICOM.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:37",
        "end_time": "43:39",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:39-04:26",
        "transcript": "A DICOM. But say for example with um breast MRI, you could have DICOM fields of the raw data, you could have it showing subtracted images after uptake of a contrast, you could have a image where you've collapsed it into a MIP. We find for example inputting the MIP gives you better performance than inputting just the subtraction image or and and things like if you have volume data, do you input the volume data or do you input the slices of the volume data. All those are before you even get to your algorithm and I don't know if people spend enough time on that. That's how I see it. Um, have you run into that?",
        "speaking duration": 47,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:39",
        "end_time": "44:26",
        "annotations": {
            "propose new idea": "The speaker introduces a new perspective on data preparation for AI analysis by discussing different methods of inputting data.",
            "develop idea": "The speaker elaborates on the concept of data preparation by giving examples of different input methods for AI algorithms.",
            "ask question": "The speaker asks for others' experiences or thoughts on the matter of data preparation for AI algorithms."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:26-04:26",
        "transcript": "How do you decide what goes into your algorithm?",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:26",
        "end_time": "44:26",
        "annotations": {
            "ask question": "The speaker is requesting information on how decisions are made about what goes into an algorithm."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:26-04:37",
        "transcript": "I mean between the volumetric and slices it's easy it depends how much volumetric examples I have. Usually I have like 10 volumetric examples and each one has hundreds of slices or thousands of slices and I go by slices.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:26",
        "end_time": "44:37",
        "annotations": {
            "develop idea": "The speaker is elaborating on their approach to data analysis, discussing how they decide to use volumetric examples or slices based on the data they have.",
            "signal expertise": "The speaker is sharing their experience and approach, indicating their familiarity with the topic of data analysis in imaging."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:40-04:41",
        "transcript": "But the format.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:40",
        "end_time": "44:41",
        "annotations": {
            "ask question": "The speaker is seeking clarification on the format."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:42-04:45",
        "transcript": "Oh you mean the way the data is stored in the format?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:42",
        "end_time": "44:45",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on the format of the data."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:45-04:46",
        "transcript": "Right. What are well, not the format.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:45",
        "end_time": "44:46",
        "annotations": {
            "ask question": "The speaker is seeking clarification on what aspects are being referred to, excluding the format.",
            "clarify goal": "The question indirectly seeks to clarify the goal or focus of the discussion regarding data beyond just the format."
        }
    },
    {
        "speaker": "Beck Kamilov",
        "timestamp": "04:46-04:56",
        "transcript": "That's like application collaborator dependent, right? Uh, well for me at least it's uh depends what's application, so that tells me the format.",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:46",
        "end_time": "44:56",
        "annotations": {
            "develop idea": "The speaker is elaborating on how the format of data is determined by the application.",
            "offer feedback": "The speaker is providing insight based on their experience."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:56-04:57",
        "transcript": "Right.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:56",
        "end_time": "44:57",
        "annotations": {
            "Supportive Response": "The utterance 'Right.' is a supportive response as it expresses agreement with the previous statement."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "05:00-05:11",
        "transcript": "I think it's a little bit as a barrier because I don't think that you we have enough resources to answer some of those questions. Sometimes they're still driven by what you have access to.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:00",
        "end_time": "45:11",
        "annotations": {
            "identify gap": "The speaker explicitly mentions a lack of resources as a barrier to answering questions, indicating a gap in current capabilities."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:11-05:24",
        "transcript": "So if you were to ask me how do I figure out what to input to the network, my answer would be I sit with the radiologist. I sit with the domain expert on imaging. I sit with the human AI instrument.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:11",
        "end_time": "45:24",
        "annotations": {
            "develop idea": "She is expanding on the idea of figuring out what to input to the network by suggesting collaboration with experts.",
            "signal expertise": "Maryellen Giger is explicitly stating her own approach and suggesting it as a method, which implies she is signaling her expertise.",
            "supportive response": "She is providing a positive and helpful response.",
            "offer feedback": "She is offering feedback on how to approach the problem."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:24-05:25",
        "transcript": "I use human human aided AI development.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:24",
        "end_time": "45:25",
        "annotations": {
            "clarify goal": "The speaker is describing her approach to AI development, indicating her goal involves human-aided processes."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "05:25-05:36",
        "transcript": "And not all of us are in a place where we can do that. Right? Like I'm not at a medical institution. And so how do I get that access? How do I that's not a resource I have.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:25",
        "end_time": "45:36",
        "annotations": {
            "ask question": "The speaker is asking how to access certain resources, explicitly questioning how to get that access.",
            "identify gap": "The speaker identifies a gap in resources or capabilities, specifically mentioning not being at a medical institution and lacking access to certain resources."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:36-05:36",
        "transcript": "Okay, so",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:36",
        "end_time": "45:36",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:36-05:37",
        "transcript": "Right.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:36",
        "end_time": "45:37",
        "annotations": {
            "None": "The utterance is a brief acknowledgment without additional content."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:37-06:12",
        "transcript": "Okay, well that's that's major. To me, that's a barrier. You um AI developers need um um need that. I I get that access all the time that's why I like where I am, but um that's that's really important that the network network needs to connect the AI developer with the domain expert of that imaging task.",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:37",
        "end_time": "46:12",
        "annotations": {
            "identify gap": "Maryellen Giger explicitly recognizes a barrier or gap in the current process of AI development for imaging tasks.",
            "process management": "Maryellen Giger highlights the importance of connecting AI developers with domain experts as part of managing the AI development process."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:12-06:13",
        "transcript": "It it it will save you tons of time.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:12",
        "end_time": "46:13",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and positive evaluation that connecting AI developers with domain experts will save time."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:13-06:15",
        "transcript": "What about Shannon and Shiva? How do you get your images?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:13",
        "end_time": "46:15",
        "annotations": {
            "ask question": "The speaker is requesting information from Shannon and Shiva about how they obtain their images."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:15-06:17",
        "transcript": "Are you have domain expert issues?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:15",
        "end_time": "46:17",
        "annotations": {
            "ask question": "The speaker is requesting information about Shannon and Shiva's experience with domain expert issues.",
            "encourage participation": "The speaker is inviting Shannon and Shiva to share their experiences, encouraging participation in the discussion."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "06:18-07:14",
        "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, if you want coffee, I bring you coffee and then when you are sitting in the reading room just please, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access.",
        "speaking duration": 56,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
        "start_time": "46:18",
        "end_time": "47:14",
        "annotations": {
            "identify gap": "Shiva explicitly mentions a problem with access, indicating a gap in current practices or resources.",
            "propose new idea": "Shiva suggests that if funding agencies or hospitals recognized the importance of their work, it could help solve the problem.",
            "supportive response": "Shiva seconds Katie's point about it being hard to get access, showing agreement."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "07:14-07:14",
        "transcript": "Yes.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
        "start_time": "47:14",
        "end_time": "47:14",
        "annotations": {
            "acknowledge contribution": "The speaker is acknowledging a prior statement, showing agreement.",
            "supportive response": "The speaker is expressing agreement, which is a form of positive evaluation."
        }
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "07:14-07:31",
        "transcript": "But then like we have to. We have to find a way to just get to that. So then if we had more infrastructure to provide a path for that, it could be really great.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
        "start_time": "47:14",
        "end_time": "47:31",
        "annotations": {
            "propose new idea": "The speaker suggests developing infrastructure to provide a path for AI development in medical imaging.",
            "identify gap": "The speaker identifies a lack of infrastructure as a current gap.",
            "supportive response": "The utterance expresses a positive and constructive tone towards solving the problem."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:31-07:32",
        "transcript": "Okay, this yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:31",
        "end_time": "47:32",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:32-07:32",
        "transcript": "I think",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:32",
        "end_time": "47:32",
        "annotations": {
            "None": "No relevant code applies to this incomplete utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:32-07:33",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:32",
        "end_time": "47:33",
        "annotations": {
            "supportive response": "The speaker is expressing agreement or acknowledgment of a previous statement."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:33-07:34",
        "transcript": "Okay, good.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:33",
        "end_time": "47:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:34-07:34",
        "transcript": "Um",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:34",
        "end_time": "47:34",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:34-07:35",
        "transcript": "Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:34",
        "end_time": "47:35",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:35-07:35",
        "transcript": "Okay, good.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:35",
        "end_time": "47:35",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:35-07:36",
        "transcript": "We've got 20 minutes.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:35",
        "end_time": "47:36",
        "annotations": {
            "process management": "The speaker is informing the group about the time left in the meeting, which is an act of managing the meeting flow."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:36-07:37",
        "transcript": "Thankfully.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:36",
        "end_time": "47:37",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:37-07:38",
        "transcript": "I would not be able to throw that together.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:37",
        "end_time": "47:38",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:38-07:38",
        "transcript": "Okay.",
        "speaking duration": 0,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:38",
        "end_time": "47:38",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges a prior statement or contribution."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:38-07:41",
        "transcript": "I think you're doing a great job here, Shannon. Shannon, where do you see things can be move merged?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:38",
        "end_time": "47:41",
        "annotations": {
            "supportive response": "The speaker is expressing a positive evaluation of Shannon's performance.",
            "ask question": "The speaker is seeking Shannon's opinion on where things can be merged."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:41-07:42",
        "transcript": "Where do you have the domain expert issue?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:41",
        "end_time": "47:42",
        "annotations": {
            "Ask question": "The speaker is requesting information about where group members have domain expert issues.",
            "Identify gap": "The speaker is highlighting a gap in resources or support related to domain experts.",
            "Encourage participation": "The speaker is inviting group members to share their experiences with domain expert issues."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:01-00:37",
        "transcript": "Yeah, that to me that's a night and day um that helps you. I I I um I always, you know, feel for you guys that in that situation. How about the biology people, the image people doing AI on bio imaging, biological imaging, cellular imaging. What's what's holding you up? You have access I would assume to biologist much easier than they have access to medical imaging people. Alex, do you have access to who you need to talk to? And then also Girgis, I can ask.",
        "speaking duration": 36,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 11.1,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:01",
        "end_time": "50:37",
        "annotations": {
            "ask question": "The speaker is seeking information about the challenges faced by others in the group, specifically regarding their access to domain experts for AI-related tasks in biological imaging.",
            "encourage participation": "The speaker invites specific individuals, Alex and Girgis, to contribute their thoughts or expertise, encouraging their participation in the discussion."
        }
    },
    {
        "speaker": "Alex Walsh",
        "timestamp": "00:38-00:45",
        "transcript": "Yeah, I think my limitations are how much data do I need and we already have that on there.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
        "start_time": "50:38",
        "end_time": "50:45",
        "annotations": {
            "identify gap": "Alex explicitly states a limitation or gap they are facing, which is the need for data."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:46-00:49",
        "transcript": "Okay, so you have your domain experts. You have your biologist right there.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:46",
        "end_time": "50:49",
        "annotations": {
            "None": "No relevant code directly applies to this utterance"
        }
    },
    {
        "speaker": "Alex Walsh",
        "timestamp": "00:50-00:51",
        "transcript": "Right. Yeah.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
        "start_time": "50:50",
        "end_time": "50:51",
        "annotations": {
            "supportive response": "The speaker is expressing agreement with a previous statement, indicating a positive evaluation without adding new content."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "00:51-00:53",
        "transcript": "Girgis, do you have that?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:51",
        "end_time": "50:53",
        "annotations": {
            "ask question": "The speaker is requesting information from Girgis about having access to something needed."
        }
    },
    {
        "speaker": "Girgis Obaid",
        "timestamp": "00:53-02:39",
        "transcript": "Yeah, well, so so our our approach uh at least machine learning from a completely different perspective. So we collaborate with some folks here uh trying to understand how nanoparticles will accumulate into tumors and what that actually means. And the problem at least from the perspective of the the domain experts is not necessarily that yes, this is a tumor, but it's more about the technology that's being developed. So if you use a a certain type of particle or contrast agent and suggest that this is tumor selective, the interpretation that's being presented at least in the primary literature is very biased by a lot of um I guess you could you could say misinterpretation that's that's been perpetuated over a couple of decades. So people will assume that certain types of materials will always accumulate in tumors and if it does, then yes, we have a tumor. So the problem is not necessarily just on the on the image interpretation side, but it's more about the the contrast agent itself. And so the way that we approach it is that the input that we need needs to be built up as well. It's not just a contrast agent, but it's more using some nanotech experts to suggest that okay, well, this contrast agent will also accumulate similarly to another contrast agent. So you have to put um a second uh piece of information into the input of the algorithm itself to suggest that if you see this kind of a trend, this is a false positive. So you're teaching it what a false positive is based on the material that you're using as a contrast agent right from the very start from the get go so that you don't end up with false positives at the end. So it's we're kind of more on the front end of things and and and in my field the domain experts that are lacking is more on the on the material well nanobio interaction side of things.",
        "speaking duration": 106,
        "nods_others": 1,
        "smile_self": 10.4,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:53",
        "end_time": "52:39",
        "annotations": {
            "develop idea": "Girgis is expanding on their approach to machine learning for tumor imaging, explaining the challenges and how they address them.",
            "identify gap": "Girgis identifies a gap in domain expertise, specifically in the nanobio interaction side of things.",
            "clarify goal": "Girgis discusses the goal of accurately interpreting images to understand nanoparticle accumulation in tumors."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "02:40-02:47",
        "transcript": "So you're doing your AI based on knowledge of known biology and chemistry? Would that be correct wording?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:40",
        "end_time": "52:47",
        "annotations": {
            "ask question": "The speaker is requesting clarification or information about whether Girgis Obaid's AI is based on knowledge of known biology and chemistry."
        }
    },
    {
        "speaker": "Girgis Obaid",
        "timestamp": "02:47-03:47",
        "transcript": "It's it's more about so it's it's hard for me to to explain without going into details. But let's let's take nanoparticle contrast agents um for optical imaging. That's one of the things that we look into. And there are clinical trials that suggest that you can use these contrast these nanoparticles as contrast agents for positive tumor detection and image guided surgery. And that's all very well and good. You can see the image, you can probably use AI to delineate the uh tumor boundary to be a little bit better. But there are secondary biological factors um that contribute to errors that haven't been considered right at the start. So we try and hit it on both ends, not just what the image actually tells us, but what the agent that we're administering, how that's going to interact with the tissue and how that then contributes to a false positive. And so then feeding in information about what false positive materials or materials that give false positives is actually going to look like when you finally get the image.",
        "speaking duration": 60,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "52:47",
        "end_time": "53:47",
        "annotations": {
            "develop idea": "The speaker elaborates on the challenges of using nanoparticle contrast agents and the importance of considering secondary biological factors.",
            "identify gap": "The speaker identifies a gap in current approaches regarding the consideration of secondary biological factors that contribute to errors.",
            "offer feedback": "The speaker provides insights into how to improve current methods by suggesting a more comprehensive approach to error consideration."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "03:49-04:14",
        "transcript": "So I always think of AI as having two types of components. One is where it's model driven where it has these physical limitations, chemistry limitations, but it when biology um where it's it's model driven and um the model is built on these principles. You could use deep learning in it, but in the end you have these constraints on it.",
        "speaking duration": 25,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:49",
        "end_time": "54:14",
        "annotations": {
            "develop idea": "The speaker elaborates on her perspective about AI, discussing its two types of components.",
            "clarify goal": "The speaker aims to provide clarity on her understanding or approach to AI by categorizing it."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:14-04:52",
        "transcript": "The other type of AI is in general you can think of it as statistical, you know, it's the deep learning, it's um uh having the machine actually learn and I personally believe that in the future we need a mixture of these. I think it would be extremely interesting to have like um both types applied to your situation Girgis because you have you know, a lot of times it's hard to find the person with the model. You know, it's um but how do you want to bring that point up in this this Google Doc?",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:14",
        "end_time": "54:52",
        "annotations": {
            "propose new idea": "The speaker suggests applying both types of AI to Girgis's situation, indicating a new approach.",
            "ask question": "The speaker asks Girgis how he would like to bring this point up in the Google Doc, requesting information or opinion.",
            "develop idea": "The speaker elaborates on her belief about the future need for a mixture of AI types and its potential application."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "04:52-04:53",
        "transcript": "Help us, where would you put it and how would you put it?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:52",
        "end_time": "54:53",
        "annotations": {
            "encourage participation": "The speaker is inviting others to contribute their thoughts or ideas.",
            "process management": "The speaker is seeking input on how to manage the process of adding content to a Google Doc."
        }
    },
    {
        "speaker": "Girgis Obaid",
        "timestamp": "04:54-05:00",
        "transcript": "I I guess it probably it probably ties in with the with the ground truth to a certain extent.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "54:54",
        "end_time": "55:00",
        "annotations": {
            "develop idea": "The speaker connects their previous point about the interaction between nanoparticles and biological systems to the concept of ground truth in AI model development.",
            "clarify goal": "The utterance helps in understanding how Girgis's point ties into the larger discussion on ground truth and AI model development."
        }
    },
    {
        "speaker": "Girgis Obaid",
        "timestamp": "05:00-05:16",
        "transcript": "But maybe the generalizability part of things. And again, I I see it from a whole different perspective. I know a lot of folks here use um patient images, but I'm talking more about the generalizability again of the contrast agent and how that will behave.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:00",
        "end_time": "55:16",
        "annotations": {
            "develop idea": "The speaker is expanding on the idea of generalizability, specifically in the context of contrast agents.",
            "identify gap": "The speaker touches upon the challenge of generalizability, which can be seen as identifying a gap in current approaches."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:16-05:22",
        "transcript": "So it's something relationship of the model to the physics chemistry and biology of the imaging situation.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:16",
        "end_time": "55:22",
        "annotations": {
            "clarify goal": "The speaker is reflecting on the importance of the relationship between the model used in imaging and the physics, chemistry, and biology of the imaging situation, which clarifies the goal of integrating these aspects into their work."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "05:22-05:23",
        "transcript": "I guess so.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:22",
        "end_time": "55:23",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "05:23-05:25",
        "transcript": "Sorry, where is my cursor?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "55:23",
        "end_time": "55:25",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:00-06:03",
        "transcript": "Well, I see a little red dock by the word generalizable.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:00",
        "end_time": "56:03",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "06:04-06:10",
        "transcript": "Oh, that's that's not me. But yeah. Um sorry, I was I was trying to",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 16.7,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:04",
        "end_time": "56:10",
        "annotations": {
            "None": "The utterance consists of brief expressions of acknowledgment and apology without adding new content or explicitly fitting into any of the defined codes."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:10-06:11",
        "transcript": "Yeah, you sure can. Everybody can.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:10",
        "end_time": "56:11",
        "annotations": {
            "supportive response": "The speaker is expressing agreement and positive evaluation for other group members' contributions."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "06:11-06:23",
        "transcript": "Um sorry, the people are editing the presentation and I'm not able to make any changes. That's what I've been trying to figure out.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:11",
        "end_time": "56:23",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:23-06:34",
        "transcript": "So no one hits save. How's that? It kicks people in other groups. Shannon, if you want, I can add the names so that you can focus on the conversation.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:23",
        "end_time": "56:34",
        "annotations": {
            "process management": "The speaker is suggesting a way to manage the collaboration process to avoid disruptions.",
            "assign task": "The speaker offers to add names, which can be considered as assigning or taking on a task."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "06:34-06:39",
        "transcript": "Yeah, thank you added it and they all got lost.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:34",
        "end_time": "56:39",
        "annotations": {
            "acknowledge contribution": "The speaker acknowledges another person's action (adding names) and provides feedback on the outcome."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "06:39-06:43",
        "transcript": "Yep. Yeah. Yeah, so I can do that.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:39",
        "end_time": "56:43",
        "annotations": {
            "None": "The utterance is a brief agreement and acknowledgment without adding new content."
        }
    },
    {
        "speaker": "Katy Keenan",
        "timestamp": "06:43-06:46",
        "transcript": "Okay, thank you.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:43",
        "end_time": "56:46",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "06:46-06:52",
        "transcript": "Yeah and are you able to open up your the slide deck to put in at least the final three points?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:46",
        "end_time": "56:52",
        "annotations": {
            "Process Management": "The speaker is managing the flow of tasks and directing someone to update the slide deck.",
            "Assign Task": "The speaker is assigning or reminding someone of their task to update the slide deck with at least the final three points."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "06:52-07:11",
        "transcript": "No, that's what I'm talking about. The Google Doc is fine. Please edit away there. It's the slide deck that keeps kicking me out every time I try to make an edit.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:52",
        "end_time": "57:11",
        "annotations": {
            "acknowledge contribution": "Shannon Quinn acknowledges the previous discussion or statement about the documents and responds to it.",
            "offer feedback": "Shannon provides feedback on the current state of the Google Doc and the slide deck, highlighting an issue with the latter."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:11-07:14",
        "transcript": "So what if you just take yeah, okay.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:11",
        "end_time": "57:14",
        "annotations": {
            "supportive response": "The utterance expresses agreement or a positive sentiment.",
            "process management": "The utterance relates to managing the flow of discussion or tasks."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:14-07:34",
        "transcript": "Can you download the PowerPoint to your computer? Um I'm actually just going to draft I'm going to draft it out in the Google Doc. Okay. Okay. Um Now I forgot what um",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:14",
        "end_time": "57:34",
        "annotations": {
            "ask question": "The speaker requests an action (downloading the PowerPoint).",
            "process management": "The speaker is managing the workflow by suggesting an alternative action (drafting in Google Doc)."
        }
    },
    {
        "speaker": "Shannon Quinn",
        "timestamp": "07:20-07:21",
        "transcript": "You were going to mention something about generalizability.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:20",
        "end_time": "57:21",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification on a prior statement about generalizability."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:34-07:55",
        "transcript": "Yes, well model driven by the um physics chemistry and biology of the um uh contrast agents properties? I don't know if I got that right.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:34",
        "end_time": "57:55",
        "annotations": {
            "ask question": "The speaker is explicitly asking for confirmation or clarification on their understanding of a previous point about model-driven approaches in AI."
        }
    },
    {
        "speaker": "Girgis Obaid",
        "timestamp": "07:56-07:58",
        "transcript": "Yeah, that that's that pretty much.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:56",
        "end_time": "57:58",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "07:58-08:00",
        "transcript": "knowledge wrong?",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:58",
        "end_time": "58:00",
        "annotations": {
            "ask question": "The speaker is requesting information or clarification about the correctness of some knowledge."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:08-08:09",
        "transcript": "Okay, good.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:08",
        "end_time": "58:09",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:09-08:17",
        "transcript": "So I think we we all as a group um um maybe uh Paris.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:09",
        "end_time": "58:17",
        "annotations": {
            "Encourage participation": "The speaker is attempting to involve Paris in the conversation.",
            "Process management": "The utterance manages the flow of conversation by possibly transitioning to a new point or involving someone new."
        }
    },
    {
        "speaker": "Paris Perdikaris",
        "timestamp": "08:18-08:21",
        "transcript": "Yeah, I think",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:18",
        "end_time": "58:21",
        "annotations": {
            "None": "No relevant code applies to this utterance"
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "08:21-08:22",
        "transcript": "We got to bring this down to three bullets.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:21",
        "end_time": "58:22",
        "annotations": {
            "process management": "Maryellen Giger instructs the group to bring their discussion down to three bullets, managing the meeting's flow and structure."
        }
    },
    {
        "speaker": "Paris Perdikaris",
        "timestamp": "08:22-09:11",
        "transcript": "Uh, sure, maybe one comment that just to follow up to what you what was just discussed, which may be interesting is I totally agree with you that, you know, kind of the future lies in this hybrid approach where statistical learning or purely data driven learning will be interfaced with model based uh principles and domain knowledge. Now the question is to get us there, obviously, you know, one cannot expect that we can just take an algorithm developed to classify dogs and cats and that will work. So and also we cannot expect that the computer scientist will learn chemistry and biology and will actually develop this specialized system.",
        "speaking duration": 49,
        "nods_others": 0,
        "smile_self": 10.2,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:22",
        "end_time": "59:11",
        "annotations": {
            "supportive response": "Paris agrees with a previous point and builds upon it.",
            "develop idea": "Paris suggests a hybrid approach combining statistical learning with model-based principles and domain knowledge."
        }
    },
    {
        "speaker": "Paris Perdikaris",
        "timestamp": "09:11-09:23",
        "transcript": "So the only question is who do we train and how do we train them to work in this interface and contribute the tools that we need in the future.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "59:11",
        "end_time": "59:23",
        "annotations": {
            "process management": "The speaker is discussing the process of training individuals to work with the interface and contribute to the tools needed in the future.",
            "encourage participation": "The speaker is inviting input from others on how to train individuals to work with the new tools and interface."
        }
    },
    {
        "speaker": "Maryellen Giger",
        "timestamp": "09:23-09:26",
        "transcript": "So you're saying the tools, the AI tools are not good enough?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "59:23",
        "end_time": "59:26",
        "annotations": {
            "ask question": "The speaker is asking for confirmation or clarification on whether the current AI tools are not sufficient."
        }
    },
    {
        "speaker": "Paris Perdikaris",
        "timestamp": "09:26-10:00",
        "transcript": "Well, I'm saying that that the way things have been working is we borrow a system that is successful in classifying dogs and cats and now we're trying to use it to segment cancer cells. And maybe that works to some extent, but if we want to sort of develop more specialized systems that bring in this domain knowledge and you know, um are tailored or more specialized to a given task, who is going to do this and who has the expertise to do this and how do we train people to actually have that expertise to to do that.",
        "speaking duration": 34,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "59:26",
        "end_time": "60:00",
        "annotations": {
            "develop idea": "The speaker is expanding on existing ideas, discussing the limitations and potential future directions of current AI approaches in medical imaging.",
            "ask question": "The utterance contains questions about who will develop more specialized systems and how they will be trained, which implies a request for information.",
            "critical response": "The speaker is providing a critique of current approaches, suggesting they are insufficient for the task at hand.",
            "clarify goal": "The speaker is discussing the goal of developing more specialized AI systems that can incorporate domain knowledge."
        }
    }
]