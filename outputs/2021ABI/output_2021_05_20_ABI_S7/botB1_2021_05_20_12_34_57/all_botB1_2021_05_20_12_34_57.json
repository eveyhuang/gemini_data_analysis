[
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:00-00:10",
        "transcript": "your name so Josh doesn't have to type your name into the slides, so you can keep it open, you can also monitor um and if you feel like something is missed then you can, you know, call it out. Um",
        "speaking duration": 10,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:00",
        "end_time": "00:10",
        "annotations": {
            "assign task": "Kristen assigns the task of monitoring the meeting and calling out anything missed to someone, so Josh doesn't have to type their name into the slides."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "00:10-00:17",
        "transcript": "we're going to know that this is going to be our file. So is it separate groups in that folder?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:10",
        "end_time": "00:17",
        "annotations": [
            {
                "explain or define term or concept": "The speaker is trying to understand the file structure, which can be seen as defining or clarifying the file organization concept.",
                "ask clarifying question": "The speaker is asking a question to clarify how the files are organized within the folder."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:17-00:37",
        "transcript": "Um, so if you open up the the Google slides, I think we can all edit at the same time. Josh can keep track of the main um bullet points that we want to report out on. Um but at least you can go in and put your name in on that list.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:17",
        "end_time": "00:37",
        "annotations": {
            "explain or define term or concept": "The speaker is explaining how to use Google Slides for collaborative editing.",
            "assign task": "The speaker assigns Josh the task of keeping track of the main bullet points.",
            "encourage particpatioin": "The speaker encourages everyone to edit the slides and add their names to the list."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:37-00:58",
        "transcript": "The other thing I was thinking is that um if we're going to report out on key points from our discussion, I am sure that there are other topics of discussion that will come up that might fall off that list of key points. Um maybe Richard who's on on in our room can um make a comment. Are we supposed to put those other ideas into the parking lot or just keep them ourselves or record them somewhere else?",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:37",
        "end_time": "00:58",
        "annotations": {
            "ask clarifying question": "The speaker is asking whether ideas that fall outside the key points should be put in the parking lot, kept to themselves, or recorded elsewhere, seeking clarification on the procedure for handling these ideas.",
            "encourage particpatioin": "The speaker is encouraging Richard to make a comment, inviting him to contribute to the discussion."
        }
    },
    {
        "speaker": "Richard Weiner",
        "timestamp": "00:59-01:18",
        "transcript": "either of those things you can do. If you think they're really valuable to put in the parking lot, please do. You can keep them for yourselves. I suggest Josh take some notes on the side which he can share with people and then you at the very end of the meeting you added it into the key points for the discussion and just have a lot of fun in the discussion.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "00:59",
        "end_time": "01:18",
        "annotations": {
            "explain or define term or concept": "Richard is explaining what to do with ideas that are not key points, clarifying the options available to the team.",
            "propose decision": "Richard suggests Josh take notes on the side to share with people, proposing a concrete action for Josh.",
            "encourage particpatioin": "Richard encourages the team to have fun in the discussion, promoting a positive and collaborative environment."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:18-01:25",
        "transcript": "Okay, sounds perfect. Okay, does anyone have any questions before we take our minute to think?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:18",
        "end_time": "01:25",
        "annotations": {
            "confirm decision": {
                "Explanation": "Kristen confirms that Richard's suggestions about handling additional discussion points are acceptable."
            },
            "encourage particpatioin": {
                "Explanation": "Kristen invites anyone to ask questions before they take a minute to think, encouraging participation."
            }
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "01:25-01:38",
        "transcript": "Uh, I have a quick logistic question. So the slide is uh is called psi log ABI meeting slides. And then where are we supposed to put our names? Is it slide 16 session 1.4?",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:25",
        "end_time": "01:38",
        "annotations": {
            "ask clarifying question": "Sixian is asking for clarification on where to put their names on the slides, which is a logistical detail related to the meeting."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "01:38-01:42",
        "transcript": "I already copied and pasted all of our names in there, so we're good on names.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:38",
        "end_time": "01:42",
        "annotations": {
            "confirm decision": "Josh confirms that he has already taken care of adding everyone's names to the slides, finalizing the task and indicating that it's been completed."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:42-01:44",
        "transcript": "Okay. It's slide 22.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:42",
        "end_time": "01:44",
        "annotations": {
            "explain or define term or concept": "Kristen is clarifying the location of the slide where names should be placed, which is slide 22, in response to a question about where to put names."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "01:45-01:47",
        "transcript": "Oh, slide 22. Okay, perfect. Thank you.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:45",
        "end_time": "01:47",
        "annotations": {
            "acknowledge contribution": "Sixian You acknowledges Kristen Maitland's contribution of providing the correct slide number.",
            "confirm decision": "Sixian You confirms that slide 22 is the correct slide, finalizing the information."
        }
    },
    {
        "speaker": "Richard Weiner",
        "timestamp": "01:48-01:55",
        "transcript": "And I'll be jumping in and out through through a few rooms. So if I leave, uh don't worry about it and I'll be quiet the rest of the way.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:48",
        "end_time": "01:55",
        "annotations": {
            "explain or define term or concept": "Richard is explaining his role and actions during the meeting, clarifying that he will be moving between rooms and that his absence should not be a concern.",
            "encourage particpatioin": "Richard is encouraging the team to continue their discussion without worrying about his presence or absence."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:55-01:56",
        "transcript": "Okay. Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:55",
        "end_time": "01:56",
        "annotations": {
            "acknowledge contribution": "Kristen acknowledges Richard's contribution after he explained how to handle additional discussion topics and offered logistical support."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:57-02:14",
        "transcript": "Okay, so I'm going to set a timer for one minute for you each to think about your topic related to uh super resolution methods. We were given two kind of prompt questions, but I think you have other ideas and other questions that you think you might want to ask. So I'll just we'll have one minute of silence for thinking.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "01:57",
        "end_time": "02:14",
        "annotations": [
            {
                "encourage particpatioin": "Kristen encourages the team to think about their topic and other ideas or questions they might want to ask related to super resolution methods, building on the previous discussion about the meeting's structure and goals."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:28-03:55",
        "transcript": "Um, so one thing I'll say is that I'll just ask if anyone would like to start the conversation. Um I'm going to try and keep an eye out on if there's someone that is not contributing and I will call on you at a certain point just to make sure we hear from everyone. Um and I do ask that you be respectful of other people's time and so um if you do feel like you're contributing quite a bit that's excellent, but maybe make sure that everyone has a chance to speak.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:28",
        "end_time": "03:55",
        "annotations": [
            {
                "encourage particpatioin": "Kristen is explicitly asking if anyone would like to start the conversation, encouraging participation.",
                "assign task": "Kristen is assigning herself the task of monitoring participation and calling on people to ensure everyone contributes.",
                "explain or define term or concept": "Kristen is explaining the expectation of being respectful of other people's time and ensuring everyone has a chance to speak."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:55-03:58",
        "transcript": "Okay. So who would like to get started?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:55",
        "end_time": "03:58",
        "annotations": {
            "encourage particpatioin": "Kristen is explicitly asking for someone to start the conversation, encouraging participation from the group."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "03:59-04:03",
        "transcript": "I can get started on one of the topics.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "03:59",
        "end_time": "04:03",
        "annotations": {
            "offer constructive criticism": "Sixian You is offering to start the discussion on one of the topics, which can be seen as a constructive way to move the meeting forward."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "04:03-05:27",
        "transcript": "Uh, I really like the second question, how can we mitigate or utilize multiple scattering when we transition this technique to in vivo applications? I think there are two ways to think about it. So if we are talking about like traditional super resolution techniques like optics, uh multiple scattering is the enemy because they scramble your light. So the first way to think about it is how can we gate these multiple scattering? How can we reject them so that we can only get ballistic photons that carry the truly valuable information. And then a second direction, a second perspective on this is how do we use multiple scattering to get more information? Because these ballistic photons decay exponentially as you go deeper into the tissue.",
        "speaking duration": 84,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "04:03",
        "end_time": "05:27",
        "annotations": {
            "present new idea": "The speaker introduces the idea of mitigating or utilizing multiple scattering when transitioning super-resolution techniques to in vivo applications, which is a novel concept in the context of the discussion.",
            "expand on existing idea": "The speaker expands on the initial question by suggesting two ways to think about it: gating/rejecting multiple scattering and using multiple scattering to get more information.",
            "explain or define term or concept": "The speaker explains that in traditional super-resolution techniques like optics, multiple scattering is detrimental because it scrambles light, providing context for the subsequent discussion.",
            "provide supporting evidence": "The speaker provides supporting evidence by stating that ballistic photons decay exponentially as you go deeper into the tissue, justifying the need to utilize multiple scattering for more information."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "05:27-05:28",
        "transcript": "That's great and thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:27",
        "end_time": "05:28",
        "annotations": {
            "express agreement": "Sixian expresses agreement with the previous turn, which was Sixian's own contribution, showing self-affirmation.",
            "acknowledge contribution": "Sixian acknowledges their own contribution, expressing gratitude for their own input."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:29-05:34",
        "transcript": "And I just realized that we did not introduce ourselves first. So uh Sixian, why why don't you start and introduce yourself?",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:29",
        "end_time": "05:34",
        "annotations": {
            "acknowledge contribution": "Kristen acknowledges Sixian's contribution by saying \"That's great and thank you\" in the previous utterance.",
            "encourage particpatioin": "Kristen encourages Sixian to start by introducing themselves to the group."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:34-05:47",
        "transcript": "We'll go around, make sure we just it'll be a very brief so your name and institution which we can see, but um a brief uh introduction of your background and what perspective you have on this topic in particular.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:34",
        "end_time": "05:47",
        "annotations": {
            "explain or define term or concept": "Kristen is explaining the format of the introductions, specifying that they should include name, institution, background, and perspective on the topic.",
            "encourage particpatioin": "Kristen is encouraging everyone to introduce themselves and share their perspectives on the topic."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "05:50-06:08",
        "transcript": "Um, my name is Sixian Yo. I just started at MIT uh three months ago, two months ago. Uh my lab develops optically imaging technologies especially for microscopy applications. We are interested in using optics and algorithms to solve real world biomedical problems.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "05:50",
        "end_time": "06:08",
        "annotations": {
            "explain or define term or concept": "Sixian is introducing himself and his lab's focus on optical imaging technologies for microscopy applications, providing context for his perspective on the topic."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:09-06:10",
        "transcript": "Thank you. Uh Dylan.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:09",
        "end_time": "06:10",
        "annotations": {
            "acknowledge contribution": "Kristen thanks Sixian for their introduction, acknowledging their contribution to the conversation.",
            "encourage particpatioin": "Kristen then calls on Dylan to participate, encouraging them to introduce themselves as well."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:11-06:37",
        "transcript": "Hi, I'm uh Dylan Burnette. I'm uh an associate professor at Vanderbilt University. I just got tenure so I'm technically now not uh new, although I feel new still. I have new people problems.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:11",
        "end_time": "06:37",
        "annotations": [
            {
                "explain or define term or concept": "Dylan introduces himself and his position at Vanderbilt University, providing context about his background for the discussion."
            },
            {
                "express humor": "Dylan makes a lighthearted comment about getting tenure and having 'new people problems', adding a touch of humor to his introduction."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:37-06:54",
        "transcript": "Um, I am a cell biologist by training and I've been using light microscopy for about 20 years now studying everything from neuroscience to cancer and now I work on heart. So I'm very interested in how the heart grows on a single cell level.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:37",
        "end_time": "06:54",
        "annotations": {
            "explain or define term or concept": "Dylan is providing background information about his expertise, which includes his training as a cell biologist and his experience with light microscopy, to provide context for his perspective on the topic.",
            "present new idea": "Dylan introduces his interest in how the heart grows on a single cell level, which is a new topic within the context of his introduction."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:54-06:56",
        "transcript": "And we combine everything from very low mag imaging",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:54",
        "end_time": "06:56",
        "annotations": {
            "expand on existing idea": "Dylan is building on the topic of super resolution methods, adding details about his work and imaging techniques."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:56-07:00",
        "transcript": "to super resolution imaging and electron microscopy to attack our problems. So",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "06:56",
        "end_time": "07:00",
        "annotations": {
            "expand on existing idea": "Dylan is expanding on his introduction by listing the different imaging techniques he uses, building on his earlier statement about his background and research interests."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:00-07:02",
        "transcript": "the problem is very simple and general.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:00",
        "end_time": "07:02",
        "annotations": {
            "explain or define term or concept": "Dylan is setting the stage for his contribution by characterizing the problem they are addressing, which is a general concept explanation."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:02-07:04",
        "transcript": "How does a heart muscle cell",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:02",
        "end_time": "07:04",
        "annotations": {
            "explain or define term or concept": "Dylan is explaining his research area, which involves studying heart muscle cells, to provide context for his perspective on super-resolution methods."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:04-07:06",
        "transcript": "get bigger. That's it.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:04",
        "end_time": "07:06",
        "annotations": {
            "explain or define term or concept": "Dylan is explaining the problem he is trying to solve, which is how a heart muscle cell gets bigger."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:06-07:07",
        "transcript": "It's pretty complicated it turns out.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:06",
        "end_time": "07:07",
        "annotations": {
            "express humor": "Dylan makes a humorous remark about the complexity of the problem he's studying, following his introduction of his research on heart muscle cell growth."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:07-07:08",
        "transcript": "But that's our question.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:07",
        "end_time": "07:08",
        "annotations": {
            "explain or define term or concept": "Dylan is explaining the central question his lab is trying to answer, which is how a heart muscle cell gets bigger, to provide context for his perspective on super-resolution methods."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:39-07:40",
        "transcript": "Great, thank you. Aseema?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:39",
        "end_time": "07:40",
        "annotations": {
            "acknowledge contribution": "Kristen acknowledges Dylan's introduction and contributions to the discussion.",
            "encourage particpatioin": "Kristen invites Aseema to introduce herself and contribute to the discussion."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "07:40-07:41",
        "transcript": "Hi, I'm Aseema Mohanty.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:40",
        "end_time": "07:41",
        "annotations": {
            "None": "This utterance is a simple introduction and does not fit any of the defined codes."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "07:41-07:42",
        "transcript": "Um, I",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:41",
        "end_time": "07:42",
        "annotations": {
            "encourage particpatioin": "Kristen Maitland called on Aseema to introduce herself and her background, so Aseema is starting to speak."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "07:42-08:00",
        "transcript": "I've recently started as a faculty at Tufts University in Boston. Um and I work on uh nanophotonics. Um so that's like chip scale optics and so um uh we've been kind of working on um optical phase arrays and creating 3D structured light from a chip.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "07:42",
        "end_time": "08:00",
        "annotations": [
            {
                "explain or define term or concept": "The speaker explains that nanophotonics is like chip scale optics to provide clarity on their area of expertise."
            }
        ]
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "08:00-08:02",
        "transcript": "Um and so my kind of",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:00",
        "end_time": "08:02",
        "annotations": {
            "None": "This utterance is incomplete and does not express a complete idea, decision, or question, so no code applies."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "08:02-08:17",
        "transcript": "perspective on super resolution is is there anything that we can do to kind of, you know, handle some of the limitations of bulk um optics or high NA objectives and miniaturize that to make it kind of feasible for um more portable applications.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:02",
        "end_time": "08:17",
        "annotations": {
            "present new idea": "Aseema introduces a novel concept of handling limitations of bulk optics or high NA objectives and miniaturizing them for portable applications, which hasn't been discussed before in this specific context."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "08:17-08:18",
        "transcript": "Okay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:17",
        "end_time": "08:18",
        "annotations": {
            "acknowledge contribution": "The utterance \"Okay\" acknowledges the previous speaker's introduction and perspective on super-resolution, without expressing agreement or expanding on the ideas."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:18-08:19",
        "transcript": "Thank you. Josh.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:18",
        "end_time": "08:19",
        "annotations": {
            "encourage particpatioin": "Kristen Maitland is inviting Josh to introduce himself and his background, continuing the round of introductions."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "08:39-08:41",
        "transcript": "Um, hi, I'm Luke Mortenson.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:39",
        "end_time": "08:41",
        "annotations": {
            "None": "This utterance is simply introducing himself and does not fit any of the codes."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "08:41-08:43",
        "transcript": "I'm assistant professor at the University of Georgia.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:41",
        "end_time": "08:43",
        "annotations": {
            "None": "This utterance is simply introducing himself and does not fit any of the codes."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "08:43-08:47",
        "transcript": "Um, although I will be an associate as of July 1st, so I'm kind of in the intermediate space of still feeling new.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:43",
        "end_time": "08:47",
        "annotations": {
            "express humor": "Luke makes a lighthearted comment about his upcoming promotion and still feeling new, which is intended to be humorous."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "08:47-08:53",
        "transcript": "Um, but um, uh uh my lab is primarily focused on uh multiphoton imaging.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:47",
        "end_time": "08:53",
        "annotations": {
            "explain or define term or concept": "Luke is explaining his lab's focus on multiphoton imaging, which provides context for his perspective on super-resolution methods."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "08:53-09:01",
        "transcript": "Um, so we do um like two photon, we're moving look towards like second harmonic, third harmonic generation type stuff.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "08:53",
        "end_time": "09:01",
        "annotations": {
            "expand on existing idea": "Luke is building on the topic of super-resolution methods by adding details about the specific types of multiphoton imaging his lab uses, including two-photon, second harmonic, and third harmonic generation."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "09:01-09:15",
        "transcript": "Um, and we're looking at moving to kind of like near IR wavelengths to get um I guess 1300, 1700 to kind of like pure deeper into tissue and also some scattering correction approaches.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:01",
        "end_time": "09:15",
        "annotations": {
            "expand on existing idea": "Luke is expanding on his lab's focus on multiphoton imaging by adding that they are looking at moving to near IR wavelengths to penetrate deeper into tissue and use scattering correction approaches, building upon his earlier introduction of his background."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "09:15-09:26",
        "transcript": "Um, um I guess our application is looking at bone and muscle regeneration primarily. Um, so we're looking at like a bone wound healing and um",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:15",
        "end_time": "09:26",
        "annotations": {
            "expand on existing idea": "Luke is expanding on his introduction by providing more details about the applications his lab is working on, specifically bone and muscle regeneration, building upon his earlier mention of multiphoton imaging."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "09:26-09:44",
        "transcript": "muscle dynamics, um looking at mitochondria, organelles like that. And also focusing on uh therapeutic stem cells. So for both of those like muscle bone applications, um trying to design MSC therapies and bio manufacture those.",
        "speaking duration": 18,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:26",
        "end_time": "09:44",
        "annotations": {
            "expand on existing idea": "Luke is expanding on his introduction by providing more details about the specific applications of his multiphoton imaging research, including muscle dynamics, mitochondria, and therapeutic stem cells, building upon his earlier statement about bone and muscle regeneration."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:45-09:46",
        "transcript": "Thank you. Matt?",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "09:45",
        "end_time": "09:46",
        "annotations": {
            "encourage particpatioin": "Kristen Maitland is explicitly inviting Matt to introduce himself and his background, continuing the round-robin introductions."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "00:00-00:36",
        "transcript": "understanding chemical and biochemical dynamics in at the nanoscale. Uh, one of the things that that we really pushed recently is basically leveraging uh signals that are other than just brightness to to understand what's happening at the nanoscale. So for us, a lot of it is uh fluorescence polarization, um, to understand how molecules are organized, not just where they are, but how the structures are arranged, for example, uh with applications to uh understanding lipid architectures and also uh amyloid protein structures as well. Thank you.",
        "speaking duration": 36,
        "nods_others": 1,
        "smile_self": 11,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:00",
        "end_time": "10:36",
        "annotations": {
            "explain or define term or concept": "The speaker explains their lab's focus on leveraging signals beyond brightness, specifically fluorescence polarization, to understand nanoscale chemical and biochemical dynamics, providing context to their perspective on super-resolution methods.",
            "expand on existing idea": "The speaker expands on their lab's focus by providing specific examples of applications, such as understanding lipid architectures and amyloid protein structures, building upon the initial explanation of their research interests."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:36-00:39",
        "transcript": "Stefan?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "10:36",
        "end_time": "10:39",
        "annotations": {
            "encourage particpatioin": "Kristen Maitland is explicitly inviting Stefan to introduce himself and his background, continuing the round-robin introductions."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "00:40-01:29",
        "transcript": "Hi, my name is Stefan. I'm from the University of Oklahoma. I'm in biomedical engineering. Um, I'm trained as a chemist. Um now I'm in my fourth year as a assistant professor and my research group focuses on nanomedicine, so applying nanotechnology for treatment and diagnosis of um cancer specifically and we are interested in understanding um the transport of drug carriers and small molecule drugs through the body and how those drug carriers interact with cells. So for this super resolution information is is really the key to understand those transport pathways.",
        "speaking duration": 49,
        "nods_others": 1,
        "smile_self": 1,
        "smile_other": 1,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the text Biomedical Nano-Engineering Lab and the website https://wilhelm-lab.com. It also shows the logo for the Gallogly College of Engineering and the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
        "start_time": "10:40",
        "end_time": "11:29",
        "annotations": {
            "explain or define term or concept": "Stefan explains his research group's focus on nanomedicine, specifically applying nanotechnology for cancer treatment and diagnosis, which provides context for his perspective on super-resolution methods.",
            "present new idea": "Stefan introduces the idea of using super-resolution information to understand transport pathways of drug carriers and small molecule drugs, which is a novel application within the context of the discussion."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:29-01:30",
        "transcript": "Great, thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:29",
        "end_time": "11:30",
        "annotations": {
            "acknowledge contribution": "Kristen acknowledges the previous speaker's introduction, showing recognition of their input."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:30-01:34",
        "transcript": "Um, Uze, can you tell me how to pronounce your name correctly, please?",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 25,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:30",
        "end_time": "11:34",
        "annotations": {
            "ask clarifying question": "Kristen is asking Uze to clarify the correct pronunciation of their name, indicating a need for more information."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:34-01:35",
        "transcript": "Uzay.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:34",
        "end_time": "11:35",
        "annotations": {
            "explain or define term or concept": "Uzay is defining how to pronounce his name, which Kristen asked for in the prior turn."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:35-01:35",
        "transcript": "Uzay, thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:35",
        "end_time": "11:35",
        "annotations": {
            "acknowledge contribution": "Kristen acknowledges Uzay's response, thanking him for providing the correct pronunciation of his name."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:36-02:54",
        "transcript": "Thank you so much. So, um, I'm Uzay and I'm from Purdue University and I'm at the School of Health Science as a biomedical engineering. I'm electrical engineer in principle, but I have been doing biomedical stuff since I graduated and that includes all developing new techniques for diagnostic purpose of MRI and the reason I'm interested in super resolution is all always try to find the link between the lab resolution to to in vivo or contact animal resolution, so microscopic scale. So I always keep an eye on what's happening in the smaller scale higher resolution and to see what can be translatable to animal. So my research is ranging from cancer to neurological imaging and lipidomics to metabolomics and also cancer and also includes physiological intervention and also bone sodium content and ex nuclei and phosphorus all types of imaging, but I really like to make the link between the lab to the from bench to bedside actually.",
        "speaking duration": 78,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "11:36",
        "end_time": "12:54",
        "annotations": {
            "explain or define term or concept": "The speaker explains their interest in super-resolution techniques by linking lab resolution to in vivo animal resolution, clarifying their perspective on the topic.",
            "expand on existing idea": "The speaker expands on their background and research interests, building on the initial introduction prompt by Kristen.",
            "acknowledge contribution": "The speaker thanks Kristen for the opportunity to introduce themselves."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:54-02:55",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:54",
        "end_time": "12:55",
        "annotations": {
            "acknowledge contribution": "Kristen Maitland acknowledges the previous speaker's introduction."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:55-03:03",
        "transcript": "Vivian?",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "12:55",
        "end_time": "13:03",
        "annotations": {
            "encourage particpatioin": "Kristen Maitland is explicitly inviting Vivian to introduce herself and contribute to the discussion, as she has done with other participants."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:00-03:03",
        "transcript": "Oh, and unmute, please.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:00",
        "end_time": "13:03",
        "annotations": {
            "encourage particpatioin": "Kristen Maitland is prompting Vivian to speak by reminding her to unmute, encouraging her participation in the discussion."
        }
    },
    {
        "speaker": "Vivian Qian Liu",
        "timestamp": "03:05-03:53",
        "transcript": "Hello, uh, I'm Vivian Liu. I'm from McGill University. Uh, I'm at uh the Institute of uh parasitology and also McGill Center for viral diseases. I am trained as a molecular virologist and molecular cell biologist as a PhD student and then in my postdoc, I uh, I joined a biophysical lab where I learned how to build uh single molecule localization microscopy.",
        "speaking duration": 48,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:05",
        "end_time": "13:53",
        "annotations": [
            {
                "explain or define term or concept": "Vivian is explaining her background and training, including her experience with single molecule localization microscopy, which clarifies her perspective for the group."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:53-03:54",
        "transcript": "Great, thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:53",
        "end_time": "13:54",
        "annotations": {
            "acknowledge contribution": "Kristen acknowledges the previous speaker's introduction."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "03:54-04:20",
        "transcript": "And Candace is in our room, but she um is on another zoom, so when she gets back in, we can um have her introduce herself. So thank you for that um kind of brief introduction that really helps put things in context for us. And maybe if we could just pick up where we left off with the discussion.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "13:54",
        "end_time": "14:20",
        "annotations": {
            "acknowledge contribution": "Kristen Maitland acknowledges the brief introductions from the participants, indicating she appreciates their input and that it helps provide context for the discussion.",
            "encourage particpatioin": "Kristen Maitland mentions Candace will introduce herself when she returns, encouraging her future participation.",
            "propose decision": "Kristen Maitland suggests resuming the discussion where they left off, proposing a concrete choice for the group."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "04:20-04:21",
        "transcript": "Josh, did you want to build off of um what you were saying in about using wavefront uh go ahead.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:20",
        "end_time": "14:21",
        "annotations": {
            "encourage particpatioin": "Kristen is explicitly inviting Josh to speak and contribute to the discussion, building off of what he was saying previously."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:21-05:55",
        "transcript": "Sure, sure. So I think that um I just see a a game of diminishing returns if we're just trying to get better at gauging things out. Um and so especially now we push to multiphoton, two, three, I don't know, can we do four or five? Like at what level does that get so complicated and so expensive that it's not really it's not really useful. And so I I would really like to I think my background is is in more of the second thinking more about the second part of this question, but I think what intrigues me about this room is thinking about the two of these together, especially because super resolution microscopy I think is often speaking as somebody who's not well trained in that area, but seems to me to be very photon start in general, like you need a lot of light. Um and so if you're saying, okay, well I'm going to throw out all the scattered photons, you're walking a you know, that line is going to get hard to walk pretty quickly. So I I think that I really like the thinking about how how can we maybe take these two together and I'm not I haven't seen too much looking at super resolution combined with thinking deeper in tissue and how to think about scattering. And the last thing I'll say just to uh is I also wonder what the room is for conversations in between let's say minimally invasive types of technology as a stepping stone to getting to the ultimate goal where we just shine some light outside the body and then capture everything outside the body non invasively, but maybe minimally invasive with um, you know, fibers, fiber bundles, uh these kind of things can be a a nice stepping stone to push things into the into practice because I think with biomedical imaging outside of the like really big success of OCT, there is not so many optical like biomedical optical techniques that have really made a significant um, you know, push into the clinic.",
        "speaking duration": 94,
        "nods_others": 0,
        "smile_self": 1,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:21",
        "end_time": "15:55",
        "annotations": [
            {
                "present new idea": "Josh introduces the idea of using minimally invasive technologies as a stepping stone to non-invasive imaging, suggesting fiber bundles as an example."
            },
            {
                "expand on existing idea": "Josh expands on the idea of mitigating or utilizing multiple scattering by questioning the practicality of increasing the number of photons in multiphoton microscopy and suggesting combining super-resolution with deeper tissue imaging techniques."
            },
            {
                "offer constructive criticism": "Josh offers constructive criticism by pointing out the potential limitations of relying solely on gating out scattered photons in super-resolution microscopy due to its photon-starved nature."
            }
        ]
    },
    {
        "speaker": "Vivian Qian Liu",
        "timestamp": "04:40-05:55",
        "transcript": "Uh I want to add something uh to to uh idea. So she was mentioned about using uh how to uh how to manipulate the scattering interference. So there is something um I was thinking about. Uh, I was doing uh uh super resolution when I was doing super resolution microscope, I always wanted to stabilize the sample so that with a with a long uh long-term imaging, for example, like 30 minutes, I don't get a great uh sample drift. So one way I was thinking while I was a post talk is to use the scattering light from the cell. So we take uh we take the scattering light uh the image using scattering light of the cell at at the beginning of the imaging and after a few minutes, we take another one. So by the end, like by the end of the imaging, we could use those image to align um kind of put to the kind of uh correct the drift. So that's one thing I was thinking about. Uh, but I haven't tested and I'm not sure how precise we can do as my uh uh I claim it 10 nanometer uh uh uh precision. So I'm trying to make sure how I can how precisely I can do that. And uh some thoughts for the first uh question like how can super resolution uh methods can be translated to uh uh organismal applications. Um, I have been thinking about that for the past few years. Um, one thing I found uh uh that could be helpful is maybe uh stabilizing the floor for chemistry because right now uh I put a lot of time on doing uh imaging analysis uh like look at all the localizations and how to cluster them, how to figure out the organization of the proteins. But at the end of the day, I thought if we could use different floor force to map these what I mean is if I put it in a example, see if we have a DNA molecule, they can uh kind of fold into different structure. Like if we wanted to figure out the structure, let's see uh we can use uh maybe the barcoding system, like we can since we know the sequence, we probably can uh use the barcoding to map the entire sequence, then then we label that molecule uh on cells, then we can image that. Maybe we know, we would figure out like uh how they position the spatial. So that's So I think um maybe uh aside from the imaging processing just using AI or deep learning to look at the clusters or organizations, maybe uh uh floor for might be helpful on that. That was my thought.",
        "speaking duration": 175,
        "nods_others": 0,
        "smile_self": 1,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "14:40",
        "end_time": "15:55",
        "annotations": [
            {
                "expand on existing idea": "Vivian builds on the idea of manipulating scattering interference, mentioned earlier, by suggesting using scattering light to stabilize samples and correct for drift during long-term super-resolution imaging."
            },
            {
                "present new idea": "Vivian presents a new idea of stabilizing fluorophore chemistry and using different fluorophores to map molecules, like DNA, to understand their spatial positioning, suggesting a barcoding system based on DNA sequence."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "00:00-00:59",
        "transcript": "So I would say that this this this question goes well beyond what I think about normally. Um, because we're trying to get to structural resolution. And if you do that in an animal, it would be too much data. We don't have big enough computers for that. And so this is a very interesting, you know, concept because when we want to look at an animal, we just cut off a piece of our zebra fish and take that tissue and we call that an animal or an organism. Um, but I I think this is a very interesting conversation, but what will we do with that data if we got super res from an entire animal. Like I'm not even sure what we do with it. And that's what I'm actually scared about that part. I guess when we have a single cell, we're we're also doing expansion microscopy and we're doing structural elimination or single molecule imaging on top of that. And I'm calculating resolution and it's scaring me already.",
        "speaking duration": 59,
        "nods_others": 0,
        "smile_self": 15.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:00",
        "end_time": "20:59",
        "annotations": [
            {
                "present new idea": "Dylan introduces the idea of the challenges of dealing with the amount of data generated from super-resolution imaging of an entire animal, which hasn't been explicitly discussed before."
            },
            {
                "express concern": "Dylan expresses concern about the feasibility and utility of obtaining super-resolution data from an entire animal due to the overwhelming amount of data and the lack of clear applications for it."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "00:59-01:04",
        "transcript": "I'm I'm I'm just it's exciting but also scary at the same time.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "20:59",
        "end_time": "21:04",
        "annotations": {
            "express enthusiasm": "Dylan expresses excitement about the prospect of obtaining super-resolution data from an entire animal, building on the discussion about translating super-resolution methods to organismal applications.",
            "express frustation": "Dylan expresses being scared about the prospect of obtaining super-resolution data from an entire animal, building on the discussion about translating super-resolution methods to organismal applications."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:14-01:27",
        "transcript": "Can I uh, so similar to your question actually, your question is originating from a problem actually going back to whole animal or big organism will be bring a lot of data.",
        "speaking duration": 13,
        "nods_others": 1,
        "smile_self": 15.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:14",
        "end_time": "21:27",
        "annotations": {
            "expand on existing idea": "Uzay is building on Dylan's previous statement about the challenges of handling large datasets from whole-animal super-resolution imaging, suggesting that his question is related to the problem Dylan raised.",
            "acknowledge contribution": "Uzay acknowledges Dylan's contribution by stating that his question is similar to Dylan's question."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:27-01:28",
        "transcript": "Now the question is,",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:27",
        "end_time": "21:28",
        "annotations": {
            "present new idea": "Uzay is about to introduce a new question or idea, following up on Dylan's concerns about the amount of data generated from super-resolution imaging in whole animals."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:30-02:07",
        "transcript": "how from my point of view, I'm a microscopic person and even our data is big, but uh it's not as complicated as yours. Uh, but it has its own difficulty. How you are seeing all you guys are optical imaging and super resolution compared to myself to make it really translatable to real life or big animal or live animal uh thing. So what is your pathway to bring those techniques to this and considering your concern about the size of the data.",
        "speaking duration": 37,
        "nods_others": 1,
        "smile_self": 18.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "21:30",
        "end_time": "22:07",
        "annotations": {
            "ask clarifying question": "Uzay is asking how the other researchers, who are working on optical imaging and super-resolution microscopy, plan to translate their techniques to real-life or large animal applications, especially considering the concerns about the size of the data, building on Dylan's concern about the amount of data generated from whole animal imaging."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "02:10-02:17",
        "transcript": "So is it possible to to combine structured light and uh scattering at the same time? Is that too complicated?",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:10",
        "end_time": "22:17",
        "annotations": {
            "ask clarifying question": "Dylan asks if it's possible to combine structured light and scattering, seeking clarification on the feasibility of this combination, building on the discussion of super-resolution techniques and their application to in vivo imaging."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "02:17-02:20",
        "transcript": "Sorry, I'm not I'm not a physicist, but",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:17",
        "end_time": "22:20",
        "annotations": {
            "explain or define term or concept": "Dylan is clarifying that he is not a physicist, which explains his lack of expertise in the physics-related aspects of the discussion."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "02:21-03:13",
        "transcript": "we are using structured light uh through the line of slide sheet and in and and it's this um, you know, basic run of the mill technologies. Um, but can you collect scattered light from that sort of information? Because that's already up and running of in many, many labs around the country and world right now. Uh, would being able to combine something like the light of slide sheet which penetrates into tissues pretty decently, let's not say great, but decently. Now it's good as 400 tongue wood. But um, uh, but we uh, but that also has already structured information with it. Does that complicate getting scattered light or not? Because that's kind of a fascinating idea. Uh, that I haven't really thought too much about. And at least three of you have thought a lot about it. So that's pretty cool.",
        "speaking duration": 52,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "22:21",
        "end_time": "23:13",
        "annotations": {
            "ask clarifying question": "Dylan asks if it is possible to collect scattered light when using structured light, seeking clarification on the feasibility of combining these techniques.",
            "present new idea": "Dylan presents the idea of combining structured light with scattered light collection, which he admits he hasn't thought much about before.",
            "express enthusiasm": "Dylan expresses enthusiasm for the idea of combining structured light and scattered light collection, calling it \"pretty cool.\""
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:18-05:06",
        "transcript": "I guess my two cents on this is by de facto as optical engineers, we try to throw out the scattered light. That's the conventional wisdom. We always have done that. And so every optical system you pick up whether it's your iPhone or a microscope is designed to throw that information out. And that's the that I think is the kernel of the revolutionary idea here is like let's remove that constraint and go back to the drawing board and think differently. And so that I think that that's one thing. The other thing I was thinking about related to this conversation of so much data and resolution is you need the resolution but not everywhere. And maybe we don't need the super resolution at all points. So you can think at a native structure like I want to try to have, you know, again as optical designers, conventionally, we think about isotropic resolution everywhere. But in a more if we remove that constraint and think about, well maybe I just care about super resolution here and here and here and here in these specific parts of the cell and everywhere else, I don't care. It's fine if I have millimeter resolution maybe. I just want to be able to zoom into these certain areas. And so maybe there's I think if we think about more interesting ways to we have a limited number of pixels or voxels or bits or however you want to whatever fundamental quanta of information you want to think about that we can distribute along our in our sample. And so can we think about innovative ways to redistribute that in a in a way that's efficient but maybe isn't, you know, interpretable without a algorithm to understand or reconstruct or give us some meaningful information about what's going on.",
        "speaking duration": 108,
        "nods_others": 0,
        "smile_self": 30.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "23:18",
        "end_time": "25:06",
        "annotations": [
            {
                "present new idea": "Josh introduces the idea of challenging the conventional approach of discarding scattered light in optical engineering and instead exploring how to utilize it, which is a novel concept in the context of the discussion."
            },
            {
                "expand on existing idea": "Josh expands on the idea of data overload by suggesting that super-resolution might not be necessary everywhere in a sample, proposing a method to distribute resolution efficiently, building on the previous discussion about the challenges of handling large datasets from whole-animal imaging."
            }
        ]
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "05:07-05:07",
        "transcript": "Yeah, Josh, I I'd like to to build off of that.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:07",
        "end_time": "25:07",
        "annotations": {
            "expand on existing idea": "Matt Lew expresses his intention to build upon Josh's previously stated idea about scattering and resolution, indicating he will add details or variations to it."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "05:07-06:45",
        "transcript": "So I think you made a great point about the uh the the sort of paradigm of of at least microscopy uh and ballistic imaging that we throw away all the scattered light. Then we're kind of forgetting our friends in the diffuse optics regime. So let's think of DOT diffuse optical tomography and people sort of um uh there's there's actually a colleague here at Washu who builds the whole brain uh uh imaging device, right? And and looks at uh sort of function uh um by collecting diffuse light off of there. So maybe um maybe uh a regime of pushing the resolution there might be helpful. Uh, right now it's sort of spatially resolved based upon the average number of scattering events. It takes light longer to travel further or or uh uh and and you can sort of resolve some things in depth that way. So maybe that's one way we can think about it. I think maybe another question is um like if we take our existing technologies that can penetrate deep but somehow are deficient in some other axis. So let's just say pet for example, right? The gold standard in in specifically detecting something uh um within within the body and organism. Uh, is there something that optical imaging if engineered the right way, maybe with the the fancy uh fluorescent based reporters that we saw uh earlier in the keynote. Um, maybe there's something that we can do to to to solve a more targeted problem as a as a as a as a prototype for for for uh for solving the the bigger question that that was posed. Um, just a couple ideas there.",
        "speaking duration": 98,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "25:07",
        "end_time": "26:45",
        "annotations": [
            {
                "acknowledge contribution": {
                    "Explanation": "Matt acknowledges Josh's point about throwing away scattered light in microscopy and ballistic imaging, recognizing Josh's contribution to the discussion."
                }
            },
            {
                "expand on existing idea": {
                    "Explanation": "Matt expands on the idea of using scattered light by bringing up diffuse optical tomography (DOT) and how it's used to image the brain, building upon the previous discussion about scattering."
                }
            },
            {
                "present new idea": {
                    "Explanation": "Matt presents the idea of using existing technologies like PET scans and combining them with optical imaging to solve targeted problems, introducing a new approach to the discussion."
                }
            }
        ]
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "06:46-08:14",
        "transcript": "I'd like to I'd like to kind of jump on that as well. Um, I I feel like one thing that I I and this might just be my inexperience with the super resolution field, but like um, one thing we don't really talk about much is what and and similar to what Matt was talking about is um, what could we kind of learn from, you know, we're kind of used to it a certain type of imaging with an objective with a very high NA, you know, lens and and I feel like that's kind of a bulk of the problem and I'd like to understand from people who are doing microscopy and and like uh, you know, what are kind of the limitations um from people who are actually using super resolution um with those objective lenses that that you guys use um in terms of I guess field of view and like the amount of power that you need to be able to illuminate an entire section.",
        "speaking duration": 88,
        "nods_others": 0,
        "smile_self": 30.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "26:46",
        "end_time": "28:14",
        "annotations": {
            "expand on existing idea": "Aseema wants to build on Matt's idea about leveraging diffuse optics by discussing limitations of current super-resolution microscopy techniques.",
            "ask clarifying question": "Aseema asks about the limitations of using high NA objective lenses in super-resolution microscopy, specifically regarding field of view and power requirements, seeking to understand the challenges faced by those using these techniques."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:15-09:01",
        "transcript": "So I will say that from because I'm the I'm I'm I'm the uh I'm the honer here not the forger. I don't uh I don't uh I I developed one technique and no one ever used it. So it was called bomb because back in the day anything with single markers had to have acronym. Uh, and I learned through that that I should not develop techniques. I should just take other people's and",
        "speaking duration": 46,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "28:15",
        "end_time": "29:01",
        "annotations": [
            {
                "express humor": "Dylan makes a self-deprecating joke about his experience developing a technique that was not widely adopted, using humor to lighten the mood."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "09:01-09:55",
        "transcript": "Um, but I'll say as a as a user, and I'm we're pretty advanced users, uh that we are pretty much addicted to the high NA lens because it's what's available. It's what's commercially available, it's what we can order. We're not going to build our own lenses. And that is why we use them. There's no one has come up with a better way that I can purchase to do this and it's very limiting because high NA is usually uh uh for the most of our of our work for super res which is single molecule or structured light.",
        "speaking duration": 54,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "29:01",
        "end_time": "29:55",
        "annotations": {
            "expand on existing idea": "Dylan is expanding on Aseema's question about the limitations of high NA lenses in super-resolution microscopy by explaining that they are used because they are readily available, despite their limitations.",
            "provide supporting evidence": "Dylan supports his statement about being addicted to high NA lenses by stating that they are commercially available and easy to order, which is why they are used despite their limitations.",
            "express frustation": "Dylan expresses frustration with the limitations of high NA lenses, stating that there is no better alternative available for purchase, which limits their work in super-resolution microscopy."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "09:55-10:00",
        "transcript": "Um, and I generally put those into just two categories. I know that some of you are have four categories in super res.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "29:55",
        "end_time": "30:00",
        "annotations": {
            "explain or define term or concept": "Dylan is clarifying his understanding of super-resolution microscopy by stating that he generally puts the techniques into two categories, while acknowledging that others might have four categories."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "10:00-10:14",
        "transcript": "Um, but when you think about it from that way, it's very limiting as far as Z depth, so how far you can go, so your axial dimension that you can penetrate your sample is limited.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:14",
        "annotations": {
            "expand on existing idea": "Dylan is expanding on Aseema's question about the limitations of high NA lenses in super-resolution microscopy by explaining that high NA lenses limit the Z depth, or axial dimension, that one can penetrate a sample."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "00:00-00:12",
        "transcript": "what y'all are talking about because we are literally doing like quarter of a cell and that's good. So we're still modern and we're only at a quarter of a cell right now. So.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 25,
        "smile_other": 33,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:00",
        "end_time": "30:12",
        "annotations": {
            "express enthusiasm": "Dylan expresses enthusiasm about the current progress, stating that working with a quarter of a cell is good and they are still modern, showing excitement about their work."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "00:12-00:27",
        "transcript": "And are are have you found that there are any techniques that if you kind of decouple the excitation from the collection, like can you win anything there with with I don't know.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 40,
        "smile_other": 13,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:12",
        "end_time": "30:27",
        "annotations": {
            "ask clarifying question": "Aseema is asking if decoupling excitation from collection can improve super-resolution techniques, seeking clarification on potential benefits based on the previous discussion about limitations of high NA lenses."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "00:27-00:33",
        "transcript": "Yeah, um, I don't think that any of our microscopes are designed to do that.",
        "speaking duration": 6,
        "nods_others": 1,
        "smile_self": 50,
        "smile_other": 50,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:27",
        "end_time": "30:33",
        "annotations": {
            "reject idea": "Dylan rejects Aseema's idea about decoupling excitation from collection, stating that their microscopes aren't designed for that."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "00:33-00:56",
        "transcript": "Yeah, okay. So I mean yeah, no I'm I'm I'm just I'm coming from a different kind of world of of, you know, you know, we everything we do is like little chips with, you know, light coming out here and creating patterns and but we don't have the I mean it's it's crazy for me to think about being able to combine that with a microscope, but you know, I think there must be ways.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 48,
        "smile_other": 13,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:33",
        "end_time": "30:56",
        "annotations": {
            "present new idea": "Aseema presents the idea of combining her work with chips that emit light and create patterns with microscopy, suggesting a new approach to overcome limitations of current super-resolution techniques.",
            "express enthusiasm": "Aseema expresses enthusiasm about the potential of combining her chip-based light manipulation techniques with microscopy, indicating excitement about the possibilities.",
            "expand on existing idea": "Aseema expands on the discussion about limitations of high NA lenses by suggesting a different approach using chips with light patterns, building on the previous discussion about the challenges of current microscopy techniques."
        }
    },
    {
        "speaker": "Andrew Feig",
        "timestamp": "00:57-01:03",
        "transcript": "Dylan, your task is to have the right quarter cell at the right time to capture what it is you want to see.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 33,
        "smile_other": 33,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "30:57",
        "end_time": "31:03",
        "annotations": {
            "assign task": "This utterance assigns Dylan the task of capturing the right quarter of a cell at the right time, which is a specific responsibility."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "01:03-01:36",
        "transcript": "Yes, and and and and and and and that was expansion microscopy where I had to do uh what we now refer to structure elimination as low back imaging. Um, and we had to we had to do that live, fix that cell and then expand it, find the cell again.",
        "speaking duration": 33,
        "nods_others": 0,
        "smile_self": 24,
        "smile_other": 3,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:03",
        "end_time": "31:36",
        "annotations": {
            "expand on existing idea": "Dylan is expanding on the previous discussion about super-resolution microscopy and its limitations by providing an example of expansion microscopy and how it relates to structural elimination.",
            "explain or define term or concept": "Dylan explains that what they now refer to as 'structure elimination' was previously known as 'low back imaging' to clarify the terminology used in their research."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "01:36-01:39",
        "transcript": "So I'm really excited but I'm also kind of confused at the same time.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:36",
        "end_time": "31:39",
        "annotations": {
            "express enthusiasm": "Dylan expresses excitement about the topic of discussion, as indicated by the phrase \"I'm really excited\".",
            "express frustation": "Dylan expresses confusion about the topic of discussion, as indicated by the phrase \"I'm also kind of confused at the same time.\""
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:43-01:51",
        "transcript": "Yeah, I guess one of the fundamental limitations, at least with fluorescence, is that uh we're dealing with um just a standard dipole radiation pattern.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:43",
        "end_time": "31:51",
        "annotations": {
            "explain or define term or concept": "Matt Lew is explaining a fundamental limitation of fluorescence, which involves dealing with a standard dipole radiation pattern, to provide context for the discussion."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "01:47-01:49",
        "transcript": "[Drinking]",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:47",
        "end_time": "31:49",
        "annotations": {
            "express humor": "The speaker is making a non-verbal action of drinking, which is likely intended to be humorous in the context of the conversation."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:49-02:11",
        "transcript": "So what that will mean is that then the light just goes everywhere. I mean, of course it's zero along the dipole axis, but that's a sine squared kind of fall off.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "31:49",
        "end_time": "32:11",
        "annotations": {
            "explain or define term or concept": "Matt Lew is explaining the fundamental limitation of fluorescence, which is the standard dipole radiation pattern, to clarify why light goes everywhere, building on the discussion about limitations of current microscopy techniques."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "02:11-02:33",
        "transcript": "Um, in terms of decoupling excitation and emission, there's a lot of interesting light sheet stuff. It turns out that that's now a mechanical engineering problem because you if you want high NA and two high NA objectives next to each other, it's it's impossible.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:11",
        "end_time": "32:33",
        "annotations": {
            "expand on existing idea": "Matt Lew is expanding on the discussion about limitations of high NA lenses and decoupling excitation and emission, building on Aseema's question about decoupling excitation and collection and Dylan's response that their microscopes aren't designed for that.",
            "explain or define term or concept": "Matt Lew explains that decoupling excitation and emission in light sheet microscopy becomes a mechanical engineering problem due to the difficulty of placing two high NA objectives next to each other, clarifying a practical challenge related to the technique."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "02:33-02:55",
        "transcript": "So, um, one of the most cool things that's coming out of uh Calico labs, which is an independent sort of foundation funded thing is is Andrew York's work on remote focusing and uh basically doing some interesting optical tricks to get a light sheet scanning in there along with high NA detection and that I think is probably where the sort of classic uh uh innovation like frontier is right now in terms of high resolution and organism and fast, like that um I've been impressed by that recently.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 14,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:33",
        "end_time": "32:55",
        "annotations": {
            "expand on existing idea": "Matt Lew is building on the discussion about limitations of high NA lenses and decoupling excitation/emission by mentioning Andrew York's work on remote focusing as a potential solution.",
            "provide supporting evidence": "Matt Lew mentions Andrew York's work at Calico labs as an example of innovative work combining light sheet scanning with high NA detection, supporting the idea of pushing the boundaries of high-resolution imaging in organisms.",
            "express enthusiasm": "Matt Lew expresses excitement about Andrew York's work, indicating optimism about its potential to advance high-resolution imaging in organisms."
        }
    },
    {
        "speaker": "Aseema Mohanty",
        "timestamp": "02:57-03:34",
        "transcript": "Is is there tolerance in the community um for having something that let's say you have a objective lens and then you have something next to it, but it's very tiny, let's say it's, you know, 50 microns thin, is there tolerance in the community for having something that's some semi, you know, invasive to be able to kind of get some of these light sheet techniques um more portable or, you know, useful for an organism.",
        "speaking duration": 37,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "32:57",
        "end_time": "33:34",
        "annotations": {
            "ask clarifying question": "Aseema is asking about the community's acceptance of semi-invasive techniques to improve light sheet microscopy, building on the discussion about limitations of current high NA lens techniques."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "03:34-04:03",
        "transcript": "Yeah, I mean I think so. Um, the at least, you know, if you think about like the head mounted microscopes and things like that, like that like building a cranial window in and having some small thing next next to that's not a big deal. And then a lot of the sort of super res stuff right now is still cover slip based, you know, epi fluorescence so you can easily put stuff down at least on on on that epi side.",
        "speaking duration": 29,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "33:34",
        "end_time": "34:03",
        "annotations": {
            "express agreement": "Matt agrees with Aseema's question about tolerance in the community for semi-invasive techniques, indicating that head-mounted microscopes and cover slip-based super-resolution methods are already somewhat invasive.",
            "expand on existing idea": "Matt expands on the idea of semi-invasive techniques by providing examples like head-mounted microscopes and cover slip-based super-resolution methods, suggesting that the community is already somewhat tolerant of such approaches."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "04:09-04:15",
        "transcript": "Can someone explain how one would detect the scattered light?",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:09",
        "end_time": "34:15",
        "annotations": {
            "ask clarifying question": "Luke is asking for an explanation on how to detect scattered light, showing he wants to understand the practical methods for doing so, which builds on the prior discussion about using scattered light for imaging."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "04:15-04:24",
        "transcript": "How what kind of detectors will we need? I just is flat CMOS chip I bet, right? So what kind of detectors are you imagining?",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:15",
        "end_time": "34:24",
        "annotations": [
            {
                "ask clarifying question": "Dylan is asking about the type of detectors needed to detect scattered light, seeking clarification on the practical aspects of implementing the idea of using scattered light for imaging."
            },
            {
                "encourage particpatioin": "Dylan is encouraging others to contribute by asking what kind of detectors they are imagining."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "04:24-04:44",
        "transcript": "I'm I'm a practical guy. I kind of want to imagine what you're going to what what what are you going to capture this with, right? Um, is it is is it something that exists or you or do you have to invent it?",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:24",
        "end_time": "34:44",
        "annotations": {
            "ask clarifying question": "Dylan is asking what kind of detectors Luke is imagining to capture the scattered light, seeking clarification on the practical aspects of the proposed method."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "04:44-04:47",
        "transcript": "So I can jump in if needed.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:44",
        "end_time": "34:47",
        "annotations": {
            "encourage particpatioin": "Kristen offers to jump in, which encourages others to participate in the discussion."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "04:47-05:04",
        "transcript": "Um, so if you think of um structured illumination and you're capturing that image with a camera and so this with the structured illumination, you're illuminating certain areas, your light gets scattered.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "34:47",
        "end_time": "35:04",
        "annotations": [
            {
                "explain or define term or concept": "Kristen is explaining the concept of structured illumination and how it relates to capturing images with a camera, clarifying how light scatters during the process."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:04-05:55",
        "transcript": "So you collect light from everywhere and then usually you do um there's an algorithm that automatically calculates where that light is coming from and it removes that scattering light. So you're already capturing the scattered light, it's just that you are removing it. In confocal, you're using a pin hole to collect that um the light the ballistic photons that you are interested in and you're using that pin hole to block all those other scattered lights um where it's coming from. And so if you collect with a camera and you focus if you collect the light from where your pin hole would be, that would be your, you know, from your central focal area, but you could collect the scattered um multi photon light so that you can then collect more of that signal.",
        "speaking duration": 51,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:04",
        "end_time": "35:55",
        "annotations": {
            "explain or define term or concept": "Kristen explains how structured illumination captures light and uses algorithms to remove scattered light, and how confocal microscopy uses a pinhole to block scattered light and collect ballistic photons, clarifying the processes involved in each technique.",
            "expand on existing idea": "Kristen expands on the discussion about detecting scattered light by explaining how structured illumination and confocal microscopy handle it, building on the previous questions about detectors and scattered light.",
            "provide supporting evidence": "Kristen supports her explanation by describing the specific mechanisms used in structured illumination and confocal microscopy to handle scattered light, providing concrete examples of how these techniques work."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "05:55-06:00",
        "transcript": "Um, so it just depends a little bit on your imaging strategy and and what the um orientation would be.",
        "speaking duration": 5,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "35:55",
        "end_time": "36:00",
        "annotations": {
            "explain or define term or concept": "Kristen is explaining how the detection of scattered light depends on the imaging strategy and orientation, clarifying the relationship between these factors and light collection."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "06:04-06:17",
        "transcript": "Yeah, yeah, we try to devolve out almost all the what we refer to it as out of focus light and not scatter light but um so we're talking about sing we still talking about a single detector here when we're using scattered light?",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:04",
        "end_time": "36:17",
        "annotations": {
            "ask clarifying question": "Dylan asks if they are still talking about a single detector when using scattered light, seeking clarification on the detection method for scattered light, which Luke asked about in the previous turn."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:17-06:18",
        "transcript": "Well, it depends.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:17",
        "end_time": "36:18",
        "annotations": {
            "resolve conflict": "Kristen's response of \"Well, it depends\" serves to mediate the discussion by acknowledging that the answer is not straightforward and depends on the specific context, following a discussion about detecting scattered light and imaging strategies."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:18-07:08",
        "transcript": "I think in a lot of ways and anybody else can jump jump in at any point, but um that light is coming from that focal spot, but um in multi photon you might want to capture all of the scattered um multi photon light so that you can then collect more of that signal. Um, so it just depends a little bit on your imaging strategy and and what the um orientation would be.",
        "speaking duration": 50,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "36:18",
        "end_time": "37:08",
        "annotations": {
            "explain or define term or concept": "Kristen explains that in multi-photon imaging, one might want to capture all the scattered multi-photon light to collect more signal, clarifying the concept of capturing scattered light in different imaging strategies.",
            "encourage particpatioin": "Kristen encourages others to contribute to the discussion at any point."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:09-07:12",
        "transcript": "Okay, so.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:09",
        "end_time": "37:12",
        "annotations": [
            {
                "acknowledge contribution": "Dylan acknowledges Kristen's explanation of how scattered light is handled in different imaging strategies, but does not agree or expand on it."
            }
        ]
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "07:09-07:12",
        "transcript": "Can someone explain how one would detect the scattered light?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:09",
        "end_time": "37:12",
        "annotations": {
            "ask clarifying question": "Luke is asking for an explanation on how to detect scattered light, indicating he needs clarification on this concept, which is a follow up to the discussion about structured illumination and capturing images with a camera."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:13-07:27",
        "transcript": "How what kind of detectors will we need? I just is flat CMOS chip I bet, right? So what kind of detectors are you imagining?",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:13",
        "end_time": "37:27",
        "annotations": [
            {
                "ask clarifying question": "Dylan is asking what kind of detectors are needed to detect scattered light, following up on Luke's question about how to detect scattered light."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "07:29-07:44",
        "transcript": "I'm I'm a practical guy. I kind of want to imagine what you're going to what what what are you going to capture this with, right? Um, is it is is it something that exists or you or do you have to invent it?",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:29",
        "end_time": "37:44",
        "annotations": {
            "ask clarifying question": "Dylan asks what kind of detectors are being imagined to capture the scattered light, questioning whether existing technology can be used or if new technology needs to be invented, following up on Luke's question about detecting scattered light."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:44-07:47",
        "transcript": "So I can jump in if needed.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:44",
        "end_time": "37:47",
        "annotations": {
            "encourage particpatioin": "Kristen offers to contribute to the discussion, encouraging further participation from others."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:47-08:04",
        "transcript": "Um, so if you think of um structured illumination and you're capturing that image with a camera and so this with the structured illumination, you're illuminating certain areas, your light gets scattered.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "37:47",
        "end_time": "38:04",
        "annotations": {
            "explain or define term or concept": "Kristen is explaining the concept of structured illumination and how light scatters when capturing an image with a camera, providing context for the subsequent discussion on detecting scattered light."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:04-08:55",
        "transcript": "So you collect light from everywhere and then usually you do um there's an algorithm that automatically calculates where that light is coming from and it removes that scattering light. So you're already capturing the scattered light, it's just that you are removing it. In confocal, you're using a pin hole to collect that um the light the ballistic photons that you are interested in and you're using that pin hole to block all those other scattered lights um where it's coming from. And so if you collect with a camera and you focus if you collect the light from where your pin hole would be, that would be your, you know, from your central focal area, but you could collect the scattered um multi photon light so that you can then collect more of that signal.",
        "speaking duration": 51,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:04",
        "end_time": "38:55",
        "annotations": [
            {
                "explain or define term or concept": "The speaker explains how structured illumination captures scattered light and removes it algorithmically, and how confocal microscopy uses a pinhole to block scattered light, clarifying the different approaches to handling scattered light in these techniques, in response to a question about detecting scattered light."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:55-09:04",
        "transcript": "Um, so it just depends a little bit on your imaging strategy and and what the um orientation would be.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "38:55",
        "end_time": "39:04",
        "annotations": {
            "explain or define term or concept": "This sentence explains that the method of detecting scattered light depends on the imaging strategy and orientation, clarifying the factors influencing the detection process."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:00-00:11",
        "transcript": "So one thing, so scattering in tissue or in your sample affects both your illumination and your ability to focus to a spot.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:00",
        "end_time": "40:11",
        "annotations": {
            "explain or define term or concept": "This utterance explains how scattering affects both illumination and focusing in tissue samples, clarifying the concept of scattering in the context of imaging."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:11-00:30",
        "transcript": "And it also affects your collection. Um, and so, you know, there's some approaches to try to, um, control the light going to your spot to enhance your ability to focus to that tight spot or or to, um, improve your illumination.",
        "speaking duration": 19,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:11",
        "end_time": "40:30",
        "annotations": {
            "expand on existing idea": "This utterance expands on the previously mentioned idea of scattering in tissue affecting illumination by adding that it also affects light collection, building on the discussion of how scattering impacts imaging."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:30-00:44",
        "transcript": "That depends, but you could, so for example, if you use some information, um, like if you're imaging in fluorescence, but you collect some information using the reflectance, you know, without you're going through your filters, that might be one aspect.",
        "speaking duration": 14,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:30",
        "end_time": "40:44",
        "annotations": {
            "expand on existing idea": "Kristen is expanding on the previous discussion about detecting scattered light and imaging strategies by suggesting using reflectance information alongside fluorescence imaging to gather more data."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:44-01:16",
        "transcript": "Um, so I think, um, it it would take a big picture look at what are you trying to do, what are is your imaging system or your microscope that you're trying to use and, um, how is scattering affecting your ability to image what you're trying to see.",
        "speaking duration": 32,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "40:44",
        "end_time": "41:16",
        "annotations": {
            "explain or define term or concept": "Kristen is explaining the importance of considering the overall imaging goal, the specific imaging system, and the impact of scattering on image quality, which is a conceptual overview.",
            "encourage particpatioin": "Kristen is encouraging the group to consider the big picture and how scattering affects their imaging, inviting them to think broadly about the problem."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:16-01:17",
        "transcript": "or image at a depth, you know, that maybe you can't reach. Um, and then taking into into consideration your sample that the light is traveling through and how does that in influence or impact your ability to image, whether it be resolution or depth or field of view.",
        "speaking duration": 31,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:16",
        "end_time": "41:17",
        "annotations": {
            "explain or define term or concept": "This sentence explains how scattering affects the ability to image at a certain depth, resolution, or field of view, which is a clarification of the concept of imaging limitations.",
            "expand on existing idea": "This sentence builds upon the previous discussion about scattering in tissue and its effects on imaging, adding details about how it influences resolution, depth, and field of view."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:17-01:23",
        "transcript": "Yeah, maybe to to jump off that and and bridge back to what, uh, what Sishian was talking about at the beginning.",
        "speaking duration": 6,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:17",
        "end_time": "41:23",
        "annotations": {
            "expand on existing idea": "Matt Lew is building upon the previous discussion about imaging and scattering, referencing Sixian's earlier comments to connect his point to the initial topic."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:23-01:30",
        "transcript": "Like if we're in the fluorescence and, uh, some of the light from your floor for gets multiply scattered.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:23",
        "end_time": "41:30",
        "annotations": {
            "explain or define term or concept": "This sentence explains the concept of light scattering in fluorescence microscopy, which is relevant to the ongoing discussion about super-resolution techniques and their limitations in biological tissues."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:30-01:42",
        "transcript": "There's kind of two ways that we might think of detecting it. One is just waiting long enough because those multiply scattered photons would take longer to get to you. So you you kind of wait long enough and see where they landed and maybe those were your scattered photons.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:30",
        "end_time": "41:42",
        "annotations": {
            "expand on existing idea": "Matt is expanding on the previous discussion about detecting scattered light, building on Kristen's explanation of how scattering affects imaging and Sixian's initial question about mitigating or utilizing multiple scattering.",
            "explain or define term or concept": "Matt is explaining a method of detecting scattered photons by waiting for them to arrive at the detector, as they take longer to reach the detector due to multiple scattering events."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "01:42-02:10",
        "transcript": "The other thing that I think Josh is really better expert at is, um, if you change your imaging instrument in some way because that light was determinate that scattering was deterministic, like the cell boundaries that the light scattered off of were at certain some place relative to your imaging system.",
        "speaking duration": 28,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "41:42",
        "end_time": "42:10",
        "annotations": {
            "acknowledge contribution": "Matt Lew acknowledges Josh's expertise in imaging instruments and deterministic scattering, recognizing his contribution to the discussion."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "02:10-02:45",
        "transcript": "If you change the instrument a little bit to better leverage those scattering patterns and get more light out now and get more light in, then you have a signature for for for fixing your image a little bit. So the the the imaging problem becomes harder now because it's no longer a uh, uh, optically engineered perfect objective that does your job for you.",
        "speaking duration": 35,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:10",
        "end_time": "42:45",
        "annotations": {
            "expand on existing idea": "This utterance builds upon the previous discussion about detecting scattered light and leveraging it for imaging, adding the idea of changing the instrument to better leverage scattering patterns.",
            "explain or define term or concept": "The speaker explains that changing the instrument to leverage scattering patterns makes the imaging problem harder because it moves away from relying on a perfectly engineered objective.",
            "provide supporting evidence": "The speaker provides reasoning to strengthen the idea of changing the instrument, stating that it can provide a signature for fixing the image."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "02:45-02:46",
        "transcript": "Now you've got to reoptimize the imaging system on the fly for your specific sample and then you got to make sure that whatever you thought the scattering was from, wherever it was from and whenever it was from, like that's actually what you're detecting because it in principle, at least with elastically scattered light, there's no way to identify it any other way. Like the the photon energy is going to be the same, right? And, uh, and so, yeah.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:45",
        "end_time": "42:46",
        "annotations": {
            "expand on existing idea": "Matt is building on the previous discussion about detecting scattered light and how to leverage it, adding that the imaging system needs to be reoptimized for the specific sample to account for deterministic scattering.",
            "explain or define term or concept": "Matt explains that with elastically scattered light, there's no way to identify it because the photon energy remains the same, clarifying a key concept in the discussion.",
            "provide supporting evidence": "Matt provides the reasoning that the photon energy remains the same with elastically scattered light, supporting the claim that it's difficult to identify."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "02:48-02:57",
        "transcript": "There's also some interesting things with scattering connecting back to our conversation about numerical aperture, which counter, you know, counterintuitively scattering can actually help you.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:48",
        "end_time": "42:57",
        "annotations": {
            "present new idea": "Josh introduces the idea that scattering, contrary to conventional wisdom, can actually be helpful, which is a novel concept in the context of the discussion."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "02:57-03:17",
        "transcript": "Because at the fundamental level, high NA is about high spatial frequencies is about high angle illumination and so scattering has a way of creating this for you because of the, you know, in strongly scattering tissue after you, you know, scatter enough, you're at lambda over two.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "42:57",
        "end_time": "43:17",
        "annotations": {
            "explain or define term or concept": "The speaker explains that high numerical aperture (NA) is fundamentally about high spatial frequencies and high angle illumination, clarifying the concept of NA in the context of the discussion.",
            "expand on existing idea": "The speaker expands on the discussion about scattering by stating that scattering can help achieve high NA because it creates high angle illumination, building on the previous discussion about scattering and its effects on imaging."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:17-03:44",
        "transcript": "Um, so that I think is something else too that you make your your enemy, your friend in some sense by, you know, taking advantage of what's happening there and then maybe you maybe you decouple from the traditional connection with lenses between field of view and working depth and NA and the geometrical piece of lens design.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:17",
        "end_time": "43:44",
        "annotations": {
            "expand on existing idea": "Josh is building on the previous discussion about scattering and numerical aperture, suggesting that scattering, traditionally seen as an enemy in imaging, can be leveraged to create high angle illumination, which is related to high numerical aperture, and to decouple traditional lens design constraints.",
            "present new idea": "Josh presents the idea of making the enemy (scattering) a friend by taking advantage of it and decoupling from the traditional connection with lenses between field of view, working depth, NA, and the geometrical piece of lens design, which was not explicitly mentioned before."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "03:44-04:01",
        "transcript": "There's only so many parameters you have to to tweak, but if you can think about your lens as a and I think Sishan will be, you know, with Laura, she always talks about like your lens is a Laura Waller, your lens is a matrix basically, which I love that like picture thinking about.",
        "speaking duration": 17,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "43:44",
        "end_time": "44:01",
        "annotations": {
            "expand on existing idea": "This utterance expands on the idea of scattering and high numerical aperture by suggesting a different way to think about lenses, building on the previous discussion about leveraging scattering and high NA to improve imaging.",
            "acknowledge contribution": "The speaker acknowledges Laura Waller's perspective on lenses as matrices, recognizing her contribution to the field.",
            "express enthusiasm": "The speaker expresses enthusiasm for the idea of thinking about lenses as matrices, indicating excitement about this perspective."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:01-04:21",
        "transcript": "Um, you know, and in the wavefront shaping community, we think of like replacing a lens with a cube of salt or something like, you know, cube of sugar or something and just sending light through it and if you know what the, you know, the matrix is, mathematically there may be some interesting properties there that you can leverage that may actually help you and not hurt you.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:01",
        "end_time": "44:21",
        "annotations": {
            "present new idea": "Josh introduces the idea of replacing a lens with a cube of salt or sugar and leveraging its mathematical matrix properties, which is a novel concept in the context of the discussion.",
            "expand on existing idea": "Josh expands on the idea of scattering and high numerical aperture (NA) by suggesting that scattering can be helpful and that the traditional connection between lenses, field of view, working depth, and NA can be decoupled.",
            "provide supporting evidence": "Josh supports his idea by referencing Laura Waller's concept of thinking of a lens as a matrix, providing a basis for leveraging the properties of scattering materials."
        }
    },
    {
        "speaker": "Silvian You",
        "timestamp": "04:22-04:23",
        "transcript": "That's a great point.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:22",
        "end_time": "44:23",
        "annotations": {
            "acknowledge contribution": "Sixian acknowledges a previous point made by another participant, showing recognition of their input."
        }
    },
    {
        "speaker": "Silvian You",
        "timestamp": "04:23-04:27",
        "transcript": "Um, I was also doing post in Laura Waller's lab and uh I really like her perspective that.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:23",
        "end_time": "44:27",
        "annotations": [
            {
                "acknowledge contribution": "Sixian acknowledges Josh's point about scattering and high NA, but does not agree or expand on it."
            }
        ]
    },
    {
        "speaker": "Silvian You",
        "timestamp": "04:27-04:39",
        "transcript": "Uh, lens is just a face mask, right? So whatever whatever point spread function you want in the end, you can somehow and reverse engineer the lens you want.",
        "speaking duration": 12,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:27",
        "end_time": "44:39",
        "annotations": [
            {
                "expand on existing idea": "This utterance builds upon the previously mentioned idea of thinking about lenses as matrices, adding the analogy of a lens being a 'face mask' that can be reverse-engineered to achieve a desired point spread function."
            }
        ]
    },
    {
        "speaker": "Silvian You",
        "timestamp": "04:39-04:52",
        "transcript": "And uh back to Dylan's question, that's actually really um, uh, I think it's also a very good point to start framing off. Um, so to solve the problem, I think we can start from two.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:39",
        "end_time": "44:52",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "The phrase \"back to Dylan's question, that's actually really um, uh, I think it's also a very good point\" acknowledges Dylan's prior question."
            }
        }
    },
    {
        "speaker": "Silvian You",
        "timestamp": "04:52-05:01",
        "transcript": "Uh, one is detection, how can you reassign photons based on different properties, based on different characteristics of photons you capture.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "44:52",
        "end_time": "45:01",
        "annotations": {
            "present new idea": "This sentence introduces a novel concept of reassigning photons based on their properties, which hasn't been explicitly discussed in this specific way before, though the general idea of leveraging scattered light has been discussed."
        }
    },
    {
        "speaker": "Silvian You",
        "timestamp": "05:01-05:25",
        "transcript": "And then second way is uh second way, how can you form the beam for? For example, for light sheet microscopy, it's very hard to get get a nice light sheet after scattering. So how can you use wavefront engineering or scattering compensation to get a nice illumination in the beginning.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:01",
        "end_time": "45:25",
        "annotations": [
            {
                "expand on existing idea": "Sixian is expanding on the previous point about detection by introducing a second approach to address the problem of scattering, building upon the discussion of reassigning photons based on their properties."
            },
            {
                "present new idea": "Sixian presents a new idea of using wavefront engineering or scattering compensation to improve illumination in light sheet microscopy, which is a novel approach not explicitly mentioned before."
            }
        ]
    },
    {
        "speaker": "Silvian You",
        "timestamp": "05:25-05:38",
        "transcript": "So you don't worry that much about detection later. Um, my question is, um, like what is the fundamental limit in either direction.",
        "speaking duration": 13,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:25",
        "end_time": "45:38",
        "annotations": [
            {
                "present new idea": "Sixian is presenting a new idea about not worrying about detection later by focusing on beam formation, which hasn't been explicitly discussed in this way before."
            },
            {
                "ask clarifying question": "Sixian is asking a clarifying question about the fundamental limits in either direction (detection or beam formation), seeking to understand the constraints of each approach."
            }
        ]
    },
    {
        "speaker": "Silvian You",
        "timestamp": "05:38-06:01",
        "transcript": "So if we try all these methods and we push our depth like 10% more, is it worth it? Uh, and this applies for both um detection and illumination. Detection, you have photo photon starvation, you have noise issue and for illumination, um, no matter how much you compensate.",
        "speaking duration": 23,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "45:38",
        "end_time": "46:01",
        "annotations": {
            "ask clarifying question": "Sixian is asking if the effort to increase imaging depth by 10% using various methods is worthwhile, given the limitations in both detection and illumination, following a discussion about leveraging scattered light and wavefront engineering.",
            "expand on existing idea": "Sixian expands on the previous discussion about detection and illumination methods by questioning the fundamental limits and trade-offs involved in pushing imaging depth further, building on the conversation about numerical aperture and scattering.",
            "provide supporting evidence": "Sixian provides supporting evidence for the limitations of both detection and illumination by mentioning photon starvation and noise issues in detection, and the limits of compensation in illumination, following a discussion about the challenges of imaging deeper into tissue."
        }
    },
    {
        "speaker": "Silvian You",
        "timestamp": "06:01-06:12",
        "transcript": "At some point you lose the correlation between photons and you lost uh at one point it's just random walk. So how much more can we push and what is the fundamental challenge in the in the field right now.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:01",
        "end_time": "46:12",
        "annotations": {
            "explain or define term or concept": "The speaker explains the concept of losing correlation between photons and the point where it becomes a random walk, which is important for understanding the limits of imaging techniques.",
            "ask clarifying question": "The speaker is asking what the fundamental challenge in the field is right now, seeking to understand the limitations of current methods."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:13-06:16",
        "transcript": "And Luke, can we hear from you as well?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:13",
        "end_time": "46:16",
        "annotations": {
            "encourage particpatioin": "Kristen is explicitly inviting Luke to contribute to the discussion, ensuring everyone has a chance to speak, as she mentioned earlier."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "06:18-06:20",
        "transcript": "Um, yeah, sure.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:18",
        "end_time": "46:20",
        "annotations": {
            "acknowledge contribution": "Luke is responding to Kristen's request to hear from him, acknowledging her invitation for him to speak."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "06:20-06:35",
        "transcript": "So I I think I mean, I think that one of the challenges that I see is is like how much deeper can you go? How much further can you go is a major problem.",
        "speaking duration": 15,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:20",
        "end_time": "46:35",
        "annotations": {
            "present new idea": "Luke introduces the idea that a major challenge is how much deeper one can image, which hasn't been explicitly stated as a primary challenge in the immediately preceding conversation, though depth has been mentioned as a limitation."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "06:35-07:17",
        "transcript": "But a a bigger problem that we've noticed is how long does it take you to get there? You know, because you can do a decent job of understanding what's happening to the light and like recreating a focus and then detecting whatever signal you get out. But you're really going to have to detect for a really long time to get enough photons out and overcome your SNR problems.",
        "speaking duration": 42,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "46:35",
        "end_time": "47:17",
        "annotations": {
            "expand on existing idea": "Luke is building on the previous discussion about the challenges of imaging deeper into tissue, adding that the time required to acquire enough photons to overcome SNR problems is a significant issue.",
            "present new idea": "Luke introduces the problem of long acquisition times needed to get enough photons and overcome SNR issues when imaging deeper, which hasn't been explicitly discussed before."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "07:17-07:41",
        "transcript": "Or it's going to take you quite a while to do the correction factor and even, you know, current best in class that's pretty, you know, for a whole organism or, you know, whether it's like the whole organism or just a whole organism.",
        "speaking duration": 24,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:17",
        "end_time": "47:41",
        "annotations": {
            "expand on existing idea": "Luke is expanding on the previous discussion about the challenges of imaging deeper into tissue, adding that the time required for correction factors is a significant problem, especially for whole organisms.",
            "express frustation": "Luke expresses frustration with the time it takes to perform correction factors, implying that it is a significant limitation to current methods."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "07:41-07:50",
        "transcript": "In both cases, you're looking at problems with, you know, signal and movement and time. And, um, you know, those those seem like like major issues.",
        "speaking duration": 9,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:41",
        "end_time": "47:50",
        "annotations": {
            "expand on existing idea": "Luke is building on the previous discussion about the challenges of imaging deeper into tissue, adding that signal, movement, and time are major issues to consider, expanding on the challenges of pushing the depth of imaging."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "07:50-08:17",
        "transcript": "That in order to get it from the point of where it requires full um deconstruction of the organism, you know, which is definitely and a useful and insightful approach. Back to something that's maybe hopefully happening in a dynamic setting, we can understand like how things are are altering with time. Um, you know, sort of like our keynote talk is, I think, you know, trying to bridge those two two spectrum I I think is sort of is a challenge.",
        "speaking duration": 27,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "47:50",
        "end_time": "48:17",
        "annotations": {
            "expand on existing idea": "Luke is building on the previous discussion about the challenges of imaging deeper into tissue and the trade-offs between resolution, depth, and time, adding the point that the time required for correction and detection is a significant issue.",
            "express alternative decision": "Luke is expressing an alternative to the approach of full deconstruction of the organism, suggesting that it would be more useful to understand how things are altering with time in a dynamic setting.",
            "present new idea": "Luke is presenting the idea of bridging the gap between full deconstruction of the organism and dynamic imaging, which is a new concept in the context of the discussion."
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:18-08:25",
        "transcript": "But if you're trying to detect things in multiple dimensions, let's just say time, if things are going to take longer to get there.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:18",
        "end_time": "48:25",
        "annotations": [
            {
                "expand on existing idea": "Dylan is building on Luke's point about the challenges of imaging deeper and the time it takes to get there, adding the dimension of time to the discussion."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:25-08:47",
        "transcript": "Is it possible that you could just use multiple detectors? Because when we when we go and put two cameras on our system, we want them to be par focal basically. We want to them to be in in the exact same focal plane.",
        "speaking duration": 22,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:25",
        "end_time": "48:47",
        "annotations": [
            {
                "expand on existing idea": "Dylan is expanding on the discussion of detecting scattered light and improving imaging depth by suggesting the use of multiple detectors, building upon the previous discussion about challenges in detecting scattered light and the limitations of current imaging techniques."
            },
            {
                "ask clarifying question": "Dylan is asking if using multiple detectors is a viable solution to improve detection in multiple dimensions, building upon the previous discussion about challenges in detecting scattered light and the limitations of current imaging techniques."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "08:47-09:03",
        "transcript": "But can you alternate the detectors to detect um things that take longer to get there? Just move the camera closer. I mean, can I don't know if if with with one detector we're going to be able to get to this thing and.",
        "speaking duration": 16,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "48:47",
        "end_time": "49:03",
        "annotations": {
            "present new idea": {
                "Explanation": "Dylan suggests alternating detectors or moving the camera closer to detect signals that take longer to arrive, presenting a novel approach to signal detection."
            }
        }
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "09:03-09:14",
        "transcript": "And you and you guys are the physics people, but I can't imagine this is going to be solved with one camera. It's just going to take too darn long to image an organism.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:03",
        "end_time": "49:14",
        "annotations": {
            "reject idea": {
                "Explanation": "Dylan rejects the idea that the problem can be solved with one camera, implying it will take too long to image an organism, building on the prior discussion about the challenges of imaging depth and time."
            }
        }
    },
    {
        "speaker": "Silvian You",
        "timestamp": "09:15-09:17",
        "transcript": "You're definitely not crazy.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "49:15",
        "end_time": "49:17",
        "annotations": {
            "express agreement": "Sixian You expresses agreement with Dylan Burnette's idea that multiple detectors might be needed for imaging an organism, indicating support for the idea."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "00:00-00:12",
        "transcript": "even be more photon starved. Um, so it's always a trade off. The more multiplex, the the the less photons you have. So.",
        "speaking duration": 12,
        "nods_others": 2,
        "smile_self": 25.0,
        "smile_other": 66.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:00",
        "end_time": "50:12",
        "annotations": {
            "expand on existing idea": "Sixian is expanding on Dylan's idea of using multiple detectors by pointing out the trade-off between multiplexing and photon availability, building on the discussion about detection methods and their limitations.",
            "provide supporting evidence": "Sixian supports the idea of trade-offs by stating that the more multiplexed the system, the fewer photons are available, providing a reason why using multiple detectors might not be a straightforward solution."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:21-00:34",
        "transcript": "Uh, Candace, would you like to introduce yourself? I know that we've been talking without you, but if you'd like to just mention um your area um that you work in and especially related to super resolution and maybe your interest in this area just briefly.",
        "speaking duration": 13,
        "nods_others": 1,
        "smile_self": 7.0,
        "smile_other": 50.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:21",
        "end_time": "50:34",
        "annotations": {
            "encourage particpatioin": "Kristen is directly asking Candace to introduce herself and her interests, which encourages her to participate in the discussion."
        }
    },
    {
        "speaker": "Candace Fleischer",
        "timestamp": "00:35-01:11",
        "transcript": "Yeah, I I really apologize about that. Um, so I'm Candace Fleischer at Emory University in Atlanta. Um, my my group primarily focuses on MR spectroscopy and um of the brain. And you know, we don't do a lot of super resolution in the I I also came from an optical background. So we don't do it in that sense, but maybe Oze, maybe you've already discussed like compressed sensing. I'm not sure if we've gotten that far, but in MR, we do kind of have ways that we refer to as super resolution, but um certainly not in the same way. I came I heard multiplexing. So I imagine we're talking about optical imaging.",
        "speaking duration": 36,
        "nods_others": 1,
        "smile_self": 11.0,
        "smile_other": 50.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "50:35",
        "end_time": "51:11",
        "annotations": [
            {
                "explain or define term or concept": "Candace is explaining that while her group doesn't do super-resolution in the optical sense, they have similar techniques in MR spectroscopy, clarifying the term 'super resolution' in the context of her work."
            },
            {
                "acknowledge contribution": "Candace acknowledges that she heard the term multiplexing, recognizing the contribution of the previous speakers."
            }
        ]
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:12-01:15",
        "transcript": "the resolution wise we we are not on the same level.",
        "speaking duration": 3,
        "nods_others": 1,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:12",
        "end_time": "51:15",
        "annotations": {
            "acknowledge contribution": "Uzay acknowledges Candace's introduction and contribution, but does not agree or expand on it."
        }
    },
    {
        "speaker": "Candace Fleischer",
        "timestamp": "01:16-01:18",
        "transcript": "Right.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 100.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:16",
        "end_time": "51:18",
        "annotations": {
            "express agreement": "Candace is explicitly agreeing with Uzay's statement that their resolution levels are not the same, indicating agreement with the prior speaker."
        }
    },
    {
        "speaker": "Uzay Emir",
        "timestamp": "01:19-01:51",
        "transcript": "so far. So I didn't want to intervene any part of the discussion, but I was thinking to introduce to my whether we will be able to use the magnetic properties and you know, uh to change the optical behavior and make it useful and do multimodality imaging with your approaches. I have been reading and I have been approached a couple of colleagues to use the ultra high field to change the optical properties. Uh use a magnet, but I don't know whether any of you interested in from that perspective.",
        "speaking duration": 32,
        "nods_others": 1,
        "smile_self": 50.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:19",
        "end_time": "51:51",
        "annotations": {
            "present new idea": "Uzay introduces the idea of using magnetic properties to change optical behavior for multimodal imaging, which hasn't been discussed before.",
            "encourage particpatioin": "Uzay ends the utterance by asking if anyone is interested in this perspective, inviting others to contribute to the discussion."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "01:52-02:54",
        "transcript": "Well, I will definitely say that there's an opportunity for people from different modalities to learn from each other. And so I do think I'm really glad that there are two of you that are in MR in this room because I feel like as you discuss with each other in the next couple days, um if you can talk about um how you approach you know, resolution and improving resolution and something like compressed sensing, you know, which is applied to both fields, but the different approaches, I think sometimes it's hard for them to bridge over those those gaps between fields. And so the more you can talk together about, well how do you do this or why do you do that or um there's a real opportunity there I think in terms of working together across fields. Um, so I'll just point that out. Um, we have about um 15 minutes left, I believe. Um, yeah, and so uh we'll maybe just talk for another five minutes and then I think we should revisit kind of our key points and and try to narrow those down so that when Josh reports out, we have a a more focused report out.",
        "speaking duration": 62,
        "nods_others": 1,
        "smile_self": 11.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "51:52",
        "end_time": "52:54",
        "annotations": [
            {
                "encourage particpatioin": "Kristen encourages collaboration and knowledge sharing between participants from different modalities, specifically MR and optical imaging, to bridge the gaps between fields and improve resolution approaches, building on Candace's introduction of MR spectroscopy."
            },
            {
                "propose decision": "Kristen proposes to continue the discussion for another five minutes and then revisit the key points to narrow them down for Josh's report, managing the remaining time in the meeting."
            }
        ]
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "03:06-03:07",
        "transcript": "maybe just oh.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "Yes",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:06",
        "end_time": "53:07",
        "annotations": [
            {
                "encourage particpatioin": "Matt Lew is encouraging someone else to contribute to the conversation, as Kristen Maitland mentioned they would talk for another five minutes and then revisit key points."
            }
        ]
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "03:08-03:51",
        "transcript": "Uh, I'll throw out one quick one and and maybe it goes nowhere. Um, in terms of interesting ways of probing the tissues optically, is there some way that we can engineer photons or maybe even coupled photons so that their probability of scattering is less without let's say not, you know, not even knowing what the tissue looks like. Um, I don't know, let's say entangled photons for instance, example, right? Uh, are there cute little tricks that we could do to uh make them more robust to what classical detection would fail at. Uh, you know, maybe it requires us to to go about that way. Just just a thought.",
        "speaking duration": 43,
        "nods_others": 0,
        "smile_self": 11.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:08",
        "end_time": "53:51",
        "annotations": {
            "present new idea": "Matt introduces a novel concept of engineering photons or coupled photons to reduce their scattering probability in tissues, which hasn't been discussed before.",
            "expand on existing idea": "Matt builds upon the previous discussion about scattering and detection by suggesting a specific approach using engineered or entangled photons to overcome limitations in classical detection methods.",
            "propose decision": "Matt proposes exploring the use of engineered or entangled photons to improve optical tissue probing, suggesting a direction for future investigation."
        }
    },
    {
        "speaker": "Sixian You",
        "timestamp": "03:51-05:21",
        "transcript": "Uh, people are going longer wavelength to avoid scattering. Uh, so that's one way and I feel like uh the notion you mentioned entangled photons could be very interesting because people are already doing that for telescope and as we know, we are the retarded grandkids for from the astronomist as micro physicist. So maybe maybe that's the I I feel like that could be a very high risk, high reward uh uh notion to do. Uh, I also want to bring back to Vivian's comments in the beginning uh about fluorophores and I think um I forgot the other uh the other comment about but I think there uh are some ways to move this forward with innovations in fluorophore. I'm not the expert in it, but um I was seeing this like um they called it sparse imaging, sparse labeling. So what they do is that instead of just labeling like everywhere, they have this very strong, distinct and punctuate spots in the cells. So, um, I feel like that's that's uh something we could take advantage of either in compressed sensing or guide star imaging. Um, and we can even just to think about what imaging needs and then collaborate with chemists to design the fluorophores we want, what shape they want to be, what color etc, etc.",
        "speaking duration": 90,
        "nods_others": 0,
        "smile_self": 12.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "53:51",
        "end_time": "55:21",
        "annotations": {
            "expand on existing idea": "Sixian expands on Vivian's earlier comments about fluorophores, suggesting that innovations in fluorophores, such as sparse labeling, could help move the field forward.",
            "express enthusiasm": "Sixian expresses enthusiasm for Matt's idea of using entangled photons, calling it a \"very high risk, high reward\" notion."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "05:22-06:18",
        "transcript": "So one thing to add to this one, I think for engineering uh is uh quite intriguing and uh from a nanoparticle perspective, uh there are materials out there where you can uh tune the lifetime. So maybe it's it's not just the spectral properties but also um like the luminescence lifetime of those materials that that can then be used as as labels um for certain features um of of interest, right? And one example um uh material is called up conversion nanoparticles that have anti anti stokes emission. Um they um typically have luminescence lifetimes in like the millisecond or microsecond range. So that's um orders of magnitude difference to to what you would have with the commercial floor so this may also be uh helpful in the end.",
        "speaking duration": 56,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen share shows the Wilhelm Lab logo and the text \"Biomedical Nano-Engineering Lab\" and the lab's website address. The screen share remains static throughout the segment.",
        "start_time": "55:22",
        "end_time": "56:18",
        "annotations": {
            "expand on existing idea": "Stefan is building on the previous discussion about fluorophores by suggesting that engineering nanoparticles with tunable luminescence lifetimes could be used as labels for features of interest, expanding on the idea of fluorophore innovations.",
            "provide supporting evidence": "Stefan provides supporting evidence by mentioning upconversion nanoparticles with anti-Stokes emission and their luminescence lifetimes in the millisecond or microsecond range, which is significantly different from commercial fluorophores, to support the idea of using engineered nanoparticles."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "06:24-06:45",
        "transcript": "So maybe that uh that brings up an idea in my head. Um, Stefan on on like modulating those like how about magnetic fields to let's say prepare them to be more scattering or less or more up converting or less. And that gives us maybe a way of uh controlling them and making them better emitters for deep tissue imaging, I'm not sure.",
        "speaking duration": 21,
        "nods_others": 0,
        "smile_self": 14.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "56:24",
        "end_time": "56:45",
        "annotations": {
            "present new idea": "Matt introduces a novel concept of using magnetic fields to modulate nanoparticles, influencing their scattering or up-conversion properties for improved deep tissue imaging, building on Stefan's comment about tuning the lifetime of nanoparticles.",
            "expand on existing idea": "Matt builds upon Stefan's idea of engineering nanoparticles with tunable lifetimes by suggesting the use of magnetic fields to control their scattering or up-conversion properties, aiming to enhance their effectiveness as emitters for deep tissue imaging.",
            "encourage particpatioin": "Matt directly addresses Stefan, inviting him to consider the potential of magnetic fields in modulating nanoparticle properties."
        }
    },
    {
        "speaker": "Stefan Wilhelm",
        "timestamp": "06:46-07:41",
        "transcript": "Yeah, absolutely. Like when uh when you mentioned this, I thought immediately about um assembling um uh objects at the nanoscale that as a single object do not scatter, but when they come together and form an assembly, then all of a sudden they scatter light very efficiently. So this definitely something that that we could could work on. And then the other thing um engineering the the luminescence lifetime and this can happen through multiple means. Um material engineering is probably the the easiest step to do just playing around with the element compositions that you uh put in into those nano materials gives you already uh different lifetimes. Um how this could be changed with um external fields, magnetic fields, I'm not sure but that's definitely interesting idea.",
        "speaking duration": 55,
        "nods_others": 0,
        "smile_self": 11.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen share shows the Wilhelm Lab logo and the text \"Biomedical Nano-Engineering Lab\" and the lab's website address. The screen share remains static throughout the segment.",
        "start_time": "56:46",
        "end_time": "57:41",
        "annotations": [
            {
                "expand on existing idea": "Stefan expands on Matt Lew's idea of using magnetic fields to control scattering, suggesting assembling nanoscale objects that scatter light efficiently when they come together, building upon the previous discussion about modulating light scattering with magnetic fields."
            },
            {
                "expand on existing idea": "Stefan expands on the idea of engineering fluorophores, suggesting tuning the luminescence lifetime of nanomaterials as labels, building on Vivian and Sixian's comments about fluorophore innovation."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "07:42-08:20",
        "transcript": "Okay, so I think we should um try to summarize and come up with our key points, but we had lots of different great ideas. And so I would say if you know, from our discussion, we should use that parking lot to capture some of those as potential um areas that we could probe further in your later discussions and and may, you know, result in in a proposal. Um, but at this time I think we should look at um what we want to report out for our key points.",
        "speaking duration": 38,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "57:42",
        "end_time": "58:20",
        "annotations": [
            {
                "propose decision": "Kristen suggests the group should summarize and identify key points from the discussion, which is a concrete choice for the group to focus on reporting out.",
                "assign task": "Kristen assigns the task of summarizing and identifying key points to the group."
            }
        ]
    },
    {
        "speaker": "Silvia Ronco",
        "timestamp": "08:11-08:22",
        "transcript": "Sorry, sorry to interrupt. Do you know where you need to put the main main discussions in the PowerPoint? Okay, good. Thanks.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 18.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "Yes",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:11",
        "end_time": "58:22",
        "annotations": [
            {
                "ask clarifying question": "The speaker is asking a question to clarify where the main points of the discussion should be placed in the PowerPoint presentation."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:27-09:07",
        "transcript": "Okay, so what are should we try to narrow it down to three topic areas of what we discussed? I think that because it is such a short recording report out time, um I think you want to go with the um the most exciting ideas, not necessarily what we talked about the most. So um so maybe but I'm going to leave it up to you to come up with um what we'll cover.",
        "speaking duration": 40,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "58:27",
        "end_time": "59:07",
        "annotations": [
            {
                "propose decision": "Kristen proposes narrowing down the discussion to three topic areas for the report out, suggesting focusing on the most exciting ideas rather than what was discussed the most, to make the report more focused."
            }
        ]
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "09:08-09:59",
        "transcript": "I guess one idea that's exciting me is thinking about multimodal maybe non-traditional use of contrast. So this conversation that Stefan's point that he just brought up about thinking about how do we, you know, maybe something that separated these individual things don't scatter light well, but then due to some kind of biological or chemical change within the organism, they come together and then oops, now they're it's I mean, in some sense it's kind of like, you know, G camp or any other kind of reporter, but like new reporters that maybe are ultrasonically or magnetically or some other modality that is deeper penetrating into tissue, you know, using that to modulate those to detect them optically.",
        "speaking duration": 51,
        "nods_others": 0,
        "smile_self": 10.0,
        "smile_other": 0.0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "59:08",
        "end_time": "59:59",
        "annotations": {
            "present new idea": "The speaker introduces the idea of using multimodal, non-traditional contrast agents that respond to biological or chemical changes within the organism to enhance detection, building on Stefan's point about engineering materials with tunable lifetimes.",
            "expand on existing idea": "The speaker expands on the idea of using new reporters, similar to G-camp, but modulated by modalities like ultrasound or magnetism for deeper tissue penetration, connecting it to the earlier discussion about contrast agents and their properties.",
            "express enthusiasm": "The speaker expresses excitement about the idea of multimodal contrast agents, indicating a positive reaction to the potential of this approach."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "00:00-00:08",
        "transcript": "a general class is kind of that that strikes me as something that's an exciting area that we could explore.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 25,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:00",
        "end_time": "60:08",
        "annotations": {
            "express enthusiasm": "The speaker expresses excitement about the potential of exploring a general class of ideas related to multimodal contrast agents, building on the previous discussion about using magnetic or ultrasonic modalities for deeper tissue penetration."
        }
    },
    {
        "speaker": "Luke Mortensen",
        "timestamp": "00:17-00:37",
        "transcript": "kind of along those ideas, something that is multimodal of analysis where you can use like an as an MR probe, but then also has super resolution capabilities for like photo switching or something. So you could do, you know, if you could actually migrate to that spot of interest, you could get super resolution using the same probe.",
        "speaking duration": 20,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:17",
        "end_time": "60:37",
        "annotations": {
            "expand on existing idea": "This utterance builds upon the previous idea of multimodal contrast by suggesting a specific multimodal analysis using an MR probe with super-resolution capabilities, adding a concrete example to the discussion.",
            "present new idea": "The utterance introduces the novel concept of a multimodal probe that combines MR and super-resolution capabilities, which hasn't been explicitly mentioned before."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:52-00:55",
        "transcript": "Any other ideas that we should be reporting out on?",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "60:52",
        "end_time": "60:55",
        "annotations": {
            "encourage particpatioin": "Kristen is explicitly asking if anyone has any further ideas to contribute to the discussion, encouraging participation from the group."
        }
    },
    {
        "speaker": "Siwan You",
        "timestamp": "01:02-02:12",
        "transcript": "Uh, I think one idea, uh, that was brought up by a few people was pretty exciting. Uh, the idea of, um, I can summarize as adaptive imaging. So, I think Josh bring out this idea. So first you have low resolution imaging, and then you come in with high resolution imaging. So, um, so, uh, we can combine with MRI, right? So I was, I forgot this person's name, but I was talking to another person in the breakout session that they were developing this low field MRI where they can be portable as a probe, right? So imagine, uh, you are doing, uh, clinic session and you have this probe with MRI and then you're doing this scanning and then when you have a suspicious area, you heard a beep from the AI algorithms and then you have a needle that comes out that gives you the optical fiber and then insert into do kind of do a real time at a point of procedure diagnosis. Uh, so kind of combine this non invasive MRI with non with minimal invasive optical cellular resolution imaging.",
        "speaking duration": 70,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "61:02",
        "end_time": "62:12",
        "annotations": [
            {
                "expand on existing idea": "Sixian is building upon the ideas of adaptive imaging and combining low-resolution and high-resolution techniques, which were previously mentioned by Josh and others in the conversation."
            },
            {
                "present new idea": "Sixian presents a novel concept of combining portable low-field MRI with minimally invasive optical cellular resolution imaging for real-time point-of-procedure diagnosis, which has not been explicitly discussed before."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "02:19-03:45",
        "transcript": "Yes, so just from my my experience, I guess, that's um one area that in terms of optical imaging that, you know, I've tried to develop was using actually fluorescence lifetime imaging of in a microscopic view of tissue and oral cavity. Um and then using um we developed a confocal microscope that also would go into the oral cavity and we design our own miniature lens that's about um less than a centimeter in diameter. So it's relatively small can fit inside. Um and there you're doing kind of that point measurement but it's with imaging looking at um cell nuclei um that have been identified based on the metabolic changes in the tissue um using the fluorescence lifetime. There's one other group that also uses distortion in the lens so that um on it captures a larger field of view that has a worse resolution, but at the center it has better resolution um but a very limited field of view so that you could use it to kind of guide around um and then you if you see something at the edge of the focus then you move it to the center and you get that higher resolution in the center. So there's just a couple ideas of some and then one thing that I I didn't really hear uh being brought up but photoacoustic imaging for increased depth um we didn't really discuss but for that kind of multimodality and and using a different type of excitation for your in comparison to your detection.",
        "speaking duration": 86,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "62:19",
        "end_time": "63:45",
        "annotations": [
            {
                "expand on existing idea": "Kristen is building on the idea of adaptive imaging that Sixian brought up, providing her own experience in developing optical imaging techniques for tissue and oral cavity using fluorescence lifetime imaging and confocal microscopy."
            },
            {
                "present new idea": "Kristen introduces the idea of using photoacoustic imaging for increased depth, which hadn't been discussed previously in the conversation."
            }
        ]
    },
    {
        "speaker": "Uzay Ermir",
        "timestamp": "03:46-04:12",
        "transcript": "Yeah, I do think that the photoacoustic is feasible for MRI as well. So I do see great illustration about this kidney and they embedded this photoacoustic and try to induce the ultrasound outside and try to write it up and we can also do the same thing with MRI that might be really interesting way to look at the photoacoustic. We don't have any chance to discuss that.",
        "speaking duration": 26,
        "nods_others": 0,
        "smile_self": 15,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "63:46",
        "end_time": "64:12",
        "annotations": {
            "expand on existing idea": "The speaker is building on the previous discussion about multimodality imaging, specifically photoacoustic imaging, and suggesting its feasibility with MRI.",
            "express enthusiasm": "The speaker expresses excitement about the potential of combining photoacoustic imaging with MRI, indicating a positive outlook on this approach."
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "04:14-04:50",
        "transcript": "So I do again encourage you to put ideas in the parking lot especially because even though this is a short virtual meeting this week, but um hopefully you will all be back next year and the year after and so if you plan to seed now you might come back to it um in the future. Um so I hope this is just the beginning of your discussion together um not necessarily all of you together but uh with individuals that you may find other people at the conference that were not in our room that um may be able to help build on some ideas that you're um starting to form.",
        "speaking duration": 36,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "64:14",
        "end_time": "64:50",
        "annotations": [
            {
                "encourage particpatioin": "Kristen encourages the team to continue brainstorming and contributing ideas to the 'parking lot' for future discussions, even beyond this meeting."
            },
            {
                "express enthusiasm": "Kristen expresses optimism that this discussion is just the beginning of their collaboration and idea formation."
            }
        ]
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "04:55-05:06",
        "transcript": "This is what I have for our slide. I'm not sure what people think about this one if you want to give me any feedback. I was just trying to synthesize what we were just talking about.",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a Google Slides presentation titled \"Scalog_ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists super-resolution methods: Multi-modal probes, Adaptive Imaging, and Co-designing illumination and collection. It also lists the participants, facilitator, and reporter.",
        "start_time": "64:55",
        "end_time": "65:06",
        "annotations": {
            "encourage particpatioin": "Josh is asking for feedback from the group on the slide he has prepared, encouraging them to contribute their thoughts.",
            "present new idea": "Josh is presenting the slide he created, which is a new synthesis of the group's discussion."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "05:44-05:46",
        "transcript": "I guess the second point is is somewhat related to big the big data.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "Yes",
        "screenshare_content": "The screen shows a Google Slides presentation titled \"Scalog_ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists super-resolution methods: Multi-modal probes, Adaptive Imaging, and Co-designing illumination and collection. It also lists the participants, facilitator, and reporter. The Adaptive Imaging point is highlighted with a blue box.",
        "start_time": "65:44",
        "end_time": "65:46",
        "annotations": {
            "expand on existing idea": "This utterance builds upon the previous discussion about key points to report out, specifically relating the second point to the issue of big data, which was brought up when discussing the challenges of super-resolution imaging in whole organisms."
        }
    },
    {
        "speaker": "Josh Brake",
        "timestamp": "05:46-05:50",
        "transcript": "Like all the we had we talked quite a bit about how to deal with the data too.",
        "speaking duration": 4,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "65:46",
        "end_time": "65:50",
        "annotations": [
            {
                "acknowledge contribution": "This utterance acknowledges the prior discussion about handling data, without adding new information or expanding on it."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "06:05-06:41",
        "transcript": "Yeah, and related to that data there we were looking at different um light sheet microscopes from different companies and how they handle the large data size and um just in their software aspect. Some would um just in how they manage the data so that when you go in you want to look like zoom into an area of interest, it doesn't keep that whole large data set so you can kind of have that um just how you approach the data. I think really makes a difference in being able to work with it. Um because it yeah, it is a lot of a lot a lot of data.",
        "speaking duration": 36,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "66:05",
        "end_time": "66:41",
        "annotations": {
            "expand on existing idea": "Kristen Maitland expands on the previous point about big data by discussing how different light sheet microscopes and their software handle large data sizes, building on the conversation about the challenges of dealing with large datasets in imaging.",
            "provide supporting evidence": "Kristen Maitland provides supporting evidence for the challenges of big data by mentioning that different light sheet microscopes from different companies have different approaches to managing the large data size, and that the approach to the data makes a difference in being able to work with it.",
            "express enthusiasm": "Kristen Maitland expresses enthusiasm by saying that the approach to the data makes a difference in being able to work with it, and that it is a lot of data."
        }
    },
    {
        "speaker": "Matt Lew",
        "timestamp": "07:46-07:54",
        "transcript": "No, I think it went well. Thank you uh Kristen for for facilitating us and getting everyone a chance to speak.",
        "speaking duration": 8,
        "nods_others": 0,
        "smile_self": 75,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "67:46",
        "end_time": "67:54",
        "annotations": {
            "acknowledge contribution": "Matt Lew acknowledges Kristen's contribution in facilitating the discussion and ensuring everyone had a chance to speak, showing appreciation for her role in the meeting."
        }
    },
    {
        "speaker": "Siwan You",
        "timestamp": "07:55-08:51",
        "transcript": "Yeah, I really like the we have the questions to guide us and then we kind of each uh each one of us kind of just uh uh branch off that. Uh, I I think um what I would like better is uh I feel like um so first we can go around of introductions for each one and then when we are having this discussion, uh, I feel like a lot of people, everybody has really good points that we could build a more fluid and um more a coherent coherent conversation instead of one by one. So, uh, but uh then I guess these are trade off then maybe uh we cannot get to hear some people's opinions. Uh, maybe. So maybe we could do like first round table uh introduction, round table short ideas and then uh more uh just a kind of just very casual uh coherent fluid discussions.",
        "speaking duration": 56,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "67:55",
        "end_time": "68:51",
        "annotations": [
            {
                "express agreement": "Sixian expresses agreement with the questions that guided the discussion, indicating a positive sentiment towards the structure provided."
            },
            {
                "offer constructive criticism": "Sixian offers constructive criticism by suggesting a different format for the discussion, proposing a round table introduction followed by a more fluid conversation to improve coherence."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "08:54-09:01",
        "transcript": "Yes, I do feel that especially in this virtual format that it does feel like, okay, it's your turn to talk.",
        "speaking duration": 7,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "68:54",
        "end_time": "69:01",
        "annotations": {
            "acknowledge contribution": {
                "Explanation": "Kristen acknowledges that the virtual format makes the discussion feel like it's each person's turn to talk, recognizing the limitations of the format."
            }
        }
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "09:01-09:40",
        "transcript": "There's a little bit less flow. Um I was wondering if it would be better after the introductions that if each person talk like briefly state what they're interested in discussing and you could almost like group them in and say, okay, first we're going to talk about this particular direction and then we'll cover this direction. Um so that would be one thought. I think it's hard because of the the topics are relatively broad actually even though, you know, in some ways they're specific, but they're relatively broad and you can approach them in different ways and so it's um it's almost hard to put your ideas into, you know, kind of groups.",
        "speaking duration": 39,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "69:01",
        "end_time": "69:40",
        "annotations": [
            {
                "propose decision": "Kristen suggests a different meeting structure where each person briefly states their interests after introductions, which is a concrete choice for the group to consider for future meetings."
            },
            {
                "expand on existing idea": "Kristen is building on Sixian's suggestion to improve the flow of the discussion by proposing a specific structure for future meetings, adding details on how to group topics."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:00-00:31",
        "transcript": "information from other fields in imaging that might influence our approaches. Um, but I do feel that each person had something different to add that um, it might have been hard to kind of narrow down the topics because they are um, there's so much to cover, I think. But I hope that you continue to have your discussions with each other in the different um gather rooms or towns or without you get to be in um so you can continue these uh conversations.",
        "speaking duration": 31,
        "nods_others": 2,
        "smile_self": 15,
        "smile_other": 10,
        "distracted_others": 0,
        "hand_gesture": "Open Palms",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:00",
        "end_time": "70:31",
        "annotations": [
            {
                "acknowledge contribution": "Kristen acknowledges that each person added something different, recognizing their individual inputs to the discussion."
            },
            {
                "encourage particpatioin": "Kristen encourages the participants to continue their discussions in other venues, promoting further engagement and collaboration."
            }
        ]
    },
    {
        "speaker": "Kristen Maitland",
        "timestamp": "00:36-00:48",
        "transcript": "Okay, well I think we're about done. We could probably head back to the main room. Um, thank you Josh for um taking notes and for reporting out for us and we'll see you guys later in the conference.",
        "speaking duration": 12,
        "nods_others": 1,
        "smile_self": 25,
        "smile_other": 50,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:36",
        "end_time": "70:48",
        "annotations": [
            {
                "confirm decision": "Kristen suggests that the group is done and can head back to the main room, confirming the end of the discussion."
            },
            {
                "acknowledge contribution": "Kristen thanks Josh for taking notes and reporting out for the group."
            }
        ]
    },
    {
        "speaker": "Dylan Burnette",
        "timestamp": "00:48-00:49",
        "transcript": "Thank you.",
        "speaking duration": 1,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 100,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "70:48",
        "end_time": "70:49",
        "annotations": [
            {
                "acknowledge contribution": "Dylan Burnette is acknowledging the discussion or the facilitation of the meeting, expressing gratitude."
            }
        ]
    },
    {
        "speaker": "Andrew Feig",
        "timestamp": "02:10-02:12",
        "transcript": "is coming right now, the room's just closed.",
        "speaking duration": 2,
        "nods_others": 0,
        "smile_self": 0,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "72:10",
        "end_time": "72:12",
        "annotations": [
            {
                "None": "No code applies to this utterance."
            }
        ]
    },
    {
        "speaker": "Shiva Abbaszadeh",
        "timestamp": "02:14-02:17",
        "transcript": "No, I guess my brain felt like as if I have to creek on it.",
        "speaking duration": 3,
        "nods_others": 0,
        "smile_self": 100,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "Pointing",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "72:14",
        "end_time": "72:17",
        "annotations": [
            {
                "express humor": "The speaker uses a humorous analogy of their brain 'creaking' to express the mental effort required during the discussion."
            }
        ]
    },
    {
        "speaker": "Andrew Feig",
        "timestamp": "02:19-02:30",
        "transcript": "Okay, welcome back to the main room. Um, so uh I certainly bopped around a little bit and heard some really great conversations and so Richard you",
        "speaking duration": 11,
        "nods_others": 0,
        "smile_self": 10,
        "smile_other": 0,
        "distracted_others": 0,
        "hand_gesture": "None",
        "interuption": "No",
        "overlap": "No",
        "screenshare": "No",
        "screenshare_content": "None",
        "start_time": "72:19",
        "end_time": "72:30",
        "annotations": [
            {
                "acknowledge contribution": "Andrew Feig acknowledges the great conversations that took place in the breakout rooms, recognizing the participants' input."
            }
        ]
    }
]