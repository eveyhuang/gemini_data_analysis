{
    "meeting_annotations": [
        {
            "speaker": "Josh Brake",
            "timestamp": "00:00-00:08",
            "transcript": "a general class is kind of that that strikes me as something that's an exciting area that we could explore.",
            "speaking duration": 8,
            "nods_others": 0,
            "smile_self": 25,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "00:17-00:37",
            "transcript": "kind of along those ideas, something that is multimodal of analysis where you can use like an as an MR probe, but then also has super resolution capabilities for like photo switching or something. So you could do, you know, if you could actually migrate to that spot of interest, you could get super resolution using the same probe.",
            "speaking duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:52-00:55",
            "transcript": "Any other ideas that we should be reporting out on?",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Siwan You",
            "timestamp": "01:02-02:12",
            "transcript": "Uh, I think one idea, uh, that was brought up by a few people was pretty exciting. Uh, the idea of, um, I can summarize as adaptive imaging. So, I think Josh bring out this idea. So first you have low resolution imaging, and then you come in with high resolution imaging. So, um, so, uh, we can combine with MRI, right? So I was, I forgot this person's name, but I was talking to another person in the breakout session that they were developing this low field MRI where they can be portable as a probe, right? So imagine, uh, you are doing, uh, clinic session and you have this probe with MRI and then you're doing this scanning and then when you have a suspicious area, you heard a beep from the AI algorithms and then you have a needle that comes out that gives you the optical fiber and then insert into do kind of do a real time at a point of procedure diagnosis. Uh, so kind of combine this non invasive MRI with non with minimal invasive optical cellular resolution imaging.",
            "speaking duration": 70,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:19-03:45",
            "transcript": "Yes, so just from my my experience, I guess, that's um one area that in terms of optical imaging that, you know, I've tried to develop was using actually fluorescence lifetime imaging of in a microscopic view of tissue and oral cavity. Um and then using um we developed a confocal microscope that also would go into the oral cavity and we design our own miniature lens that's about um less than a centimeter in diameter. So it's relatively small can fit inside. Um and there you're doing kind of that point measurement but it's with imaging looking at um cell nuclei um that have been identified based on the metabolic changes in the tissue um using the fluorescence lifetime. There's one other group that also uses distortion in the lens so that um on it captures a larger field of view that has a worse resolution, but at the center it has better resolution um but a very limited field of view so that you could use it to kind of guide around um and then you if you see something at the edge of the focus then you move it to the center and you get that higher resolution in the center. So there's just a couple ideas of some and then one thing that I I didn't really hear uh being brought up but photoacoustic imaging for increased depth um we didn't really discuss but for that kind of multimodality and and using a different type of excitation for your in comparison to your detection.",
            "speaking duration": 86,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Uzay Ermir",
            "timestamp": "03:46-04:12",
            "transcript": "Yeah, I do think that the photoacoustic is feasible for MRI as well. So I do see great illustration about this kidney and they embedded this photoacoustic and try to induce the ultrasound outside and try to write it up and we can also do the same thing with MRI that might be really interesting way to look at the photoacoustic. We don't have any chance to discuss that.",
            "speaking duration": 26,
            "nods_others": 0,
            "smile_self": 15,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "04:14-04:50",
            "transcript": "So I do again encourage you to put ideas in the parking lot especially because even though this is a short virtual meeting this week, but um hopefully you will all be back next year and the year after and so if you plan to seed now you might come back to it um in the future. Um so I hope this is just the beginning of your discussion together um not necessarily all of you together but uh with individuals that you may find other people at the conference that were not in our room that um may be able to help build on some ideas that you're um starting to form.",
            "speaking duration": 36,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Josh Brake",
            "timestamp": "04:55-05:06",
            "transcript": "This is what I have for our slide. I'm not sure what people think about this one if you want to give me any feedback. I was just trying to synthesize what we were just talking about.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scalog_ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists super-resolution methods: Multi-modal probes, Adaptive Imaging, and Co-designing illumination and collection. It also lists the participants, facilitator, and reporter."
        },
        {
            "speaker": "Josh Brake",
            "timestamp": "05:44-05:46",
            "transcript": "I guess the second point is is somewhat related to big the big data.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scalog_ABI Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists super-resolution methods: Multi-modal probes, Adaptive Imaging, and Co-designing illumination and collection. It also lists the participants, facilitator, and reporter. The Adaptive Imaging point is highlighted with a blue box."
        },
        {
            "speaker": "Josh Brake",
            "timestamp": "05:46-05:50",
            "transcript": "Like all the we had we talked quite a bit about how to deal with the data too.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "06:05-06:41",
            "transcript": "Yeah, and related to that data there we were looking at different um light sheet microscopes from different companies and how they handle the large data size and um just in their software aspect. Some would um just in how they manage the data so that when you go in you want to look like zoom into an area of interest, it doesn't keep that whole large data set so you can kind of have that um just how you approach the data. I think really makes a difference in being able to work with it. Um because it yeah, it is a lot of a lot a lot of data.",
            "speaking duration": 36,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "07:46-07:54",
            "transcript": "No, I think it went well. Thank you uh Kristen for for facilitating us and getting everyone a chance to speak.",
            "speaking duration": 8,
            "nods_others": 0,
            "smile_self": 75,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Siwan You",
            "timestamp": "07:55-08:51",
            "transcript": "Yeah, I really like the we have the questions to guide us and then we kind of each uh each one of us kind of just uh uh branch off that. Uh, I I think um what I would like better is uh I feel like um so first we can go around of introductions for each one and then when we are having this discussion, uh, I feel like a lot of people, everybody has really good points that we could build a more fluid and um more a coherent coherent conversation instead of one by one. So, uh, but uh then I guess these are trade off then maybe uh we cannot get to hear some people's opinions. Uh, maybe. So maybe we could do like first round table uh introduction, round table short ideas and then uh more uh just a kind of just very casual uh coherent fluid discussions.",
            "speaking duration": 56,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:54-09:01",
            "transcript": "Yes, I do feel that especially in this virtual format that it does feel like, okay, it's your turn to talk.",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "09:01-09:40",
            "transcript": "There's a little bit less flow. Um I was wondering if it would be better after the introductions that if each person talk like briefly state what they're interested in discussing and you could almost like group them in and say, okay, first we're going to talk about this particular direction and then we'll cover this direction. Um so that would be one thought. I think it's hard because of the the topics are relatively broad actually even though, you know, in some ways they're specific, but they're relatively broad and you can approach them in different ways and so it's um it's almost hard to put your ideas into, you know, kind of groups.",
            "speaking duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}