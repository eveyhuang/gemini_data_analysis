{
    "meeting_annotations": [
        {
            "speaker": "David Van Valen",
            "timestamp": "00:00-00:25",
            "transcript": "I could always commercialize it, um, and just as a safety as a safety net. Um, and so I would likely start with humans, um, human tissues, human cell lines, um, etcetera, etcetera. Um, if there's enough uh utility and people want to expand into like other um to other model organisms, then you can you can do that. Um, but that's after there's uh there's enough buy in.",
            "speaking duration": 25,
            "nods_others": 2,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "00:25-02:46",
            "transcript": "Yeah. I mean I I speak so I'm I'm speaking as someone who's like actively managing um, you know, several large scale um image collection, curation and annotation projects. It is very hard to get these things um funded and generally speaking, people, which is surprising to me now that we're in like 2021 like five years like at least five years after this AI revolution, um, people do not see the value in generating like these collections um and and and what they can actually do for the life sciences. So I think like what what hasn't been talked about is how yet um is how these collections for, you know, creating for creating like these integrated um, you know, multimodal understandings of, you know, different biological systems, is also the same data and associated labels that are going to create the algorithms that are going to be required to interpret like said data. Um, and so neither effort's going to is going to happen until, you know, this, you know, I'd say like from a a term from my, you know, old days in medicine would be scut work, um, you know, work that is essential for the system to to operate, but, you know, is grungy and nobody wants to do. None of this stuff's going to happen until people um start doing it, right? Um, and then because things just get like much less exciting, you know, it's not about, you know, okay, what clever algorithm I designing or, you know, what cool microscope am I making or anything like that's, you know, stokes intellectual curiosity, it's, you know, how do I structure the data, you know, what associated metadata, um, how what things are people going to want to be able to uh do with it because you have to think about that um ahead of time when you're designing um when you're designing these databases and, you know, if there's annotation involved, what flavor of labels uh do are you going to need to be able to make. Um, these are the things that actually matter for these projects to succeed, but they're not interesting, they're not exciting um at all.",
            "speaking duration": 141,
            "nods_others": 10,
            "smile_self": 10.0,
            "smile_other": 10.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "02:46-02:49",
            "transcript": "You know, the nth plus one omix data set. At least in my view. Sorry, people can chime in and disagree with me if I want probably want to.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Dylan McCreedy",
            "timestamp": "02:50-03:50",
            "transcript": "I think the one example of that kind of aggregation of many different types of data in a reference that's already been mentioned is is the Allen Brain map, but just looking at the immense amount of effort and the, you know, over a decade of work that it's taken just to assemble that, um, is is mind boggling to think of everything that went into it, but it is kind of one example where they picked a particular species, you know, mostly most of the data is mice and trying to assemble many different types of modalities across it. So I put I'm sure everybody's aware of it, but I just put the link in there, but what are the things that frustrates me the most is they have, you know, this is really just limited to the brain and they even have a spinal cord version of this, but it's in situ at two different ages and and that's it.",
            "speaking duration": 60,
            "nods_others": 3,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "03:50-04:06",
            "transcript": "Can I ask a question actually of of of David because you know, I think Dylan brought up a good point of the Allen Brain Atlas and the advantage of that, but of course, I think one of their key advantages is they did all the experiments in a very standardized way all in house.",
            "speaking duration": 16,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "04:06-05:25",
            "transcript": "Yeah. So that is a good question. Um, this shouldn't this shouldn't degenerate into a, you know, I shouldn't be like dominating like this discussion. Um, I just want to say say that out loud. But I think you can you can go either path. Um, and in my lab we've done um, we've done both. Um, so we're building a, you know, a large collection of imaging data that so that we can annotate it and, you know, develop models for both segmentation and tracking. Um, and then make sure that they're robust across, you know, the a wide variety of different cell lines that both we and other people um that other people use.",
            "speaking duration": 79,
            "nods_others": 1,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "05:25-05:30",
            "transcript": "Uh, will we get the same, you know, sort of robustness for the imaging stuff? I'd say, you know, maybe.",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "05:30-05:31",
            "transcript": "I see.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "05:31-05:31",
            "transcript": "So you don't have to train a specific model.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "05:31-05:32",
            "transcript": "Yeah, no.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "05:32-05:32",
            "transcript": "Yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "05:32-05:32",
            "transcript": "Yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "05:32-06:17",
            "transcript": "The goal is to have one model that works for everything. Um, and you can get that um the challenge is making these data sets and part of that process is compiling and curating data across different um the different things that people are looking at. Um, that's not challenging.",
            "speaking duration": 45,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "06:17-06:17",
            "transcript": "That's not easy.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "David Van Valen",
            "timestamp": "06:17-06:17",
            "transcript": "Um that is that is challenging. Sorry.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:18-08:51",
            "transcript": "I want to connect a point that Jazz and Dylan made, which is uh we're talking about designing these larger projects with hypothesis testing in mind and uh Dylan brings up well there's aspects of Allen Brain that just make it incompatible. But at this point Allen Brain has been around long enough where I know to structure my experiments around those particular like time points. It's like I'm interested in those developmental stages because I have access to that data. And I think that's also the the power of certain model organisms where it's like you know the genome is there, you know all these tools are already laid out. And if uh if a larger project can be built around built with that utility where people can start designing their own hypothesis driven research around that shared resource. I think that's where the that's where the real power is. That's where things take off. And that's also where Allen fails is that there's a lot of partial data sets in some of the most interesting points and you just get to it and you don't quite know how to interact with it. As as a personal note, I think another thing that that makes one of these larger projects work or not work is can you drop a graduate student into it with a couple tutorials? Like if you have to be steeped in that large scale project in order to access it and and interact with it in any way, it doesn't work. You have to have here's how you get the basic data out. Here's some tutorial things. You have to be able to leave somebody with, you know, reasonable amount of training, but who are novices. They have to be able to make progress on on those data sets in order for them to have value to the larger community.",
            "speaking duration": 153,
            "nods_others": 1,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd",
            "timestamp": "08:55-09:57",
            "transcript": "I mean we're part of this um human cell atlas effort, right? And I would say that a very strong amount of effort has been put into the the omix side of it of integrating metadata across these things and doing that. I would say so far this is just a personal opinion is that the imaging side is a is a mess because everyone's not annotating metadata and there's no place to upload the data actually. So we just we're storing everything on our own, which is not really a feasible path forward because no one can really look at it except the people part of the network we're in. But even if we do generate all that reference data set, which is what you know, the goal is, it's still very difficult to know how to leverage that to to come back to this time issue. So, you know, I still to me there's there's different time scales, right? So if we want to like we want to the promises about activity, but we can think about any molecular level activity that's transient. That's lost in all the experiments that we've been kind of talking about here, right? In terms of a lot of what we're talking about. And so I I still see that as like a really big challenge of",
            "speaking duration": 62,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}