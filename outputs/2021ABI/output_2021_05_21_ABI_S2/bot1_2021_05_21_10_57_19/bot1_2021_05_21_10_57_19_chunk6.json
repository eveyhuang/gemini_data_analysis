{
    "meeting_annotations": [
        {
            "speaker": "Arnold Mayer, McGill",
            "timestamp": "00:00-00:45",
            "transcript": "which then has a turn. So you can have a cell that migrates along a track and then it has to turn and then you can specially and temporally analyze what's happening during this specific turning process. Then you have different cells, you don't use the same cell but you use different cells in a stereotypical behavior um to register the different molecular events uh over time. So that's that's something that you know we're we're trying to um establish more and there there are certainly with with microfabrication there's there are ways of of uh forcing cells into specific behaviors and and helping with that issue. It goes back to this multiplexing uh problem of spatial temporal analysis.",
            "speaking duration": 45,
            "nods_others": 3,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "00:46-01:17",
            "transcript": "Could you uh could you also have something where you know you have a bunch of different sensors at once in the same cell that they may be somewhat broadly distributed and then they are each tagged with a barcode and even if they're all in the same color then afterwards you could fix the sample and do some kind of um fixed tissue labeling or multi round fixed tissue labeling to identify based on the barcode what what what sensor it was even though they were all you know green at the time or something like that.",
            "speaking duration": 31,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Arnold Mayer, McGill",
            "timestamp": "01:18-01:34",
            "transcript": "Okay, okay. Yeah, yeah, I see I see what you mean. So you would have you would multiplex the uh the acquisition and then later basically deconvolve and decide who was who in the end. Yeah, that's an interesting idea. We haven't we haven't thought about that yet, but that could could definitely work.",
            "speaking duration": 16,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Jin Zhang, UCSD",
            "timestamp": "01:34-01:39",
            "transcript": "I guess you need to sort of link that that read out to that barcode somehow.",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Arnold Mayer, McGill",
            "timestamp": "01:40-01:41",
            "transcript": "Yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "01:42-02:05",
            "transcript": "Yeah, I was thinking again, I mean based just on my own experience of doing it with an in situ hybridization approach afterwards once the cells are fixed, but it would it assumes that you can register between the live data where everything is green and the fixed data where you can disaggregate who's who. Um and I I mean yeah. I don't know how how feasible that would be within that type of cell.",
            "speaking duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Jin Zhang, UCSD",
            "timestamp": "02:06-03:00",
            "transcript": "So uh Andrew actually put uh uh something in the chat. Uh so there perhaps uh optogenetic clues that could uh tattoo a cell. That's uh that's an idea as well. Uh related to Arnold um comment the the computational multiplexing or kind of an internal reference. I think that has been used also in a lot of other settings for example in cell migration right like the the rather than turn like the the the edge of the cell could serve as a internal reference in some context as well. So I guess related to uh either the optogenetic tooling or some cell features that serve as internal reference um can we think about linking different modalities? Uh I think Lingyan has something to say.",
            "speaking duration": 54,
            "nods_others": 0,
            "smile_self": 80,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Lingyan Shi, UCSD",
            "timestamp": "03:01-05:32",
            "transcript": "Yes, yes. Uh I think another modality, actually I like Matt's idea about the barcoding. But the barcoding you mentioned maybe it's fluorescence related. And I think there is a possibility that we do barcoding with Raman. Raman based technique. Oh, even without the barcoding technique, we can do hyperspectral hyper hyperspectral imaging with the Raman based technology. So that means if we can speed up the imaging collection, then we have a stack of image that covers a certain spectrum. So each molecule, each molecule that we want to look at have its own spectrum profile. So if the the image stack, the hyperspectral image stack have for example uh 512 multiplied by 512 pixels and each pixel have its own spectrum information covered. And that allow us to do computational algorithm to do clustering, clustering out the same similar spectrum groups of the pixels. So if group one have this same Raman spectrum, then these pixels will be assigned to uh for example red color, one color. And group two we we cluster out again and we assign different second color. And then there's no limitation as long as we can group out uh uh a group of of spectrum profile, we can assign a color for that specific group of uh molecule. So the the in the end each pixel there is a dominating molecule signal. dominating molecule signal is uh the the the final assigned color.",
            "speaking duration": 151,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Nick Galan, West. Wash. Univ.",
            "timestamp": "05:33-05:34",
            "transcript": "Can I ask a question about that?",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Nick Galan, West. Wash. Univ.",
            "timestamp": "05:35-07:07",
            "transcript": "I I was wondering because because we I started looking into doing a little bit of Raman for another project because we have a spectroscopist and we just got a new Renishaw imaging Raman and I'm curious is there a way to if you wanted to label so that you could mark a subcellular compartment with fluorescence, right? Because maybe you know you're you're you know, I know you can you can you can separate mitochondria and nucleus, you know, things big structures really well. But if you wanted to label something like say a cilium so that you could identify it with fluorescence and then image the cilium with Raman, how can you separate out the fluorescence from the Raman signal? And if so, like that that seems like a really cool multimodal approach to be able to say here's a cellular compartment. Now what is the biochemical makeup of this compartment would be something that could be really interesting.",
            "speaking duration": 92,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Lingyan Shi, UCSD",
            "timestamp": "07:08-07:52",
            "transcript": "Uh I do two photon fluorescence which means that because the focus plan will be a little bit different if you use visible laser instead of near infrared laser. So I use the same laser to do the the pump for the SRS imaging but use the same wavelength to do the two photon fluorescence for for G camp or for other fluorescence signal. So other fluorescence signal can be um can be imaged by two photon fluorescence very well. For example the the the one that we usually talk about like label free NADH or flavor molecules and we can quickly just image with two photon fluorescence in the same region of interest.",
            "speaking duration": 44,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Lingyan Shi, UCSD",
            "timestamp": "07:52-08:10",
            "transcript": "So this this is like a uh hyperspectrum hyperspectral image idea how we how we catch that signal.",
            "speaking duration": 18,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The presenter shared a PowerPoint presentation titled \"Label free SRS hyperspectral image\". The slide contained a diagram illustrating the concept of hyperspectral imaging, showing a stack of images and a graph of intensity vs. Raman shift. The slide also contained a series of images at different wavelengths."
        },
        {
            "speaker": "Lingyan Shi, UCSD",
            "timestamp": "08:11-08:48",
            "transcript": "For example we have a cell. So um sorry this one is not the best example. But I can show um for example this this image is from brain, the brain tissue and we can get the protein signal here from imaging modality and the lipid signal here it's also from imaging modality and different types of lipids.",
            "speaking duration": 37,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The presenter changed the slide to \"Label Free Detection of Lipid Subtypes during aging processes\". The slide contained images of aged and young mouse brain front lobe, showing different lipid subtypes."
        },
        {
            "speaker": "Lingyan Shi, UCSD",
            "timestamp": "08:49-09:29",
            "transcript": "So uh you can overlapping them together. The signal can be overlapped. Uh at the same time we can generate H and E digital H and E based on SRS SRS signal. So we don't need to do standing, label free too. So it's a it's a label free imaging of region of interest in our brain. Uh with actually we we can also catch other channels like NADH or flavor. So the wavelength is the same.",
            "speaking duration": 40,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The presenter changed the slide to \"Label Free Detection of Lipid Subtypes during aging processes\". The slide contained images of aged and young mouse brain front lobe, showing different lipid subtypes."
        }
    ]
}