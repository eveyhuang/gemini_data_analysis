{
    "meeting_annotations": [
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "00:00-00:21",
            "transcript": "cell, there's another set of translation. So it's a beating cilia on a moving cell, so that would be a different thing. So you can immobilize them, um, the the cells, not the cilia. And then if you do that, you can get a glancing blow of the side cilia where you can image just through an individual one. Um, I can show an example if if you'd like, uh, I can I can share screen.",
            "speaking duration": 21,
            "nods_others": 3,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "00:22-00:36",
            "transcript": "See here.",
            "speaking duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Domenico (Nick) Galati shared his screen. First, he opened a document with text related to primary cilia and signaling pathways. Then, he opened a Google search page and typed \"galati lab\" in the search bar."
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "00:36-00:41",
            "transcript": "So I guess this this is a a bunch of siliates swimming around, but that's not what we're talking about.",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows Domenico (Nick) Galati's video feed again."
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "00:44-01:25",
            "transcript": "So here is an example of of the DIC type images that you can get and these this is acquired at 600 frames per second. And so we can slow down the wave form and we can track it, but now imagine trying to track a particle moving within that. Um, that's that seems to be the the the problem and I haven't seen anybody even come close to doing it. Again, one thing that people would do is they would maybe treat this with a drug that makes the cilia stop beating and then track them, but you know, that's that's the barrier. So some way to combine the DIC with fluorescence",
            "speaking duration": 41,
            "nods_others": 1,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows Domenico (Nick) Galati's video feed again. Then, a graph is displayed."
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "01:25-01:25",
            "transcript": "at the",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Melike Lakadamyali, UCSD",
            "timestamp": "01:26-02:09",
            "transcript": "So I mean with today's cameras like you know scientific CMOS cameras those frame rates are not out of reach, right? 100 hertz um is not out of reach of an SCMOS camera's frame rate. And so then the question is like can you correct for that motion, right? Um, because when you're tracking your protein you're going to have to um um find a way to to subtract the motion of the cilium uh from the motion of the protein itself. Um, is that motion of the cilium very stereotypical? Like can you sort of characterize and and and correct for it?",
            "speaking duration": 43,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "02:10-02:36",
            "transcript": "I I believe I I can't personally. I think that computational folks can. Um, certainly I think that they can do it. Um, and but but I don't I can't do it. So that would be that that's a barrier right there is that trying to, you know, I think correct and straighten would be one way to do it so that you could, you know, take that curved wave form",
            "speaking duration": 26,
            "nods_others": 0,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "02:36-02:51",
            "transcript": "turn it into a linear rod and then correct for it. So that's a it's an interesting idea. Um, so that would definitely be a computational approach. And then with the CMOS stuff, that the I use a a prime 95B scientific CMOS and the frame rates aren't the issue, it's it is definitely getting the the signal for the protein of interest.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matt Lovett-Barron, UCSD",
            "timestamp": "02:52-02:57",
            "transcript": "Is there any way to have a non fluorescence contrast agent against some of these proteins of interest?",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "02:58-03:01",
            "transcript": "Good thought, I don't know. That's a good thought.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "03:01-03:22",
            "transcript": "Um, you know, one thing that potentially maybe, I don't know. I don't know much about this quantitative phase imaging, but QPI might be one way to to kill two birds with one stone and that just avoid we wouldn't have molecular specificity, but even tracking one of the granules moving within that structure,",
            "speaking duration": 21,
            "nods_others": 0,
            "smile_self": 30,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "03:22-03:22",
            "transcript": "maybe",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd, Arizona State University",
            "timestamp": "03:23-04:35",
            "transcript": "So one issue with a lot of QPIs is it's multiple images. I mean there are ones that aren't, but um typically you need to introduce some sort of diversity in the phase so then you can extract, you know, what the refracted index was. So you need to look at the image somehow in with multiple views. So this can be pretty low though for certain techniques and so the frame rate can still get pretty high. Um, the you know, one the issue is how much is it moving in 3D in like one sort of time step, right? So that that also so let's say you needed minimum three views, I'm just guessing, you could make some technique, you know, how far is it going to displace between each of those three shots or do you need to come up with some sort of simultaneous multi focal technique, which exists, but you keep every time you do that you split the light so you're really going to need transmitted light measurements, right where your photon, your excitation photons are doing the work, not your emission photons.",
            "speaking duration": 72,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matt Lovett-Barron, UCSD",
            "timestamp": "04:36-04:40",
            "transcript": "What about um uh I used to do a little bit of light field microscopy where you put a lenslet array uh so that you can get kind of multiple",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matt Lovett-Barron, UCSD",
            "timestamp": "04:40-04:50",
            "transcript": "views in the same camera frame. But the issue is then it's really computationally expensive to deconvolve into an image and resolution is only so so.",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd, Arizona State University",
            "timestamp": "04:57-05:00",
            "transcript": "I mean, I think those methods are getting a lot better.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd, Arizona State University",
            "timestamp": "05:00-05:25",
            "transcript": "Um, they're very similar in spirit to the also different views for QPI. So so either way you're talking about somehow combining something that has a different view of the image to then try and reconstruct it in 3D, right? The nice part about the QPI is it gets the refractive index and that's still a bit tricky to get with a light field setup.",
            "speaking duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd, Arizona State University",
            "timestamp": "05:25-05:35",
            "transcript": "Um, and so that that phase diversity you need is a little tricky.",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "05:36-05:36",
            "transcript": "No,",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Moheny, Tufts U. (she/her)",
            "timestamp": "05:36-05:37",
            "transcript": "Can I ask a quick question?",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Moheny, Tufts U. (she/her)",
            "timestamp": "05:37-06:15",
            "transcript": "Um, so you had mentioned previously that a lot of your issue is um kind of being photon starved and not being able to get enough light in the end of the day. Is that because of the labeling or is it because of the optical system and somewhere you're throwing out a lot of the light? What would what is the kind of cause?",
            "speaking duration": 38,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "06:15-06:26",
            "transcript": "Yeah, so I mean it's a good I I I don't quite know the answer. My assumption is is that it's a little bit of both. And so like people have only really tried to do this because with with wide field, right?",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Domenico (Nick) Galati, West. Wash. Univ.",
            "timestamp": "06:26-07:51",
            "transcript": "I think it's it's generally like a wide field approach because we do want the most number of photons and we want speed. So camera based wide field analysis is kind of the standard approach. And so, you know, we're we're we could label brighter, we could try to, you know, you know, I guess late wide field with deconvolution would probably be the next step. So just to do simple deconvolution would probably be the next step. But beyond that, I I don't know where the photons. I don't know, you know, we can try just going brighter. We're using typical FPs like GFP and and Mneon which is pretty bright, but so could be a combination of both.",
            "speaking duration": 85,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Moheny, Tufts U. (she/her)",
            "timestamp": "07:51-07:52",
            "transcript": "Yeah, it's",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Aseema Moheny, Tufts U. (she/her)",
            "timestamp": "07:52-08:21",
            "transcript": "it's it's a lot of the techniques. I've heard this from multiple people in multiple discussions that in the end of the day it comes down to not getting enough uh photons back and and I'm just trying to figure out is it the system or it's the actual labeling, but no one can seem to tell me.",
            "speaking duration": 29,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd, Arizona State University",
            "timestamp": "09:28-09:57",
            "transcript": "I mean in this case, I guess my personal take would be when you run the CMOS really fast, you have enough read noise versus the photons being detected and I I think the other single molecule people have experience with this too that it's very difficult you're you're you're noise limited in the number of photons you're detecting from the floor for in this type of situation. But it doesn't mean that's always the case, but here that's especially going to I think be the hardest part because even though they're very efficient when you run them fast, they're still quite noisy. So,",
            "speaking duration": 29,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}