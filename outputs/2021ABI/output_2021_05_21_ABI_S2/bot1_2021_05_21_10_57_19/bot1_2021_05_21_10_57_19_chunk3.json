{
    "meeting_annotations": [
        {
            "speaker": "Doug Shepherd",
            "timestamp": "00:00-00:50",
            "transcript": "RNA measurements for certain gene regulatory networks. So, uh, there's a natural meeting of the two of those, which is we're interested in either scaling the measurements up or combining them with live cell measurements. And so recently, we've been translating our imaging methods, which are very similar to what super resolution groups use, and that's where my background is, into more of the fast 3D imaging. So to that end, we've been working in very high resolution light sheet imaging.",
            "speaking duration": 50,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd",
            "timestamp": "00:50-01:29",
            "transcript": "So what this has allowed us to do is scale a lot of our methods up to where we're imaging at single molecule resolution, but in like centimeters of tissue or looking at organoids and then fixing them and doing spatial transcriptomics on them. The problem with that and the thing that I still have a lot of questions about is should we be measuring at that resolution to answer the questions we have across space and time. So it's great to generate all of this data and we can regularly do it now, but we don't actually know what we're doing with it most for the most part. We have our own questions, but then collaborators come to us and then we hand them 100 terabytes of data and they just look at us like we're crazy, even if we give them all the computational pipeline to reconstruct it.",
            "speaking duration": 39,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Doug Shepherd",
            "timestamp": "01:29-01:52",
            "transcript": "So I I would like people to step back and think like, what do I really need to answer the question I'm looking for? Like more is not necessarily better in my opinion. And it drives the technology sometimes because like there's a resolution race, right? But it it doesn't mean that we're answering questions better. And so I think some careful thought about what really needs to be quantified across space and time can make a big difference.",
            "speaking duration": 23,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kirsten Maitland",
            "timestamp": "01:53-01:57",
            "transcript": "Great, thank you. Um, and last but not least, uh, Liyan.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Lingyan Shi",
            "timestamp": "01:59-04:10",
            "transcript": "Hello? Yes. Hi, hi everyone. Uh, my name is Liyan Shi. Uh, I'm from Bioengineering Department at UCSD. Uh, I just established my lab in 2019. Uh, basically, we are developing, we are developing the optical imaging platform and we integrate the Raman based microscopy such as stimulated Raman microscopy and with the multiphoton fluorescence microscopy together. So this is a multimodality imaging system, not only allow us to visualize the metabolic activities such as those small metabolites like glucose, amino acids or fatty acids, we can directly visualize them because the isotope we add onto those small metabolites will form the new chemical bond, which is, uh, for example, carbon deuterium bond, so we don't need to do click chemistry to add the bulky fluorescence probe anymore. So this layer of metabolic information, uh, can be visualized at the same time, we want to see, for example, the calcium fluorescence signal in the same region of interest. So this, uh, combined imaging platform can be used to solve some biological questions such as neurovascular coupling system.",
            "speaking duration": 131,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Lingyan Shi",
            "timestamp": "04:10-05:07",
            "transcript": "Uh, for example, we, we are so interested in how neuron talk to those other type of cells such as endothelium cells on the vasculature system, like the the uh blood brain barrier, for example. So, uh, another layer of information that we couldn't really image because of the technical limitation is how the endothelium cell from the vasculature system signaling back to the the neuron and uh how these feedback uh feedback circuits that work. So, uh, if we combine both the Raman based imaging with the multiphoton fluorescence imaging together, then we can visualize both layers of information at the same time, specially and temporarily for in vivo imaging. So that means, uh, we can inject some isotope labeled metabolites such as glucose or amino acid into the vasculature system,",
            "speaking duration": 57,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Lingyan Shi",
            "timestamp": "05:07-06:15",
            "transcript": "Then we can image them directly with SRS microscopy and uh, we also see the the calcium calcium signal with G camp based uh genetic mutation mouse, for example, mouse brain. So, uh, at at that moment, we can specially resolve those subcellular resolution of metabolic activities, how the neuron uptake glucose, for example, or sites uptake glucose, how they shuttling those energy to the neuron, then um simultaneously, we see the calcium calcium signal from sites or from endothelium cell, how they behave. And this phenomenon, the interaction can allow us to quantify how does the blood brain barrier permeability change or how it influence the metabolic, for example, the protein synthesis or lipid synthesis and also allow us to really see subtypes of lipids because the Raman based technology have the ability to allow us to resolve and this is subcellular which overcome the barrier um that mass mass spectrum to based imaging system has. And also 3D volume metric, that is the ability that this imaging platform can can solve for the which is surpass the mass spectrum to based imaging modality.",
            "speaking duration": 68,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kirsten Maitland",
            "timestamp": "06:15-06:31",
            "transcript": "Great, thank you. Okay, so we've heard lots of great ideas related to the topic and um I do feel that based on the conversation, um some of you kind of post questions that others may have may want to respond to.",
            "speaking duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Kirsten Maitland",
            "timestamp": "06:31-07:35",
            "transcript": "Um, I would suggest that maybe we start with kind of the um high spatial resolution while gathering temporal information and the challenges there. And then maybe the next topic we could cover um doing the high resolution um but over a large field of view and the challenges in that. Um, and then um I'd also like to be able to have a chance to discuss the multimodality approaches and getting um different spatial information and and the registration topic that was brought up. Um, so that's just a suggestion but I'm happy to let you guys just talk, but maybe we could start with um talking about the challenges in gathering high temporal information um with high spatial resolution and I'll just let anyone um start it off, otherwise I can call on someone.",
            "speaking duration": 64,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "07:35-08:06",
            "transcript": "I'm interested uh if you don't mind, I'm interested to hear a little bit more about Nick's application looking at cilia because it seems like for a lot of us, you know we have this issue of of looking at things with fluorescence microscopes and as a consequence it's a lot about the signal to noise of the sensor and so forth. But I mean it seems like Nick has this interesting um system where he's able to look at cilia uh that maybe doesn't require those sorts of labeling. So I'm curious what maybe that would be an easier one to scale up speed with some kind of camera based method.",
            "speaking duration": 31,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Nick Galan",
            "timestamp": "08:06-09:31",
            "transcript": "Yeah, so so thanks for showing some interest in it. to traditionally, if you need to image cilia that are beating, which is the most challenging situation, they're beating at anywhere from 20 hertz to some extreme protist that live in the sea can beat up to 150 hertz. So that's that's a different story. And typically you're imaging them if you if you need to do temporal imaging, you need to image them at around 100 hertz to get reliable, you know, wave forms. And so we do that with DIC. So DIC microscopy with just a camera is the best way to track the ciliary wave form. Um, but then if you want to track trafficking within this bending whip like wave form, that's where you need to do fluorescence. And so what the field has done is that they've either taken cilia that are beating and immobilized them pharmacologically so that they're not beating and then tracked protein trafficking within them. But that's such a major perturbation that, you know, we still don't know what protein trafficking within a beating cilium looks like because of that. So one thing, yeah, I don't know, you know, and now you can do the combined DIC fluorescence, you know, that's not a challenging technique, but getting enough signal is then that becomes the challenge. So getting enough signal from what could be one to five proteins and part of like a particle train, um, to get enough signal from that to reliably track it within the wave form seems to be where the barrier is, if that makes any sense.",
            "speaking duration": 85,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        },
        {
            "speaker": "Matthew Lovett-Barron",
            "timestamp": "09:31-09:44",
            "transcript": "And can I ask how your uh how are you looking at the cilia such that like where's your optical plane? Is it that you're looking through a bunch of cilia or you're looking along the length of some of them?",
            "speaking duration": 13,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None"
        }
    ]
}