{
    "meeting_annotations": [
        {
            "speaker": "Stephen Fried",
            "timestamp": "00:00-01:20",
            "transcript": "As an experimentalist who works on protein folding I would say that we're just really excited. We think this is an amazing tool. We obviously weren't competing with Google to do this and now we're just really glad that we can be beneficiaries of what I think is a truly revolutionary technology. I think that in terms of the concern, when people say the protein folding problem, it's actually kind of a semantic issue where there really isn't one protein folding problem. When Christian Anfinsen first used that phrase, he did in Google's defense, he did actually use it to mean structure prediction. Of course what's happened over the last four or five decades is that we now know that protein folding is interesting for many other reasons other than being able to potentially predict structures. And so the term has kind of taken on more meanings than it originally had when it was first articulated. So that was just something I wanted to clarify. Just to update a little bit because this is a space that we do a lot of reading and thinking on, they just came out with a preprint two or three days ago to predict complexes as well, like multimers, which apparently works pretty well. So it's pretty remarkable the rate of progress.",
            "speaking duration": 80,
            "self_expression": "enthusiastic, articulate, passionate",
            "others_expression": "engaged, attentive, thoughtful",
            "interruption": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "other": "The speaker uses frequent hand gestures to emphasize his points and explain concepts."
        },
        {
            "speaker": "Stephen Yi",
            "timestamp": "01:20-03:52",
            "transcript": "Yeah I just want to follow up on that that was exactly what I was trying to say because we work on protein protein interactions and the network for a long time now. So exactly when DeepMind first came out with AlphaFold the first question is can they really predict protein protein interaction interfaces? The answer is no. And that's okay. And then when you were talking to people more and more there are many things that AlphaFold didn't really yet produce and generate for us. Yes it's a very amazing platform there are no doubts. So we came up with this paper like almost like 10 years ago. So that was the first time when people predict that the protein interaction network generated by computational prediction can be of even higher quality compared to experimentally generated data set. They have proof of that they have evidence they have a lot of things and it was really high quality. A lot of times because of experimental failures, noise, batch effect and all of that. So apparently of course you cannot really compare to a carefully designed computational algorithm. So definitely see a huge application and potential that we can benefit from AlphaFold. But at the same time as Stephen Fried just mentioned now that a couple of days ago maybe last month this new paper came out saying that they were able to modify this algorithm to predict protein protein interaction complexes. And my student has been working on that to see if we can benefit by integrating with PDB that I know Abhishek has mentioned there too to see if you can somehow use the prediction to broaden and extend to many different protein interactions and then figure out I think the key thing that we want to do is to see the mutational effect how that localized to the protein structure the interaction interface. AlphaFold is perfect in that regard. We can really leverage that information and then model our network to really generate potential effect of mutations and then maybe also model a patient level where you have a set of five six driver mutations combination of them what will be the effect. I think it's just the beginning of many exciting things.",
            "speaking duration": 152,
            "self_expression": "thoughtful, confident, articulate",
            "others_expression": "engaged, attentive, smiling",
            "interruption": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "other": "The speaker uses a virtual background of a university campus."
        },
        {
            "speaker": "Stephen Fried",
            "timestamp": "03:52-04:29",
            "transcript": "So I want to actually ask Stephen you about that because that was something that I was wondering. So if you have let's say a protein that there is a mutation that causes a disease and the main way that that mutation causes the disease is by destabilizing the protein to the point that it doesn't properly fold or gets degraded or something to that effect. So am I understanding you properly in what you're saying that you think that if you then typed in to AlphaFold here's the exact same sequence I'm just going to mutate this one phenylalanine to a valine that it would then properly predict that the whole thing falls apart?",
            "speaking duration": 37,
            "self_expression": "curious, engaged, inquisitive",
            "others_expression": "engaged, attentive",
            "interruption": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "other": "This question effectively builds on the previous speaker's point to deepen the discussion."
        },
        {
            "speaker": "Stephen Yi",
            "timestamp": "04:29-06:04",
            "transcript": "Yes so that's we've been working on that actually that's not published but for the past I would say three to five months now. So you know exactly because excitement by AlphaFold. So at the beginning when you first check the mutant and wild type form so yeah there's no change almost the same but actually for people who are very familiar with PDB I think Abhishek may know this more than me you're able to generate a score a quantitative score that compare the sequence similarity and structural similarity or structural differences. You know when you rotate the structure from the current position 90 degrees rotating you say this is different no they are the same. So you have to have a way to quantify. So there is a way that we can somehow see that single point mutation can really generate the structural differences. I think you can look at that more for structural differences folding and other things. We just started but I think there are for sure some interesting thing that AlphaFold can offer even in terms of protein folding too. At least we can see some sort of thing on the protein surfaces because we are interested more in interactions and then you see some sort of structural surface changes obviously and then by the structural alignment score you can say yes it is really a real change.",
            "speaking duration": 95,
            "self_expression": "enthusiastic, knowledgeable, excited",
            "others_expression": "engaged, nodding, attentive",
            "interruption": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "other": "None"
        },
        {
            "speaker": "Rigoberto Hernandez",
            "timestamp": "06:04-06:08",
            "transcript": "So Abhishek you've been called out a couple of times by them. You want to",
            "speaking duration": 4,
            "self_expression": "facilitating, inclusive, observant",
            "others_expression": "smiling, engaged, turning attention",
            "interruption": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "other": "This is a clear act of facilitation to ensure another participant has a chance to speak."
        },
        {
            "speaker": "Abhishek SINGHAROY",
            "timestamp": "06:08-10:03",
            "transcript": "I have very strong feelings on AlphaFold. It's fantastic actually it's very very good. So actually my feeling is a bit different. I would not like to think about the 10 years in future with AlphaFold. I would like to think about the 10 years in future with Google with what the CEO of Google is thinking might be potentially once he has gotten AlphaFold out. So now if we think in that direction where did AlphaFold come from? The reason we really like this because we essentially have a statistical mechanics kind of a mindset which really gets us into neural networks and this sort of a multi-sequence alignment. So essentially as a community we were already highly biased on which this 500 million dollars investment is now being it's a we are the return on investment. So in a way that's my way of thinking. Now let's think from a different side. Where did machine learning the way we are thinking over the last five years come from? The first wave was in 1960s where already Boltzmann motors not Boltzmann generator but Boltzmann motors were generated. There's a second wave in 1980s and this is the third wave of machine learning holding the hands of GPUs. So from where I like to think is algorithms biology. There are seven different entry points of machine learning. Anything and everything that we are doing right now is the machine learning of neural networks brain. How does the brain work? That is one way and what we are trying to do is we are trying to cast all our problems essentially in terms of how our brain thinks. There are six other ways I've forgotten the names of the six others one of them is quorum sensing. There are reviews in algorithms biology of these seven ways three of them doesn't even have mathematical theorems derived let go of it hasn't even reached computer science it's in the applied math level. So I think of machine learning it's heavily biased by our interpretation of things. It's a virtual machine. So our interpretation is statistical mechanical which goes very nicely with this neural gas. And so this is very very good. And therefore now coming down to AlphaFold I think therefore the next if we follow this track I would invite everyone to look into the six other tracks. But if we follow this track I think dynamics would be extremely important to learn. The question is should we learn dynamics with neural networks with the way we are thinking about our brain thinks about things is that the ansatz to follow or should we think of other ways of machine learning altogether? And I think that's where as biologists we can contribute because we know from this biological side how does nature use seven algorithms. If we can treat this problem these seven that way then possibly it's going to be easier. I know the reason of doing neural networks LSTMs GANs the different kinds of objects also because now they are available there's a lot of implementation but can we think of it beyond that?",
            "speaking duration": 235,
            "self_expression": "passionate, enthusiastic, visionary",
            "others_expression": "highly engaged, nodding, attentive",
            "interruption": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "other": "The speaker provides a broader, more philosophical perspective on the topic, connecting the specific tool to the larger context of machine learning history and corporate strategy."
        }
    ]
}