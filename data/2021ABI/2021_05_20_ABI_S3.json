{
    "all_speakers": [
        "Joshua Brake",
        "Silvia Ronco",
        "Andrew Feig",
        "Candace Fleischer",
        "bot1",
        "Aseema Mohseny",
        "Dylan Burnette",
        "Kristen Marland",
        "Kristen Maitland",
        "Aseema Mohanty",
        "Richard Weisman",
        "Stefan Wilhelm",
        "Unidentified speaker",
        "Kristen Macland",
        "Matt Lew",
        "Sixian You",
        "Qian Liu",
        "Shiva Abbaszadeh",
        "Uzay Emir",
        "Luke Mortensen"
    ],
    "total_speaking_length": 3649,
    "all_data": [
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:00-00:16",
            "transcript": "more discussion. I am sure that there are other topics of discussion that will come up that might fall off that list of key points. Um, maybe Richard who's on on in our room can um make a comment. Are we supposed to put those other ideas into the parking lot or just keep them ourselves or record them somewhere else?",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:00",
            "end_time": "00:16",
            "annotations": {
                "process management": "Kristen Maitland is managing the meeting flow by suggesting more discussion and questioning how to handle additional ideas that might come up.",
                "ask question": "She asks for input or clarification on what to do with other ideas that might come up during the discussion, specifically questioning the procedure for handling these ideas.",
                "encourage participation": "By inviting Richard to make a comment, Kristen Maitland is encouraging participation from him."
            }
        },
        {
            "speaker": "Richard Weisman",
            "timestamp": "00:17-00:36",
            "transcript": "And either of those things you can do. If you think they're really valuable to put in the parking lot, please do. You can keep them for yourselves. I suggest Josh take some notes on the side, which he can share with people, and then you at the very end of the meeting you added it into the key points uh for the discussion. And just have a lot of fun in the discussion.",
            "speaking_duration": 19,
            "nods_others": 1,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the logo of Research Corporation for Science Advancement. The logo is a blue figure eight with the text \"RESEARCH CORPORATION for SCIENCE ADVANCEMENT\" below it. The screen remains static throughout the segment.",
            "start_time": "00:17",
            "end_time": "00:36",
            "annotations": {
                "process management": "The speaker is providing instructions on managing the flow of ideas and discussion, indicating how to handle additional topics.",
                "assign task": "The speaker assigns Josh the task of taking notes on the side to be shared with others."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:36-00:43",
            "transcript": "Okay, sounds perfect. Okay, does anyone have any questions before we take our minute to think?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 29.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:36",
            "end_time": "00:43",
            "annotations": {
                "supportive response": "The speaker confirms the previous suggestion, showing agreement.",
                "encourage participation": "The speaker invites others to share their questions or thoughts before proceeding."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "00:43-00:56",
            "transcript": "Uh, I have a quick logistic question. So the slide is uh is called Psi log ABI meeting slides. And then where are we supposed to put our names? Is it slide 16 session one?",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 23.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:43",
            "end_time": "00:56",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification on a prior statement or idea proposed by another group member, specifically about where to put their names on the slides."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "00:57-01:00",
            "transcript": "I already copied and pasted all of our names in there, so we're good on names.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 33.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:57",
            "end_time": "01:00",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:00-01:02",
            "transcript": "Okay. It's slide 22.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:00",
            "end_time": "01:02",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "01:03-01:06",
            "transcript": "Uh slide 22. Okay, perfect. Thank you.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:03",
            "end_time": "01:06",
            "annotations": {
                "acknowledge contribution": "The speaker verbally recognizes another group member's input with 'Thank you'.",
                "supportive response": "The speaker expresses agreement or confirmation with 'Okay, perfect'."
            }
        },
        {
            "speaker": "Richard Weisman",
            "timestamp": "01:06-01:13",
            "transcript": "And I'll be jumping in and out through through a few rooms. So if I leave, uh don't worry about it and I'll be quiet the rest of the way.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 14.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the logo of Research Corporation for Science Advancement. The logo is a blue figure eight with the text \"RESEARCH CORPORATION for SCIENCE ADVANCEMENT\" below it. The screen remains static throughout the segment.",
            "start_time": "01:06",
            "end_time": "01:13",
            "annotations": {
                "process management": "This code applies because Richard is managing the group's expectations about his participation and availability during the meeting, which relates to managing the meeting flow and structure."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:13-01:15",
            "transcript": "Okay. Thank you.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:13",
            "end_time": "01:15",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland is verbally recognizing Richard Weisman's input by saying 'Okay. Thank you.'"
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:15-02:30",
            "transcript": "Okay, so I'm going to set a timer for one minute for you each to think about your topic related to uh super resolution methods. We were given two kind of prompt questions, but I think you have other ideas and other questions that you might want to ask. So I'll just we'll have one minute of silence for thinking.",
            "speaking_duration": 75,
            "nods_others": 0,
            "smile_self": 1.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:15",
            "end_time": "02:30",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by setting a timer for one minute of silence for thinking.",
                "clarify goal": "The speaker clarifies the goal by having the group think about topics related to super resolution methods and referring to provided prompt questions."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "02:31-02:36",
            "transcript": "So both three, I don't I don't have you assigned. I need so I don't know how to put you in.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:31",
            "end_time": "02:36",
            "annotations": {
                "identify gap": "The speaker explicitly recognizes a lack of information or resources for task assignment.",
                "ask question": "The speaker requests information or clarification on how to handle the assignment issue.",
                "process management": "The utterance relates to managing the group's composition or task assignments."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "02:37-02:40",
            "transcript": "You don't have me, you don't see me in there in the room?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:37",
            "end_time": "02:40",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification about their visibility or inclusion in the meeting materials.",
                "identify gap": "The speaker is highlighting their lack of visibility or inclusion in the room or document."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "02:40-02:46",
            "transcript": "I don't see you as an assigned. I don't know why.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:40",
            "end_time": "02:46",
            "annotations": {
                "identify gap": "The speaker recognizes a lack of knowledge or an issue (not being able to see someone as assigned) in the system they are working with.",
                "ask question": "The speaker is seeking clarification or information about why they cannot see the person as assigned."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:46-03:12",
            "transcript": "Okay. That is strange. Do you I mean, um so one thing I'll say is that I'll just ask if anyone would want like to start the conversation. Um I'm going to try and keep an eye out on if there is someone that is not contributing and I will call on you at a certain point just to make sure we hear from everyone. Um and I do ask that you be respectful of other people's time and so um if you do feel like you're contributing quite a bit, that's excellent, but maybe make sure that everyone has a chance to speak.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 15.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:46",
            "end_time": "03:12",
            "annotations": {
                "process management": "Kristen Maitland is managing the meeting flow by indicating she will monitor participation and ensure everyone has a chance to speak.",
                "encourage participation": "Kristen Maitland invites participants to contribute by asking if anyone wants to start the conversation and ensures everyone has a chance to speak."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "03:12-03:17",
            "transcript": "Okay, so who would like to get started?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 40.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:12",
            "end_time": "03:17",
            "annotations": {
                "encourage participation": "The speaker is inviting others to contribute their thoughts or ideas by asking who would like to get started."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "03:17-04:46",
            "transcript": "I can get started on one of the topics. Uh I really like the second question, how can we mitigate or utilize multiple scattering when we transition this technique to invivo applications? I think there are two ways to think about it. So if we are talking about like traditional super resolution techniques like in optics, uh multiple scattering is the enemy because they scramble your light. So the first way to think about it is how can we gate these multiple scattering? How can we reject them so that we can only get ballistic photons that carry the truly valuable information. And then so I guess one direction along this way is to think how can we more efficiently uh select these ballistic photons. And then a second direction, a second perspective on this is how do we use multiple scattering to get more information? Because these ballistic photons decay exponentially as you go deeper into the tissue. Uh so if we can use the but multiple scattering uh process looks random, but it's deterministic. So if we have physics model that can take advantage of this uh interference and use that to our advantage because with multiple scattering, you can actually get more angles, right? So with that you get more field of view, you get more uh uh resolution. So uh I I think that part is pretty interesting.",
            "speaking_duration": 89,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:17",
            "end_time": "04:46",
            "annotations": {
                "propose new idea": "The speaker introduces a new idea on how to approach the problem of multiple scattering in super resolution techniques by suggesting two directions: gating/rejecting multiple scattering and utilizing it.",
                "develop idea": "The speaker expands on their proposed idea by providing detailed explanations and potential approaches for both directions, including using physics models to leverage multiple scattering for more information."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "04:47-05:07",
            "transcript": "That's great and thank you. And I just realized that we did not introduce ourselves first. So uh Sishan, why why don't you start and introduce yourself? We'll go around, make sure we just it'll be a very brief so your name and institution which we can see, but um a brief uh introduction of your background and what perspective you have on this topic in particular.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 15.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:47",
            "end_time": "05:07",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland acknowledges a previous contribution by saying 'That's great and thank you'.",
                "process management": "Kristen Maitland manages the meeting process by deciding to have everyone introduce themselves.",
                "encourage participation": "Kristen Maitland invites participation from all members by asking them to introduce themselves."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "05:08-05:26",
            "transcript": "Uh my name is Sishan Yo. I just started at MIT uh three months ago, two months ago. Uh my lab develops optical imaging technologies, especially for microscopy applications. We are interested in using optics and algorithms to solve real world biomedical problems.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 11.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:08",
            "end_time": "05:26",
            "annotations": {
                "signal expertise": "The speaker explicitly states their background, including their lab's focus on optical imaging technologies and their recent start at MIT, indicating their expertise or potential expertise in the field."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:26-05:28",
            "transcript": "Thank you. Uh Dylan.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:26",
            "end_time": "05:28",
            "annotations": {
                "acknowledge contribution": "The speaker is thanking someone, which is a form of acknowledging a contribution.",
                "encourage participation": "By saying 'Uh Dylan', Kristen Maitland is encouraging or inviting Dylan to participate."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "05:29-06:12",
            "transcript": "I am uh Dylan Burnette. I'm a an associate professor at Vanderbilt University. I just got tenure, so I'm technically now not uh new, although I feel new still. I have new people problems. Um I am a cell biologist by training and I've been using light microscopy for about 20 years now to study everything from neurons to cancer and now I work on heart. So I'm very interested in how the heart grows on a single cell level.",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 2.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:29",
            "end_time": "06:12",
            "annotations": {
                "signal expertise": "The speaker explicitly states his own expertise, qualifications, and experience as a cell biologist and his work with light microscopy."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:12-06:12",
            "transcript": "Great.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:12",
            "end_time": "06:12",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or acknowledgment with a positive tone."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "06:13-06:13",
            "transcript": "Aseema?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:13",
            "end_time": "06:13",
            "annotations": {
                "encourage participation": "invites someone else in the group to contribute their expertise, opinions or ideas."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "06:15-06:56",
            "transcript": "Hi, I'm Aseema Mohanty. Um, I recently started as a faculty at Tuffs University in Boston. Um, and I work on uh nanophotonics. Um, so that's like chip scale optics and so um uh we've been kind of working on um optical phase arrays and creating 3D structured light from a chip. Um, and so my kind of perspective on super resolution is is there anything that we can do to kind of, you know, handle some of the limitations of bulk um optics or high NA objectives and miniaturize that to make it kind of feasible for um more portable applications.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 41.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:15",
            "end_time": "06:56",
            "annotations": {
                "signal expertise": "The speaker explicitly states her own expertise and background in nanophotonics and her work on optical phase arrays and 3D structured light.",
                "ask question": "The speaker asks if there is anything that can be done to handle the limitations of bulk optics or high NA objectives and miniaturize them for more portable applications."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "06:56-06:57",
            "transcript": "Okay. Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:56",
            "end_time": "06:57",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges a contribution with 'Thank you'.",
                "supportive response": "The 'Okay' indicates agreement or validation."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "06:57-06:57",
            "transcript": "Josh?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:57",
            "end_time": "06:57",
            "annotations": {
                "encourage participation": "The speaker is directly addressing Josh, inviting him to contribute his thoughts or ideas to the discussion."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "07:00-07:54",
            "transcript": "Everybody, my name is Josh Brake. I am an assistant professor in the engineering department at Harvey Mudd College. My training is in engineering and specifically in electrical engineering. I did my PhD work in um biomedical optics, specifically looking at how to use optical wavefront shaping to peer deeper into tissue. And so I really resonated with what we were just talking about about the second option, which I think is the much better one, maybe unbiased, but uh to try to harness the multiply scattered photons and in some sense redeem those to make them make them useful for our for our optical imaging techniques. Uh the last thing I'll say is just that as an engineer, I'm a tool builder by nature and so I'm really looking forward to meeting all of you and hearing about Kristen what you said in the main session really resonated with me too. How can I bring engineering skills to bear to solve solve problems? So thanks.",
            "speaking_duration": 54,
            "nods_others": 0,
            "smile_self": 11.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:00",
            "end_time": "07:54",
            "annotations": {
                "develop idea": "Josh elaborates on his research and thoughts on harnessing multiply scattered photons, building on previous discussions.",
                "signal expertise": "Josh explicitly states his background and expertise in electrical engineering and biomedical optics.",
                "supportive response": "Josh expresses resonance with previous discussions and shows enthusiasm for the topic."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:54-07:55",
            "transcript": "Great, thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:54",
            "end_time": "07:55",
            "annotations": {
                "supportive response": "The speaker expresses a positive evaluation and thanks for a previous contribution, fitting the definition of a supportive response."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:55-07:56",
            "transcript": "Uh Luke?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:55",
            "end_time": "07:56",
            "annotations": {
                "encourage participation": "The speaker is explicitly inviting Luke to contribute his thoughts or ideas, which is a clear attempt to encourage participation."
            }
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "07:57-08:55",
            "transcript": "Um, hi, I'm Luke Mortenson. I'm assistant professor at the University of Georgia. Um, although I will be associate as of July 1st, so I'm kind of in the intermediate space of still feeling new. Um, but um, uh uh my lab is primarily focused on uh multiphoton imaging. Um, so we do um like two photon, we're moving towards like second harmonic, third harmonic generation type stuff. Um, and we're looking at moving to kind of like near IR wavelengths to get um, I guess with 1300, 1700 to kind of like peer deeper into tissue and also some scattering correction approaches um to look at um as how much we can get in there and try to get rid of things that are causing negative interference, etc. And um um I guess our application is looking at bone and muscle regeneration primarily.",
            "speaking_duration": 58,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:57",
            "end_time": "08:55",
            "annotations": {
                "signal expertise": "The speaker explicitly states their own expertise and qualifications, mentioning their position as an assistant professor at the University of Georgia and the focus of their lab."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:55-08:56",
            "transcript": "Thank you. Matt.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:55",
            "end_time": "08:56",
            "annotations": {
                "acknowledge contribution": "The speaker is expressing gratitude, which acknowledges someone's contribution.",
                "encourage participation": "The speaker is also inviting or addressing someone named Matt, which encourages participation."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "09:06-09:54",
            "transcript": "Hi. Uh I'm Matt Lou. Um I'm an assistant professor in electrical and systems engineering at Washu. Uh my group works on um building single molecule imaging techniques for just understanding um chemical and biochemical dynamics in at the nano scale. Uh one of the things that that we really pushed recently is basically leveraging uh signals that are other than just brightness to to understand what's happening at the nano scale. So for us, uh a lot of it is uh fluorescence polarization.",
            "speaking_duration": 48,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "09:06",
            "end_time": "09:54",
            "annotations": {
                "signal expertise": "The speaker explicitly states his own expertise and qualifications related to the task by introducing himself and his work in electrical and systems engineering, and his group's focus on single molecule imaging techniques."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "00:00-00:47",
            "transcript": "I'm Stefan, I'm from the University of Oklahoma. I'm in biomedical engineering. Um, I'm trained as a chemist. Uh, now I'm in my fourth year as a system professor and my research group focuses on nanomedicine, so applying nanotechnology for treatment and diagnosis of cancer specifically and we are interested in understanding um the transport of drug carriers and small molecule drugs through the body and how those drug carriers interact with cell surface. So for us super resolution information is is really the key to understand those transport pathways. Um, and my lab is applying techniques such as expansion microscopy to get a better understanding of those intracellular transport pathways.",
            "speaking_duration": 47,
            "nods_others": 10,
            "smile_self": 10,
            "smile_other": 20,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:00",
            "end_time": "10:47",
            "annotations": {
                "develop idea": "The speaker explains how super resolution information and techniques like expansion microscopy are key to understanding intracellular transport pathways."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:47-00:52",
            "transcript": "Great, thank you. Um, Uzay, can you tell me how to pronounce your name correctly, please?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:47",
            "end_time": "10:52",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification on how to pronounce Uzay's name."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:52-00:53",
            "transcript": "Uzay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:52",
            "end_time": "10:53",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:53-00:54",
            "transcript": "Uzay, thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:53",
            "end_time": "10:54",
            "annotations": {
                "acknowledge contribution": "This code applies because Kristen Maitland is verbally recognizing Uzay Emir's input regarding the pronunciation of his name."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:54-02:12",
            "transcript": "Thank you so much. So, um, I'm Uzay and I'm from Purdue University and I'm at the School of Health Sciences as a biomedical engineering. I'm electrical engineer in principle, but I have been doing biomedical stuff since I graduated and that includes all developing new techniques for diagnostic purpose of MRI and the reason I'm interested in super resolution is always try to find the link between the lab resolution to to in vivo or contact animal resolution so microscopic scale. So I always keep an eye on what's happening in the smaller scale higher super resolution and to see what can be translatable to animal. So my research is ranging from cancer to neurological imaging and lipidomics to metabolomics and also cancer and also includes physiological intervention and also bone sodium content and X nuclei and phosphorus all types of imaging but I really like to make the link between the lab to do from bench to bedside actually.",
            "speaking_duration": 78,
            "nods_others": 1,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:54",
            "end_time": "12:12",
            "annotations": {
                "signal expertise": "The speaker explicitly states his background, qualifications, and research focus, signaling his expertise in the field.",
                "develop idea": "The speaker elaborates on his research interests and how they relate to super resolution microscopy, providing context and background."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:12-02:13",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "12:12",
            "end_time": "12:13",
            "annotations": {
                "acknowledge contribution": "The speaker is expressing gratitude, which is a form of verbally recognizing another group member's input."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:13-02:23",
            "transcript": "Vivian?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "12:13",
            "end_time": "12:23",
            "annotations": {
                "encourage participation": "The utterance is an invitation for Vivian to contribute her thoughts or ideas, encouraging her participation in the conversation."
            }
        },
        {
            "speaker": "Qian Liu",
            "timestamp": "02:23-03:11",
            "transcript": "Hello, uh, I'm Vivian Lou. I'm from McGill University. Uh, I'm at the the Institute of parasitology and also McGill Center for viral diseases. I'm trained as a molecular virologist and molecular cell biologist as a PhD student and then in my postdoc, I uh, I joined a biophysical lab where I learned how to do uh single molecule localization microscopy and I study uh virus life cycle using uh super resolution microscope. So I looked at how the virus are entered uh replicated and egress from their host cell.",
            "speaking_duration": 48,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "12:23",
            "end_time": "13:11",
            "annotations": {
                "signal expertise": "Vivian explicitly states her own expertise and qualifications related to the task, which is her background in molecular virology, molecular cell biology, and her experience with single molecule localization microscopy."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:11-03:19",
            "transcript": "Great, thank you. And Candace is in our room but she um is on another zoom, so when she gets back in we can um have her introduce herself. So thank you for that um kind of brief introduction that really helps put things in context for us.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "13:11",
            "end_time": "13:19",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland is verbally recognizing the group members' input by thanking them for their brief introductions.",
                "supportive response": "Kristen Maitland is expressing a positive evaluation for the introductions made by the group members.",
                "encourage participation": "By mentioning that Candace will introduce herself when she gets back, Kristen Maitland is inviting Candace to participate."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:19-03:33",
            "transcript": "And maybe if we could just pick up where we left off with the discussion. Josh, did you want to build off of um what you were saying in about using away from uh go ahead.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "13:19",
            "end_time": "13:33",
            "annotations": {
                "encourage participation": "The speaker invites Josh to contribute further to the discussion.",
                "process management": "The speaker attempts to manage the discussion flow by picking up from where they left off."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "03:39-05:00",
            "transcript": "Sure, sure. So I think that um I just see a a game of diminishing returns if we're just trying to get better at gating things out. Um, and so especially now we push to multiphoton two, three, I don't know, can we do four or five? Like at what level does that get so complicated and so expensive that it's not really it's not really useful. And so I I would really like to I think my background is is in more of the second thinking more about the second part of this question, but I think what intrigues me about this room is thinking about the two of these together, especially because super resolution microscopy I think is often speaking as somebody who's not well trained in that area, but seems to me to be very photon start in general. Like you need a lot of light.",
            "speaking_duration": 81,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "13:39",
            "end_time": "15:00",
            "annotations": {
                "develop idea": "Josh is expanding on existing ideas by discussing the challenges and potential limitations of certain approaches in super resolution microscopy.",
                "ask question": "Josh poses questions about the feasibility and usefulness of pushing to higher multiphoton levels."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "05:00-05:57",
            "transcript": "Um, and so if you're saying, okay, well, I'm going to throw out all the scattered photons, you're walking a you know, that line is going to get hard to walk pretty quickly. So I I think that I really like the thinking about how how can we maybe take these two together and I'm not I haven't seen too much looking at super resolution combined with thinking deeper into tissue and how to think about scattering. And the last thing I'll say just to uh is I also wonder what the room is for conversations in between let's say minimally invasive types of technology as a stepping stone to getting to the ultimate goal where we just shine some light outside the body and then capture everything outside the body non invasively, but maybe minimally invasive with um, you know, fibers, fiber bundles, uh, these kind of things can be a a nice stepping stone to push things into the into practice because I think with biomedical imaging outside of the like really big success of OCT, there's not so many optical like biomedical optical techniques that have really made a significant um, you know, push into the clinic.",
            "speaking_duration": 57,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "15:00",
            "end_time": "15:57",
            "annotations": {
                "develop idea": "Josh Brake is expanding on previous ideas about handling scattered photons and exploring the combination of super resolution techniques with deeper tissue imaging.",
                "propose new idea": "Josh suggests considering minimally invasive technologies as a stepping stone to achieving the goal of non-invasive imaging techniques.",
                "ask question": "Josh asks for thoughts on the potential of combining super resolution with deeper tissue imaging and wonders about the feasibility of certain approaches."
            }
        },
        {
            "speaker": "Qian Liu",
            "timestamp": "05:57-09:17",
            "transcript": "Uh, I I want to add something uh to to uh idea. So she was mentioned about using uh how to uh how to manipulate the scattering interference. So there is something um I was thinking about. Uh, I was doing uh uh super resolution when I was doing super resolution microscope, I always wanted to stabilize the sample so that with a with a long uh long-term imaging for example like 30 minutes, I don't get a great uh sample drift. So one way I was thinking while I was a postdoc is to use the scattering light from the cell. So we take uh we take the scattering light the image using scattering light of the cell at at the beginning of the imaging and after a few minutes we take another one. So by the end like by the end of the imaging we could use those image to align um kind of put to the kind of uh correct the drift. So that's one thing I was thinking about. Uh, but I haven't tapped it. I'm not sure how precisely I can do as my uh uh I claim a 10 nanometer uh uh uh precision. So I'm trying to make sure how I can how precisely I can do that. And uh some thoughts for the first uh question like how can super resolution uh methods can be translated to uh uh organismal applications. Um, I have been thinking about that for the past few years. Um, one thing I found uh uh that could be helpful is maybe lizing the floor for chemistry because right now uh I spend a lot of time on doing uh imaging analysis uh like look at all the localization and how to cluster them and how to figure out the organization of the proteins. But uh at the end of the day I thought if we could use different floor for to map these what I mean is if I put it in a example, see if we have a DNA molecule, they can uh kind of fold into different structure. Like if we wanted to figure out the structure, let's see uh we can use uh maybe the barcoding system like we can since we know the sequence we probably can uh use the barcoding to map the entire sequence, then then we label that the molecule uh ourselves, then we can image that maybe we know we would figure out like uh how they position the spatial. So that's So I think um maybe uh aside from the imaging processing just using AI or deep learning to look at the cluster or organization, maybe uh uh floor for can might be helpful. That was my thought.",
            "speaking_duration": 204,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "15:57",
            "end_time": "19:17",
            "annotations": {
                "develop idea": "Vivian is expanding on existing ideas by sharing her thoughts on manipulating scattering interference and stabilizing samples during super resolution microscopy.",
                "propose new idea": "Vivian introduces the idea of using a barcoding system to map molecular structures, which appears to be a new suggestion in the conversation."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "09:18-09:57",
            "transcript": "So I would say that this this this question is well beyond what I think about normally. Um, because we're trying to get to structural resolution and if you do that in an animal, it would be too much data. We don't have big enough computers for that. And so this is a very interesting, you know, concept because when we want to look at an animal, we just cut off a piece of our zebra fish and take that tissue and we call that an animal or an organism.",
            "speaking_duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "19:18",
            "end_time": "19:57",
            "annotations": {
                "identify gap": "The speaker points out the lack of sufficient computational power as a gap in their ability to analyze data from animal studies at a certain level of resolution."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "00:00-00:32",
            "transcript": "illumination or single molecule imaging on top of that. And I'm calculating resolution and it's scaring me already and it's a single cell. So do we have any idea what we do with that kind of data if we have super res and like I'm I'm I'm just it's exciting but also scary at the same time.",
            "speaking_duration": 32,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:00",
            "end_time": "20:32",
            "annotations": {
                "ask question": "The speaker explicitly asks for ideas on handling data from super-resolution microscopy, showing a clear request for information or clarification."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:32-01:25",
            "transcript": "Can I uh so similar to your question actually your question is originating from a problem actually going back to whole animal or big organism will be ring a lot of data. Now the question is how from my point of view I'm a microscopic person and even our data is big but uh it's not as complicated as yours uh but it has its own difficulties. How you are seeing all you guys are optical imaging and super resolution compared to myself to make it really translatable to real life or big animal or live animal uh thing. So what is your pathway to bring those techniques to this and considering your concern about the size of the data.",
            "speaking_duration": 53,
            "nods_others": 1,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:32",
            "end_time": "21:25",
            "annotations": {
                "ask question": "The speaker is requesting information or insights from others on how to translate super-resolution techniques to bigger organisms or live animals, considering the issue of data size and complexity."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "01:26-02:35",
            "transcript": "So is it possible to to combine structured light and of scattering at the same time? Is that too complicated? Sorry, I'm not I'm not a physicist, but we are using structured light uh through the line of slide sheet and and and it's the same, you know, basic run of the mill technologies. Um but can you collect scattered light from that sort of information? Because that's already up and running of in many, many labs around the country and world right now. Uh would be able to combine something like the lighter slide sheet which penetrates into tissues pretty decently, let's not say great, but decently. But now it's good as four photo time would. But um um but we uh but that also has already structured information with it. Does that complicate getting scattered light or not? Because that's kind of a fascinating idea uh that I hadn't really thought too much about. And at least three of you had thought a lot about it. So that's pretty cool.",
            "speaking_duration": 69,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:26",
            "end_time": "22:35",
            "annotations": {
                "ask question": "The speaker is explicitly asking questions about the possibility and feasibility of combining structured light and scattering, and how it might work with existing technologies.",
                "signal expertise": "The speaker mentions his experience with structured light technology and its applications, indicating his own expertise in the area."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "02:36-03:03",
            "transcript": "I guess my two cents on this is by de facto as optical engineers, we try to throw out the scattered light. That's the conventional wisdom. We always have done that. And so every optical system you pick up whether it's your iPhone or a microscope is designed to throw that information out. And that's the that I think is the kernel of the revolutionary idea here is like let's remove that constraint and go back to the drawing board and think differently.",
            "speaking_duration": 27,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:36",
            "end_time": "23:03",
            "annotations": {
                "propose new idea": "The speaker suggests considering the value of scattered light that is typically discarded, proposing a new approach to optical engineering.",
                "develop idea": "The speaker elaborates on the conventional approach in optical engineering and suggests a change in this approach, providing examples and context for their idea."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "03:03-04:24",
            "transcript": "Yeah, Josh, I I'd like to to build off of that. So I think you did made a great point about the uh the the sort of the paradigm of of at least microscopy uh and ballistic imaging that we throw away all the scattered light. Then we're kind of forgetting our friends in the diffuse optics regime. So let's think of DOT diffuse optical tomography and people sort of um uh there's there's actually a colleague here at Washu who builds the whole brain uh uh imaging uh device, right? And and looks at uh sort of function uh um by collecting diffuse light off of there. So maybe um maybe a a regime of pushing the resolution there might be helpful. Uh right now it's sort of spatially resolved based upon the average number of scattering events that takes light longer to travel further or or uh uh and and you can sort of resolve some things in depth that way. So maybe that's one way we can think about it. I think maybe another question is um like if we take our existing technologies that can penetrate deep but somehow are deficient in some other axis. So let's just say pet for example, right? The gold standard in in specifically detecting something uh uh within within the body and an organism. Uh is there something that optical imaging if engineered the right way, maybe with the the fancy uh fluorescent based reporters that we saw uh earlier in the keynote. Um maybe there's something that we can do to to to solve a more targeted problem as a as a as a prototype for for for uh for solving the the bigger question that that was posed. Um just a couple ideas there.",
            "speaking_duration": 81,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:03",
            "end_time": "24:24",
            "annotations": {
                "develop idea": "Matt Lew is expanding on Josh's idea about microscopy and ballistic imaging by suggesting consideration of the diffuse optics regime.",
                "propose new idea": "Matt Lew introduces the idea of using diffuse optical tomography and PET as potential approaches for solving targeted problems.",
                "ask question": "Matt Lew poses questions about the potential of optical imaging with the right engineering and reporters to solve targeted problems."
            }
        },
        {
            "speaker": "Aseema Mohseny",
            "timestamp": "04:24-04:45",
            "transcript": "I'd like to I'd like to kind of jump on that as well. Um I I feel like one thing that I I and this might just be my inexperience with the super resolution field, but like um one thing we don't really talk about much is what and and similar to what Matt was talking about is um what could we kind of learn from, you know, we're kind of used to a a certain type of imaging with an objective with a very high NA, you know, lens and and I feel like that's kind of a bulk of the problem.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 80,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:24",
            "end_time": "24:45",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by suggesting considerations for alternative approaches in super resolution imaging.",
                "critical response": "The speaker questions and critiques the common practice of using high NA lenses in super resolution imaging.",
                "ask question": "The speaker poses a question about learning from other types of imaging methods."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "04:45-04:45",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:45",
            "end_time": "24:45",
            "annotations": {
                "acknowledge contribution": "verbally recognizes another group member's input, but not agreeing or expanding",
                "supportive response": "Expressing agreement, validation, or positive evaluation for other group members' contributions without adding new content"
            }
        },
        {
            "speaker": "Aseema Mohseny",
            "timestamp": "04:45-04:45",
            "transcript": "Yeah, okay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:45",
            "end_time": "24:45",
            "annotations": {
                "None": "No relevant code applies to this utterance as it is a minimal response without substantial content."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "04:45-06:03",
            "transcript": "So I would say that from because I'm the I'm I'm the uh I'm the holer here not the forger. I don't uh I don't uh I I developed one technique and no one ever used it. So it was called bomb because back in the day anything with single molecules had to have a acronym. Uh and I learned through that that I should not develop techniques. I should just take other people's and Um but I'll say as a as a user and we're pretty advanced users uh that we are pretty much addicted to the high NA lens because it's what's available. It's what's commercially available, it's what we can order. We're not going to build our own lenses. And that is why we use them. There's no one has come up with a better way that I can purchase to do this and it's very limiting because the high NA is usually uh uh for the most of our of our work for super res which is single molecule or structured light. Um and I generally put those in just two categories. I know that some of you are have four categories of super res. Um but when you think about it from that way, it's very limiting as far as Z depth, so how far you can go, so your axial dimension that you can penetrate your sample is limited.",
            "speaking_duration": 78,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:45",
            "end_time": "26:03",
            "annotations": {
                "Identify Gap": "The speaker explicitly mentions that high NA lenses are limiting in terms of Z-depth penetration, identifying a gap in current capabilities.",
                "Develop Idea": "The speaker elaborates on why high NA lenses are used and discusses their limitations, developing the idea that there is a need for better solutions."
            }
        },
        {
            "speaker": "Aseema Mohseny",
            "timestamp": "06:03-06:03",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "26:03",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:03-06:03",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "26:03",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Aseema Mohseny",
            "timestamp": "06:03-06:03",
            "transcript": "So it's.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "26:03",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Aseema Mohseny",
            "timestamp": "06:03-07:33",
            "transcript": "I mean, yeah, no, I'm I'm I'm just I'm coming from a different kind of world of of, you know, you know, we everything we do is like little chips and so that you could do like fine resolution here and fine resolution here, you know, what are kind of the limitations um from people who are actually using super resolution um with those objective lenses that that you guys use. Um in terms of I guess field of view and like the amount of power that you need to be able to illuminate an entire section.",
            "speaking_duration": 90,
            "nods_others": 0,
            "smile_self": 70,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "27:33",
            "annotations": {
                "ask question": "Requesting information about the limitations of super resolution with objective lenses, specifically regarding field of view and illumination power.",
                "identify gap": "Implicitly recognizing a gap in her own knowledge about the practical limitations of super resolution microscopy with certain lenses.",
                "develop idea": "Expanding on the discussion by introducing a new perspective on super resolution microscopy, focusing on limitations and potential applications."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "00:00-00:14",
            "transcript": "you know, light coming out here and creating patterns and but we don't have the I mean, it's it's crazy for me to think about being able to combine that with a microscope, but you know, I think there must be ways.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 86,
            "smile_other": 14,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:00",
            "end_time": "30:14",
            "annotations": {
                "propose new idea": "The speaker suggests combining a technology with a microscope, introducing a new idea.",
                "develop idea": "The speaker elaborates on the idea by mentioning creating patterns with light and considers its application with microscopy."
            }
        },
        {
            "speaker": "Andrew Feig",
            "timestamp": "00:15-00:18",
            "transcript": "Dylan, your task is to have the right quarter cell at the right time.",
            "speaking_duration": 3,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 33,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:15",
            "end_time": "30:18",
            "annotations": {
                "assign task": "Andrew Feig explicitly assigns a task to Dylan, indicating a clear action item for him."
            }
        },
        {
            "speaker": "Andrew Feig",
            "timestamp": "00:18-00:20",
            "transcript": "to capture what it is you want to see.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:18",
            "end_time": "30:20",
            "annotations": {
                "supportive response": "The speaker provides a supportive comment encouraging others to focus on capturing what they want to see.",
                "encourage participation": "The speaker's comment can be seen as encouraging participation by reminding others to focus on their goals."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "00:21-00:49",
            "transcript": "Yes, and and and and and and and now with expansion microscopy we were having to do uh what we now refer to as structured illumination as low back imaging. Um, and we had to we do that live, fix that cell and then expand it, find the cell again and then image what is getting down to, you know, we're estimating five to 10 nanometer resolution lateral. So we're really good, but this is all people give me. I I I I I'm I'm I'm I'm I'm wanting for the uh next thing. So that's I I I I think I'm here because I am the user of the next thing, not the inventor of the next thing. So I'm getting excited but I'm also kind of confused at the same time.",
            "speaking_duration": 28,
            "nods_others": 1,
            "smile_self": 50,
            "smile_other": 21,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:21",
            "end_time": "30:49",
            "annotations": {
                "develop idea": "The speaker is elaborating on existing ideas by discussing expansion microscopy and structured illumination.",
                "identify gap": "The speaker expresses a desire for the 'next thing,' indicating a gap in current technology or knowledge.",
                "signal expertise": "The speaker shares specific details about their experience with microscopy techniques, indicating their expertise in the area."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:01-01:04",
            "transcript": "Yeah, I guess one of the fundamental limitations, at least with fluorescence.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:01",
            "end_time": "31:04",
            "annotations": {
                "None": "No relevant code directly applies to this utterance"
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:08-01:09",
            "transcript": "just a standard dipole radiation pattern.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:08",
            "end_time": "31:09",
            "annotations": {
                "None": "No relevant code directly applies to this utterance as it stands alone as a statement of fact without directly engaging with the discussion in a manner categorized by the provided codes."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:10-01:24",
            "transcript": "So what that will mean is that then the light just goes everywhere. I mean, of course it's zero along the dipole axis, but that's a sine squared kind of fall off. So what that means is you just need a huge collection angle to efficiently collect if you want to do single molecule at least.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:10",
            "end_time": "31:24",
            "annotations": {
                "develop idea": "The speaker is expanding on an existing idea through reasoning and explanation, providing more details about the challenges of single molecule imaging related to the dipole radiation pattern of fluorescence."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:24-01:28",
            "transcript": "Uh, because you're just not going to get enough photons to even detect the thing uh without it.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 25,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:24",
            "end_time": "31:28",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas through reasoning about the limitations of detecting photons in super resolution microscopy."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:29-01:34",
            "transcript": "Um, in terms of decoupling excitation and emission, there's a lot of interesting light sheet stuff.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:29",
            "end_time": "31:34",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by mentioning 'light sheet stuff' as an area of interest related to decoupling excitation and emission."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:34-01:41",
            "transcript": "It turns out that that's now a mechanical engineering problem because you if you want high NA and two high NA objectives next to each other, it's it's impossible.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:34",
            "end_time": "31:41",
            "annotations": {
                "develop idea": "The speaker is expanding on previous ideas about the limitations of microscopy techniques, specifically discussing the challenges of using high NA objectives.",
                "identify gap": "The speaker is highlighting a limitation or challenge in current technology, which is the mechanical engineering problem of placing high NA objectives next to each other."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:41-01:50",
            "transcript": "So, um, one of the most cool things that's coming out of uh Calico labs, which is an independent sort of foundation funded thing is is Andrew York's work on remote focusing.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:41",
            "end_time": "31:50",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:51-02:13",
            "transcript": "And uh basically doing some interesting optical tricks to get a light sheet scanning in there along with high NA detection and that I think is probably where the sort of classic uh uh innovation like frontier is right now in terms of high resolution and organism and fast. Like that um I've been impressed by that recently.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 14,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:51",
            "end_time": "32:13",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by discussing new methods for light sheet scanning with high NA detection.",
                "supportive response": "The speaker expresses admiration for recent innovations in optical tricks for imaging, showing a positive evaluation."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "02:15-02:47",
            "transcript": "Is is there tolerance in the community um for having something that let's say you have a objective lens and then you have something next to it, but it's very tiny, let's say it's, you know, 50 microns thin.",
            "speaking_duration": 32,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:15",
            "end_time": "32:47",
            "annotations": {
                "ask question": "The speaker is requesting information about the community's tolerance for a specific technical setup involving an objective lens and an additional tiny component."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "02:47-02:51",
            "transcript": "Is there tolerance in the community for having something that's some semi, you know, invasive to be able to kind of get some of these light sheet techniques um more portable or, you know, useful for an organism.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:47",
            "end_time": "32:51",
            "annotations": {
                "ask question": "The speaker is requesting information about the community's tolerance for having semi-invasive methods to make light sheet techniques more portable or useful for an organism."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "02:52-03:05",
            "transcript": "Yeah, I mean, I think so. Um the at least, you know, if you think about like the head mounted microscopes and things, like building a cranial window in and then having some small thing next next to that's not a big deal.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:52",
            "end_time": "33:05",
            "annotations": {
                "supportive response": "The speaker is providing an example to support the idea that having something semi-invasive can be acceptable, showing agreement with the previous discussion."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "03:05-03:16",
            "transcript": "And then a lot of the sort of super stuff right now is still cover slip based, you know, epi fluorescence so you can easily put stuff down at least on on on that epi side.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:05",
            "end_time": "33:16",
            "annotations": {
                "develop idea": "The speaker is expanding on the discussion about super resolution microscopy by providing more information about current methods and practices in the field."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:26-03:33",
            "transcript": "Okay, um, I have lots of ideas on things to talk about, but um, Stefan, how about you? What are what do you have to bring up?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 57,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:26",
            "end_time": "33:33",
            "annotations": {
                "encourage participation": "The speaker invites Stefan to contribute his thoughts or ideas to the discussion."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "03:33-04:14",
            "transcript": "Yeah, so this is an interesting discussion and uh basically I have similar concerns that Dylan mentioned earlier. Uh like with all uh the huge amount of data that you collect, but then actually how would we do this? How do we how will we get a super resolution image of entire mouse, for example, uh uh while the mouse is still alive. So, um this is a really important question and um my group and I we have thought a lot about this and how can we overcome this and how can we find a method that would allow us to to give us something reasonable and the best we came up with is, well, we probably cannot do live imaging.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "33:33",
            "end_time": "34:14",
            "annotations": {
                "identify gap": "Stefan mentions the huge amount of data collected and questions the feasibility of live imaging, highlighting a gap in current capabilities.",
                "critical response": "Stefan expresses concerns about the feasibility of achieving super-resolution imaging of an entire mouse while it is alive.",
                "develop idea": "Stefan discusses potential considerations and limitations for overcoming the challenges of super-resolution imaging in live mice."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:14-04:27",
            "transcript": "But what we could do is um uh use end points and then make tissues optically transparent, right? So removing all the the scattering.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:14",
            "end_time": "34:27",
            "annotations": {
                "propose new idea": "The speaker introduces a specific approach (using end points and making tissues optically transparent) to tackle the problem of scattering in biological tissues.",
                "develop idea": "The speaker is building upon the previous discussion about the challenges of imaging in vivo and suggesting a concrete method to address one of those challenges."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:27-04:31",
            "transcript": "Uh and then light can penetrate into the tissue.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:27",
            "end_time": "34:31",
            "annotations": {
                "develop idea": "Stefan Wilhelm is expanding on his previous idea about making tissues optically transparent to facilitate light penetration, which is a key challenge in super resolution imaging of biological tissues."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:31-04:41",
            "transcript": "And the interesting thing that we found is that when we do this, we can now actually see um our nanoparticle carriers because they are still there and they scatter light efficiently.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:31",
            "end_time": "34:41",
            "annotations": {
                "develop idea": "The speaker is elaborating on a specific aspect of their research, building on previously mentioned concepts."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:41-05:06",
            "transcript": "And now since you remove everything else in the background that will interfere, now you get a pretty clear and crisp view of where your your carriers are. So this was pretty intriguing uh when when we saw this and um it allows you to have volumetric imaging. Um, but now of course you're losing super resolution, right?",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:41",
            "end_time": "35:06",
            "annotations": {
                "develop idea": "The speaker elaborates on the implications of their approach, specifically the trade-off between volumetric imaging and super resolution.",
                "clarify goal": "The speaker discusses the objectives and limitations of their approach, highlighting the trade-offs between different imaging aspects."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:06-05:11",
            "transcript": "So then you need to go and expand your samples to get super resolution.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:06",
            "end_time": "35:11",
            "annotations": {
                "develop idea": "The speaker is expanding on the idea of how to achieve super resolution in imaging, specifically by mentioning the need to expand samples."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:11-05:24",
            "transcript": "But then you're only looking at a tiny field of view. So these are all these challenges, but at least for our research, uh what we found is that if we use the right type of nano material that scatters light efficiently.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:11",
            "end_time": "35:24",
            "annotations": {
                "develop idea": "The speaker is discussing challenges and potential solutions related to their research, building upon existing ideas.",
                "identify gap": "The speaker recognizes challenges in their research, such as limited field of view.",
                "offer feedback": "The speaker provides a potential solution based on their research findings, suggesting the use of specific nano materials."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:24-05:36",
            "transcript": "And then we work with uh tissue clearing method and expansion microscopy methods, um we can get somewhere at least um but it's not the the ideal state, but yeah, I would agree that scattering is a big problem.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:24",
            "end_time": "35:36",
            "annotations": {
                "develop idea": "Stefan Wilhelm is expanding on existing ideas by sharing specific methods his group has used.",
                "acknowledge contribution": "He acknowledges the challenge of scattering, showing agreement with previous statements."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:36-05:37",
            "transcript": "But scattering can also be.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:36",
            "end_time": "35:37",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:37-05:40",
            "transcript": "very informative depending how you utilize it.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:37",
            "end_time": "35:40",
            "annotations": {
                "develop idea": "Stefan Wilhelm's statement builds upon the existing idea that scattering can be both a problem and an opportunity, depending on how it is utilized.",
                "supportive response": "Stefan Wilhelm's statement can be seen as supportive of considering scattering in a positive light, offering an additional perspective on its utility."
            }
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "06:27-06:36",
            "transcript": "Can someone explain how one would detect the scattered light? How what kind of detectors will we need?",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:27",
            "end_time": "36:36",
            "annotations": {
                "ask question": "The speaker is requesting information on how to detect scattered light and what detectors are needed, making this an explicit question."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:36-06:41",
            "transcript": "I just a flat CMOS chip, I bet, right?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:36",
            "end_time": "36:41",
            "annotations": {
                "offer feedback": "Provides a specific suggestion for detecting scattered light.",
                "express humor": "Makes a joke or attempts to lighten the mood with 'I bet, right?'"
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:41-06:43",
            "transcript": "So what kind of detectors are you imagining?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:41",
            "end_time": "36:43",
            "annotations": {
                "ask question": "Dylan Burnette is requesting information on the kind of detectors being imagined, which directly relates to seeking clarification or expertise from other team members."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:48-07:02",
            "transcript": "Because I'm I'm a practical guy. I kind of want to imagine what you're going to where where where you're going to capture this with, right? Um is it is is there something that exists or you are you have to invent it?",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:48",
            "end_time": "37:02",
            "annotations": {
                "ask question": "The speaker is asking if there are existing detectors or if new ones need to be invented to capture scattered light."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:05-07:06",
            "transcript": "So I can jump in if needed.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:05",
            "end_time": "37:06",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:06-07:27",
            "transcript": "Um, so if you think of um structured illumination and you're capturing that image with a camera and so with the structured illumination, you're illuminating certain areas, your light gets scattered, so you collect light from everywhere.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:06",
            "end_time": "37:27",
            "annotations": {
                "develop idea": "The speaker is expanding on an existing idea by explaining how structured illumination works, specifically discussing the illumination of certain areas and the collection of scattered light."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:27-07:41",
            "transcript": "And then usually you do um there's an algorithm that automatically calculates where that light is coming from and it removes that scattering light. So you're already capturing the scattered light, it's just that you are removing it.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:27",
            "end_time": "37:41",
            "annotations": {
                "develop idea": "The utterance expands on how scattered light is handled by providing details about an algorithm that calculates where the light is coming from and removes it.",
                "acknowledge contribution": "The speaker acknowledges that in imaging techniques, scattered light is captured but then removed by an algorithm, recognizing prior discussion on the topic."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:41-08:00",
            "transcript": "In confocal, you're using a pin hole to collect that um the light the ballistic photons that you are interested in and you're using that pin hole to block all those other scattered lights um you're it's coming from.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:41",
            "end_time": "38:00",
            "annotations": {
                "develop idea": "The speaker explains an existing idea by providing a concrete example of confocal microscopy's use of a pinhole to collect ballistic photons and block scattered light, thereby expanding on the discussion about imaging techniques."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:00-08:16",
            "transcript": "And so if you collect with a camera and you focus if you collect that light from where your pin hole would be, that would be your, you know, from your central focal area, but you could collect the scattered um multi photon light so that you can then collect more of that signal.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:00",
            "end_time": "38:16",
            "annotations": {
                "develop idea": "The speaker is expanding and providing more details on an existing idea about collecting scattered multiphoton light in imaging techniques.",
                "supportive response": "The utterance expresses agreement and provides additional information to support the ongoing discussion."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:16-08:22",
            "transcript": "Um, so it just depends a little bit on your imaging strategy and and what the um orientation would be.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:16",
            "end_time": "38:22",
            "annotations": {
                "supportive response": "The utterance acknowledges previous discussion points and suggests considering various factors, showing a supportive and validating tone.",
                "summarize conversation": "It reflects on the discussion to guide further action by mentioning dependence on imaging strategy and orientation.",
                "clarify goal": "The utterance helps in clarifying that the approach may depend on specific factors like imaging strategy and orientation."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:22-08:30",
            "transcript": "Yeah, yeah, we try to deconvolve out almost all the what we refer to it as out of focus light in not scattered light, but um.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:22",
            "end_time": "38:30",
            "annotations": {
                "develop idea": "The speaker elaborates on their approach to handling out-of-focus light in imaging experiments."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:30-08:33",
            "transcript": "So I'm still kind of confused. How is that going to work?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:30",
            "end_time": "38:33",
            "annotations": {
                "ask question": "The utterance is a request for clarification on how the proposed method will work."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:39-08:42",
            "transcript": "on on on on an engine. This is kind of why we're here, right?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:39",
            "end_time": "38:42",
            "annotations": {
                "clarify goal": "The speaker is seeking confirmation that the current discussion aligns with the purpose or goals of their meeting or project."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:42-08:49",
            "transcript": "I I I I don't understand how that is going to be a thing that can be developed.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:42",
            "end_time": "38:49",
            "annotations": {
                "critical response": "The speaker expresses skepticism or doubt about the feasibility of developing a technique that utilizes scattered light in imaging."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:49-08:56",
            "transcript": "Because if if it was just as simple as I have a CMOS camera and I have very images, I can make them sharp, we would have probably already done that, right?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:49",
            "end_time": "38:56",
            "annotations": {
                "critical response": "Dylan questions the feasibility of using a CMOS camera to achieve super resolution by implying that if it were easy, it would have been done already."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:56-09:03",
            "transcript": "Um and and we do our best that we can by by reassigning uh the out of focus photons into the plane that we're supposed to be.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:56",
            "end_time": "39:03",
            "annotations": {
                "develop idea": "The speaker is explaining how they currently handle out-of-focus photons by reassigning them into the correct plane.",
                "identify gap": "The utterance implies limitations in the current method of reassigning out-of-focus photons."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "09:03-09:06",
            "transcript": "There's algorithms for that. So we're talking about.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:03",
            "end_time": "39:06",
            "annotations": {
                "develop idea": "Dylan is engaging with previous ideas and moving the discussion forward by mentioning algorithms."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:00-00:35",
            "transcript": "through your filters, that might be one aspect. Um, so I think um it it would take a big picture look at what are you trying to do, what are is your imaging system or your microscope that you're trying to use and um how is scattering affecting your ability to image what you're trying to see or image at a depth, you know, that maybe you can't reach. Um, and then taking into into consideration your sample that the light is traveling through and how does that influence or impact your ability to image whether it be resolution or depth or field of view.",
            "speaking_duration": 35,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:00",
            "end_time": "40:35",
            "annotations": {
                "develop idea": "The utterance expands on previous ideas by suggesting a holistic approach to tackling scattering issues in imaging.",
                "offer feedback": "She offers a suggestion for approaching the problem by considering the imaging system and sample.",
                "identify gap": "Implicitly recognized as she discusses considering the sample and imaging system to address limitations."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "00:35-02:05",
            "transcript": "Yeah, maybe to to jump off that and and bridge back to what uh what Sian was talking about at the beginning. Like if we're in the fluorescence and uh some of the light from your floor for gets multiply scattered, there's kind of two ways that we might think of detecting it. One is just waiting long enough because those multiply scattered photons will take longer to get to you. So you you kind of wait long enough and see where they landed and maybe those were your scattered photons. The other thing that I think Josh is really better expert at is um if you change your imaging instrument in some way because that light was determinate that scattering was deterministic, like the cell boundaries that the light scattered off of were at certain some place relative to your imaging system. If you change the instrument a little bit to better leverage those scattering patterns and get more light out now and get more light in, then you have a signature for for for fixing your image in the bit. So the the the the imaging problem becomes harder now because it's no longer uh uh optically engineered perfect objective that does your job for you. Now you've got to reoptimize the imaging system on the fly for your specific sample and then you got to make sure that whatever you thought the scattering was from wherever it was from and whenever it was from like that's actually what you're detecting because it in principle at least with elastically scattered light, there's no way to identify it any other way. Like the photon energy is going to be the same, right? And uh and so yeah.",
            "speaking_duration": 90,
            "nods_others": 2,
            "smile_self": 15,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:35",
            "end_time": "42:05",
            "annotations": {
                "develop idea": "The speaker is expanding on previous ideas discussed, specifically those related to handling scattered photons in super resolution microscopy.",
                "offer feedback": "The speaker provides suggestions for detecting scattered photons, discussing potential approaches and considerations."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "02:05-03:40",
            "transcript": "There's also some interesting things with scattering connecting back to our conversation about numerical aperture, which counter, you know, counterintuitively scattering can actually help you because at the fundamental level, high NA is about high spatial frequencies is about high angle illumination and so scattering has a way of creating this for you because of the, you know, in strongly scattering tissue after you, you know, scatter enough, you're at lambda over two. Um, so that I think is something else too that you make your you make your your enemy your friend in some sense by, you know, taking advantage of what's happening there and then maybe you maybe you decouple from the traditional connection with lenses between field of view and working depth and NA and the geometrical piece of lens design, there's only so many parameters you have to to tweak, but if you can think about your lens as a and I think Sian will be, you know, with Laura, she always talks about like your lens is a Laura Waller, your lens is a matrix basically, which I love that like picture thinking about um, you know, and in the wavefront shaping community, we think of like replacing a lens with a cube of salt or something like, you know, cube of sugar or something and just sending light through it and if you know what the you know, the matrix is, mathematically there may be some interesting properties there that you can leverage that may actually help you and not hurt you.",
            "speaking_duration": 95,
            "nods_others": 1,
            "smile_self": 20,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:05",
            "end_time": "43:40",
            "annotations": {
                "develop idea": "The speaker is expanding on previous ideas about scattering and its benefits in optical imaging.",
                "propose new idea": "The speaker introduces new perspectives on leveraging scattering and novel lens design approaches."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "03:40-04:00",
            "transcript": "That's a great point. Um, I was also doing post in Laura Waller's lab and uh I really like her perspective that uh lens is just a phase mask, right? So whatever whatever point spread function you want in the end, you can somehow engineer the lens you want.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:40",
            "end_time": "44:00",
            "annotations": {
                "acknowledge contribution": "Sian You verbally recognizes Josh Brake's input with 'That's a great point.'",
                "develop idea": "Sian You expands on the discussion by sharing a perspective from Laura Waller's lab, elaborating on how lenses can be engineered."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "04:00-05:31",
            "transcript": "And uh back to Dylan's question, that's actually really um uh I think it's also a very good point to start framing off. Um, so to solve the problem, I think we can start from two. Uh one is detection, how can you reassign photons based on different properties, based on different characteristics of photons you capture and then how can you reassign it. And then second way is uh second way, how can you form the beam for for example, for light sheet microscopy, it's very hard to get a nice light sheet after scattering. So how can you use wavefront engineering or scattering compensation to get a nice illumination in the beginning. So you don't worry that much about detection later. Um, my question is um like what is the fundamental limit in either direction. So if we try all these methods and we push our depths like 10% more, is it worth it? Uh, and this applies for both um detection and illumination. Detection, you have photo photon starvation, you have noise issue and for illumination, um no matter how much you compensate, at some point you lose the correlation between photons and you lost uh at one point it's just random walk. So how much more can we push and what is the fundamental challenge in the in the field right now.",
            "speaking_duration": 91,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:00",
            "end_time": "45:31",
            "annotations": {
                "propose new idea": "The speaker introduces two approaches to solve the problem: improving detection and illumination.",
                "develop idea": "The speaker elaborates on the two approaches, discussing methods like wavefront engineering and challenges such as photon starvation and noise.",
                "ask question": "The speaker asks about the fundamental limit of these approaches and whether pushing them further is worthwhile."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:31-05:36",
            "transcript": "And Luke, can we hear from you as well?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:31",
            "end_time": "45:36",
            "annotations": {
                "encourage participation": "The speaker invites Luke to contribute his thoughts or ideas to the discussion."
            }
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "05:36-06:15",
            "transcript": "Um, yeah, sure. So I I think I mean, I think that one of the challenges that I see is is like how much deeper can you go? How much further can you go is a major problem. But I think a a bigger problem that we've noticed is how long does it take you to get there? You know, because you can do a decent job of understanding what's happening to the light and like recreating a focus and then detecting whatever signal you get out.",
            "speaking_duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:36",
            "end_time": "46:15",
            "annotations": {
                "identify gap": "Luke explicitly recognizes gaps in current technology or methods, specifically regarding how much deeper one can go and the time it takes to achieve certain imaging goals.",
                "develop idea": "Luke is expanding on previous ideas discussed, focusing on the challenges of depth and time in super resolution microscopy."
            }
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "06:15-07:35",
            "transcript": "But you're really going to have to detect for a really long time to get enough photons out and overcome your SNR problems or it's going to take you quite a while to do the correction factor and even you know, current best in class it's pretty, you know, for a whole organism or, you know, whether it's like the whole organism or just a whole organism, in both cases you're looking at problems with, you know, signal and movement and time. And um, you know, those those seem like like major issues that in order to get it from the point of where it requires full um deconstruction of the organism, you know, which is definitely and a useful and insightful approach back to something that's maybe hopefully happening in a dynamic setting, we can understand like how things are are altering with time. Um, you know, sort of like our keynote talk is. I think, you know, trying to bridge those two two spectrum I think is sort of as a as a challenge.",
            "speaking_duration": 80,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:15",
            "end_time": "47:35",
            "annotations": {
                "develop idea": "expanding on existing ideas related to challenges in imaging large or whole organisms",
                "identify gap": "highlighting the gap between detailed but static analysis and dynamic real-time understanding",
                "clarify goal": "discussing the goals and challenges of achieving deeper, faster, and more informative imaging"
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "07:36-08:33",
            "transcript": "But if you're trying to detect things in multiple dimensions such as you say time, if things are going to take longer to get there, is it possible that you could just use multiple detectors? Because when we when we go and put two cameras on our system, we want them to be par focal basically. We want to them to be in the exact same focal plane. But can you alternate the detectors to detect um things that take longer to get there, just move the camera closer. I mean can I don't know if if with one detector we're going to be able to get to this thing and you and you guys are the physics people, but I can't imagine this is going to be solved with one camera. It's just going to take too darn long to image an organism.",
            "speaking_duration": 57,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:36",
            "end_time": "48:33",
            "annotations": {
                "ask question": "The speaker asks a question about the possibility of using multiple detectors to detect things over time.",
                "develop idea": "The speaker develops an idea by suggesting an alternative approach of using multiple detectors to solve the problem of imaging over time."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "08:33-09:31",
            "transcript": "You're definitely not crazy. There is definitely a lot of multi view uh microscopes for all kinds of modalities over there. Uh actually people do it. I I think there are like uh several ways to come about it. One is kind of multi view, so you scan uh different regions at the same time and somehow they end up in different pathways and you can use different cameras to detect it. And for scattering problems or for aberration problems, uh you have this pupil plane where you can also simultaneously uh kind of correct uh different aberrations and scattering for different regions. So there are ways to deal with it, but uh then if you do that, then you are at the danger of even being more photon starved. Um, so it's always a tradeoff. The more multiplex, the the the less photons you have. So.",
            "speaking_duration": 58,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:33",
            "end_time": "49:31",
            "annotations": {
                "develop idea": "The speaker expands on existing ideas by explaining how multi-view microscopes and pupil planes can be used to address scattering and aberration problems.",
                "supportive response": "The speaker provides a supportive response by acknowledging the previous speaker's concern and offering potential solutions."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "09:40-09:52",
            "transcript": "Uh Candace, would you like to introduce yourself? I know that we've been talking without you, but if you'd like to just mention um your area um that you work in and especially related to super resolution and maybe your interest in this area just briefly.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:40",
            "end_time": "49:52",
            "annotations": {
                "encourage participation": "The speaker, Kristen Maitland, invites Candace to contribute by introducing herself and sharing her area of work, especially related to super resolution."
            }
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "09:52-10:15",
            "transcript": "Yeah, I I really apologize about that. Um, so I'm Candace Fleischer, I'm at Emory University in Atlanta. Um, my",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:52",
            "end_time": "50:15",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "00:00-00:29",
            "transcript": "my group primarily focuses on MR spectroscopy and of the brain and you know, we don't do a lot of super resolution in the I I also came from an optical background. So we don't do it in that sense, but maybe Oze, maybe you've already discussed like compressed sensing. I'm not sure if we've gotten that far, but in MR, we do kind of have ways that we refer to as super resolution, but certainly not in the same way. I came I heard multiplexing. So I imagine we're talking about optical imaging.",
            "speaking_duration": 29,
            "nods_others": 4,
            "smile_self": 21,
            "smile_other": 21,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:00",
            "end_time": "50:29",
            "annotations": {
                "signal expertise": "Candace states her group's focus on MR spectroscopy and her optical background, indicating her expertise.",
                "ask question": "Candace asks if compressed sensing has been discussed, seeking information about previous conversations."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:29-01:10",
            "transcript": "No resolution wise we we are not on the same level so far. So I didn't want to intervene any part of the discussion, but I was thinking to introduce to my whether we will be able to use the magnetic properties and you know, to change the optical behavior and make it useful and do multimodality imaging with your approaches. I have been reading and I have been approached a couple of colleagues to use the ultra high field to change the optical properties.",
            "speaking_duration": 41,
            "nods_others": 3,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:29",
            "end_time": "51:10",
            "annotations": {
                "propose new idea": "Uzay Emir introduces a new idea about using magnetic properties to change optical behavior for multimodality imaging.",
                "identify gap": "Uzay Emir implies a gap in current approaches by mentioning he's not on the same level resolution-wise and suggests a different approach."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "01:11-02:23",
            "transcript": "Well, I will definitely say that there's an opportunity for people from different modalities to learn from each other. And so I do think I'm really glad that there are two of you that are in MR in this room because I feel like as you discuss with each other in the next couple days, um if you can talk about um how you approach you know, resolution and improving resolution and some like compressed sensing, you know, which is applied in both fields, but the different approaches, I think sometimes it's hard for them to bridge over those those gaps between fields. And so the more you can talk together about, well, how do you do this or why do you do that or um there's a real opportunity there I think in terms of working together across fields. Um, so I'll just point that out. Um, we have about um 15 minutes left, I believe. Um, yeah. And so uh we'll maybe just talk for another five minutes and then I think we should revisit kind of our key points and and try to narrow those down so that when Josh reports out, we have a a more focused report out.",
            "speaking_duration": 72,
            "nods_others": 4,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:11",
            "end_time": "52:23",
            "annotations": {
                "encourage participation": "Kristen Marland encourages discussion between participants from different fields.",
                "process management": "Kristen Marland manages the meeting flow by mentioning the time left and suggesting a plan for the remaining time."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "02:24-03:09",
            "transcript": "maybe just oh, I'll throw out one quick one and and maybe it goes nowhere. Um in terms of interesting ways of probing the tissues optically, is there some way that we can engineer photons or maybe even coupled photons so that their probability of scattering is less without let's say not, you know, not even knowing what the tissue looks like. Um I don't know, let's say entangled photons for instance example, right? Uh are there cute little tricks that we could do to uh make them more robust to what classical detection would fail at. Uh you know, maybe it it requires us to to go about that way. Just just a thought.",
            "speaking_duration": 45,
            "nods_others": 2,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:24",
            "end_time": "53:09",
            "annotations": {
                "propose new idea": "The speaker introduces the idea of engineering photons to reduce scattering, suggesting a novel approach to optical tissue probing.",
                "ask question": "The speaker asks if there are methods (like using entangled photons) to make photons more robust to classical detection failures, seeking input from others."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "03:09-03:55",
            "transcript": "Oh, people are going longer wavelengths to avoid scattering. Uh, so that's one way and I feel like uh the notion you mentioned entangled photons could be very interesting because people are already doing that for telescope and as we know, we are the retarded grandkids from the astronomers as micro says. So maybe maybe that's the I I feel like that could be a very high risk, high reward uh uh notion to do.",
            "speaking_duration": 46,
            "nods_others": 1,
            "smile_self": 15,
            "smile_other": 15,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "53:09",
            "end_time": "53:55",
            "annotations": {
                "propose new idea": "The speaker introduces the idea of using entangled photons for optical imaging to avoid scattering.",
                "develop idea": "The speaker elaborates on the potential of using entangled photons, referencing its use in telescope technology.",
                "acknowledge contribution": "The speaker acknowledges Matt Lew's suggestion about using longer wavelengths.",
                "supportive response": "The speaker expresses a positive view towards exploring new, innovative approaches."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:40-05:35",
            "transcript": "So one thing to add to this one, I think for engineering uh is quite intriguing and uh from a nano particle perspective, uh there are materials out there where you can uh tune the lifetime. So maybe it's it's not just the spectral properties but also um like the luminescence lifetime of those materials that that can then be used as as labels um for certain features um of of interest, right? And one example um uh material is called up conversion nano particles that have anti stokes emission um they um typically have luminescence lifetimes in like the millisecond or microsecond range. So that's um orders of magnitude difference to to what you would have with the commercial for so this may also be uh helpful in the end.",
            "speaking_duration": 55,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:40",
            "end_time": "55:35",
            "annotations": {
                "propose new idea": "Stefan introduces the concept of using nanoparticles, specifically up-conversion nanoparticles, and their tunable luminescence lifetime as labels, which is a new idea in the context of the conversation.",
                "develop idea": "He elaborates on the properties of up-conversion nanoparticles, such as anti-Stokes emission and longer luminescence lifetimes, which could be beneficial for super resolution imaging."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "05:41-06:03",
            "transcript": "So maybe that's uh that brings up an idea in my head. Um Stefan on on like modulating those like how about magnetic fields to let's say prepare them to be more scattering or less or more up converting or less and that gives us maybe a way of uh controlling them and making them better emitters for deep tissue imaging. I'm not sure.",
            "speaking_duration": 22,
            "nods_others": 1,
            "smile_self": 5,
            "smile_other": 5,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:41",
            "end_time": "56:03",
            "annotations": {
                "develop idea": "The speaker is expanding on an existing idea by suggesting the use of magnetic fields to modulate the properties of materials for better deep tissue imaging."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "06:04-06:26",
            "transcript": "Yeah, absolutely. Like when uh when you mentioned this, I thought immediately about um assembling um uh objects at the nano scale that as a single object do not scatter but when they come together and form an assembly then all of a sudden they scatter light very efficiently. So this definitely something that that we could could work on.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 5,
            "smile_other": 5,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:04",
            "end_time": "56:26",
            "annotations": {
                "propose new idea": "Stefan Wilhelm introduces a new idea about assembling objects at the nano scale to control scattering.",
                "develop idea": "Stefan Wilhelm builds upon a previous discussion about using scattering for imaging by suggesting a specific method."
            }
        },
        {
            "speaker": "Silvia Ronco",
            "timestamp": "06:29-06:39",
            "transcript": "Sorry, sorry to interrupt. Do you know where you need to put the main main discussions in the PowerPoint?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:29",
            "end_time": "56:39",
            "annotations": {
                "process management": "The speaker is asking about where to put the main discussions in the PowerPoint, which relates to managing the meeting flow and organizing group activities."
            }
        },
        {
            "speaker": "Silvia Ronco",
            "timestamp": "06:39-06:40",
            "transcript": "Okay. Good. Thanks.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:39",
            "end_time": "56:40",
            "annotations": {
                "None": "The utterance is a very brief acknowledgment without adding new content or explicitly acknowledging a contribution."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:00-07:26",
            "transcript": "Okay, so I think we should um try to summarize and come up with our key points, but we had lots of different great ideas. And so I would say if you know, from our discussion, we should use that parking lot to capture some of those as potential um areas that we could probe further in your later discussions and and may, you know, result in in a proposal.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:00",
            "end_time": "57:26",
            "annotations": {
                "summarize conversation": "The speaker is summarizing what has been previously discussed by the group and suggesting a method to organize their ideas.",
                "process management": "The speaker is managing the meeting flow and suggesting how to proceed with the discussion."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:26-07:27",
            "transcript": "Um",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:26",
            "end_time": "57:27",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:27-07:51",
            "transcript": "But at this time, I think we should look at um what we want to report out for our key points.",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:27",
            "end_time": "57:51",
            "annotations": {
                "summarize conversation": "The speaker is directing the group to focus on and summarize the key points to be reported from their discussion."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:51-08:07",
            "transcript": "So what are what should we try to narrow it down to three topic areas of what we discussed? I think that because it is such a short recording report out time, um I think you want to go with the um the most exciting ideas, not necessarily what we talked about the most.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:51",
            "end_time": "58:07",
            "annotations": {
                "process management": "This code applies because Kristen Maitland is managing the meeting flow by instructing the group on how to prioritize their discussion points for a report out.",
                "summarize conversation": "This code applies because Kristen Maitland is asking the group to summarize their discussion into three key topic areas."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "08:07-08:16",
            "transcript": "So maybe but I'm going to leave it up to you to come up with um what we'll cover.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:07",
            "end_time": "58:16",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by deciding how to proceed with the discussion summary and report-out.",
                "assign task": "The speaker is assigning the task of deciding what to cover to the group."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "08:26-09:35",
            "transcript": "I guess one idea that's exciting me is thinking about how multimodal maybe non-traditional use of contrast. So this conversation that Stefan's point that he just brought up about thinking about how do we, you know, maybe something that separated these individual things don't scatter light well, but then due to some kind of biological or chemical change within the organism, they come together and then oops, now they're it's I mean, in some sense it's kind of like, you know, G camp or any other kind of reporter.",
            "speaking_duration": 69,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:26",
            "end_time": "59:35",
            "annotations": {
                "propose new idea": "Josh Blake introduces a new idea about using multimodal or non-traditional use of contrast agents that change their properties in response to biological or chemical changes.",
                "develop idea": "Josh Blake develops Stefan Wilhelm's idea about materials that scatter light when they come together, suggesting it could be used as a reporter."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "09:35-09:57",
            "transcript": "But like new reporters that maybe are ultrasonically or magnetically or some other modality that is deeper penetrating into tissue, you know, using that to modulate those to detect them optically.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:35",
            "end_time": "59:57",
            "annotations": {
                "propose new idea": "Josh introduces a new concept of using reporters modulated by ultrasonic, magnetic, or other modalities for deeper tissue penetration and optical detection.",
                "develop idea": "He expands on existing ideas by suggesting the use of different modalities to modulate reporters for better optical detection."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:10-00:13",
            "transcript": "Any other ideas we should be reporting out on?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:10",
            "end_time": "60:13",
            "annotations": {
                "ask question": "Kristen Maitland is requesting information or ideas from other team members.",
                "encourage participation": "By asking for other ideas, Kristen Maitland is inviting others to contribute their thoughts."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "00:20-01:33",
            "transcript": "Uh, I think one idea uh that was brought up by a few people was pretty exciting. Uh, the idea of um I can summarize it as adaptive imaging. So I think Josh bring out this idea so first you have low resolution imaging and then you come in with high resolution imaging. So um so uh we can combine with MRI, right? So I was I forgot this person's name, but I was talking to another person in the breakout session that they were developing this low field MRI where they can be portable as a probe, right? So imagine uh you are doing uh clinic session and you have this probe with MRI and you're doing this scanning and then when you have a suspicious area, you heard a beep from the AI algorithms and then you have a needle that comes out that gives you the optical fiber and then insert into do kind of do a real time at a point of procedure diagnosis. Uh, so kind of combine this non-invasive MRI with non with minimal invasive optical cellular resolution imaging.",
            "speaking_duration": 73,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:20",
            "end_time": "61:33",
            "annotations": {
                "Develop idea": "The speaker expands on an existing idea by suggesting its application in a specific context, combining low-resolution and high-resolution imaging with MRI.",
                "Supportive response": "The speaker expresses a positive view of the adaptive imaging idea.",
                "Summarize conversation": "The speaker attempts to summarize an idea discussed earlier about adaptive imaging."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:37-03:03",
            "transcript": "Yes, so just from my my experience, I guess, that's um one area that in terms of optical imaging that, you know, I've tried to to develop was using actually fluorescence lifetime imaging of in a macroscopic view of tissue and oral cavity. Um and then using um we developed a confocal microscope that also would go into the world cavity and we design our own miniature lens that's about um less than a centimeter in diameter. So it's relatively small, can fit inside. Um and there you're doing kind of that point measurement, but it's with imaging looking at um cell nuclei um that have been identified based on the metabolic changes in the tissue um using the fluorescence lifetime. There's one other group that also uses distortion in the lens so that um on it captures a larger field of view that has a worse resolution, but at the center it has better resolution um but a very limited field of view so that you could use it to kind of guide around um and then you if you see something at the edge of the focus then you move it to the center and you get that higher resolution in the center. So there's just a couple ideas of some and then one thing that I I didn't really hear being brought up but photoacoustic imaging for increased depth um we didn't really discuss but for that kind of multimodality and and using a different type of excitation through your in comparison to your detection.",
            "speaking_duration": 86,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:37",
            "end_time": "63:03",
            "annotations": {
                "code name": "develop idea",
                "explanation": "The speaker is expanding on existing ideas by sharing her experiences with fluorescence lifetime imaging and confocal microscopy."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:04-03:31",
            "transcript": "Yeah, I do think that the photoacoustic is feasible for MRI as well. So I do see great illustration about this kidney and they embedded this photoacoustic and try to induce the ultrasound outside and try to write it up and you can also do the same thing with MRI that might be really interesting way to look at the photoacoustic. We don't have any chance to discuss that.",
            "speaking_duration": 27,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:04",
            "end_time": "63:31",
            "annotations": {
                "supportive response": "The speaker expresses a positive view on the idea of combining photoacoustic with MRI."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:32-04:13",
            "transcript": "So I do again encourage you to put ideas in the parking lot especially because even though this is a short virtual meeting this week, but um hopefully you will all be back next year and the year after and so if you plan to see now you might come back to it um in the future. Um so I hope this is just the beginning of your discussion together um not necessarily all of you together but um with individuals that you may find other people at the conference that were not in our room that um may be able to help build on some ideas that you're um starting to form.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:32",
            "end_time": "64:13",
            "annotations": {
                "process management": "The speaker is providing guidance on how to manage and continue the discussion beyond the current meeting.",
                "encourage participation": "The speaker is inviting participants to contribute their ideas and engage with others who might be able to help develop these ideas further."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "04:13-04:24",
            "transcript": "This is what I have for our slide. I'm not sure what people think about this one if you want to give me any feedback. I was just trying to synthesize what we were just talking about.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
            "start_time": "64:13",
            "end_time": "64:24",
            "annotations": {
                "ask question": "Josh is asking for feedback from the group, which is a request for information or opinions.",
                "encourage participation": "By asking for feedback, Josh is encouraging others to participate in the discussion.",
                "summarize conversation": "Josh mentions that he was trying to synthesize what they were just talking about, which indicates an attempt to summarize."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "05:02-05:14",
            "transcript": "I guess the second point is is somewhat related to big the big data. Like all the we had we talked quite a bit about how to deal with the data too. So thinking about how to trade those off.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
            "start_time": "65:02",
            "end_time": "65:14",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges previous discussion about dealing with data.",
                "offer feedback": "The speaker suggests thinking about how to trade off dealing with big data."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:23-06:01",
            "transcript": "Yeah, and related to that data there we were looking at different um light sheet microscopes from different companies and how they handle the large data size and um just in their software aspect some would um just in how they manage the data so that when you go in you want to look like zoom into an area of interest it doesn't keep that whole large data set so you can kind of have that um just how you approach the data. I think really makes a difference in be able to work with it um because it yeah, it is a lot of a lot of data.",
            "speaking_duration": 38,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
            "start_time": "65:23",
            "end_time": "66:01",
            "annotations": {
                "process management": "The speaker discusses how different light sheet microscopes from various companies handle large data sets in their software, affecting the ability to work with the data."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "07:04-07:12",
            "transcript": "No, I think it went well. Thank you uh Kristen for for facilitating us and getting everyone a chance to speak.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "67:04",
            "end_time": "67:12",
            "annotations": {
                "acknowledge contribution": "Matt Lew verbally recognizes Kristen's input as a facilitator, thanking her for facilitating the discussion and giving everyone a chance to speak."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "07:13-08:11",
            "transcript": "Yeah, I really like the we have the questions to guide us and then we kind of each uh each one of us kind of just uh uh branch off that. Um I I think um what I would like better is uh I feel like um so first we can go around introduction for each one and then when we are having this discussion, uh I feel like a lot of people, everybody has really good points that we could build a more fluid and um more coherent coherent conversation instead of one by one. So uh but uh then I guess it's a trade off then maybe we cannot get to hear some people's opinions um maybe. So maybe we could do like first round table uh introduction round table short ideas and then uh more uh just kind of just very casual uh coherent fluid discussions.",
            "speaking_duration": 58,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "67:13",
            "end_time": "68:11",
            "annotations": {
                "propose new idea": "The speaker introduces a new suggestion for discussion structure.",
                "offer feedback": "The speaker provides specific suggestions for improving the discussion process.",
                "encourage participation": "The speaker encourages more inclusive participation in discussions."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:12-09:55",
            "transcript": "Yes, I do feel that especially in this virtual format that it does feel like okay, it's your turn to talk and there's a little bit less flow. Um I was wondering if it would be better after the introductions that if each person talk like briefly state what they're interested in discussing and you could almost like group them in and say okay, first we're going to talk about this particular direction and then we'll cover this direction. Um so that would be one thought. I think it's hard because of the the topics are relatively broad actually even though you know, in some ways they're specific, but they're relatively broad and you can approach them in different ways and so it's um it's almost hard to put your ideas into, you know, kind of groups. You know, and when I was looking at this topic I was thinking we could talk about new applications for super resolution that are, you know, it's not currently applied to. We could talk about different um advances to the implementation and then um I was also I was glad to see that there were people from MRI in here that if we could um get some information from other fields in imaging that might influence our approaches. Um but I do feel that each person had something different to add that um it might have been hard to kind of narrow down the topics because they are um there's so much to cover. I think. But I hope that you continue to have your discussions with each other in the different um gather rooms or towns or without you get to be in um so you can continue these uh conversations.",
            "speaking_duration": 103,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "68:12",
            "end_time": "69:55",
            "annotations": {
                "process management": "The speaker is discussing how to manage the meeting flow and facilitate discussions.",
                "offer feedback": "The speaker is providing a suggestion for improving the discussion process.",
                "clarify goal": "The speaker is reflecting on the goals and challenges of the discussion."
            }
        },
        {
            "speaker": "Kristen Macland",
            "timestamp": "00:00-00:06",
            "transcript": "notes and for reporting out for us and we will see you guys later in the conference.",
            "speaking_duration": 6,
            "nods_others": 4,
            "smile_self": 20,
            "smile_other": 80,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:00",
            "end_time": "70:06",
            "annotations": {
                "process management": "Managing meeting flow, specifically concluding the meeting and mentioning reporting out and seeing each other later in the conference."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "00:06-00:07",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 1,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:06",
            "end_time": "70:07",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:07-00:07",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:07",
            "end_time": "70:07",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:08-00:08",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:08",
            "end_time": "70:08",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:08-00:09",
            "transcript": "Nice meeting you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:08",
            "end_time": "70:09",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:09-00:09",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:09",
            "end_time": "70:09",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "00:10-00:11",
            "transcript": "Great to meet everybody.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:10",
            "end_time": "70:11",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Andrew Feig",
            "timestamp": "01:29-01:30",
            "transcript": "Guys.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "71:29",
            "end_time": "71:30",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:32-01:35",
            "transcript": "God, my brain felt like as if I have to creak really.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "71:32",
            "end_time": "71:35",
            "annotations": {
                "express humor": "The speaker makes a joke about their brain feeling like it has to creak, indicating a humorous expression of mental fatigue."
            }
        }
    ]
}