{
    "all_speakers": [
        "Shiva Abbaszadeh, UCSC",
        "Sandra Laney",
        "Gergis Obaid",
        "Lu Wei Caltech",
        "Alex Walsh",
        "Shiva Abbaszadeh",
        "Girgis Obaid",
        "Paris Perdikaris (UPenn)",
        "Carolyn Bayer",
        "Paris Perdikaris",
        "Richard Wiener",
        "Shannon Quinn",
        "Maryellen Giger",
        "Katy Keenan",
        "Maryellen Giger UChicago",
        "Beck Kamilov",
        "Katy Keenan, NIST (she/her)",
        "Lu Wei",
        "Jim Mitchell",
        "Beck Kamilov (WashU)"
    ],
    "total_speaking_length": 3172,
    "all_data": [
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:07-00:17",
            "transcript": "Uh for the person who just joined, uh we're taking a minute to uh go through the topics and jot down a few ideas for discussion on our own.",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:07",
            "end_time": "00:17",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining the current activity to someone who just joined the meeting, clarifying what 'we're taking a minute to do' means in this context.",
                "assign task": "The speaker is assigning the task of jotting down ideas for discussion to the team members."
            }
        },
        {
            "speaker": "Sandra Laney",
            "timestamp": "00:17-00:34",
            "transcript": "Okay, that gives me a great opportunity to just say that I'm here as a butterfly on the wall as an observer. I'm from the a foundation and um I will actually be jumping off so no offense to anybody, but I have to jump off at at the top of the hour. Thanks.",
            "speaking duration": 17,
            "nods_others": 0,
            "smile_self": 18,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:17",
            "end_time": "00:34",
            "annotations": {
                "explain or define term or concept": "The speaker explains their role as 'a butterfly on the wall as an observer', clarifying their presence as a non-participating observer.",
                "acknowledge contribution": "The speaker is acknowledging the opportunity to speak, but not agreeing or expanding on any prior idea.",
                "assign task": "The speaker is assigning the task of understanding their limited participation to the team members."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:34-00:36",
            "transcript": "Okay, great.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:34",
            "end_time": "00:36",
            "annotations": {
                "express agreement": "Maryellen expresses agreement with Sandra's statement about observing and leaving the meeting early."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:36-01:11",
            "transcript": "So I think that's about a minute. So hopefully you'll be able to jot some notes down and the next thing we want to do is do a brief introduction. For example, I will give you mine. I'm Mary Ellen Giger, I'm at the University of Chicago. My research is in biomedical engineering and I do this for medical reasons to develop new diagnostic but also in biology with cellular data to help um facilitate discoveries. Carolyn, can you introduce yourself? You got 30 seconds.",
            "speaking duration": 35,
            "nods_others": 0,
            "smile_self": 11,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:36",
            "end_time": "01:11",
            "annotations": {
                "assign task": "Maryellen assigns the task of introducing herself to Carolyn, directing her to speak next.",
                "encourage particpatioin": "Maryellen encourages Carolyn to participate by asking her to introduce herself.",
                "explain or define term or concept": "Maryellen introduces herself as an example of the brief introduction she is requesting from others."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "01:12-01:29",
            "transcript": "Yeah, I'm Carolyn Bayer. Um my research is in photoacoustic imaging. Um I'm at Tulane University. Um much of our work is focused on imaging the placenta for pregnancy and development. Um but nice meeting everyone.",
            "speaking duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:12",
            "end_time": "01:29",
            "annotations": [
                {
                    "explain or define term or concept": "Carolyn is introducing herself and her research area, which involves explaining her field of study."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "00:00-00:16",
            "transcript": "Washington University in St. Louis. My area is computational imaging, but I focus on biomedical imaging. A lot of the things I do focuses on image reconstruction, restoration and sometimes data acquisition, but not hardware, just software.",
            "speaking duration": 16,
            "nods_others": 0,
            "smile_self": 7,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:00",
            "end_time": "00:16",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining their area of expertise and the specific focus within that area, defining the scope of their work for the team."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:16-00:17",
            "transcript": "Okay, thank you, Katie.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:16",
            "end_time": "00:17",
            "annotations": {
                "acknowledge contribution": "Maryellen acknowledges Katie's introduction, showing recognition of her input."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "00:21-00:53",
            "transcript": "Hi, I'm at the National Institute of Standards and Technology. NIST's first role in imaging was around for MRI and validating results across centers. So we try to use quantitative techniques. We don't always get the same answer when we try them places. And now we're expanding into more validation of some of these techniques and also exploring what's possible at lower magnetic field strengths.",
            "speaking duration": 32,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:21",
            "end_time": "00:53",
            "annotations": {
                "explain or define term or concept": "The speaker explains NIST's role in imaging, specifically MRI validation across centers, to provide context about their work.",
                "expand on existing idea": "The speaker expands on NIST's role by mentioning their current expansion into validating techniques and exploring lower magnetic field strengths, building upon the initial description of their work."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:53-00:57",
            "transcript": "Thank you and Shiva, I'm going to cross my Hollywood squares here.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:53",
            "end_time": "00:57",
            "annotations": {
                "express humor": "Maryellen makes a joke about crossing her \"Hollywood squares\", which is a reference to the game show, to express humor."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "00:58-01:04",
            "transcript": "Hi, this is Shiva. I'm from University of California, Santa Cruz. So I do work on instrumentation for positron emission tomography and x-ray imaging.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:58",
            "end_time": "01:04",
            "annotations": {
                "explain or define term or concept": "Shiva is explaining her area of expertise, which is instrumentation for positron emission tomography and x-ray imaging, to provide context for the group."
            }
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "01:04-01:20",
            "transcript": "And then I'm really interested in like improving sensitivity and then quantitative accuracy of these imaging modalities.",
            "speaking duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:04",
            "end_time": "01:20",
            "annotations": {
                "present new idea": "Jim introduces his interest in improving sensitivity and quantitative accuracy of imaging modalities, which is a new focus not explicitly mentioned by others before.",
                "expand on existing idea": "Jim's statement builds upon the previous discussion about imaging techniques and validation, adding a specific interest in improving sensitivity and quantitative accuracy."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:20-01:24",
            "transcript": "Thank you, Shayna.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:20",
            "end_time": "01:24",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger acknowledges Shayna's introduction, recognizing her input to the conversation."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:28-01:30",
            "transcript": "You referring to me? I'm Shannon.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:28",
            "end_time": "01:30",
            "annotations": {
                "ask clarifying question": "Shannon asks if Maryellen was referring to her, seeking clarification on the intended recipient of the previous statement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:30-01:31",
            "transcript": "Shannon.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:30",
            "end_time": "01:31",
            "annotations": {
                "acknowledge contribution": "Maryellen acknowledges Shannon's presence after Shannon clarified that she was being referred to, recognizing her participation in the meeting."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:31-01:31",
            "transcript": "Yes.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:31",
            "end_time": "01:31",
            "annotations": {
                "express agreement": "Shannon Quinn is explicitly agreeing with Maryellen Giger that she is referring to her."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:31-01:34",
            "transcript": "I got a new floor. I'm Shannon.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 66,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:31",
            "end_time": "01:34",
            "annotations": [
                {
                    "express humor": "Maryellen makes a joke about forgetting Shannon's name, indicating she got a new floor, which is a humorous way to acknowledge her mistake."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:35-01:57",
            "transcript": "I'm Shannon Quinn, I'm an assistant professor in computer science and cell bio at University of Georgia. I work in biomedical imaging and computational modeling of cellular and subcellular systems. I develop new artificial intelligence techniques for a unified representation of spatial and temporal signals and I work in the construction of open source software for domain scientists.",
            "speaking duration": 22,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:35",
            "end_time": "01:57",
            "annotations": {
                "explain or define term or concept": "Shannon is introducing herself and her background, which serves to explain her expertise and role in the collaboration.",
                "present new idea": "Shannon mentions developing new artificial intelligence techniques for a unified representation of spatial and temporal signals, which is a novel concept introduced by her.",
                "expand on existing idea": "Shannon expands on her work in biomedical imaging by adding that she works in computational modeling of cellular and subcellular systems."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:58-02:00",
            "transcript": "Gergis.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:58",
            "end_time": "02:00",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger acknowledges Gergis's presence in the meeting, but does not agree or expand on any idea."
            }
        },
        {
            "speaker": "Gergis Obaid",
            "timestamp": "02:01-02:25",
            "transcript": "Hi yes, so I'm Gergis Obaid. I'm assistant professor at University of Texas at Dallas. Been here about a year. I work predominantly on molecular targeted nanoparticles for photodynamic cancer therapy.",
            "speaking duration": 24,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:01",
            "end_time": "02:25",
            "annotations": {
                "explain or define term or concept": "Gergis is explaining his role and research area to the group, defining his focus on molecular targeted nanoparticles for photodynamic cancer therapy, which is a concept that may be new to some members."
            }
        },
        {
            "speaker": "Gergis Obaid",
            "timestamp": "02:25-02:25",
            "transcript": "Thank you, Alex.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:25",
            "end_time": "02:25",
            "annotations": {
                "acknowledge contribution": "Gergis acknowledges Alex's contribution, likely for introducing him."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:25-02:29",
            "transcript": "Thank you, Alex.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:25",
            "end_time": "02:29",
            "annotations": {
                "acknowledge contribution": "Maryellen is verbally recognizing Alex's input after he spoke, but not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Alex Walsh",
            "timestamp": "02:29-02:52",
            "transcript": "Hi, I'm Alex. I'm at Texas A&M University and I do optical microscopy. Mostly looking at label free stuff, so molecules that are already in your cells like NADH and FAD to study cellular metabolism. And we do that for a variety of applications including drug response in cancer and studying laser tissue interactions.",
            "speaking duration": 23,
            "nods_others": 0,
            "smile_self": 8,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:29",
            "end_time": "02:52",
            "annotations": {
                "explain or define term or concept": "The speaker explains that they are looking at label free stuff, which are molecules already in cells like NADH and FAD, to study cellular metabolism, clarifying the type of microscopy they use."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:52-02:53",
            "transcript": "Thank you and Lou.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:52",
            "end_time": "02:53",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger is acknowledging Lou's upcoming introduction, similar to how she acknowledged previous speakers."
            }
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "02:56-03:22",
            "transcript": "I am Lou Wei. I'm assistant professor of chemistry here at Caltech. We perform optical imaging, particular vibrational microscopy on biological cells and we're interested in small molecule imaging mostly understanding the metabolic activities.",
            "speaking duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:56",
            "end_time": "03:22",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is defining their area of expertise, which includes optical imaging and vibrational microscopy on biological cells, clarifying their focus for the group."
                }
            ]
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "03:22-03:22",
            "transcript": "Thank you and Paris.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:22",
            "end_time": "03:22",
            "annotations": {
                "acknowledge contribution": "Lu Wei is acknowledging Maryellen Giger's contribution of introducing him, but not agreeing or expanding on any ideas."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:23-03:24",
            "transcript": "Thank you and Paris.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:23",
            "end_time": "03:24",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger is acknowledging Paris's introduction, but not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "03:25-03:40",
            "transcript": "Hello, I'm at the University of Pennsylvania. My expertise is in computational science and machine learning. And basically I'm developing computational methods for modeling and simulation of biological systems with a focus on cardiovascular flows.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:25",
            "end_time": "03:40",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining his expertise in computational science and machine learning, providing context for his contributions to the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:40-03:51",
            "transcript": "Thank you and we have five visitors which I was told hop in and out. Um if you would mind to say something you can or else we're going to get right to the purpose.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:40",
            "end_time": "03:51",
            "annotations": {
                "encourage particpatioin": "Maryellen is inviting the five visitors to introduce themselves if they wish to participate."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:51-03:51",
            "transcript": "Okay.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:51",
            "end_time": "03:51",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger acknowledges the previous speaker's introduction, signaling a transition to the next speaker or topic."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:51-04:06",
            "transcript": "We'll get right to the purpose. So, we have um oh next order is we need a recorder and who would also then present in three minutes for the group.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:51",
            "end_time": "04:06",
            "annotations": {
                "propose decision": "The utterance proposes the need for a recorder and someone to present in three minutes, suggesting a concrete choice for the group to make regarding meeting logistics."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:06-04:22",
            "transcript": "Um, I could do it randomly or we can have a volunteer. Um you you should be able to get to the Google Drive and um this is great training when you're facilitating in your senior career cycle.",
            "speaking duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:06",
            "end_time": "04:22",
            "annotations": [
                {
                    "propose decision": "Maryellen proposes two options for selecting a recorder and presenter: randomly or by volunteer."
                },
                {
                    "encourage particpatioin": "Maryellen encourages someone to volunteer by mentioning that it is great training for facilitating in their senior career cycle."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:26-04:35",
            "transcript": "Okay, should I close my eyes and pick on the screen and I end up on Shannon. Congratulations.",
            "speaking duration": 9,
            "nods_others": 0,
            "smile_self": 55,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:26",
            "end_time": "04:35",
            "annotations": {
                "express humor": "Maryellen makes a joke about randomly selecting someone to present, congratulating Shannon in advance, which expresses humor."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:37-04:37",
            "transcript": "So we're looking at",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:37",
            "end_time": "04:37",
            "annotations": {
                "explain or define term or concept": "Shannon is likely going to explain or define a term or concept, as indicated by the phrase \"So we're looking at\", which suggests she is about to introduce a topic or concept."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:37-04:40",
            "transcript": "So we're looking at",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:37",
            "end_time": "04:40",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging someone to participate by indicating that they are about to start looking at something together, likely prompting the other person to contribute their thoughts."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:40-04:40",
            "transcript": "the PowerPoint deck?",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:40",
            "end_time": "04:40",
            "annotations": {
                "ask clarifying question": "Shannon asks a clarifying question to confirm if they should be looking at the PowerPoint deck, given Maryellen's previous statement about 'looking at'."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:40-04:47",
            "transcript": "Yes, so if you go to the and it's the if you you continue to around slide 20 or so you should you should find it should say um",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:40",
            "end_time": "04:47",
            "annotations": [
                {
                    "explain or define term or concept": "Maryellen is explaining where to find the relevant information in the PowerPoint deck, specifically around slide 20."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:54-04:55",
            "transcript": "It's 17 right now.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:54",
            "end_time": "04:55",
            "annotations": {
                "explain or define term or concept": "Shannon is clarifying the slide number in the PowerPoint deck that Maryellen is referring to, ensuring everyone is on the same page."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:55-05:01",
            "transcript": "Um, no probably a little past 20. 23.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:55",
            "end_time": "05:01",
            "annotations": {
                "explain or define term or concept": "Maryellen is clarifying the slide number in the PowerPoint deck that Shannon should be looking at, providing a more precise location than the previous estimate."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:02-05:03",
            "transcript": "Ah, yes.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:02",
            "end_time": "05:03",
            "annotations": {
                "express agreement": "Shannon Quinn expresses agreement after Maryellen Giger directed her to slide 23 in the PowerPoint deck."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:03-05:06",
            "transcript": "Okay. 20, 24 in fact. So yeah.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:03",
            "end_time": "05:06",
            "annotations": {
                "acknowledge contribution": "Shannon is acknowledging Maryellen's guidance on the slide number to look at in the PowerPoint deck."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:07-05:10",
            "transcript": "Is it supposed to be a separate recorder and um reporter?",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:07",
            "end_time": "05:10",
            "annotations": {
                "ask clarifying question": "Maryellen is asking a question to clarify whether the roles of recorder and reporter should be held by different people, which is relevant to the meeting's organization."
            }
        },
        {
            "speaker": "Sandra Laney",
            "timestamp": "05:11-05:14",
            "transcript": "So is one taking the notes and one reporting?",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:11",
            "end_time": "05:14",
            "annotations": {
                "ask clarifying question": "Sandra is asking to clarify if the roles of note-taker and reporter are separate, following Maryellen's request for a recorder and presenter."
            }
        },
        {
            "speaker": "Richard Wiener",
            "timestamp": "05:15-05:27",
            "transcript": "One one person can do it and one person can do both, I think. Yeah, and you can take the notes, you don't have to put the notes into the PowerPoint yet, you can take those, share it with people, they can add and then can condense them into the PowerPoint so that there's one slide.",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:15",
            "end_time": "05:27",
            "annotations": [
                {
                    "propose decision": "Richard is suggesting how the task of recording and reporting can be handled, proposing that one person can do both or that the notes can be taken separately and then condensed."
                },
                {
                    "expand on existing idea": "Richard is elaborating on the process of recording and reporting, adding details about how notes can be taken, shared, and then condensed into a PowerPoint slide."
                }
            ]
        },
        {
            "speaker": "Richard Wiener",
            "timestamp": "05:27-05:27",
            "transcript": "Sounds good.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:27",
            "end_time": "05:27",
            "annotations": {
                "confirm decision": "Richard confirms the decision that one person can take notes and another can report, or one person can do both."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:27-05:33",
            "transcript": "Okay, are you are you okay with that, Shannon?",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:27",
            "end_time": "05:33",
            "annotations": {
                "confirm decision": "Maryellen is checking if Shannon is okay with the suggestion that one person can take notes and report, which was just discussed."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:33-05:33",
            "transcript": "Yep.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:33",
            "end_time": "05:33",
            "annotations": {
                "confirm decision": "Shannon confirms that she is okay with taking notes and reporting, as suggested by Richard."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:33-05:36",
            "transcript": "Okay, great, thank you.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:33",
            "end_time": "05:36",
            "annotations": {
                "express agreement": "Maryellen expresses agreement with Shannon's willingness to take on the task of both recorder and reporter, as discussed in the previous turns."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-06:15",
            "transcript": "So now let's go in the beginning of the session, you all had the one minute to kind of collect your thoughts on the topics and we will start with the three bullets that are listed, but if any of you think that there's a major other bullet that you think would be useful to look into, we can go there too. One thing I drew from listening to all your introductions, we all do computational science.",
            "speaking duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:36",
            "end_time": "06:15",
            "annotations": [
                {
                    "propose decision": "Maryellen proposes to start with the three listed bullets but also allows for the introduction of other major topics, suggesting a direction for the discussion."
                },
                {
                    "present new idea": "Maryellen introduces the idea that they all do computational science, which is a new observation based on the introductions."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:15-06:19",
            "transcript": "Um, uh and it seems that some are at more of a macro scale, some are at micro scale.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:15",
            "end_time": "06:19",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining the different scales at which the computational science is being applied, macro and micro, to summarize the introductions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:19-06:24",
            "transcript": "Um, and probably some work in 2D and some in 3D. But we all do computational science of images at one point.",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:19",
            "end_time": "06:24",
            "annotations": [
                {
                    "explain or define term or concept": "Maryellen is explaining the commonality between the participants, which is that they all do computational science of images, some in 2D and some in 3D."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:24-06:36",
            "transcript": "So I I think we're um all in this together. So let's start with the first one, um 3D imaging can yield massive data sets too large to quantitate and fully scrutinize manually.",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:24",
            "end_time": "06:36",
            "annotations": [
                {
                    "propose decision": "Maryellen proposes to start with the first bullet point, which is about 3D imaging yielding massive datasets, to guide the discussion."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:36-06:41",
            "transcript": "What data are required to effectively train AI ML algorithms to assess these data sets.",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:36",
            "end_time": "06:41",
            "annotations": {
                "ask clarifying question": "Maryellen is asking what data is required to train AI/ML algorithms, seeking clarification on the necessary data inputs given the context of 3D imaging producing large datasets."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:41-06:45",
            "transcript": "So how many of you do work with massive data sets?",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:41",
            "end_time": "06:45",
            "annotations": {
                "ask clarifying question": "Maryellen is initiating the discussion on the topic of 3D imaging and massive datasets, and she is asking how many people work with massive datasets to gauge the group's experience with the topic."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:46-06:49",
            "transcript": "I know I do. Big, yeah.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:46",
            "end_time": "06:49",
            "annotations": {
                "express agreement": "Maryellen agrees with the implicit question of whether people work with massive datasets, based on the previous turn where she asked \"So how many of you do work with massive data sets?\"."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:50-06:50",
            "transcript": "Okay.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:50",
            "end_time": "06:50",
            "annotations": [
                {
                    "acknowledge contribution": "Maryellen Giger is acknowledging a previous statement or action, but without necessarily agreeing or expanding on it; this is a general acknowledgement."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "06:58-07:00",
            "transcript": "Um, I have well.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:58",
            "end_time": "07:00",
            "annotations": [
                {
                    "acknowledge contribution": "Beck Kamilov acknowledges that he also works with massive datasets, similar to what Maryellen Giger mentioned."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "00:00-01:05",
            "transcript": "uh data or model adaptation to different data, right? So, uh what do I mean by this? So you train your data uh on one type of data set, say, you know, you do MRI scan, uh it has certain artifact patterns, you train the model on that. Now you apply to something else and we know that it doesn't work very well if, you know, you applied it to a configuration doesn't work. Now there are a bunch of ideas out there, uh you know, in in the computer vision community in the machine learning community where people try to bridge those things, but it's still not we don't yet have, you know, killer technology that allows us, you know, we don't understand both the limits of how we can adapt the models to different applications. At the same time, you know, what's the best way to do the adaptation of the models that we already pre-trained to a new application, right? So deep learning models are not traditional software in the sense that I can go and just edit it. It's all in the weights of the training thing. So how do we reuse, adapt uh those models.",
            "speaking duration": 65,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:00",
            "end_time": "11:05",
            "annotations": [
                {
                    "present new idea": "Beck introduces the idea of data or model adaptation to different datasets, which is a novel concept in the context of the discussion about training AI/ML algorithms for large 3D imaging datasets.",
                    "explain or define term or concept": "Beck explains the concept of adapting models trained on one type of data to another, clarifying what he means by 'data or model adaptation'.",
                    "expand on existing idea": "Beck expands on the initial idea of data adaptation by discussing the limitations of current adaptation techniques and the challenges of adapting deep learning models, building upon the initial mention of data adaptation."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:06-01:22",
            "transcript": "So how do we use metrology to appropriately measure how we're doing in our development as well as in the end product so that it is generalizable? I think that's what you were getting at as well as say unbiased and fair.",
            "speaking duration": 16,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "11:06",
            "end_time": "11:22",
            "annotations": {
                "ask clarifying question": "The speaker is asking how to use metrology to measure development and the end product to ensure generalizability, unbiasedness, and fairness, seeking clarification on how to achieve these goals.",
                "acknowledge contribution": "The speaker acknowledges that her question relates to the previous speaker's point about data or model adaptation."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "01:23-01:23",
            "transcript": "Yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "11:23",
            "end_time": "11:23",
            "annotations": {
                "express agreement": "Beck Kamilov agrees with Maryellen Giger's summarization of his previous points about using metrology to measure development and ensure generalizability, fairness, and lack of bias."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:24-01:24",
            "transcript": "Are those major topics that",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "11:24",
            "end_time": "11:24",
            "annotations": {
                "ask clarifying question": "Maryellen is asking if the topics discussed are major topics, seeking confirmation and clarity on the direction of the conversation."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:32-01:52",
            "transcript": "I think we should add kind of explainability to it too because in order to like uh focus more about the second part that what data are required to effectively train as we try to model and then create kind of some explanation to take away from that black box of how the algorithm is working.",
            "speaking duration": 20,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "11:32",
            "end_time": "11:52",
            "annotations": [
                {
                    "present new idea": "The speaker introduces the idea of adding 'explainability' as a key consideration, which hasn't been explicitly mentioned before in the conversation.",
                    "expand on existing idea": "The speaker builds on the previous discussion about data requirements for training AI/ML algorithms by suggesting the need for explainability to understand how the algorithms are working."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:52-02:22",
            "transcript": "And then make it more explainable is going to help us to see what are the different information that the data is leading to give us our accurate output and then as we learn and as we try to make it more explainable, that's become a tools for us to just try to focus in the information that we need.",
            "speaking duration": 30,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "11:52",
            "end_time": "12:22",
            "annotations": [
                {
                    "expand on existing idea": "This utterance builds upon the previous discussion about data and model adaptation by suggesting that explainability should be added to the discussion, which is a way to improve the development and generalization of AI/ML models."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:22-02:26",
            "transcript": "Okay, I I agree explainability and then to the end user interpretability.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "12:22",
            "end_time": "12:26",
            "annotations": {
                "express agreement": "Maryellen explicitly agrees with Shiva's point about the importance of explainability in AI/ML models, building on the previous discussion about training AI/ML algorithms and adapting models to different datasets.",
                "expand on existing idea": "Maryellen expands on Shiva's idea of explainability by adding the concept of interpretability for the end user, building on the previous discussion about training AI/ML algorithms and adapting models to different datasets."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:27-02:42",
            "transcript": "So, um Shannon, would you want to share your screen and we could all pull it over so we can still see each other, but that way we can give you is that useful or not? I don't know what notes you're taking, that's why.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "12:27",
            "end_time": "12:42",
            "annotations": [
                {
                    "encourage particpatioin": "Maryellen is directly asking Shannon if she wants to share her screen, encouraging her to participate in the discussion."
                },
                {
                    "ask clarifying question": "Maryellen is asking if sharing the screen would be useful for Shannon, seeking clarification on her needs for note-taking."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:43-02:50",
            "transcript": "I'm I'm unfortunately on Zoom on an iPad and taking notes on a desktop with the monitors right behind it.",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:43",
            "end_time": "12:50",
            "annotations": {
                "express frustration": "Shannon expresses frustration about her current setup, being on Zoom on an iPad while taking notes on a desktop, which seems inconvenient for screen sharing."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:50-02:52",
            "transcript": "Ah.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:50",
            "end_time": "12:52",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger is acknowledging Shannon's previous statement about her setup with the iPad and desktop, but is not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:54-03:03",
            "transcript": "So, um I could turn it into a Google Doc that I can then share a link to with everybody in here if that would be preferable.",
            "speaking duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:54",
            "end_time": "13:03",
            "annotations": {
                "propose decision": "Shannon proposes to turn her notes into a Google Doc and share the link, offering a concrete choice for the group on how to share the notes."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:03-03:22",
            "transcript": "Because I like seeing everyone while we're having a discussion and I know I can kind of make the slide part very small and still see you all. Um but I think we need that visual feedback.",
            "speaking duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:03",
            "end_time": "13:22",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging participation by expressing her preference for seeing everyone during the discussion, suggesting it aids visual feedback and thus, better engagement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:22-03:24",
            "transcript": "So do you do you all want to do a uh Google Drive?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:22",
            "end_time": "13:24",
            "annotations": {
                "propose decision": "Maryellen is suggesting a concrete choice for the group, which is to use a Google Drive for sharing notes, following Shannon's explanation of her note-taking setup."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:24-03:26",
            "transcript": "Or do you want someone to",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:24",
            "end_time": "13:26",
            "annotations": {
                "encourage particpatioin": "Maryellen is asking a question to encourage someone else to contribute to the discussion about how to share notes."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "03:26-03:30",
            "transcript": "I'm comfortable with the Google Drive, uh Google Doc, Google Doc.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:26",
            "end_time": "13:30",
            "annotations": {
                "express agreement": "Beck Kamilov expresses agreement with the suggestion of using a Google Doc, which was proposed by Maryellen Giger as a way to share notes during the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:30-03:45",
            "transcript": "Right, Google Doc, I'm sorry. So if you send that link in the chat, we can just click on it and then it's as if we're viewing the screen. That would be useful because",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:30",
            "end_time": "13:45",
            "annotations": {
                "confirm decision": "Maryellen confirms the decision to use a Google Doc for note-taking, which was previously suggested by Shannon and agreed upon by Beck.",
                "explain or define term or concept": "Maryellen clarifies that she meant 'Google Doc' instead of 'Google Drive', ensuring everyone understands the tool being discussed.",
                "express enthusiasm": "Maryellen expresses that using the Google Doc would be useful for the discussion."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "03:45-03:45",
            "transcript": "Yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:45",
            "end_time": "13:45",
            "annotations": {
                "express agreement": "Beck Kamilov agrees with Maryellen Giger's suggestion to use a Google Doc for note-taking, which was proposed in the previous turn."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:45-03:46",
            "transcript": "Um",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:45",
            "end_time": "13:46",
            "annotations": {
                "None": "This utterance does not fit any of the codes in the codebook because it is an incomplete sentence and does not express any idea, question, or action."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:46-04:24",
            "transcript": "Does anyone have any other thoughts on the first bullet which is in a way kind of our discussion blended into the third bullet? You know, we talked about um what kind of errors, you know, if we think about errors that are acceptable, those are quantitated by the metrology of the system. how are you going to measure the performance? How are you going to measure the variation of your system? How will you measure how unbiased or general your system is?",
            "speaking duration": 38,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:46",
            "end_time": "14:24",
            "annotations": {
                "encourage particpatioin": "Maryellen is asking if anyone has any other thoughts, encouraging others to contribute to the discussion.",
                "expand on existing idea": "Maryellen is elaborating on the first bullet point by connecting it to the third and discussing errors, performance measurement, variation, bias, and generalization, building upon the initial topic of 3D imaging and massive datasets.",
                "explain or define term or concept": "Maryellen is explaining the concept of acceptable errors and how they are quantified by the metrology of the system."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "04:25-04:56",
            "transcript": "Yeah, I think I feel like since we're often imaging biological processes and looking at clinical images, um really knowing what ground truth is, um can be very challenging. Um it's not, you know, often the result might be correlated to pathology for example, if you're looking at cancer, but you don't really know that that pathology is accurate either.",
            "speaking duration": 31,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "14:25",
            "end_time": "14:56",
            "annotations": {
                "present new idea": "The speaker introduces the challenge of knowing the ground truth when imaging biological processes and clinical images, which is a novel point in the discussion.",
                "provide supporting evidence": "The speaker supports the idea that knowing the ground truth is challenging by mentioning that pathology, which is often correlated to the result, may not always be accurate."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "04:57-05:07",
            "transcript": "Um do you think Carolyn that it's like having uh the expert lead on it or are you um like what would make it more true?",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:57",
            "end_time": "15:07",
            "annotations": {
                "ask clarifying question": "Katy is asking Carolyn a clarifying question about what would make the ground truth more accurate when imaging biological processes and clinical images, after Carolyn mentioned the challenge of knowing what ground truth is."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "05:08-05:15",
            "transcript": "Um probably better images, right? Like since we're we're all looking at it with the image lens, right?",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "15:08",
            "end_time": "15:15",
            "annotations": {
                "expand on existing idea": "Carolyn is expanding on the previous discussion about the challenges of knowing the ground truth when imaging biological processes and clinical images, suggesting that better images would improve the situation.",
                "provide supporting evidence": "Carolyn supports her idea by stating that they are all looking at the problem through the \"image lens\", implying that the quality of the images is a fundamental factor in their work."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:19-05:25",
            "transcript": "Yeah, when I think of imaging, I think of both acquisition and interpretation.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "15:19",
            "end_time": "15:25",
            "annotations": {
                "explain or define term or concept": "Maryellen is defining what she means by 'imaging' to include both acquisition and interpretation, clarifying the scope of the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:25-06:16",
            "transcript": "I think we have to go back to the application and what is the task? And I think the truth um I'm going to throw this out. So a lot of us probably do segmentation, right? And then you ask, well how do you evaluate it? Well, maybe you use a dice coefficient or something like that. But it there's also the more broader picture saying, well, my segment works depending on my final truth, which might be based on pathology.",
            "speaking duration": 51,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "15:25",
            "end_time": "16:16",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is explaining the concept of 'truth' in the context of image segmentation and how it relates to the application and task at hand, particularly in relation to pathology as the final truth."
                },
                {
                    "expand on existing idea": "The speaker is expanding on the discussion about ground truth by relating it to segmentation and evaluation metrics like the dice coefficient, building on the previous discussion about the challenges of defining ground truth in biological and clinical images."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:16-06:23",
            "transcript": "Um, just what do you think?",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "16:16",
            "end_time": "16:23",
            "annotations": {
                "encourage particpatioin": "Maryellen Giger is asking for someone's opinion on the topic being discussed, which is related to ground truth in imaging and its evaluation, encouraging participation from the group."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "06:24-07:38",
            "transcript": "Well, I kind of I kind of agree with Carolyn's point about the uh ground truth, like what really is the ground truth? Um the way I see it is multiplexing the uh final yes no answer. So the input, let's say for example if it was histology, getting the manual input of the pathologist as well as some maybe molecular markers of the histological sections could be, you know, proteomics in addition to some genomic data, multiplexing the ground truth, well, getting working closer towards a ground truth by multiplexing the outputs at the end in order to train the intermediate. In my opinion is the best because I don't really know if there really is going to be a ground truth at that point because everything to a certain extent is either uh subjective to the observer if there's a pathologist or to uh experimental bias or fluctuations if you're going to get false positives or false negatives in the in the markers or the genomics themselves. So yeah, I'm I'm a little bit I'm kind of leaning more towards having building up the information at the at the end first in order to then bridge that gap because if you don't have that then it doesn't really make sense.",
            "speaking duration": 74,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "16:24",
            "end_time": "17:38",
            "annotations": [
                {
                    "express agreement": "Girgis agrees with Carolyn's point about the difficulty of defining ground truth, showing agreement with a previously stated idea.",
                    "present new idea": "Girgis presents the idea of multiplexing the final yes/no answer by combining pathologist input, molecular markers, proteomics, and genomic data to work towards a more reliable ground truth, which is a novel approach not previously discussed.",
                    "expand on existing idea": "Girgis expands on the discussion about ground truth by suggesting that multiplexing outputs at the end, such as histology, pathologist input, molecular markers, proteomics, and genomic data, can help train the intermediate steps, building upon the previous discussion about the challenges of defining ground truth."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:38",
            "transcript": "Sounds good.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:38",
            "end_time": "17:38",
            "annotations": {
                "confirm decision": "Maryellen Giger confirms a decision that was previously proposed, indicating agreement and finalization."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:39-07:40",
            "transcript": "Um",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:39",
            "end_time": "17:40",
            "annotations": {
                "None": "No code applies to this utterance."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:41-08:21",
            "transcript": "I maybe I want to also bring up one thing. There is an interesting thing, the concept, right? Um in the so if you have errors in your ground truth and those errors are not systematic, meaning if you average them out across the whole data set, right? And then they average out to be a very small quantity, you can in principle train still with this form of errors and your model will not learn. So there is an interesting technical question there, what kind of errors are tolerable in the training data.",
            "speaking duration": 40,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:41",
            "end_time": "18:21",
            "annotations": [
                {
                    "present new idea": "Beck introduces the concept of tolerable errors in ground truth, suggesting that non-systematic errors that average out can still allow for effective model training, which is a novel idea in the context of the discussion about ground truth challenges.",
                    "explain or define term or concept": "Beck explains the concept of 'non-systematic errors' in the context of ground truth, clarifying that these are errors that average out across the dataset and do not significantly impact model training, which helps the group understand the nuances of error types in training data."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:21-08:21",
            "transcript": "Yeah.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "18:21",
            "end_time": "18:21",
            "annotations": {
                "express agreement": "Maryellen agrees with the point that there are tolerable errors in the training data, which was brought up by Beck in the previous turn."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:22-08:55",
            "transcript": "Yeah, I think we need to train and test with messy data because that's what the real world is. And sometimes, you know, we can do initial development, it's we do initial development of a filter in continuous domain, um but then when we go to actual image domain is pixelated and quantized, it doesn't quite work, but it gets you maybe 80, 85% there. Um, you know, we start in the ideal world and then um make it work in the messy real world.",
            "speaking duration": 33,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "18:22",
            "end_time": "18:55",
            "annotations": [
                {
                    "provide supporting evidence": "The speaker supports the idea of training with messy data by providing an example of developing a filter in a continuous domain that doesn't work perfectly when applied to the pixelated and quantized image domain, suggesting that real-world data is inherently messy."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "08:56-09:16",
            "transcript": "And by the way, anything like changes like this you just mentioned that pixelation changes. Those are the systematic things that you could in principle incorporate to this as non-trainable elements or adaptable elements of machine learning models.",
            "speaking duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "18:56",
            "end_time": "19:16",
            "annotations": {
                "expand on existing idea": "Beck expands on Maryellen's point about pixelation in real-world images by suggesting that these systematic changes can be incorporated as non-trainable or adaptable elements in machine learning models, building upon the discussion of training and testing with messy data.",
                "provide supporting evidence": "Beck provides a potential solution to the problem of pixelation changes in real-world images, suggesting incorporating them as non-trainable or adaptable elements in machine learning models, which supports the idea of adapting models to different data."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "09:16-09:17",
            "transcript": "So",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:16",
            "end_time": "19:17",
            "annotations": [
                {
                    "None": "No code applies to this utterance as it is incomplete."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:00-00:41",
            "transcript": "This is a major problem. I mean this problem and even uh it um the aspects about um the generalizability, um the bias that biases an AI is is really important. Um, what would you need to make this dream work? And I'm going to ask Lou. What what would take uh well maybe um you're more imaging than AI, right? Yeah, so I I well, you could take a pass if you want, but go ahead if you want to.",
            "speaking duration": 41,
            "nods_others": 0,
            "smile_self": 15,
            "smile_other": 3,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:00",
            "end_time": "20:41",
            "annotations": [
                {
                    "acknowledge contribution": "Maryellen acknowledges the importance of the problem of generalizability and bias in AI, which builds upon the previous discussion about errors in ground truth and training data.",
                    "explain or define term or concept": "Maryellen is defining the problem of generalizability and bias in AI, which is important for the group to understand.",
                    "encourage particpatioin": "Maryellen encourages Lou to participate by asking what would be needed to make the dream work, even acknowledging that Lou might be more focused on imaging than AI."
                }
            ]
        },
        {
            "speaker": "Lu Wei Caltech",
            "timestamp": "00:41-02:45",
            "transcript": "Right, yeah, so I I'm more of imaging than AI. I'm here actually um trying to learn some um questions or or abilities for AI that could help us to interpretate uh imaging and do imaging segmentation. So um I'm new to the AI field. We're trying to adopting uh different networks for um um training and uh one part of the research in my lab is we do uh label free imaging um such that there's um a ton of uh images but not so much specific contrast. So we're trying to use an AI to allow us to uh do specific imaging. Um so I guess the question I have is uh there are a lot of different networks out there. Um well with with or specifically with very fine um um um differences. Um but there's not much of the benchmark um to allow us to compare um unless we're trying to use our own data to train it and then um to compare with of course different uh um um basically to adopt each of the techniques and compare it with our own data. Um before that there's really no way to know specifically what would be the best candidate for us. Um and also another thing um related to um I guess the uh um um validity of the interpretation is uh what kind of signal noise ratios do we need as both training set and also the prediction set and um is there any uh limitations on resolutions um that we should be aware of um before we do the um training. So so I guess I'm here more of to uh looking to the possibilities and asking questions then then providing some of the insights. Sorry about that.",
            "speaking duration": 124,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 1,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:41",
            "end_time": "22:45",
            "annotations": [
                {
                    "explain or define term or concept": "Lu Wei explains that they are more focused on imaging but are trying to learn about AI to help with image interpretation and segmentation, clarifying their background and goals."
                },
                {
                    "ask clarifying question": "Lu Wei asks about the lack of benchmarks for comparing different AI networks and the required signal-to-noise ratios and resolution limitations for training and prediction sets, seeking guidance on AI model selection and training parameters."
                },
                {
                    "encourage particpatioin": "Lu Wei states that they are there to ask questions and learn, inviting others to provide insights based on their expertise."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "02:45-03:00",
            "transcript": "Well no, I think that's very useful. You're telling us what you want and some of us in it in AI research and development kind of have to um work to uh uh give that to you. We we need to understand the end user.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:45",
            "end_time": "23:00",
            "annotations": [
                {
                    "acknowledge contribution": "Maryellen acknowledges Lu Wei's contribution by stating that her input is very useful, recognizing her perspective as an imaging expert seeking AI solutions."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:00-03:43",
            "transcript": "Because you know, earlier we talked about this pipeline of the AI pipeline, we we talked about for example segmentation, do you measure it while you're segmenting it or you look at the end point and the end point depends on the end user. And even if um even if it's an autonomous AI system, there's an end user somewhere. Somewhere it's affecting it and I think uh this field is still very young because a lot of the work being done is very um very focused.",
            "speaking duration": 43,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:00",
            "end_time": "23:43",
            "annotations": {
                "expand on existing idea": "The speaker expands on the previously discussed AI pipeline, specifically segmentation, and how its evaluation depends on the end user.",
                "explain or define term or concept": "The speaker explains that the endpoint of the AI pipeline depends on the end user, even in autonomous systems, to clarify the importance of the end user perspective.",
                "present new idea": "The speaker introduces the idea that the AI field is still very young because a lot of the work being done is very focused, which is a novel concept in the context of the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:43-04:56",
            "transcript": "You know, you'll read the papers it was for this task with this database, maybe from different institutions, but it's just the the needle in a in a big haystack of all the other questions going on in medicine and biology. Um, but we can but many of the techniques, many of the metrology, the way to evaluate them, you know, how do you get around ground truth? Those I think there's um, I don't want to say a menu, but there is I think a short list and for me, um, though I have a lot of things that I would like in the world, I would like everyone to have access to this really clear short list of how how do I do all these things. Um, oh one of the things um I I don't want to forget before time goes by is we should look at bullet number two. And to me can can we extend our AI pipeline so it's very long, so it starts with acquisition, starts with the patient. In fact, someone thing by us is called closed loop imaging where this is that this is the what the patient needs, the patient gets it all the way to getting it and then doing the interpretation. To me that's you have to extend your AI to go through that entire pipeline.",
            "speaking duration": 73,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:43",
            "end_time": "24:56",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is explaining the concept of an AI pipeline and how it can be extended to include the entire process from patient acquisition to interpretation, which is meant to clarify the scope of AI in imaging."
                },
                {
                    "propose decision": "The speaker proposes that the AI pipeline should be extended to start with acquisition and the patient, suggesting a concrete choice for the group to consider."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:56-04:56",
            "transcript": "Yes.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:56",
            "end_time": "24:56",
            "annotations": [
                {
                    "express agreement": "Maryellen explicitly agrees with a prior statement."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh, UCSC",
            "timestamp": "04:56-04:57",
            "transcript": "Yes, that makes me so happy.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:56",
            "end_time": "24:57",
            "annotations": {
                "express enthusiasm": "The speaker expresses excitement and optimism, indicated by the statement \"Yes, that makes me so happy,\" which suggests a positive reaction to the preceding discussion about extending the AI pipeline."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:57-05:03",
            "transcript": "Oh, okay. Interesting. Okay, we have a happy group here. Good.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:57",
            "end_time": "25:03",
            "annotations": [
                {
                    "express enthusiasm": "Maryellen expresses enthusiasm by saying \"Interesting. Okay, we have a happy group here. Good.\", showing a positive reaction to Shiva's previous statement."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh, UCSC",
            "timestamp": "05:03-05:50",
            "transcript": "Yeah, I'm very excited to read, you know, like papers and then there are different groups that now thinking about kind of uh reconstructing the image, you know, using AI directly. And then since I usually work on kind of limited angle problem, so then I really uh think about how AI can just like really give us more information and then how we can even to interpret data that they are low dose and then we get kind of the information of higher dose. So I think that's um regarding this part, the question number two, I I think it's a very exciting time in the field and I'm really happy to learn and then implement them in my like research.",
            "speaking duration": 47,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "25:03",
            "end_time": "25:50",
            "annotations": [
                {
                    "express enthusiasm": "Shiva expresses excitement about reading papers on AI-based image reconstruction, building on Maryellen's suggestion to extend the AI pipeline, indicating enthusiasm for the field's progress."
                },
                {
                    "expand on existing idea": "Shiva expands on the idea of AI in imaging by mentioning its potential for image reconstruction, especially in limited angle problems and low-dose data interpretation, building on the discussion about extending the AI pipeline."
                },
                {
                    "express enthusiasm": "Shiva expresses excitement about the current state of the field and her eagerness to learn and implement AI in her research, reinforcing her positive reaction to the discussion about AI's potential in imaging."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:50-05:54",
            "transcript": "Great. So maybe optimizing along the pipeline individually and then the whole item.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "25:50",
            "end_time": "25:54",
            "annotations": {
                "propose decision": {
                    "Explanation": "Maryellen suggests optimizing the AI pipeline both individually and as a whole, proposing a concrete choice for the group to consider."
                }
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:54-06:05",
            "transcript": "Which includes acquisition and interpretation and then interpretation is by AI or human or AI aided human. But so patient um coming in for an imaging exam all the way to deciding the treatment.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "25:54",
            "end_time": "26:05",
            "annotations": {
                "expand on existing idea": "Maryellen expands on the idea of optimizing the AI pipeline, adding that it includes acquisition and interpretation, whether by AI, human, or AI-aided human, and extends from the patient's initial imaging exam to the final treatment decision, building upon the previous discussion about extending the AI pipeline.",
                "present new idea": "Maryellen presents the new idea of considering the entire process from patient exam to treatment as part of the AI pipeline, which hasn't been explicitly mentioned in this comprehensive way before.",
                "explain or define term or concept": "Maryellen clarifies that the interpretation stage of the AI pipeline can involve AI, humans, or AI-aided humans, explaining the different possibilities for how the interpretation is done."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:05-06:17",
            "transcript": "We got to do all that together as opposed we got everyone doing little niches here and there. So um that would be good. So yes, back.",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:05",
            "end_time": "26:17",
            "annotations": [
                {
                    "propose decision": "Maryellen proposes that the group should work together on the entire AI pipeline, from patient to treatment, instead of focusing on individual niches, suggesting a concrete choice for the group's approach."
                },
                {
                    "express agreement": "Maryellen explicitly agrees with a previously mentioned idea or decision, indicating alignment and support."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov (WashU)",
            "timestamp": "06:20-06:43",
            "transcript": "Uh I think one thing to think about in that context and you know, I'm very excited about that problem as well about, you know, the whole pipeline doing, but we need to think also about fragility of the system. Again, it comes back to generalization.",
            "speaking duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:20",
            "end_time": "26:43",
            "annotations": [
                {
                    "express enthusiasm": "Beck expresses excitement about the problem of the whole pipeline, indicating enthusiasm.",
                    "expand on existing idea": "Beck builds on the idea of the whole pipeline by adding the consideration of the system's fragility and generalization, which Maryellen introduced in the previous turns."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov (WashU)",
            "timestamp": "06:43-06:43",
            "transcript": "Right.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:43",
            "end_time": "26:43",
            "annotations": {
                "express agreement": "Beck Kamilov says \"Right\", which indicates agreement with the previous statement made by Maryellen Giger about the importance of considering the entire AI pipeline from patient to treatment."
            }
        },
        {
            "speaker": "Katy Keenan, NIST (she/her)",
            "timestamp": "06:44-07:39",
            "transcript": "There's a question around like um there's kind of a high barrier to entry as far as solving those sorts of problems because you want to have access to all the data types in order to solve that sort of problem. And uh like when you operate at a single institution, you're limited to the vendor system that you have access to. Or uh you know, in medical imaging when the vendors develop something, they're pulling it off of all of their own image sets and then it's not generalizable to the other vendors. So when I was, you know, thinking about the first bullet point, it was like uh like what data is required? I mean, you kind of want all the things. Uh and so I think that's a big challenge is how to and then how do we get it to people? Um there's a lot of access issues.",
            "speaking duration": 55,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:44",
            "end_time": "27:39",
            "annotations": [
                {
                    "present new idea": "The speaker introduces the idea that there is a high barrier to entry for solving problems related to AI in imaging due to limited access to diverse data types, which has not been explicitly mentioned before.",
                    "expand on existing idea": "The speaker expands on the existing idea of what data is required to effectively train AI/ML algorithms by stating that access to all data types is needed, which builds on the previous discussion about the challenges of training AI models with limited data.",
                    "express frustation": "The speaker expresses frustration about the difficulty of accessing diverse data types needed to solve AI problems in imaging, highlighting the limitations of single-institution data and vendor-specific systems."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:39-07:41",
            "transcript": "So we want all the data.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:39",
            "end_time": "27:41",
            "annotations": {
                "express agreement": "Maryellen is agreeing with Katy's point in the previous turn that solving the problem of generalizability requires access to all data types."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:41-07:54",
            "transcript": "That's one of the they asked us what do we want? We want all the data and we you you there technically we could do a lot. We are limited by data and culture I would say. The giving of data, the sharing of data even.",
            "speaking duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:41",
            "end_time": "27:54",
            "annotations": {
                "present new idea": "Maryellen introduces the idea that the group wants 'all the data' to solve problems, which hasn't been explicitly stated before, framing it as a requirement.",
                "express frustation": "Maryellen expresses frustration that they are limited by data and culture, specifically the giving and sharing of data, which is hindering their progress.",
                "expand on existing idea": "Maryellen expands on Katy's point about the data needed to solve problems, stating that they want all the data but are limited by data access and sharing culture, building on the previous discussion about data limitations."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:54-07:54",
            "transcript": "Right.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:54",
            "end_time": "27:54",
            "annotations": {
                "express agreement": "The utterance 'Right' expresses agreement with the previous statement made by Katy Keenan about the need for all data to solve problems related to AI in imaging."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:54-08:04",
            "transcript": "But if we had a massive method or so we we can do that. I saw Paris shaking his head. I think big mistake. So what are you thinking about?",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:54",
            "end_time": "28:04",
            "annotations": {
                "encourage particpatioin": "Maryellen Giger saw Paris shaking his head and then asked him what he was thinking about, inviting him to contribute to the discussion."
            }
        },
        {
            "speaker": "Katy Keenan, NIST (she/her)",
            "timestamp": "08:04-08:04",
            "transcript": "Oh.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:04",
            "end_time": "28:04",
            "annotations": {
                "acknowledge contribution": "The speaker is acknowledging the previous speaker's point, but not necessarily agreeing or expanding on it, as Maryellen Giger just asked Paris what he was thinking about."
            }
        },
        {
            "speaker": "Paris Perdikaris (UPenn)",
            "timestamp": "08:09-09:01",
            "transcript": "Uh it's a great discussion so far. I mean I'm a little bit on the less optimistic side on the front that you know, data and AI by alone will address all those issues. And perhaps one thing to think about is how we integrate domain knowledge into this pipeline in a way that is informative and gives us the right sort of prior information we need.",
            "speaking duration": 52,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:09",
            "end_time": "29:01",
            "annotations": [
                {
                    "express enthusiasm": "Paris expresses enthusiasm about the discussion so far, indicating a positive sentiment towards the ongoing conversation.",
                    "express alternative decision": "Paris expresses an alternative decision by stating he is less optimistic that data and AI alone will address all the issues, suggesting a different perspective from the previous discussion.",
                    "present new idea": "Paris presents a new idea by suggesting integrating domain knowledge into the AI pipeline to provide informative prior information, which hasn't been explicitly discussed before."
                }
            ]
        },
        {
            "speaker": "Paris Perdikaris (UPenn)",
            "timestamp": "09:01-09:01",
            "transcript": "Yes.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:01",
            "end_time": "29:01",
            "annotations": {
                "express agreement": "Paris explicitly agrees with the prior statement about the limitations of data and AI alone, and the need to integrate domain knowledge."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "09:02-09:14",
            "transcript": "Yes, I to me domain knowledge, domain expertise, what you know, all of us here if we're in imaging and AI in biology or medicine, we are working in an interdisciplinary field.",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:02",
            "end_time": "29:14",
            "annotations": [
                {
                    "express agreement": "Maryellen agrees with Paris's point about integrating domain knowledge into the AI pipeline, building on the previous discussion about the limitations of relying solely on data and AI."
                },
                {
                    "expand on existing idea": "Maryellen expands on the idea of domain knowledge by emphasizing the interdisciplinary nature of the field, connecting it to the expertise of the people in the meeting."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:20",
            "transcript": "have many you all are smart, you all have great AI technologies, but I think we're looking at the issues of how do we bring it all together? Um, um, to me, that's the challenge. Alex, I haven't put you on the spot. I'm sorry, you're right in the middle of my screen and I keep going.",
            "speaking duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:00",
            "end_time": "30:20",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "The speaker acknowledges the intelligence and AI capabilities of the group members, recognizing their contributions to the field."
                },
                "present new idea": {
                    "Explanation": "The speaker introduces the idea of bringing all the AI technologies together to address the challenges in the field, which is a novel concept in the context of the discussion."
                },
                "encourage particpatioin": {
                    "Explanation": "The speaker directly addresses Alex, apologizing for not including him in the discussion and inviting him to participate."
                }
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "00:21-00:22",
            "transcript": "Zoom has a question, no, Jim?",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:21",
            "end_time": "30:22",
            "annotations": {
                "encourage particpatioin": "Beck Kamilov encourages Jim to participate by asking if he has a question, after Maryellen Giger had been calling on other participants."
            }
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "00:23-00:51",
            "transcript": "Yeah, I have I have a question quickly. I know in other domains, um, you know, I know a lot about the Tesla autopilot work. The crowd sourcing of images and and so on has helped them a lot to improve that. Is there crowd sourcing going on here and and and where do those images end up residing that everybody could have access to the same large set of images?",
            "speaking duration": 28,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:23",
            "end_time": "30:51",
            "annotations": [
                {
                    "ask clarifying question": "The speaker is asking if there is crowd sourcing of images in the medical imaging domain, similar to Tesla's autopilot work, to improve AI models, which is a request for information."
                },
                {
                    "provide supporting evidence": "The speaker mentions Tesla's autopilot work and how crowd sourcing of images has helped them improve, providing an example from another domain to support the potential benefits of crowd sourcing in medical imaging."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:51-01:47",
            "transcript": "Uh, there is crowd sourcing in radiology. They do it at radiology meetings and also across the web where they they recruit some one project had over 180 radiologists who did multiple annotations on uh chest images. So they can do it. So and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to",
            "speaking duration": 56,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:51",
            "end_time": "31:47",
            "annotations": [
                {
                    "provide supporting evidence": "Maryellen provides an example of crowd sourcing in radiology, where radiologists annotate chest images, to support the idea that technically, a lot can be done."
                },
                {
                    "acknowledge contribution": "Maryellen acknowledges Jim's question about crowd sourcing of images."
                },
                {
                    "encourage particpatioin": "Maryellen encourages those in cellular imaging to talk about their experience and asks Alex about it, inviting them to contribute to the discussion."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:47-02:02",
            "transcript": "so and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to people sit and circle cells. crazy just to create data and that gets back to bullet one. How many cells do you have to circle to have enough data to algorithm. Um, but yes, the crowd sourcing it does it does exist, but it's it's not on a massive um scale. Good point, Jim. And sorry I didn't see your hand ready. So I'm used to this, not the stationary one that they have on. Alex.",
            "speaking duration": 75,
            "nods_others": 0,
            "smile_self": 30.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:47",
            "end_time": "32:02",
            "annotations": [
                {
                    "acknowledge contribution": {
                        "Explanation": "The phrase \"Good point, Jim\" acknowledges Jim's prior question about crowd sourcing of images."
                    }
                },
                {
                    "assign task": {
                        "Explanation": "The phrase \"I'm going to ask Alex about that\" assigns Alex the task of talking about their experience with cellular images."
                    }
                },
                {
                    "explain or define term or concept": {
                        "Explanation": "The speaker explains the concept of people manually circling cells to create data, relating it back to the earlier discussion about the amount of data needed for algorithms."
                    }
                }
            ]
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "02:03-02:04",
            "transcript": "Thank you back.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:03",
            "end_time": "32:04",
            "annotations": {
                "acknowledge contribution": "The speaker is acknowledging Beck's contribution for pointing out that Jim had a question."
            }
        },
        {
            "speaker": "Alex Walsh",
            "timestamp": "02:04-03:35",
            "transcript": "Yeah, we do a lot of circling cells. Um, yeah, we do auto fluorescence imaging, so it's low very low signal to noise and that creates a challenge for automated ways to process our data. And so we can see the patterns, but it's very hard to train traditional pipelines to do the segmentation. So that's why we've been working with AI. And actually, I really like Paris's point and you worded that much better than I was going to. Um, but my first interactions with AI and microscopy was stuff to for noise removal and um improving resolution and lowering laser power and stuff and I was just blown away by that work. And but I have right the same we know we know physical and biological boundaries on these conditions and I would like to see more integration of that into AI like if I'm segmenting a cell and it puts the nucleus, you know, right up against the edge of the cell, that's probably not where the nucleus is, right? It's more in the center. So how can we incorporate these things that we know um are are biological or physical boundaries and have the AI say like flag that oh that can't be right. Let's try again. Um, I think that gets into your errors, you know, what errors do we tolerate and how can we improve and minimize those.",
            "speaking duration": 91,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:04",
            "end_time": "33:35",
            "annotations": [
                {
                    "provide supporting evidence": "Alex describes their experience with auto fluorescence imaging and the challenges of low signal-to-noise ratios, supporting the need for AI in processing such data, which was previously discussed."
                },
                {
                    "express agreement": "Alex explicitly agrees with Paris's point about integrating domain knowledge into AI pipelines, indicating agreement with a previously stated idea."
                },
                {
                    "expand on existing idea": "Alex expands on the idea of integrating domain knowledge by providing a specific example of how biological and physical boundaries can be incorporated into AI for cell segmentation, building upon Paris's earlier point."
                },
                {
                    "offer constructive criticism": "Alex offers constructive criticism by suggesting that AI systems should flag segmentation results that violate known biological or physical boundaries, aiming to improve the accuracy and reliability of the AI's output."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:36-04:00",
            "transcript": "I that's a a very good point. Um, when when I find when training AI, you should take advantage of a priori knowledge as well as what image are you inputting? Yes, one could say if I have infinite amount of data, infinite amount of truth, I can train it if I I just let it chug away, right?",
            "speaking duration": 24,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:36",
            "end_time": "34:00",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "The phrase \"that's a very good point\" acknowledges Alex's prior contribution about integrating biological and physical boundaries into AI."
                },
                "expand on existing idea": {
                    "Explanation": "Maryellen expands on Alex's point about integrating domain knowledge into AI by suggesting taking advantage of a priori knowledge and the input image during AI training."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:00-04:16",
            "transcript": "But we don't have that especially in um the medical biomedical field, you know, you know, for things like image net, there's lots of pictures of cats and dogs and cars and light poles and all, but we don't have a lot of that annotated in the medical field even though we're generating so many medical images per day.",
            "speaking duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:00",
            "end_time": "34:16",
            "annotations": {
                "provide supporting evidence": "The utterance provides supporting evidence for the challenges in training AI in the medical field by contrasting it with the availability of annotated data in other fields like ImageNet, where there are abundant labeled images of common objects.",
                "expand on existing idea": "This utterance expands on the existing idea of the challenges in training AI for medical imaging, which was previously discussed in the context of ground truth and data limitations."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:16-04:30",
            "transcript": "Um, and I I I I appreciate um these comments on the a priori because we we need to help the AI. I you know, sometimes I tell my students think like a human because if you know that um image presentation A is better for the human to look at than image presentation B.",
            "speaking duration": 14,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:16",
            "end_time": "34:30",
            "annotations": [
                {
                    "expand on existing idea": "Maryellen expands on the idea of incorporating prior knowledge into AI training, which Alex had just discussed, by emphasizing the importance of helping the AI and thinking like a human."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:30-05:13",
            "transcript": "Why give the AI raw data? In a way, you're you're training in files, the training of all these humans has they have been reading images for many, many years. So how many of you in a sense consider what image am I giving to the AI and do you sometimes do the preprocessing to help the AI learn because you have limited data?",
            "speaking duration": 43,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:30",
            "end_time": "35:13",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining the concept of using preprocessed images instead of raw data for AI training, drawing an analogy to how humans are trained to read images over many years.",
                "present new idea": "Maryellen introduces the idea of preprocessing images before feeding them to AI, suggesting it can help the AI learn better with limited data.",
                "ask clarifying question": "Maryellen is asking how many of the participants consider what image they are giving to the AI and if they preprocess the data to help the AI learn, seeking to understand the current practices of the group."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:13-05:13",
            "transcript": "Caroline, what do you think of that?",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:13",
            "end_time": "35:13",
            "annotations": {
                "encourage particpatioin": "Maryellen Giger is directly asking Caroline for her opinion, encouraging her to contribute to the discussion."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "05:13-06:05",
            "transcript": "Yeah, no, so I was nodding because um so I I'm also focused more on the imaging and instrumentation side. Um, but I work with collaborators that um do more of the sort of machine learning or, you know, neural network development. And um, you know, that's that definitely resonates that you have sometimes picked a data set to show a specific thing, right? Um, and that data set obviously then may not be representative of what that algorithm is actually going to encounter.",
            "speaking duration": 52,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:13",
            "end_time": "36:05",
            "annotations": [
                {
                    "express agreement": "Carolyn agrees with Maryellen's point about preprocessing data to help AI learn, indicating that the idea resonates with her experience."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:06-06:21",
            "transcript": "So if we had our database, our messy database, we could include both, we can include them of different spatial resolution, we can include AI to do the reconstruction. Um, so Shannon, how's this list coming? It looks good. Looks longer than three minutes. It looks really good.",
            "speaking duration": 15,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:06",
            "end_time": "36:21",
            "annotations": [
                {
                    "encourage particpatioin": "Maryellen asks Shannon about the progress of the list, encouraging her participation."
                },
                {
                    "express enthusiasm": "Maryellen expresses enthusiasm about the list's progress, noting it looks good and longer than three minutes."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:31-06:34",
            "transcript": "I'm trying to get the main points.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:31",
            "end_time": "36:34",
            "annotations": {
                "acknowledge contribution": "Shannon is acknowledging the request to summarize the discussion, but not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:34-06:41",
            "transcript": "Okay. Um, do you want us to go through? Do you want to kind of summarize for us and then we can so so the topic here is",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:34",
            "end_time": "36:41",
            "annotations": [
                {
                    "encourage particpatioin": "Maryellen is encouraging Shannon to summarize the points, inviting her to contribute to the discussion."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:41-07:01",
            "transcript": "um what's the next big thing for this field? How can you what would be your dream of where it would go and um uh near the and I'll tell you how I've been trying to do my dream models.",
            "speaking duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:41",
            "end_time": "37:01",
            "annotations": [
                {
                    "propose decision": "Maryellen is proposing a direction for the discussion, asking about the next big thing for the field, which is a concrete choice for the group to discuss.",
                    "assign task": "Maryellen is assigning the task of thinking about the future of the field to the group."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:01-07:03",
            "transcript": "Is it the open question?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:01",
            "end_time": "37:03",
            "annotations": {
                "ask clarifying question": "Beck Kamilov is asking if the current topic of discussion is the \"open question\" that Maryellen Giger mentioned, seeking confirmation on the discussion's focus."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:03-07:07",
            "transcript": "That's is it a clinical question? What do you mean on the",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:03",
            "end_time": "37:07",
            "annotations": [
                {
                    "ask clarifying question": "Maryellen is asking for clarification on whether the previous statement was a clinical question, seeking to understand the speaker's intention."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:07-07:14",
            "transcript": "I'm sorry. like are we discussing big big should we kind of",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:07",
            "end_time": "37:14",
            "annotations": [
                {
                    "ask clarifying question": "Beck is asking a clarifying question about the topic of discussion, specifically if they should be discussing big picture ideas."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:14-07:34",
            "transcript": "I think one thing that just was coming to my mind while we're discussing is like it would be amazing to have a recipe of how much data we need for a task. There is no recipe, you know, like you come to a problem, you say, I want to segment this thing.",
            "speaking duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:14",
            "end_time": "37:34",
            "annotations": [
                {
                    "present new idea": "Beck introduces the novel concept of having a 'recipe' for determining the amount of data needed for a specific task, which hasn't been explicitly discussed before."
                },
                {
                    "express frustration": "Beck expresses frustration about the lack of a clear method for determining the amount of data needed for a task, highlighting the current uncertainty in the field."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:34-07:44",
            "transcript": "So, your collaborator asks, how much should I measure? Yeah. How much should I collect? Can anybody here answer?",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:34",
            "end_time": "37:44",
            "annotations": [
                {
                    "ask clarifying question": "Beck is asking a question about the amount of data needed for a task, building on the previous discussion about the challenges of determining ground truth and the need for messy data for training AI models."
                },
                {
                    "encourage particpatioin": "Beck is encouraging others to answer the question about how much data is needed for a task, inviting others to contribute to the discussion."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:44-07:54",
            "transcript": "Okay, now, how about if you know some prior information about the problem, say nucleus is in that position or that. Now, can this help me cut the data and by how much?",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:44",
            "end_time": "37:54",
            "annotations": [
                {
                    "expand on existing idea": "Building on the discussion about the amount of data needed for a task, this utterance expands on the idea by asking how prior information can help reduce the amount of data needed."
                },
                {
                    "ask clarifying question": "This utterance asks how prior information can help reduce the amount of data needed for a task, seeking clarification on the relationship between prior knowledge and data requirements."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:54-07:54",
            "transcript": "Well",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:54",
            "end_time": "37:54",
            "annotations": [
                {
                    "encourage particpatioin": "Shannon is about to speak, likely responding to a question or prompt from Maryellen or Beck, encouraging her participation in the discussion."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "07:54-07:54",
            "transcript": "Right.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:54",
            "end_time": "37:54",
            "annotations": [
                {
                    "express agreement": "Beck Kamilov is agreeing with the previous statement, which was Shannon Quinn beginning to speak."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:55-08:01",
            "transcript": "I guess I guess for me I actually want to take it one step further and almost",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:55",
            "end_time": "38:01",
            "annotations": {
                "expand on existing idea": "Shannon is building upon the previous discussion about data requirements and expressing a desire to extend the conversation further."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:01-08:04",
            "transcript": "almost take data out of the equation entirely and",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:01",
            "end_time": "38:04",
            "annotations": {
                "present new idea": "Shannon is introducing a novel concept of minimizing the reliance on data, which has not been previously discussed in the conversation."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:04-08:10",
            "transcript": "let me let me explain a bit where we've been talking a lot about",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:04",
            "end_time": "38:10",
            "annotations": {
                "explain or define term or concept": "Shannon is about to explain something, likely related to the ongoing discussion about data requirements for AI in imaging."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:10-09:54",
            "transcript": "you know, we need a lot of data, we need a lot of ground truth. Given an infinite amount of data, um that was an interesting point to me because I still wonder like would the model still learn what we wanted to learn? And I'm not I hesitate before answering and I feel like that hesitation by itself says that even our models aren't quite there yet and that maybe more data isn't exactly the problem that we're looking at. Maybe I just I keep I keep thinking of like these new methods involving self-supervised learning and few shot learning and anomaly detection where it's less about how much data you can throw at the problem and more about how we can build this architecture that without it becoming kind of a handcrafted algorithm has very specific features that it looks for. And so as a result, you don't need this lengthy training process, you don't need terabytes and terabytes of data, but what you can have to again sort of inform the end user if they don't have enough data is some sort of uncertainty quantification at the end. So for instance, if you're trying to do some kind of segmentation and you have your data set, you don't necessarily need to do a kind of calculation of how much data do I need, you just kind of give it to the algorithm, the algorithm does its few shot semi or self-supervised training and then at the end of that spits out, okay, here's the segmentation that I did and here's my certainty that it's correct.",
            "speaking duration": 104,
            "nods_others": 0,
            "smile_self": 20.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:10",
            "end_time": "39:54",
            "annotations": [
                {
                    "present new idea": "Shannon introduces the idea of using self-supervised learning, few-shot learning, and anomaly detection as alternatives to relying solely on large datasets and ground truth, which is a novel concept in the context of the discussion about data requirements for AI models.",
                    "expand on existing idea": "Shannon expands on the discussion about data requirements by suggesting that new methods like self-supervised learning and few-shot learning could reduce the need for massive datasets, building upon the previous discussion about the challenges of obtaining sufficient data and ground truth.",
                    "provide supporting evidence": "Shannon supports the idea of alternative learning methods by mentioning uncertainty quantification as a way to inform the end user even with limited data, providing a practical benefit of these approaches.",
                    "express alternative decision": "Shannon expresses an alternative to the idea that more data is always the solution, suggesting that new methods like self-supervised learning might be more effective, which goes against the earlier discussion about the need for massive datasets."
                }
            ]
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "09:54-09:58",
            "transcript": "Do do we also need the certainty on the certainty so that we can trust the certainty?",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:54",
            "end_time": "39:58",
            "annotations": {
                "ask clarifying question": "Beck is asking a question to clarify Shannon's point about uncertainty quantification, specifically if there needs to be a measure of certainty for the certainty itself to ensure trustworthiness."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:18",
            "transcript": "actually talk about having, you know, let's say the algorithm says, uh, you have 65% chance of having cancer, I am 35% sure and I am a slightly biased algorithm. So those are the three outputs I usually like, um, because",
            "speaking duration": 18,
            "nods_others": 0,
            "smile_self": 11,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:00",
            "end_time": "40:18",
            "annotations": {
                "expand on existing idea": "Maryellen is expanding on the idea of uncertainty quantification that Shannon introduced, adding the concept of algorithm bias to the uncertainty output.",
                "present new idea": "Maryellen introduces the idea of an algorithm providing three outputs: the probability of a condition (e.g., cancer), the algorithm's certainty in that probability, and a statement about the algorithm's bias, which is a novel concept in the discussion."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "00:19-00:22",
            "transcript": "Well I agree with that but I don't trust the 35%. How would I trust that 35",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:19",
            "end_time": "40:22",
            "annotations": [
                {
                    "express agreement": "Beck agrees with the previous statement about the algorithm providing a percentage chance of cancer, but he expresses doubt about the certainty of that percentage.",
                    "ask clarifying question": "Beck asks how one can trust the certainty (35%) provided by the algorithm, seeking clarification on the reliability of the uncertainty quantification."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:22-00:23",
            "transcript": "All right, but that's what the 35",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:22",
            "end_time": "40:23",
            "annotations": {
                "explain or define term or concept": "Maryellen is about to explain what the 35% certainty means in the context of the algorithm's output, building on the previous discussion about uncertainty quantification."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "00:23-00:29",
            "transcript": "that's what the 35% except if it actually has a true statistical meaning that's non Gaussian and I don't know.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:23",
            "end_time": "40:29",
            "annotations": [
                {
                    "ask clarifying question": "Beck is questioning the validity of the 35% certainty mentioned by Maryellen, asking if it has true statistical meaning, which is a request for clarification."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:29-00:52",
            "transcript": "Right. You have to do the reproducibility, repeatability studies to get that. But that's telling you that the computer is only 35%. It's like you go to the your doctor's office and he says like, you know, you got 85% sure chance you have a chipped tooth, but I'm only 20% sure. How do you feel? So that's what but the AI has to also kind of do that. I I agree.",
            "speaking duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:29",
            "end_time": "40:52",
            "annotations": [
                {
                    "explain or define term or concept": "Maryellen explains the concept of reproducibility and repeatability studies in the context of AI certainty, building on Beck's question about trusting the certainty of AI predictions.",
                    "express agreement": "Maryellen explicitly agrees with the need for AI to provide a measure of certainty, building on the discussion about the reliability of AI predictions."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:52-01:17",
            "transcript": "Uh Shannon, that's a um, uh, I I think that's definitely what kind of outputs do you want? And I think that will differ for if you're doing um AI on biological images for discovery or are you doing it for a patient output. I'm going to ask um, um, more folks to talk here. I don't know what when do we finish? I just want to make sure we're not running out of time.",
            "speaking duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:52",
            "end_time": "41:17",
            "annotations": [
                {
                    "acknowledge contribution": "Maryellen acknowledges Shannon's contribution by saying 'that's a' after Shannon spoke about self-supervised learning and uncertainty quantification.",
                    "explain or define term or concept": "Maryellen explains that the desired outputs from AI will differ depending on whether the AI is used for biological image discovery or for patient output, clarifying the importance of considering the application when designing AI systems.",
                    "encourage particpatioin": "Maryellen encourages participation by saying 'I'm going to ask more folks to talk here', inviting others to contribute to the discussion.",
                    "ask clarifying question": "Maryellen asks 'I don't know what when do we finish? I just want to make sure we're not running out of time', seeking clarification on the meeting's end time."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:19-01:54",
            "transcript": "I always, you know, I mentioned I I like to think like a human and I think the inputs and the outputs should be very similar. I'm a big fan of handcrafted. In fact, I I think it's the world will not just be all deep learning. I grew up with handcrafted and I now incorporate deep learning and I merge them.",
            "speaking duration": 35,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:19",
            "end_time": "41:54",
            "annotations": [
                {
                    "present new idea": "Maryellen introduces the idea that AI inputs and outputs should be similar to human inputs and outputs, which is a novel concept in the context of the discussion."
                },
                {
                    "expand on existing idea": "Maryellen expands on the discussion about AI by expressing her preference for handcrafted methods and how she merges them with deep learning, building on the previous discussion about AI pipelines and data requirements."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:54-02:20",
            "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access, but then like we have to. We have to find a way to just get to that.",
            "speaking duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "41:54",
            "end_time": "42:20",
            "annotations": [
                {
                    "express frustation": "The speaker expresses frustration about the difficulty of accessing radiologists and their time, especially in hospitals where research isn't the primary focus, indicating a problem they consistently encounter."
                },
                {
                    "express agreement": "The speaker explicitly agrees with Katie's earlier statement about the difficulty of accessing data, reinforcing the shared sentiment."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:20-02:25",
            "transcript": "Okay, yes, and when I say think like a human, I'm thinking more of input and output.",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:20",
            "end_time": "42:25",
            "annotations": {
                "explain or define term or concept": "Maryellen is clarifying what she means by \"think like a human\", stating that she is referring to the input and output of the AI system, not necessarily the internal workings."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:26-03:26",
            "transcript": "Um, but if you think how radiologist are that their job is to interpret medical images. And what how do they get trained? First as a resident, they have a textbook and they go through that textbook and they learn this is what a cancer looks like. This that's handcrafted. Get a little hand waving here. And then they sit with their attending radiologist and they read day in and day out and they're told, oh, you're wrong. No, that's a false positive. That's the deep learning and that's of the radiologist brain. And then we have different structures of the brain. Some are really good at finding Waldo and weirds Waldo and some aren't. Maybe they shouldn't have been radiologist. Just like there's probably computer vision AI algorithms that way.",
            "speaking duration": 60,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:26",
            "end_time": "43:26",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker explains how radiologists are trained, starting with textbooks and then learning from attending radiologists, which is relevant to the discussion of AI training and the need for ground truth data."
                },
                {
                    "express humor": "The speaker makes a humorous remark about radiologists who may not be good at finding Waldo, suggesting that some people may not be suited for the profession, similar to how some AI algorithms may not be suitable for certain tasks."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:26-03:37",
            "transcript": "And I I think the example of giving the AI algorithm an image that radio humans find easier to read could save you a lot of training time and data when you're doing your AI. How many of you train on medical images? I think Katie does and Shannon and Shiva.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:26",
            "end_time": "43:37",
            "annotations": [
                {
                    "expand on existing idea": "This builds upon the previous discussion about the challenges of training AI models with limited data, suggesting that providing AI algorithms with images that are easier for humans to interpret could reduce training time and data requirements."
                },
                {
                    "ask clarifying question": "This asks how many of the participants train on medical images, seeking to understand the prevalence of this practice within the group."
                }
            ]
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "03:37-03:39",
            "transcript": "We're using like a DICOM.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:37",
            "end_time": "43:39",
            "annotations": {
                "explain or define term or concept": "The utterance explains the term DICOM, which is relevant to the discussion about medical imaging data."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:39-04:26",
            "transcript": "A DICOM. But say for example with um breast MRI, you could have DICOM fields of the raw data, you could have it showing subtracted images after uptake of a contrast, you could have a image where you've collapsed it into a MIP. We find for example inputting the MIP gives you better performance than inputting just the subtraction image or and and things like if you have volume data, do you input the volume data or do you input the slices of the volume data. All those are before you even get to your algorithm and I don't know if people spend enough time on that. That's how I see it. Um, have you run into that?",
            "speaking duration": 47,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:39",
            "end_time": "44:26",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining different types of DICOM fields and image processing techniques (subtracted images, MIP) in the context of breast MRI data, clarifying the options available for inputting data into AI algorithms.",
                "provide supporting evidence": "The speaker mentions that inputting MIP (Maximum Intensity Projection) images gives better performance than inputting just the subtraction image, providing empirical evidence based on their experience.",
                "ask clarifying question": "The speaker ends the utterance by asking if others have run into the same issues regarding data preprocessing and its impact on AI algorithm performance, seeking to understand if others have similar experiences."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:26-04:26",
            "transcript": "How do you decide what goes into your algorithm?",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:26",
            "end_time": "44:26",
            "annotations": {
                "ask clarifying question": "Maryellen is asking a question to understand the decision-making process behind selecting inputs for an algorithm, following a discussion about preprocessing images to help AI learn with limited data."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "04:26-04:37",
            "transcript": "I mean between the volumetric and slices it's easy it depends how much volumetric examples I have. Usually I have like 10 volumetric examples and each one has hundreds of slices or thousands of slices and I go by slices.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:26",
            "end_time": "44:37",
            "annotations": [
                {
                    "provide supporting evidence": "Beck is providing his reasoning for choosing slices over volumetric data, stating that he usually has a limited number of volumetric examples compared to the number of slices, which supports his decision-making process in data selection."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:40-04:41",
            "transcript": "But the format.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:40",
            "end_time": "44:41",
            "annotations": {
                "ask clarifying question": "Maryellen is asking for clarification on the format of the data being used for the algorithm, following a discussion about the choice between volumetric data and slices."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "04:42-04:45",
            "transcript": "Oh you mean the way the data is stored in the format?",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:42",
            "end_time": "44:45",
            "annotations": {
                "ask clarifying question": "Beck is asking for clarification on what Maryellen meant by 'format', specifically if she is referring to the way the data is stored."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:45-04:46",
            "transcript": "Right. What are well, not the format.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:45",
            "end_time": "44:46",
            "annotations": {
                "ask clarifying question": "Maryellen is asking about what data to input into the algorithm, and is now clarifying that she is not asking about the format of the data, but something else."
            }
        },
        {
            "speaker": "Beck Kamilov",
            "timestamp": "04:46-04:56",
            "transcript": "That's like application collaborator dependent, right? Uh, well for me at least it's uh depends what's application, so that tells me the format.",
            "speaking duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:46",
            "end_time": "44:56",
            "annotations": [
                {
                    "explain or define term or concept": "Beck is explaining that the format of the data depends on the application and the collaborator, clarifying the factors that influence data storage."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:56-04:57",
            "transcript": "Right.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:56",
            "end_time": "44:57",
            "annotations": [
                {
                    "express agreement": "Maryellen agrees with Beck's previous statement about the format of the data being application and collaborator dependent."
                }
            ]
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "05:00-05:11",
            "transcript": "I think it's a little bit as a barrier because I don't think that you we have enough resources to answer some of those questions. Sometimes they're still driven by what you have access to.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:00",
            "end_time": "45:11",
            "annotations": [
                {
                    "express frustation": "The speaker expresses frustration about the limitations in resources to address certain questions, indicating a barrier to progress."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:11-05:24",
            "transcript": "So if you were to ask me how do I figure out what to input to the network, my answer would be I sit with the radiologist. I sit with the domain expert on imaging. I sit with the human AI instrument.",
            "speaking duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:11",
            "end_time": "45:24",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining her process for determining the appropriate input for a neural network, which involves consulting with domain experts.",
                "provide supporting evidence": "Maryellen is providing her method of consulting with radiologists and domain experts as a way to determine the best input for a network, supporting the idea that domain knowledge is important."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:24-05:25",
            "transcript": "I use human human aided AI development.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:24",
            "end_time": "45:25",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining her approach to AI development, which involves human input and collaboration, building on the previous discussion about the importance of domain expertise and understanding the end user's needs."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "05:25-05:36",
            "transcript": "And not all of us are in a place where we can do that. Right? Like I'm not at a medical institution. And so how do I get that access? How do I that's not a resource I have.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:25",
            "end_time": "45:36",
            "annotations": [
                {
                    "express frustation": "Katy expresses frustration about not having access to resources, specifically not being at a medical institution, which limits her ability to collaborate with radiologists and domain experts, a point that Maryellen emphasized as crucial for determining the best input for AI algorithms."
                },
                {
                    "ask clarifying question": "Katy is asking how to gain access to resources and expertise, specifically how to collaborate with radiologists and domain experts when not affiliated with a medical institution, which is relevant to Maryellen's point about the importance of human-AI collaboration."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-05:36",
            "transcript": "Okay, so",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:36",
            "end_time": "45:36",
            "annotations": [
                {
                    "None": "No code applies to this utterance."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-05:37",
            "transcript": "Right.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:36",
            "end_time": "45:37",
            "annotations": [
                {
                    "express agreement": "Maryellen Giger is agreeing with the previous speaker, Katy Keenan, who stated that they don't have enough resources to answer some questions and that their work is sometimes driven by what they have access to."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:37-06:12",
            "transcript": "Okay, well that's that's major. To me, that's a barrier. You um AI developers need um um need that. I I get that access all the time that's why I like where I am, but um that's that's really important that the network network needs to connect the AI developer with the domain expert of that imaging task.",
            "speaking duration": 35,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:37",
            "end_time": "46:12",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Maryellen acknowledges Katy's point about the lack of access to domain experts as a major barrier for AI developers."
                },
                "present new idea": {
                    "Explanation": "Maryellen presents the idea that a network is needed to connect AI developers with domain experts in imaging tasks, which hasn't been explicitly stated before."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:12-06:13",
            "transcript": "It it it will save you tons of time.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:12",
            "end_time": "46:13",
            "annotations": {
                "express enthusiasm": "Maryellen expresses enthusiasm that connecting AI developers with domain experts will save time."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:13-06:15",
            "transcript": "What about Shannon and Shiva? How do you get your images?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:13",
            "end_time": "46:15",
            "annotations": [
                {
                    "encourage particpatioin": "Maryellen Giger is explicitly asking Shannon and Shiva to share their experiences, encouraging them to contribute to the discussion."
                },
                {
                    "ask clarifying question": "Maryellen Giger is asking Shannon and Shiva how they obtain their images, seeking to understand their data acquisition process."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:15-06:17",
            "transcript": "Are you have domain expert issues?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:15",
            "end_time": "46:17",
            "annotations": {
                "ask clarifying question": "Maryellen is asking Shannon and Shiva if they are having issues related to access to domain experts, following a discussion about the importance of domain expertise in AI development."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "06:18-07:14",
            "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, if you want coffee, I bring you coffee and then when you are sitting in the reading room just please, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access.",
            "speaking duration": 56,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "46:18",
            "end_time": "47:14",
            "annotations": [
                {
                    "express frustation": "Shiva expresses frustration about the difficulty of accessing radiologists and their expertise, which is critical for her research, especially since the hospital she works with is not research-focused."
                },
                {
                    "expand on existing idea": "Shiva expands on Katie's point about the difficulty of accessing data and resources, emphasizing that it is a critical problem for her research."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:14-07:14",
            "transcript": "Yes.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "47:14",
            "end_time": "47:14",
            "annotations": [
                {
                    "express agreement": "Shiva is agreeing with the previous statement made by Maryellen Giger about the critical path for success being access to domain experts."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:14-07:31",
            "transcript": "But then like we have to. We have to find a way to just get to that. So then if we had more infrastructure to provide a path for that, it could be really great.",
            "speaking duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "47:14",
            "end_time": "47:31",
            "annotations": [
                {
                    "express enthusiasm": "Shiva expresses enthusiasm for finding a way to get access to the resources needed for research, building on the prior discussion about the difficulty of accessing data and domain experts."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:31-07:32",
            "transcript": "Okay, this yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:31",
            "end_time": "47:32",
            "annotations": {
                "express agreement": "Maryellen is agreeing with Shiva's statement about the need for infrastructure to provide a path to access data and domain experts, which is a critical path for success."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:32-07:32",
            "transcript": "I think",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:32",
            "end_time": "47:32",
            "annotations": [
                {
                    "None": "No code applies to this utterance."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:32-07:33",
            "transcript": "Yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:32",
            "end_time": "47:33",
            "annotations": [
                {
                    "express agreement": "Maryellen Giger says \"Yeah\" in response to a prior statement, indicating agreement."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:33-07:34",
            "transcript": "Okay, good.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:33",
            "end_time": "47:34",
            "annotations": {
                "express agreement": "Maryellen is explicitly agreeing with the previous statement made by Shiva about the need for infrastructure to provide a path for AI developers to connect with domain experts."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:34-07:34",
            "transcript": "Um",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:34",
            "end_time": "47:34",
            "annotations": [
                {
                    "None": "No code applies to this utterance."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:34-07:35",
            "transcript": "Yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:34",
            "end_time": "47:35",
            "annotations": [
                {
                    "express agreement": "Shannon Quinn says \"Yeah\", which expresses agreement with the previous statement."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:35-07:35",
            "transcript": "Okay, good.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:35",
            "end_time": "47:35",
            "annotations": [
                {
                    "express agreement": "Maryellen expresses agreement with the previous statement, likely summarizing or affirming a point made in the discussion."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:35-07:36",
            "transcript": "We've got 20 minutes.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:35",
            "end_time": "47:36",
            "annotations": {
                "None": "This utterance does not fit into any of the codes provided in the codebook, as it is simply stating the remaining time."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:36-07:37",
            "transcript": "Thankfully.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:36",
            "end_time": "47:37",
            "annotations": [
                {
                    "express enthusiasm": "Shannon expresses relief that they have 20 minutes remaining in the meeting, indicating a positive sentiment about the time available."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:37-07:38",
            "transcript": "I would not be able to throw that together.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:37",
            "end_time": "47:38",
            "annotations": [
                {
                    "express agreement": "Shannon Quinn agrees with Maryellen Giger's statement that the list looks good and longer than three minutes, indicating that she acknowledges the difficulty of summarizing the discussion in a short time."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:38",
            "transcript": "Okay.",
            "speaking duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:38",
            "end_time": "47:38",
            "annotations": [
                {
                    "Okay": "This utterance simply acknowledges the previous statement, indicating agreement or understanding."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:41",
            "transcript": "I think you're doing a great job here, Shannon. Shannon, where do you see things can be move merged?",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:38",
            "end_time": "47:41",
            "annotations": [
                {
                    "acknowledge contribution": "Maryellen acknowledges Shannon's work by saying she is doing a great job.",
                    "encourage particpatioin": "Maryellen encourages Shannon to participate by asking her where she sees things can be merged."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:41-07:42",
            "transcript": "Where do you have the domain expert issue?",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:41",
            "end_time": "47:42",
            "annotations": {
                "ask clarifying question": "Maryellen is asking Shannon to clarify if she has issues accessing domain experts, following a discussion about the importance of domain expertise in AI development and Katy Keenan's statement about not having access to medical experts."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:01-00:37",
            "transcript": "Yeah, that to me that's a night and day um that helps you. I I I um I always, you know, feel for you guys that in that situation. How about the biology people, the image people doing AI on bio imaging, biological imaging, cellular imaging. What's what's holding you up? You have access I would assume to biologist much easier than they have access to medical imaging people. Alex, do you have access to who you need to talk to? And then also Girgis, I can ask.",
            "speaking duration": 36,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 11.1,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:01",
            "end_time": "50:37",
            "annotations": [
                {
                    "encourage particpatioin": "Maryellen Giger is trying to get more people involved in the discussion by asking for their opinions and experiences, specifically directing the question to Alex and Girgis."
                },
                {
                    "acknowledge contribution": "Maryellen Giger acknowledges the difficulty of the situation for those who lack access to domain experts, showing empathy for their challenges."
                },
                {
                    "ask clarifying question": "Maryellen Giger is asking about the challenges faced by those working on biological imaging, specifically inquiring about what is holding them up and whether they have access to the necessary experts."
                }
            ]
        },
        {
            "speaker": "Alex Walsh",
            "timestamp": "00:38-00:45",
            "transcript": "Yeah, I think my limitations are how much data do I need and we already have that on there.",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
            "start_time": "50:38",
            "end_time": "50:45",
            "annotations": [
                {
                    "acknowledge contribution": "Alex acknowledges that the question of how much data is needed has already been brought up, recognizing a prior contribution to the discussion."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:46-00:49",
            "transcript": "Okay, so you have your domain experts. You have your biologist right there.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:46",
            "end_time": "50:49",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Maryellen acknowledges that Alex has access to domain experts and biologists, recognizing his input in the discussion."
                }
            }
        },
        {
            "speaker": "Alex Walsh",
            "timestamp": "00:50-00:51",
            "transcript": "Right. Yeah.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
            "start_time": "50:50",
            "end_time": "50:51",
            "annotations": [
                {
                    "express agreement": "Alex Walsh is expressing agreement with Maryellen Giger's statement about having domain experts, which was confirmed in the previous turn."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:51-00:53",
            "transcript": "Girgis, do you have that?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:51",
            "end_time": "50:53",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging Girgis to participate in the discussion, likely asking if he has access to the domain experts he needs, similar to the previous discussion with Alex."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "00:53-02:39",
            "transcript": "Yeah, well, so so our our approach uh at least machine learning from a completely different perspective. So we collaborate with some folks here uh trying to understand how nanoparticles will accumulate into tumors and what that actually means. And the problem at least from the perspective of the the domain experts is not necessarily that yes, this is a tumor, but it's more about the technology that's being developed. So if you use a a certain type of particle or contrast agent and suggest that this is tumor selective, the interpretation that's being presented at least in the primary literature is very biased by a lot of um I guess you could you could say misinterpretation that's that's been perpetuated over a couple of decades. So people will assume that certain types of materials will always accumulate in tumors and if it does, then yes, we have a tumor. So the problem is not necessarily just on the on the image interpretation side, but it's more about the the contrast agent itself. And so the way that we approach it is that the input that we need needs to be built up as well. It's not just a contrast agent, but it's more using some nanotech experts to suggest that okay, well, this contrast agent will also accumulate similarly to another contrast agent. So you have to put um a second uh piece of information into the input of the algorithm itself to suggest that if you see this kind of a trend, this is a false positive. So you're teaching it what a false positive is based on the material that you're using as a contrast agent right from the very start from the get go so that you don't end up with false positives at the end. So it's we're kind of more on the front end of things and and and in my field the domain experts that are lacking is more on the on the material well nanobio interaction side of things.",
            "speaking duration": 106,
            "nods_others": 1,
            "smile_self": 10.4,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:53",
            "end_time": "52:39",
            "annotations": [
                {
                    "expand on existing idea": "Girgis expands on the discussion about domain expertise and data requirements by describing his team's approach to machine learning for nanoparticle accumulation in tumors, building on Maryellen's question about access to domain experts and how to decide what to input into the algorithm."
                },
                {
                    "present new idea": "Girgis presents the idea of incorporating nanotech expertise to identify potential false positives based on the contrast agent used, which is a novel approach not previously discussed."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:40-02:47",
            "transcript": "So you're doing your AI based on knowledge of known biology and chemistry? Would that be correct wording?",
            "speaking duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:40",
            "end_time": "52:47",
            "annotations": {
                "ask clarifying question": "Maryellen is asking for confirmation that her understanding of Girgis's approach to AI development, which incorporates knowledge of biology and chemistry, is accurate."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "02:47-03:47",
            "transcript": "It's it's more about so it's it's hard for me to to explain without going into details. But let's let's take nanoparticle contrast agents um for optical imaging. That's one of the things that we look into. And there are clinical trials that suggest that you can use these contrast these nanoparticles as contrast agents for positive tumor detection and image guided surgery. And that's all very well and good. You can see the image, you can probably use AI to delineate the uh tumor boundary to be a little bit better. But there are secondary biological factors um that contribute to errors that haven't been considered right at the start. So we try and hit it on both ends, not just what the image actually tells us, but what the agent that we're administering, how that's going to interact with the tissue and how that then contributes to a false positive. And so then feeding in information about what false positive materials or materials that give false positives is actually going to look like when you finally get the image.",
            "speaking duration": 60,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:47",
            "end_time": "53:47",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is explaining the concept of using nanoparticle contrast agents for optical imaging and their application in tumor detection and image-guided surgery, providing context for the subsequent discussion on potential errors.",
                    "provide supporting evidence": "The speaker mentions clinical trials that suggest the use of nanoparticle contrast agents for positive tumor detection and image-guided surgery, providing evidence for the application of these agents.",
                    "expand on existing idea": "The speaker expands on the idea of using AI in imaging by discussing secondary biological factors that contribute to errors and how the interaction of the contrast agent with the tissue can lead to false positives, building on the earlier discussion about AI's role in image interpretation."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:49-04:14",
            "transcript": "So I always think of AI as having two types of components. One is where it's model driven where it has these physical limitations, chemistry limitations, but it when biology um where it's it's model driven and um the model is built on these principles. You could use deep learning in it, but in the end you have these constraints on it.",
            "speaking duration": 25,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "53:49",
            "end_time": "54:14",
            "annotations": {
                "present new idea": {
                    "Explanation": "Maryellen introduces a novel concept of AI having two types of components: one model-driven with physical and chemical limitations, and another built on biological principles, which hasn't been explicitly discussed in this manner before."
                },
                "expand on existing idea": {
                    "Explanation": "Maryellen expands on the idea of incorporating domain knowledge into AI, building on previous discussions about the importance of a priori knowledge and constraints in AI models."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:14-04:52",
            "transcript": "The other type of AI is in general you can think of it as statistical, you know, it's the deep learning, it's um uh having the machine actually learn and I personally believe that in the future we need a mixture of these. I think it would be extremely interesting to have like um both types applied to your situation Girgis because you have you know, a lot of times it's hard to find the person with the model. You know, it's um but how do you want to bring that point up in this this Google Doc?",
            "speaking duration": 38,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:14",
            "end_time": "54:52",
            "annotations": {
                "explain or define term or concept": "The speaker explains the two types of AI: statistical (deep learning) and model-driven (physical limitations), to clarify the different approaches to AI.",
                "express enthusiasm": "The speaker expresses enthusiasm about the idea of applying both types of AI to Girgis' situation, indicating excitement about the potential of this approach.",
                "encourage particpatioin": "The speaker encourages Girgis to bring up the point in the Google Doc, inviting him to contribute his perspective to the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:52-04:53",
            "transcript": "Help us, where would you put it and how would you put it?",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:52",
            "end_time": "54:53",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging someone to contribute to the Google Doc, seeking their input on where and how to incorporate a specific point."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "04:54-05:00",
            "transcript": "I I guess it probably it probably ties in with the with the ground truth to a certain extent.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:54",
            "end_time": "55:00",
            "annotations": {
                "expand on existing idea": "Girgis is building upon the previous discussion about ground truth, suggesting his point relates to that topic."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "05:00-05:16",
            "transcript": "But maybe the generalizability part of things. And again, I I see it from a whole different perspective. I know a lot of folks here use um patient images, but I'm talking more about the generalizability again of the contrast agent and how that will behave.",
            "speaking duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:00",
            "end_time": "55:16",
            "annotations": {
                "expand on existing idea": "Girgis is expanding on the previous discussion about generalizability, but applying it to the context of contrast agents rather than patient images, building on the topic of generalizability that was already brought up.",
                "acknowledge contribution": "Girgis acknowledges that others are using patient images, which is a recognition of their work, but he is not agreeing or expanding on their specific approaches."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:16-05:22",
            "transcript": "So it's something relationship of the model to the physics chemistry and biology of the imaging situation.",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:16",
            "end_time": "55:22",
            "annotations": {
                "explain or define term or concept": "This utterance is defining the relationship between the model and the physics, chemistry, and biology of the imaging situation, which is a concept being discussed."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:22-05:23",
            "transcript": "I guess so.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:22",
            "end_time": "55:23",
            "annotations": [
                {
                    "express agreement": "Maryellen agrees with Girgis's point about generalizability and the relationship of the model to the physics, chemistry, and biology of the imaging situation."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:23-05:25",
            "transcript": "Sorry, where is my cursor?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:23",
            "end_time": "55:25",
            "annotations": {
                "express humor": "Shannon Quinn expresses humor by apologizing for not knowing where her cursor is, which is a lighthearted comment in the context of sharing her screen."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:00-06:03",
            "transcript": "Well, I see a little red dock by the word generalizable.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:00",
            "end_time": "56:03",
            "annotations": {
                "acknowledge contribution": "Maryellen acknowledges Shannon's cursor position on the Google Doc, recognizing her contribution to the shared document."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:04-06:10",
            "transcript": "Oh, that's that's not me. But yeah. Um sorry, I was I was trying to",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 16.7,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:04",
            "end_time": "56:10",
            "annotations": [
                {
                    "acknowledge contribution": {
                        "Explanation": "Shannon Quinn is acknowledging that the red dock by the word generalizable was not her doing."
                    }
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:10-06:11",
            "transcript": "Yeah, you sure can. Everybody can.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:10",
            "end_time": "56:11",
            "annotations": [
                {
                    "encourage particpatioin": "Maryellen Giger is encouraging everyone to contribute to the Google Doc that Shannon Quinn is sharing, building on the previous discussion about generalizability and the relationship of the model to the physics, chemistry, and biology of the imaging situation."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:11-06:23",
            "transcript": "Um sorry, the people are editing the presentation and I'm not able to make any changes. That's what I've been trying to figure out.",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:11",
            "end_time": "56:23",
            "annotations": [
                {
                    "express frustation": "Shannon expresses frustration that others are editing the presentation and she is unable to make changes, indicating a problem with the collaborative process."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:23-06:34",
            "transcript": "So no one hits save. How's that? It kicks people in other groups. Shannon, if you want, I can add the names so that you can focus on the conversation.",
            "speaking duration": 11,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:23",
            "end_time": "56:34",
            "annotations": [
                {
                    "assign task": "Maryellen assigns the task of focusing on the conversation to Shannon, offering to add names to the document herself so Shannon can focus on the conversation."
                }
            ]
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:34-06:39",
            "transcript": "Yeah, thank you added it and they all got lost.",
            "speaking duration": 5,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:34",
            "end_time": "56:39",
            "annotations": [
                {
                    "acknowledge contribution": "Katy Keenan acknowledges that someone added something, showing recognition of their input."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:39-06:43",
            "transcript": "Yep. Yeah. Yeah, so I can do that.",
            "speaking duration": 4,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:39",
            "end_time": "56:43",
            "annotations": [
                {
                    "confirm decision": "Shannon confirms that she can turn the notes into a Google Doc that she can then share a link to with everybody in here, which was proposed in the prior turn."
                }
            ]
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:43-06:46",
            "transcript": "Okay, thank you.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:43",
            "end_time": "56:46",
            "annotations": [
                {
                    "acknowledge contribution": "Katy Keenan is acknowledging Maryellen Giger's previous statement."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:46-06:52",
            "transcript": "Yeah and are you able to open up your the slide deck to put in at least the final three points?",
            "speaking duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:46",
            "end_time": "56:52",
            "annotations": {
                "assign task": "Maryellen is assigning Shannon the task of opening the slide deck and adding the final three points, following up on Shannon's role as the designated note-taker and reporter."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:52-07:11",
            "transcript": "No, that's what I'm talking about. The Google Doc is fine. Please edit away there. It's the slide deck that keeps kicking me out every time I try to make an edit.",
            "speaking duration": 19,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:52",
            "end_time": "57:11",
            "annotations": [
                {
                    "express frustation": "Shannon expresses frustration that she is unable to edit the slide deck, which is interfering with her task of summarizing the discussion."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:11-07:14",
            "transcript": "So what if you just take yeah, okay.",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:11",
            "end_time": "57:14",
            "annotations": [
                {
                    "acknowledge contribution": "Maryellen acknowledges the previous discussion and prepares to move on, indicating she has heard and understood the points made."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:14-07:34",
            "transcript": "Can you download the PowerPoint to your computer? Um I'm actually just going to draft I'm going to draft it out in the Google Doc. Okay. Okay. Um Now I forgot what um",
            "speaking duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:14",
            "end_time": "57:34",
            "annotations": [
                {
                    "propose decision": "Maryellen proposes downloading the PowerPoint to the computer, suggesting a course of action for Shannon to take."
                }
            ]
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:20-07:21",
            "transcript": "You were going to mention something about generalizability.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:20",
            "end_time": "57:21",
            "annotations": {
                "ask clarifying question": "Shannon is asking Maryellen to elaborate on her previous point about generalizability, seeking further information on the topic."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:34-07:55",
            "transcript": "Yes, well model driven by the um physics chemistry and biology of the um uh contrast agents properties? I don't know if I got that right.",
            "speaking duration": 21,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:34",
            "end_time": "57:55",
            "annotations": {
                "explain or define term or concept": "Maryellen is trying to define or explain the concept of a model being driven by the physics, chemistry, and biology of contrast agents, which is a concept that Girgis was discussing in the prior turn."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "07:56-07:58",
            "transcript": "Yeah, that that's that pretty much.",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:56",
            "end_time": "57:58",
            "annotations": [
                {
                    "express agreement": "Girgis confirms that Maryellen's summary of his point about AI being model-driven by the physics, chemistry, and biology of contrast agent properties is accurate."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:58-08:00",
            "transcript": "knowledge wrong?",
            "speaking duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:58",
            "end_time": "58:00",
            "annotations": {
                "ask clarifying question": "Maryellen is asking if she got the knowledge wrong, seeking confirmation or correction on her understanding of the previous discussion about model-driven AI and contrast agents."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:08-08:09",
            "transcript": "Okay, good.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:08",
            "end_time": "58:09",
            "annotations": {
                "express agreement": "Maryellen Giger is expressing agreement with a prior statement, likely in response to the ongoing discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:09-08:17",
            "transcript": "So I think we we all as a group um um maybe uh Paris.",
            "speaking duration": 8,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:09",
            "end_time": "58:17",
            "annotations": [
                {
                    "encourage particpatioin": "Maryellen Giger is inviting Paris to contribute to the discussion, as she has done with other participants previously."
                }
            ]
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:18-08:21",
            "transcript": "Yeah, I think",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:18",
            "end_time": "58:21",
            "annotations": [
                {
                    "express agreement": "Paris is agreeing with a prior statement, indicated by the phrase \"Yeah, I think\"."
                }
            ]
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:21-08:22",
            "transcript": "We got to bring this down to three bullets.",
            "speaking duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:21",
            "end_time": "58:22",
            "annotations": [
                {
                    "propose decision": "Maryellen is suggesting a concrete choice for the group to summarize the discussion into three main points."
                }
            ]
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:22-09:11",
            "transcript": "Uh, sure, maybe one comment that just to follow up to what you what was just discussed, which may be interesting is I totally agree with you that, you know, kind of the future lies in this hybrid approach where statistical learning or purely data driven learning will be interfaced with model based uh principles and domain knowledge. Now the question is to get us there, obviously, you know, one cannot expect that we can just take an algorithm developed to classify dogs and cats and that will work. So and also we cannot expect that the computer scientist will learn chemistry and biology and will actually develop this specialized system.",
            "speaking duration": 49,
            "nods_others": 0,
            "smile_self": 10.2,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:22",
            "end_time": "59:11",
            "annotations": [
                {
                    "express agreement": "Paris agrees with Maryellen's point about the future lying in a hybrid approach of statistical and model-based learning, building on the discussion about integrating domain knowledge into AI pipelines."
                },
                {
                    "expand on existing idea": "Paris expands on the idea of a hybrid approach by stating that algorithms for general classification tasks cannot be directly applied to specialized domains like medical imaging, and that computer scientists cannot be expected to master all the necessary domain knowledge."
                }
            ]
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:11-09:23",
            "transcript": "So the only question is who do we train and how do we train them to work in this interface and contribute the tools that we need in the future.",
            "speaking duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:11",
            "end_time": "59:23",
            "annotations": {
                "propose decision": {
                    "Explanation": "This utterance proposes a concrete choice for the group to consider: who should be trained and how to train them to work at the interface of data-driven and model-based approaches, which is a decision about future training strategies."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "09:23-09:26",
            "transcript": "So you're saying the tools, the AI tools are not good enough?",
            "speaking duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:23",
            "end_time": "59:26",
            "annotations": {
                "ask clarifying question": "Maryellen is asking Paris to confirm if he means that the current AI tools are inadequate, following his statement about the need for a hybrid approach and specialized systems."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:26-10:00",
            "transcript": "Well, I'm saying that that the way things have been working is we borrow a system that is successful in classifying dogs and cats and now we're trying to use it to segment cancer cells. And maybe that works to some extent, but if we want to sort of develop more specialized systems that bring in this domain knowledge and you know, um are tailored or more specialized to a given task, who is going to do this and who has the expertise to do this and how do we train people to actually have that expertise to to do that.",
            "speaking duration": 34,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:26",
            "end_time": "60:00",
            "annotations": [
                {
                    "offer constructive criticism": "Paris critiques the current approach of borrowing systems successful in other domains (like classifying dogs and cats) and applying them to segmenting cancer cells, suggesting a need for more specialized systems tailored to specific tasks."
                },
                {
                    "present new idea": "Paris presents the idea of developing more specialized AI systems that incorporate domain knowledge and are tailored to specific tasks, moving beyond simply borrowing systems from other fields."
                },
                {
                    "ask clarifying question": "Paris asks who will develop these specialized systems, who has the expertise, and how will people be trained to acquire the necessary expertise, seeking clarity on the path forward for developing more domain-specific AI tools."
                }
            ]
        }
    ]
}