{
    "all_speakers": [
        "Richard Wiener",
        "Girgis Obaid",
        "Katy Keenan",
        "Alexandra Walsh",
        "Paris Perdikaris",
        "Maryellen Giger UChicago",
        "Shannon Quinn",
        "Ulugbek Kamilov",
        "Maryellen Giger",
        "Shiva Abbaszadeh",
        "Lu Wei",
        "Lu Wei",
        "Sandra Laney",
        "Carolyn Bayer",
        "Jim Mitchell",
        "Gergis Obaid"
    ],
    "total_speaking_length": 3172,
    "all_data": [
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:07-00:17",
            "transcript": "Uh for the person who just joined, uh we're taking a minute to uh go through the topics and jot down a few ideas for discussion on our own.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:07",
            "end_time": "00:17",
            "annotations": {
                "process management": "The utterance manages the meeting flow by explaining what the group is currently doing to someone who just joined."
            }
        },
        {
            "speaker": "Sandra Laney",
            "timestamp": "00:17-00:34",
            "transcript": "Okay, that gives me a great opportunity to just say that I'm here as a butterfly on the wall as an observer. I'm from the a foundation and um I will actually be jumping off so no offense to anybody, but I have to jump off at at the top of the hour. Thanks.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 18,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:17",
            "end_time": "00:34",
            "annotations": {
                "None": "No relevant code perfectly applies to this utterance as it primarily serves as a self-introduction and does not explicitly fit into any of the provided categories."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:34-00:36",
            "transcript": "Okay, great.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:34",
            "end_time": "00:36",
            "annotations": {
                "None": "The utterance is a brief acknowledgment without adding new content or explicitly fitting into other defined categories."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:36-01:11",
            "transcript": "So I think that's about a minute. So hopefully you'll be able to jot some notes down and the next thing we want to do is do a brief introduction. For example, I will give you mine. I'm Mary Ellen Giger, I'm at the University of Chicago. My research is in biomedical engineering and I do this for medical reasons to develop new diagnostic but also in biology with cellular data to help um facilitate discoveries. Carolyn, can you introduce yourself? You got 30 seconds.",
            "speaking_duration": 35,
            "nods_others": 0,
            "smile_self": 11,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:36",
            "end_time": "01:11",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by transitioning to the next activity.",
                "signal expertise": "The speaker is explicitly stating her own expertise and background.",
                "encourage participation": "The speaker is inviting another group member to contribute their information."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "01:12-01:29",
            "transcript": "Yeah, I'm Carolyn Bayer. Um my research is in photoacoustic imaging. Um I'm at Tulane University. Um much of our work is focused on imaging the placenta for pregnancy and development. Um but nice meeting everyone.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:12",
            "end_time": "01:29",
            "annotations": {
                "signal expertise": "The speaker explicitly states their research area and affiliation, which can be seen as signaling their expertise.",
                "develop idea": "The speaker is providing information about their research, which can be seen as developing their idea or introducing their area of expertise."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:00-00:16",
            "transcript": "Washington University in St. Louis. My area is computational imaging, but I focus on biomedical imaging. A lot of the things I do focuses on image reconstruction, restoration and sometimes data acquisition, but not hardware, just software.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 7,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:29",
            "end_time": "01:45",
            "annotations": {
                "signal expertise": "The speaker explicitly states his area of expertise and focus within computational imaging, indicating his qualifications."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:16-00:17",
            "transcript": "Okay, thank you, Katie.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:45",
            "end_time": "01:46",
            "annotations": {
                "acknowledge contribution": "verbally recognizes another group member's input, but not agreeing or expanding."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "00:21-00:53",
            "transcript": "Hi, I'm at the National Institute of Standards and Technology. NIST's first role in imaging was around for MRI and validating results across centers. So we try to use quantitative techniques. We don't always get the same answer when we try them places. And now we're expanding into more validation of some of these techniques and also exploring what's possible at lower magnetic field strengths.",
            "speaking_duration": 32,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:50",
            "end_time": "02:22",
            "annotations": {
                "signal expertise": "The speaker explicitly states their role and expertise, particularly in the context of MRI and validation of results across centers.",
                "identify gap": "The speaker mentions a challenge they face ('We don't always get the same answer when we try them places'), which implies a gap in their current capabilities."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:53-00:57",
            "transcript": "Thank you and Shiva, I'm going to cross my Hollywood squares here.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:22",
            "end_time": "02:26",
            "annotations": {
                "express humor": "The speaker is making a joke about her situation, comparing it to a game show.",
                "identify gap": "The speaker implies a lack of knowledge or comfort with the technical aspects of the discussion."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "00:58-01:04",
            "transcript": "Hi, this is Shiva. I'm from University of California, Santa Cruz. So I do work on instrumentation for positron emission tomography and x-ray imaging.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:27",
            "end_time": "02:33",
            "annotations": {
                "signal expertise": "The speaker explicitly states their own expertise and qualifications related to the task by mentioning their work on instrumentation for positron emission tomography and x-ray imaging.",
                "None": "No other relevant code applies to this utterance as it primarily focuses on signaling expertise without adding new ideas, asking questions, or engaging in discussions."
            }
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "01:04-01:20",
            "transcript": "And then I'm really interested in like improving sensitivity and then quantitative accuracy of these imaging modalities.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:33",
            "end_time": "02:49",
            "annotations": {
                "None": "No relevant code strongly applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:20-01:24",
            "transcript": "Thank you, Shayna.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:49",
            "end_time": "02:53",
            "annotations": {
                "acknowledge contribution": "verbally recognizes another group member's input, but not agreeing or expanding"
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:28-01:30",
            "transcript": "You referring to me? I'm Shannon.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:57",
            "end_time": "02:59",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:30-01:31",
            "transcript": "Shannon.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:59",
            "end_time": "03:00",
            "annotations": {
                "None": "No relevant code applies to this utterance as it is a simple name correction without additional content."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:31-01:31",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:00",
            "end_time": "03:00",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:31-01:34",
            "transcript": "I got a new floor. I'm Shannon.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 66,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:00",
            "end_time": "03:03",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:35-01:57",
            "transcript": "I'm Shannon Quinn, I'm an assistant professor in computer science and cell bio at University of Georgia. I work in biomedical imaging and computational modeling of cellular and subcellular systems. I develop new artificial intelligence techniques for a unified representation of spatial and temporal signals and I work in the construction of open source software for domain scientists.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:04",
            "end_time": "03:26",
            "annotations": {
                "signal expertise": "The speaker explicitly states her own expertise or qualifications related to the task, mentioning her position, affiliation, and areas of work."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:58-02:00",
            "transcript": "Gergis.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:27",
            "end_time": "03:29",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Gergis Obaid",
            "timestamp": "02:01-02:25",
            "transcript": "Hi yes, so I'm Gergis Obaid. I'm assistant professor at University of Texas at Dallas. Been here about a year. I work predominantly on molecular targeted nanoparticles for photodynamic cancer therapy.",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:30",
            "end_time": "03:54",
            "annotations": {
                "signal expertise": "The speaker explicitly states his own expertise and qualifications related to his work in molecular targeted nanoparticles for photodynamic cancer therapy."
            }
        },
        {
            "speaker": "Gergis Obaid",
            "timestamp": "02:25-02:25",
            "transcript": "Thank you, Alex.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:54",
            "end_time": "03:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:25-02:29",
            "transcript": "Thank you, Alex.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:54",
            "end_time": "03:58",
            "annotations": {
                "acknowledge contribution": "The speaker verbally acknowledges another group member's input or presence.",
                "supportive response": "The utterance expresses a positive or appreciative tone towards the other group member."
            }
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "02:29-02:52",
            "transcript": "Hi, I'm Alex. I'm at Texas A&M University and I do optical microscopy. Mostly looking at label free stuff, so molecules that are already in your cells like NADH and FAD to study cellular metabolism. And we do that for a variety of applications including drug response in cancer and studying laser tissue interactions.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 8,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:58",
            "end_time": "04:21",
            "annotations": {
                "signal expertise": "The speaker explicitly states their area of expertise, including their work on optical microscopy, studying cellular metabolism, and applications in drug response in cancer and laser tissue interactions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:52-02:53",
            "transcript": "Thank you and Lou.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:21",
            "end_time": "04:22",
            "annotations": {
                "acknowledge contribution": "The speaker is verbally recognizing another group member's input or presence."
            }
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "02:56-03:22",
            "transcript": "I am Lou Wei. I'm assistant professor of chemistry here at Caltech. We perform optical imaging, particular vibrational microscopy on biological cells and we're interested in small molecule imaging mostly understanding the metabolic activities.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:25",
            "end_time": "04:51",
            "annotations": {
                "signal expertise": "Lu Wei explicitly states his position and area of work, signaling his expertise in the field."
            }
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "03:22-03:22",
            "transcript": "Thank you and Paris.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:51",
            "end_time": "04:51",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:23-03:24",
            "transcript": "Thank you and Paris.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:52",
            "end_time": "04:53",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "03:25-03:40",
            "transcript": "Hello, I'm at the University of Pennsylvania. My expertise is in computational science and machine learning. And basically I'm developing computational methods for modeling and simulation of biological systems with a focus on cardiovascular flows.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:54",
            "end_time": "05:09",
            "annotations": {
                "signal expertise": "This code applies because Paris explicitly states his own expertise in computational science and machine learning."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:40-03:51",
            "transcript": "Thank you and we have five visitors which I was told hop in and out. Um if you would mind to say something you can or else we're going to get right to the purpose.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:09",
            "end_time": "05:20",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by indicating that they will proceed with the agenda if the visitors do not contribute.",
                "encourage participation": "The speaker is inviting the visitors to participate by offering them the opportunity to say something."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:51-03:51",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:20",
            "end_time": "05:20",
            "annotations": {
                "process management": "Managing meeting flow"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:51-04:06",
            "transcript": "We'll get right to the purpose. So, we have um oh next order is we need a recorder and who would also then present in three minutes for the group.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:20",
            "end_time": "05:35",
            "annotations": {
                "ask question": "The utterance contains a question about who would present in three minutes.",
                "process management": "Maryellen Giger is transitioning the meeting to its next order of business.",
                "assign task": "The utterance assigns tasks of recording and presenting to group members."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:06-04:22",
            "transcript": "Um, I could do it randomly or we can have a volunteer. Um you you should be able to get to the Google Drive and um this is great training when you're facilitating in your senior career cycle.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:35",
            "end_time": "05:51",
            "annotations": {
                "process management": "Maryellen is managing the meeting process by suggesting methods for selecting someone to record or present.",
                "encourage participation": "By mentioning that this is great training for facilitating in a senior career cycle, she encourages participation."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:26-04:35",
            "transcript": "Okay, should I close my eyes and pick on the screen and I end up on Shannon. Congratulations.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 55,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:55",
            "end_time": "06:04",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by suggesting a method for randomly selecting a participant.",
                "assign task": "The speaker assigns a task or role to a participant, Shannon, through a random selection process."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:37-04:37",
            "transcript": "So we're looking at",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:06",
            "end_time": "06:06",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:37-04:40",
            "transcript": "So we're looking at",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:06",
            "end_time": "06:09",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by transitioning to the next item or purpose of the meeting.",
                "summarize conversation": "The utterance could be seen as an attempt to transition or summarize previous discussions before moving forward, though it's more about transitioning."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:40-04:40",
            "transcript": "the PowerPoint deck?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:09",
            "end_time": "06:09",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification about the PowerPoint deck."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:40-04:47",
            "transcript": "Yes, so if you go to the and it's the if you you continue to around slide 20 or so you should you should find it should say um",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:09",
            "end_time": "06:16",
            "annotations": {
                "process management": "Maryellen Giger is managing the meeting flow by instructing Shannon on how to proceed with the presentation."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:54-04:55",
            "transcript": "It's 17 right now.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:23",
            "end_time": "06:24",
            "annotations": {
                "process management": "This code applies because Shannon Quinn's statement helps manage the meeting flow by providing the current slide number, aiding in navigation as instructed by Maryellen Giger."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:55-05:01",
            "transcript": "Um, no probably a little past 20. 23.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:24",
            "end_time": "06:30",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by directing the presenter to a specific part of the presentation."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:02-05:03",
            "transcript": "Ah, yes.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:31",
            "end_time": "06:32",
            "annotations": {
                "supportive response": "Expressing agreement or confirmation with the previous statement.",
                "acknowledge contribution": "Verbally recognizing a prior statement or input from another group member."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:03-05:06",
            "transcript": "Okay. 20, 24 in fact. So yeah.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:32",
            "end_time": "06:35",
            "annotations": {
                "acknowledge contribution": "Shannon Quinn acknowledges Maryellen Giger's instruction and shows understanding of the task.",
                "supportive response": "Shannon Quinn expresses agreement and confirmation of the task or instruction given."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:07-05:10",
            "transcript": "Is it supposed to be a separate recorder and um reporter?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:36",
            "end_time": "06:39",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification on the roles of recorder and reporter.",
                "process management": "The speaker is managing or inquiring about the meeting's process and organizational structure."
            }
        },
        {
            "speaker": "Sandra Laney",
            "timestamp": "05:11-05:14",
            "transcript": "So is one taking the notes and one reporting?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:40",
            "end_time": "06:43",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification on the roles of note-taking and reporting within the meeting."
            }
        },
        {
            "speaker": "Richard Wiener",
            "timestamp": "05:15-05:27",
            "transcript": "One one person can do it and one person can do both, I think. Yeah, and you can take the notes, you don't have to put the notes into the PowerPoint yet, you can take those, share it with people, they can add and then can condense them into the PowerPoint so that there's one slide.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:44",
            "end_time": "06:56",
            "annotations": {
                "process management": "The speaker is suggesting a method for managing meeting tasks, specifically note-taking and reporting.",
                "assign task": "The speaker is assigning or suggesting how tasks (note-taking and reporting) can be handled, which involves assigning responsibilities."
            }
        },
        {
            "speaker": "Richard Wiener",
            "timestamp": "05:27-05:27",
            "transcript": "Sounds good.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:56",
            "end_time": "06:56",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with a previous suggestion about note-taking and reporting."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:27-05:33",
            "transcript": "Okay, are you are you okay with that, Shannon?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:56",
            "end_time": "07:02",
            "annotations": {
                "ask question": "The speaker is explicitly asking for Shannon's confirmation or agreement with the proposed arrangement.",
                "encourage participation": "By inquiring about Shannon's comfort level, the speaker is also inviting her to participate in the discussion."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:33-05:33",
            "transcript": "Yep.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:02",
            "end_time": "07:02",
            "annotations": {
                "Supportive Response": "The utterance 'Yep.' expresses agreement with a previous statement, fitting the definition of a supportive response."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:33-05:36",
            "transcript": "Okay, great, thank you.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:02",
            "end_time": "07:05",
            "annotations": {
                "None": "No relevant code applies to this utterance as it simply acknowledges the previous agreement and thanks the person."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-06:15",
            "transcript": "So now let's go in the beginning of the session, you all had the one minute to kind of collect your thoughts on the topics and we will start with the three bullets that are listed, but if any of you think that there's a major other bullet that you think would be useful to look into, we can go there too. One thing I drew from listening to all your introductions, we all do computational science.",
            "speaking_duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:05",
            "end_time": "07:44",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by suggesting they start with listed topics and inviting additional topics.",
                "summarize conversation": "The speaker summarizes an observation from the introductions, noting that all participants do computational science."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:15-06:19",
            "transcript": "Um, uh and it seems that some are at more of a macro scale, some are at micro scale.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:44",
            "end_time": "07:48",
            "annotations": {
                "summarize conversation": "Maryellen Giger is making an observation based on the previous introductions, summarizing the scale at which group members work."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:19-06:24",
            "transcript": "Um, and probably some work in 2D and some in 3D. But we all do computational science of images at one point.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:48",
            "end_time": "07:53",
            "annotations": {
                "summarize conversation": "The speaker is summarizing a common theme among the participants' work areas, noting they all deal with computational science of images."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:24-06:36",
            "transcript": "So I I think we're um all in this together. So let's start with the first one, um 3D imaging can yield massive data sets too large to quantitate and fully scrutinize manually.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:53",
            "end_time": "08:05",
            "annotations": {
                "process management": "The utterance manages the meeting flow by suggesting they move on to discuss a specific topic.",
                "clarify goal": "The utterance defines what will be discussed next, implying a goal of addressing the issue of 3D imaging data sets."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:36-06:41",
            "transcript": "What data are required to effectively train AI ML algorithms to assess these data sets.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:05",
            "end_time": "08:10",
            "annotations": {
                "ask question": "The utterance is a direct question seeking information on the data required to effectively train AI and ML algorithms, fitting the definition of 'ask question'."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:41-06:45",
            "transcript": "So how many of you do work with massive data sets?",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:10",
            "end_time": "08:14",
            "annotations": {
                "ask question": "The speaker is requesting information about how many group members work with massive data sets.",
                "encourage participation": "The speaker is also inviting group members to contribute their experiences."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:46-06:49",
            "transcript": "I know I do. Big, yeah.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:15",
            "end_time": "08:18",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with the previous statement, indicating she works with massive data sets."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:50-06:50",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:19",
            "end_time": "08:19",
            "annotations": {
                "None": "No relevant code applies to this utterance as it is a minimal response with no specific content that matches the provided codes."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:58-07:00",
            "transcript": "Um, I have well.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:27",
            "end_time": "08:29",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:00-01:05",
            "transcript": "uh data or model adaptation to different data, right? So, uh what do I mean by this? So you train your data uh on one type of data set, say, you know, you do MRI scan, uh it has certain artifact patterns, you train the model on that. Now you apply to something else and we know that it doesn't work very well if, you know, you applied it to a configuration doesn't work. Now there are a bunch of ideas out there, uh you know, in in the computer vision community in the machine learning community where people try to bridge those things, but it's still not we don't yet have, you know, killer technology that allows us, you know, we don't understand both the limits of how we can adapt the models to different applications. At the same time, you know, what's the best way to do the adaptation of the models that we already pre-trained to a new application, right? So deep learning models are not traditional software in the sense that I can go and just edit it. It's all in the weights of the training thing. So how do we reuse, adapt uh those models.",
            "speaking_duration": 65,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "11:29",
            "end_time": "12:34",
            "annotations": {
                "develop idea": "The speaker elaborates on the challenges and potential approaches to adapting pre-trained models to new applications.",
                "ask question": "The speaker seeks input from the group on how to reuse and adapt pre-trained models.",
                "identify gap": "The speaker highlights the current limitation in technology for adapting models to different applications."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:06-01:22",
            "transcript": "So how do we use metrology to appropriately measure how we're doing in our development as well as in the end product so that it is generalizable? I think that's what you were getting at as well as say unbiased and fair.",
            "speaking_duration": 16,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:35",
            "end_time": "12:51",
            "annotations": {
                "ask question": "The speaker is explicitly asking for information on how to use metrology for measurement, which directly aligns with the definition of asking a question.",
                "develop idea": "The speaker is also developing ideas previously discussed by highlighting the need for generalizable, unbiased, and fair outcomes in measurement."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:23-01:23",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:52",
            "end_time": "12:52",
            "annotations": {
                "Supportive Response": "The utterance 'Yeah.' expresses agreement or validation with the previous statement without adding new content.",
                "None": "Not applicable as Supportive Response applies"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:24-01:24",
            "transcript": "Are those major topics that",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:53",
            "end_time": "12:53",
            "annotations": {
                "ask question": "The speaker is requesting clarification or confirmation on whether certain topics are major topics that need to be addressed."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:32-01:52",
            "transcript": "I think we should add kind of explainability to it too because in order to like uh focus more about the second part that what data are required to effectively train as we try to model and then create kind of some explanation to take away from that black box of how the algorithm is working.",
            "speaking_duration": 20,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:01",
            "end_time": "13:21",
            "annotations": {
                "propose new idea": "The speaker introduces the concept of 'explainability' as a new aspect to consider in their discussion.",
                "develop idea": "The speaker expands on the existing idea of determining what data are required to effectively train AI/ML algorithms by suggesting the need to understand the algorithm's workings."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:52-02:22",
            "transcript": "And then make it more explainable is going to help us to see what are the different information that the data is leading to give us our accurate output and then as we learn and as we try to make it more explainable, that's become a tools for us to just try to focus in the information that we need.",
            "speaking_duration": 30,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:21",
            "end_time": "13:51",
            "annotations": {
                "develop idea": "The speaker is expanding on the idea of using explainability to improve the models and understand their outputs better.",
                "propose new idea": "The speaker suggests making algorithms more explainable as a way to understand and improve AI/ML models.",
                "offer feedback": "The speaker provides a suggestion for how to improve the models by making them more explainable."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:22-02:26",
            "transcript": "Okay, I I agree explainability and then to the end user interpretability.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:51",
            "end_time": "13:55",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by agreeing with and adding to the concept of explainability.",
                "supportive response": "The speaker is expressing agreement with the previous suggestion about explainability.",
                "offer feedback": "The speaker is providing feedback by adding the concept of 'to the end user interpretability,' which builds upon Shiva's suggestion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:27-02:42",
            "transcript": "So, um Shannon, would you want to share your screen and we could all pull it over so we can still see each other, but that way we can give you is that useful or not? I don't know what notes you're taking, that's why.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:56",
            "end_time": "14:11",
            "annotations": {
                "process management": "Maryellen Giger is managing the meeting flow by suggesting Shannon share her screen for group viewing and feedback."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:43-02:50",
            "transcript": "I'm I'm unfortunately on Zoom on an iPad and taking notes on a desktop with the monitors right behind it.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:12",
            "end_time": "14:19",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:50-02:52",
            "transcript": "Ah.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:19",
            "end_time": "14:21",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:54-03:03",
            "transcript": "So, um I could turn it into a Google Doc that I can then share a link to with everybody in here if that would be preferable.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:23",
            "end_time": "14:32",
            "annotations": {
                "propose new idea": "Shannon introduces a new method for sharing notes by suggesting to turn them into a Google Doc.",
                "ask question": "Shannon asks for the group's preference on the method of sharing notes.",
                "process management": "Shannon's suggestion is about managing the process of how notes are shared with the group."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:03-03:22",
            "transcript": "Because I like seeing everyone while we're having a discussion and I know I can kind of make the slide part very small and still see you all. Um but I think we need that visual feedback.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:32",
            "end_time": "14:51",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by expressing a preference for how to visually handle the discussion.",
                "supportive response": "The speaker is expressing a positive evaluation of the visual aspect of the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:22-03:24",
            "transcript": "So do you do you all want to do a uh Google Drive?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:51",
            "end_time": "14:53",
            "annotations": {
                "process management": "The speaker is suggesting a method (using Google Drive) for organizing group activities and collaboration."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:24-03:26",
            "transcript": "Or do you want someone to",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:53",
            "end_time": "14:55",
            "annotations": {
                "process management": "The speaker is seeking input on how to proceed with organizing note-taking or documentation, which is a part of managing the meeting process."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:26-03:30",
            "transcript": "I'm comfortable with the Google Drive, uh Google Doc, Google Doc.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:55",
            "end_time": "14:59",
            "annotations": {
                "Supportive response": "Beck Kamilov is expressing agreement and support for using Google Drive or Google Doc.",
                "Process management": "Beck Kamilov is contributing to the management of the meeting process by agreeing on a method for collaboration."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:30-03:45",
            "transcript": "Right, Google Doc, I'm sorry. So if you send that link in the chat, we can just click on it and then it's as if we're viewing the screen. That would be useful because",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:59",
            "end_time": "15:14",
            "annotations": {
                "Develop idea": "The speaker is elaborating on how to use a Google Doc for collaboration.",
                "Process management": "The speaker is managing the meeting process by suggesting a method for sharing and viewing documents."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:45-03:45",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:14",
            "end_time": "15:14",
            "annotations": {
                "acknowledge contribution": "Beck Kamilov is verbally recognizing a prior statement without adding new content."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:45-03:46",
            "transcript": "Um",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:14",
            "end_time": "15:15",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:46-04:24",
            "transcript": "Does anyone have any other thoughts on the first bullet which is in a way kind of our discussion blended into the third bullet? You know, we talked about um what kind of errors, you know, if we think about errors that are acceptable, those are quantitated by the metrology of the system. how are you going to measure the performance? How are you going to measure the variation of your system? How will you measure how unbiased or general your system is?",
            "speaking_duration": 38,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:15",
            "end_time": "15:53",
            "annotations": {
                "ask question": "The speaker is explicitly asking for thoughts or insights from the group, requesting information on additional perspectives.",
                "develop idea": "The speaker is expanding on existing ideas by probing deeper into aspects like errors, performance measurement, system variation, and unbiased generality."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "04:25-04:56",
            "transcript": "Yeah, I think I feel like since we're often imaging biological processes and looking at clinical images, um really knowing what ground truth is, um can be very challenging. Um it's not, you know, often the result might be correlated to pathology for example, if you're looking at cancer, but you don't really know that that pathology is accurate either.",
            "speaking_duration": 31,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "15:54",
            "end_time": "16:25",
            "annotations": {
                "identify gap": "The speaker is explicitly recognizing a challenge or gap in their work, which is not knowing what 'ground truth' is when imaging biological processes and looking at clinical images."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "04:57-05:07",
            "transcript": "Um do you think Carolyn that it's like having uh the expert lead on it or are you um like what would make it more true?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "16:26",
            "end_time": "16:36",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification from another team member on a prior statement or idea proposed by that group member."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "05:08-05:15",
            "transcript": "Um probably better images, right? Like since we're we're all looking at it with the image lens, right?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "16:37",
            "end_time": "16:44",
            "annotations": {
                "develop idea": "The speaker is suggesting a potential improvement (better images) to the discussion on imaging challenges.",
                "ask question": "The utterance ends with a question seeking agreement or confirmation from others."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:19-05:25",
            "transcript": "Yeah, when I think of imaging, I think of both acquisition and interpretation.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "16:48",
            "end_time": "16:54",
            "annotations": {
                "develop idea": "The speaker is expanding on the concept of imaging by highlighting two key aspects: acquisition and interpretation."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:25-06:16",
            "transcript": "I think we have to go back to the application and what is the task? And I think the truth um I'm going to throw this out. So a lot of us probably do segmentation, right? And then you ask, well how do you evaluate it? Well, maybe you use a dice coefficient or something like that. But it there's also the more broader picture saying, well, my segment works depending on my final truth, which might be based on pathology.",
            "speaking_duration": 51,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "16:54",
            "end_time": "17:45",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by discussing the evaluation of image segments and the concept of 'truth' in pathology.",
                "ask question": "The speaker indirectly poses questions to frame the discussion on evaluating image segments."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:16-06:23",
            "transcript": "Um, just what do you think?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "17:45",
            "end_time": "17:52",
            "annotations": {
                "encourage participation": "The speaker is inviting others to contribute their thoughts or opinions.",
                "ask question": "The speaker is requesting information or thoughts from other group members."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "06:24-07:38",
            "transcript": "Well, I kind of I kind of agree with Carolyn's point about the uh ground truth, like what really is the ground truth? Um the way I see it is multiplexing the uh final yes no answer. So the input, let's say for example if it was histology, getting the manual input of the pathologist as well as some maybe molecular markers of the histological sections could be, you know, proteomics in addition to some genomic data, multiplexing the ground truth, well, getting working closer towards a ground truth by multiplexing the outputs at the end in order to train the intermediate. In my opinion is the best because I don't really know if there really is going to be a ground truth at that point because everything to a certain extent is either uh subjective to the observer if there's a pathologist or to uh experimental bias or fluctuations if you're going to get false positives or false negatives in the in the markers or the genomics themselves. So yeah, I'm I'm a little bit I'm kind of leaning more towards having building up the information at the at the end first in order to then bridge that gap because if you don't have that then it doesn't really make sense.",
            "speaking_duration": 74,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:53",
            "end_time": "19:07",
            "annotations": {
                "propose new idea": "Girgis Obaid introduces a specific approach (multiplexing the final yes/no answer by incorporating multiple data types) to tackle the issue of ground truth in training AI/ML algorithms.",
                "develop idea": "He elaborates on his suggestion by explaining how this approach could work and its potential benefits.",
                "offer feedback": "Girgis Obaid provides a specific suggestion (multiplexing data types) as a way to address the challenge of ground truth."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:38",
            "transcript": "Sounds good.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:07",
            "end_time": "19:07",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or validation of a previous contribution without adding new content."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:39-07:40",
            "transcript": "Um",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:08",
            "end_time": "19:09",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:41-08:21",
            "transcript": "I maybe I want to also bring up one thing. There is an interesting thing, the concept, right? Um in the so if you have errors in your ground truth and those errors are not systematic, meaning if you average them out across the whole data set, right? And then they average out to be a very small quantity, you can in principle train still with this form of errors and your model will not learn. So there is an interesting technical question there, what kind of errors are tolerable in the training data.",
            "speaking_duration": 40,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:10",
            "end_time": "19:50",
            "annotations": {
                "develop idea": "The speaker expands on existing ideas about data quality and its impact on machine learning models.",
                "ask question": "The speaker seeks information on the tolerable level of errors in training data."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:21-08:21",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:50",
            "end_time": "19:50",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:22-08:55",
            "transcript": "Yeah, I think we need to train and test with messy data because that's what the real world is. And sometimes, you know, we can do initial development, it's we do initial development of a filter in continuous domain, um but then when we go to actual image domain is pixelated and quantized, it doesn't quite work, but it gets you maybe 80, 85% there. Um, you know, we start in the ideal world and then um make it work in the messy real world.",
            "speaking_duration": 33,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:51",
            "end_time": "20:24",
            "annotations": {
                "develop idea": "The speaker is expanding on an existing idea about dealing with real-world data by providing insights and suggestions on how to approach training and testing with messy data.",
                "offer feedback": "The speaker is providing a suggestion on how to handle the challenge of messy data, which can be seen as offering feedback on the approach to be taken."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "08:56-09:16",
            "transcript": "And by the way, anything like changes like this you just mentioned that pixelation changes. Those are the systematic things that you could in principle incorporate to this as non-trainable elements or adaptable elements of machine learning models.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:25",
            "end_time": "20:45",
            "annotations": {
                "develop idea": "The speaker is expanding on a previous discussion about handling changes in data, suggesting a way to incorporate systematic changes into machine learning models.",
                "offer feedback": "The speaker provides a specific suggestion for how to handle systematic changes, which can be seen as offering feedback on how to approach the problem."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "09:16-09:17",
            "transcript": "So",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:45",
            "end_time": "20:46",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:00-00:41",
            "transcript": "This is a major problem. I mean this problem and even uh it um the aspects about um the generalizability, um the bias that biases an AI is is really important. Um, what would you need to make this dream work? And I'm going to ask Lou. What what would take uh well maybe um you're more imaging than AI, right? Yeah, so I I well, you could take a pass if you want, but go ahead if you want to.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 15,
            "smile_other": 3,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:29",
            "end_time": "22:10",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by emphasizing the importance of generalizability and bias in AI.",
                "ask question": "The speaker asks for input on what would be needed to make the 'dream work', which is about addressing the issues of generalizability and bias in AI.",
                "encourage participation": "The speaker invites Lou to contribute his thoughts, offering him the option to pass or go ahead."
            }
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "00:41-02:45",
            "transcript": "Right, yeah, so I I'm more of imaging than AI. I'm here actually um trying to learn some um questions or or abilities for AI that could help us to interpretate uh imaging and do imaging segmentation. So um I'm new to the AI field. We're trying to adopting uh different networks for um um training and uh one part of the research in my lab is we do uh label free imaging um such that there's um a ton of uh images but not so much specific contrast. So we're trying to use an AI to allow us to uh do specific imaging. Um so I guess the question I have is uh there are a lot of different networks out there. Um well with with or specifically with very fine um um um differences. Um but there's not much of the benchmark um to allow us to compare um unless we're trying to use our own data to train it and then um to compare with of course different uh um um basically to adopt each of the techniques and compare it with our own data. Um before that there's really no way to know specifically what would be the best candidate for us. Um and also another thing um related to um I guess the uh um um validity of the interpretation is uh what kind of signal noise ratios do we need as both training set and also the prediction set and um is there any uh limitations on resolutions um that we should be aware of um before we do the um training. So so I guess I'm here more of to uh looking to the possibilities and asking questions then then providing some of the insights. Sorry about that.",
            "speaking_duration": 124,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 1,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:10",
            "end_time": "24:14",
            "annotations": {
                "ask question": "Lu Wei is asking questions about AI networks, benchmarks, signal-to-noise ratios, and resolution limitations.",
                "identify gap": "Lu Wei identifies a gap in their knowledge about AI and a need for benchmarks to compare different networks.",
                "clarify goal": "Lu Wei is seeking clarity on how to approach their problem with AI for image segmentation and interpretation."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "02:45-03:00",
            "transcript": "Well no, I think that's very useful. You're telling us what you want and some of us in it in AI research and development kind of have to um work to uh uh give that to you. We we need to understand the end user.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:14",
            "end_time": "24:29",
            "annotations": {
                "acknowledge contribution": "The speaker verbally recognizes Lu Wei's input, showing appreciation for the information provided.",
                "supportive response": "The utterance expresses a positive evaluation of Lu Wei's contribution, indicating that it is useful."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:00-03:43",
            "transcript": "Because you know, earlier we talked about this pipeline of the AI pipeline, we we talked about for example segmentation, do you measure it while you're segmenting it or you look at the end point and the end point depends on the end user. And even if um even if it's an autonomous AI system, there's an end user somewhere. Somewhere it's affecting it and I think uh this field is still very young because a lot of the work being done is very um very focused.",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:29",
            "end_time": "25:12",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas about AI pipelines, specifically discussing evaluation metrics and the role of the end user.",
                "summarize conversation": "The speaker refers back to previous discussions about the AI pipeline and segmentation.",
                "clarify goal": "The speaker is clarifying objectives related to evaluating AI system performance, emphasizing the importance of the end user."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:43-04:56",
            "transcript": "You know, you'll read the papers it was for this task with this database, maybe from different institutions, but it's just the the needle in a in a big haystack of all the other questions going on in medicine and biology. Um, but we can but many of the techniques, many of the metrology, the way to evaluate them, you know, how do you get around ground truth? Those I think there's um, I don't want to say a menu, but there is I think a short list and for me, um, though I have a lot of things that I would like in the world, I would like everyone to have access to this really clear short list of how how do I do all these things. Um, oh one of the things um I I don't want to forget before time goes by is we should look at bullet number two. And to me can can we extend our AI pipeline so it's very long, so it starts with acquisition, starts with the patient. In fact, someone thing by us is called closed loop imaging where this is that this is the what the patient needs, the patient gets it all the way to getting it and then doing the interpretation. To me that's you have to extend your AI to go through that entire pipeline.",
            "speaking_duration": 73,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "25:12",
            "end_time": "26:25",
            "annotations": {
                "identify gap": "Maryellen highlights the gap in current research, such as the lack of a clear list of techniques and metrology."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:56-04:56",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:25",
            "end_time": "26:25",
            "annotations": {
                "None": "No relevant code applies to this utterance in a meaningful way that adds substantial insight into the conversation."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "04:56-04:57",
            "transcript": "Yes, that makes me so happy.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:25",
            "end_time": "26:26",
            "annotations": {
                "supportive response": "The speaker is expressing a positive sentiment towards a previous idea, indicating agreement and support.",
                "acknowledge contribution": "The speaker is also acknowledging Maryellen Giger's contribution by expressing happiness with her idea."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:57-05:03",
            "transcript": "Oh, okay. Interesting. Okay, we have a happy group here. Good.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:26",
            "end_time": "26:32",
            "annotations": {
                "supportive response": "The utterance expresses a positive sentiment and agreement with the group's dynamics or previous discussions, aligning with the definition of a supportive response."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "05:03-05:50",
            "transcript": "Yeah, I'm very excited to read, you know, like papers and then there are different groups that now thinking about kind of uh reconstructing the image, you know, using AI directly. And then since I usually work on kind of limited angle problem, so then I really uh think about how AI can just like really give us more information and then how we can even to interpret data that they are low dose and then we get kind of the information of higher dose. So I think that's um regarding this part, the question number two, I I think it's a very exciting time in the field and I'm really happy to learn and then implement them in my like research.",
            "speaking_duration": 47,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:32",
            "end_time": "27:19",
            "annotations": {
                "develop idea": "The speaker elaborates on existing ideas by discussing how AI can be used in their area of research, specifically for limited angle problems and low-dose data.",
                "supportive response": "The speaker expresses enthusiasm and positive evaluation for the direction of the field and the potential of AI.",
                "identify gap": "The speaker implies a gap in current capabilities, particularly in handling low-dose data and limited angle problems."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:50-05:54",
            "transcript": "Great. So maybe optimizing along the pipeline individually and then the whole item.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:19",
            "end_time": "27:23",
            "annotations": {
                "develop idea": "The speaker is expanding on previous ideas about optimizing a pipeline.",
                "supportive response": "The utterance expresses a positive sentiment towards the discussion or previous ideas.",
                "offer feedback": "The speaker is providing a suggestion for how to proceed with optimizing the pipeline."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:54-06:05",
            "transcript": "Which includes acquisition and interpretation and then interpretation is by AI or human or AI aided human. But so patient um coming in for an imaging exam all the way to deciding the treatment.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:23",
            "end_time": "27:34",
            "annotations": {
                "develop idea": "The speaker is expanding on the idea of extending the AI pipeline to include acquisition, interpretation, and decision-making.",
                "clarify goal": "The speaker is defining and clarifying objectives by discussing the extension of the AI pipeline throughout the imaging process."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:05-06:17",
            "transcript": "We got to do all that together as opposed we got everyone doing little niches here and there. So um that would be good. So yes, back.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:34",
            "end_time": "27:46",
            "annotations": {
                "summarize conversation": "The speaker is summarizing her understanding of the discussion, emphasizing the need for a comprehensive and collaborative approach.",
                "supportive response": "The speaker is expressing support for the idea of working together rather than in isolated areas, indicating a positive stance towards collaboration."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:20-06:43",
            "transcript": "Uh I think one thing to think about in that context and you know, I'm very excited about that problem as well about, you know, the whole pipeline doing, but we need to think also about fragility of the system. Again, it comes back to generalization.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:49",
            "end_time": "28:12",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by mentioning the importance of considering the 'fragility of the system' and relating it back to 'generalization.'",
                "offer feedback": "The speaker is providing specific suggestions for consideration, which is about thinking about the fragility of the system and its generalization.",
                "supportive response": "The speaker is expressing agreement and validation for the discussed approach by showing excitement and suggesting further considerations."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:43-06:43",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:12",
            "end_time": "28:12",
            "annotations": {
                "supportive response": "The utterance 'Right.' is a brief expression of agreement with a previous statement, fitting the definition of a supportive response."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:44-07:39",
            "transcript": "There's a question around like um there's kind of a high barrier to entry as far as solving those sorts of problems because you want to have access to all the data types in order to solve that sort of problem. And uh like when you operate at a single institution, you're limited to the vendor system that you have access to. Or uh you know, in medical imaging when the vendors develop something, they're pulling it off of all of their own image sets and then it's not generalizable to the other vendors. So when I was, you know, thinking about the first bullet point, it was like uh like what data is required? I mean, you kind of want all the things. Uh and so I think that's a big challenge is how to and then how do we get it to people? Um there's a lot of access issues.",
            "speaking_duration": 55,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:13",
            "end_time": "29:08",
            "annotations": {
                "identify gap": "Katy highlights the gap in access to diverse data sets and the limitations of working within a single institution or vendor system.",
                "ask question": "Katy implicitly asks about the requirements for training AI/ML algorithms and how to overcome the challenges of limited data access.",
                "develop idea": "Katy expands on the challenges and implications of limited data access for AI/ML algorithm training."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:39-07:41",
            "transcript": "So we want all the data.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:08",
            "end_time": "29:10",
            "annotations": {
                "summarize conversation": "The speaker is summarizing a previously discussed point about the need for comprehensive data.",
                "clarify goal": "The utterance implicitly clarifies a goal related to the necessity of having all the data for their research."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:41-07:54",
            "transcript": "That's one of the they asked us what do we want? We want all the data and we you you there technically we could do a lot. We are limited by data and culture I would say. The giving of data, the sharing of data even.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:10",
            "end_time": "29:23",
            "annotations": {
                "identify gap": "The speaker explicitly mentions being limited by data and the culture of data sharing, indicating a gap in their current capability.",
                "clarify goal": "The speaker implies a goal of wanting all the data to advance their work, indicating a desire to overcome current limitations."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:54-07:54",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:23",
            "end_time": "29:23",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or acknowledgment of a previous statement."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:54-08:04",
            "transcript": "But if we had a massive method or so we we can do that. I saw Paris shaking his head. I think big mistake. So what are you thinking about?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:23",
            "end_time": "29:33",
            "annotations": {
                "critical response": "The speaker is questioning or challenging an idea, indicating a potential mistake.",
                "ask question": "The speaker is seeking thoughts or opinions from others, specifically Paris."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "08:04-08:04",
            "transcript": "Oh.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:33",
            "end_time": "29:33",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:09-09:01",
            "transcript": "Uh it's a great discussion so far. I mean I'm a little bit on the less optimistic side on the front that you know, data and AI by alone will address all those issues. And perhaps one thing to think about is how we integrate domain knowledge into this pipeline in a way that is informative and gives us the right sort of prior information we need.",
            "speaking_duration": 52,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:38",
            "end_time": "30:30",
            "annotations": {
                "critical response": "The speaker expresses a critical view of relying solely on data and AI.",
                "offer feedback": "The speaker provides feedback on how to improve the approach by integrating domain knowledge.",
                "develop idea": "The speaker expands on the discussion by suggesting a new aspect to consider (integrating domain knowledge)."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:01-09:01",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:30",
            "end_time": "30:30",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "09:02-09:14",
            "transcript": "Yes, I to me domain knowledge, domain expertise, what you know, all of us here if we're in imaging and AI in biology or medicine, we are working in an interdisciplinary field.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:31",
            "end_time": "30:43",
            "annotations": {
                "Supportive response": "The utterance expresses agreement and validation for the discussion on domain knowledge and expertise.",
                "Signal expertise": "The speaker implicitly signals her expertise in the field by stating her perspective on domain knowledge."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:20",
            "transcript": "have many you all are smart, you all have great AI technologies, but I think we're looking at the issues of how do we bring it all together? Um, um, to me, that's the challenge. Alex, I haven't put you on the spot. I'm sorry, you're right in the middle of my screen and I keep going.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:29",
            "end_time": "31:49",
            "annotations": {
                "process management": "The speaker is managing the discussion by highlighting a key challenge and attempting to keep the conversation on track.",
                "encourage participation": "The speaker is encouraging Alex's participation by directly involving him in the conversation."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:21-00:22",
            "transcript": "Zoom has a question, no, Jim?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:50",
            "end_time": "31:51",
            "annotations": {
                "ask question": "The speaker is inquiring if Jim has a question, requesting information or clarification.",
                "encourage participation": "By asking Jim directly if he has a question, the speaker is inviting him to contribute to the discussion."
            }
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "00:23-00:51",
            "transcript": "Yeah, I have I have a question quickly. I know in other domains, um, you know, I know a lot about the Tesla autopilot work. The crowd sourcing of images and and so on has helped them a lot to improve that. Is there crowd sourcing going on here and and and where do those images end up residing that everybody could have access to the same large set of images?",
            "speaking_duration": 28,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:52",
            "end_time": "32:20",
            "annotations": {
                "ask question": "Jim Mitchell requests information about crowd sourcing of images and where they reside, seeking clarification or expertise from the group."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:51-01:47",
            "transcript": "Uh, there is crowd sourcing in radiology. They do it at radiology meetings and also across the web where they they recruit some one project had over 180 radiologists who did multiple annotations on uh chest images. So they can do it. So and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to",
            "speaking_duration": 56,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:20",
            "end_time": "33:16",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges the contribution of crowd sourcing in radiology.",
                "supportive response": "The speaker provides a supportive response by sharing an example and expressing potential.",
                "encourage participation": "The speaker encourages participation by asking about experiences in cellular images."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:47-02:02",
            "transcript": "so and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to people sit and circle cells. crazy just to create data and that gets back to bullet one. How many cells do you have to circle to have enough data to algorithm. Um, but yes, the crowd sourcing it does it does exist, but it's it's not on a massive um scale. Good point, Jim. And sorry I didn't see your hand ready. So I'm used to this, not the stationary one that they have on. Alex.",
            "speaking_duration": 75,
            "nods_others": 0,
            "smile_self": 30.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:16",
            "end_time": "33:31",
            "annotations": {
                "develop idea": "The speaker is building on previous discussions, elaborating on the challenges faced in their field.",
                "ask question": "The speaker asks questions, such as 'How many cells do you have to circle to have enough data to algorithm.'",
                "express humor": "The speaker uses humor when saying 'crazy just to create data.'",
                "encourage participation": "The speaker invites Alex to share their experience."
            }
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "02:03-02:04",
            "transcript": "Thank you back.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:32",
            "end_time": "33:33",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "02:04-03:35",
            "transcript": "Yeah, we do a lot of circling cells. Um, yeah, we do auto fluorescence imaging, so it's low very low signal to noise and that creates a challenge for automated ways to process our data. And so we can see the patterns, but it's very hard to train traditional pipelines to do the segmentation. So that's why we've been working with AI. And actually, I really like Paris's point and you worded that much better than I was going to. Um, but my first interactions with AI and microscopy was stuff to for noise removal and um improving resolution and lowering laser power and stuff and I was just blown away by that work. And but I have right the same we know we know physical and biological boundaries on these conditions and I would like to see more integration of that into AI like if I'm segmenting a cell and it puts the nucleus, you know, right up against the edge of the cell, that's probably not where the nucleus is, right? It's more in the center. So how can we incorporate these things that we know um are are biological or physical boundaries and have the AI say like flag that oh that can't be right. Let's try again. Um, I think that gets into your errors, you know, what errors do we tolerate and how can we improve and minimize those.",
            "speaking_duration": 91,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:33",
            "end_time": "35:04",
            "annotations": {
                "develop idea": "The speaker elaborates on their experience with AI in microscopy, discussing challenges and potential improvements.",
                "ask question": "The speaker asks about incorporating biological or physical boundaries into AI.",
                "signal expertise": "The speaker mentions their experience with auto fluorescence imaging and working with AI in microscopy."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:36-04:00",
            "transcript": "I that's a a very good point. Um, when when I find when training AI, you should take advantage of a priori knowledge as well as what image are you inputting? Yes, one could say if I have infinite amount of data, infinite amount of truth, I can train it if I I just let it chug away, right?",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:05",
            "end_time": "35:29",
            "annotations": {
                "develop idea": "The speaker expands on a previous idea by discussing the importance of a priori knowledge in training AI.",
                "ask question": "The speaker asks about the approach to training AI, specifically about the role of a priori knowledge and data.",
                "supportive response": "The speaker acknowledges a previous point and builds upon it."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:00-04:16",
            "transcript": "But we don't have that especially in um the medical biomedical field, you know, you know, for things like image net, there's lots of pictures of cats and dogs and cars and light poles and all, but we don't have a lot of that annotated in the medical field even though we're generating so many medical images per day.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:29",
            "end_time": "35:45",
            "annotations": {
                "critical response": "The speaker is highlighting a limitation and challenge in the field, which can be seen as a form of critical response to the current state of data availability.",
                "clarify goal": "The speaker is also contributing to the discussion on what is needed or what the goals should be, in this case, the need for more annotated data in the medical field."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:16-04:30",
            "transcript": "Um, and I I I I appreciate um these comments on the a priori because we we need to help the AI. I you know, sometimes I tell my students think like a human because if you know that um image presentation A is better for the human to look at than image presentation B.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:45",
            "end_time": "35:59",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges and appreciates comments made by others regarding a priori knowledge.",
                "supportive response": "The speaker expresses validation for previous comments on the importance of a priori knowledge for AI.",
                "clarify goal": "The speaker clarifies the goal of helping AI by suggesting that it should be able to think like a human when evaluating image presentations."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:30-05:13",
            "transcript": "Why give the AI raw data? In a way, you're you're training in files, the training of all these humans has they have been reading images for many, many years. So how many of you in a sense consider what image am I giving to the AI and do you sometimes do the preprocessing to help the AI learn because you have limited data?",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:59",
            "end_time": "36:42",
            "annotations": {
                "ask question": "The speaker explicitly asks questions about the approach to providing data to AI.",
                "offer feedback": "The speaker provides feedback on how to approach training AI, suggesting consideration of preprocessing data.",
                "encourage participation": "The speaker encourages others to consider and share their thoughts on preprocessing data."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:13-05:13",
            "transcript": "Caroline, what do you think of that?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:42",
            "end_time": "36:42",
            "annotations": {
                "ask question": "The speaker is explicitly asking Caroline for her thoughts or opinions, which implies seeking information.",
                "encourage participation": "By directly asking Caroline, the speaker is inviting her to contribute to the discussion."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "05:13-06:05",
            "transcript": "Yeah, no, so I was nodding because um so I I'm also focused more on the imaging and instrumentation side. Um, but I work with collaborators that um do more of the sort of machine learning or, you know, neural network development. And um, you know, that's that definitely resonates that you have sometimes picked a data set to show a specific thing, right? Um, and that data set obviously then may not be representative of what that algorithm is actually going to encounter.",
            "speaking_duration": 52,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:42",
            "end_time": "37:34",
            "annotations": {
                "acknowledge contribution": "The speaker verbally recognizes and aligns with a prior statement or idea.",
                "identify gap": "The speaker explicitly points out a limitation or gap, in this case, the representativeness of datasets for algorithm training.",
                "supportive response": "The speaker expresses agreement or validation for other group members' contributions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:06-06:21",
            "transcript": "So if we had our database, our messy database, we could include both, we can include them of different spatial resolution, we can include AI to do the reconstruction. Um, so Shannon, how's this list coming? It looks good. Looks longer than three minutes. It looks really good.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:35",
            "end_time": "37:50",
            "annotations": {
                "develop idea": "The speaker is expanding on the idea of creating a comprehensive database that includes different spatial resolutions and utilizing AI for reconstruction.",
                "ask question": "The speaker asks Shannon about the status of a list.",
                "supportive response": "The speaker expresses agreement or positivity towards the list."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:31-06:34",
            "transcript": "I'm trying to get the main points.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:00",
            "end_time": "38:03",
            "annotations": {
                "summarize conversation": "The speaker is trying to get the main points of the discussion, indicating an attempt to summarize or understand the key points."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:34-06:41",
            "transcript": "Okay. Um, do you want us to go through? Do you want to kind of summarize for us and then we can so so the topic here is",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:03",
            "end_time": "38:10",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by asking the group for their preference on how to proceed.",
                "ask question": "The speaker is requesting information or clarification from the group on what they would like to do next."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:41-07:01",
            "transcript": "um what's the next big thing for this field? How can you what would be your dream of where it would go and um uh near the and I'll tell you how I've been trying to do my dream models.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:10",
            "end_time": "38:30",
            "annotations": {
                "encourage participation": "The speaker invites others to share their thoughts on the future of the field and their aspirations for where it should go, encouraging participation and discussion."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:01-07:03",
            "transcript": "Is it the open question?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:30",
            "end_time": "38:32",
            "annotations": {
                "ask question": "The speaker is asking for clarification or information about a previous statement or topic, indicating a request for more information."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:03-07:07",
            "transcript": "That's is it a clinical question? What do you mean on the",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:32",
            "end_time": "38:36",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification on the nature of the question being discussed."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:07-07:14",
            "transcript": "I'm sorry. like are we discussing big big should we kind of",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:36",
            "end_time": "38:43",
            "annotations": {
                "ask question": "The speaker is seeking clarification or confirmation on the discussion topic or direction, which aligns with requesting information or clarification."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:14-07:34",
            "transcript": "I think one thing that just was coming to my mind while we're discussing is like it would be amazing to have a recipe of how much data we need for a task. There is no recipe, you know, like you come to a problem, you say, I want to segment this thing.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:43",
            "end_time": "39:03",
            "annotations": {
                "propose new idea": "The speaker introduces the idea of having a 'recipe' for determining how much data is needed for a task.",
                "develop idea": "The speaker elaborates on the idea by comparing it to a common problem of segmenting an image and noting the absence of such a recipe."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:34-07:44",
            "transcript": "So, your collaborator asks, how much should I measure? Yeah. How much should I collect? Can anybody here answer?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:03",
            "end_time": "39:13",
            "annotations": {
                "code name": "explanation",
                "another code": "another explanation"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:44-07:54",
            "transcript": "Okay, now, how about if you know some prior information about the problem, say nucleus is in that position or that. Now, can this help me cut the data and by how much?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:13",
            "end_time": "39:23",
            "annotations": {
                "develop idea": "The speaker is exploring how prior information (e.g., nucleus position) can be used to optimize data collection or analysis."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:54-07:54",
            "transcript": "Well",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:23",
            "end_time": "39:23",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:54-07:54",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:23",
            "end_time": "39:23",
            "annotations": {
                "supportive response": "The speaker is acknowledging a previous statement, showing agreement or confirmation."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:55-08:01",
            "transcript": "I guess I guess for me I actually want to take it one step further and almost",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:24",
            "end_time": "39:30",
            "annotations": {
                "propose new idea": "The speaker is indicating a desire to take the discussion further, potentially introducing a new idea or perspective."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:01-08:04",
            "transcript": "almost take data out of the equation entirely and",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:30",
            "end_time": "39:33",
            "annotations": {
                "propose new idea": "The utterance introduces a novel approach to handling data in AI applications, suggesting minimizing or taking data out of the equation entirely.",
                "offer feedback": "The speaker's suggestion implies a critique of current data-heavy approaches and offers an alternative perspective on how data could be handled in AI applications."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:04-08:10",
            "transcript": "let me let me explain a bit where we've been talking a lot about",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:33",
            "end_time": "39:39",
            "annotations": {
                "encourage participation": "The speaker is requesting an opportunity to contribute to the discussion by explaining their point.",
                "ask question": "Alternatively, it could be seen as indirectly asking for permission or space to speak."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:10-09:54",
            "transcript": "you know, we need a lot of data, we need a lot of ground truth. Given an infinite amount of data, um that was an interesting point to me because I still wonder like would the model still learn what we wanted to learn? And I'm not I hesitate before answering and I feel like that hesitation by itself says that even our models aren't quite there yet and that maybe more data isn't exactly the problem that we're looking at. Maybe I just I keep I keep thinking of like these new methods involving self-supervised learning and few shot learning and anomaly detection where it's less about how much data you can throw at the problem and more about how we can build this architecture that without it becoming kind of a handcrafted algorithm has very specific features that it looks for. And so as a result, you don't need this lengthy training process, you don't need terabytes and terabytes of data, but what you can have to again sort of inform the end user if they don't have enough data is some sort of uncertainty quantification at the end. So for instance, if you're trying to do some kind of segmentation and you have your data set, you don't necessarily need to do a kind of calculation of how much data do I need, you just kind of give it to the algorithm, the algorithm does its few shot semi or self-supervised training and then at the end of that spits out, okay, here's the segmentation that I did and here's my certainty that it's correct.",
            "speaking_duration": 104,
            "nods_others": 0,
            "smile_self": 20.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:39",
            "end_time": "41:23",
            "annotations": {
                "propose new idea": "The speaker introduces new perspectives on data requirements and model training, questioning the necessity of large amounts of data.",
                "ask question": "The speaker poses questions about the current approach to model training and data requirements.",
                "identify gap": "The speaker highlights a potential gap in current methods, suggesting that more data may not be the solution."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "09:54-09:58",
            "transcript": "Do do we also need the certainty on the certainty so that we can trust the certainty?",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:23",
            "end_time": "41:27",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification on the need for certainty about the certainty of AI outputs."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:18",
            "transcript": "actually talk about having, you know, let's say the algorithm says, uh, you have 65% chance of having cancer, I am 35% sure and I am a slightly biased algorithm. So those are the three outputs I usually like, um, because",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 11,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:29",
            "end_time": "41:47",
            "annotations": {
                "develop idea": "The speaker is elaborating on the concept of AI output, specifically discussing how an algorithm might report its confidence and potential bias in a diagnostic context.",
                "supportive response": "The speaker is engaging with and building upon previous ideas discussed in the meeting, providing a relevant example."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:19-00:22",
            "transcript": "Well I agree with that but I don't trust the 35%. How would I trust that 35",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:48",
            "end_time": "41:51",
            "annotations": {
                "critical response": "The speaker is questioning and expressing concern about trusting the certainty provided by an algorithm, which implies a critical response to the idea of relying on such algorithms.",
                "ask question": "The speaker is asking a question about how to trust the certainty provided by an algorithm, indicating a request for information or clarification."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:22-00:23",
            "transcript": "All right, but that's what the 35",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:51",
            "end_time": "41:52",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:23-00:29",
            "transcript": "that's what the 35% except if it actually has a true statistical meaning that's non Gaussian and I don't know.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:52",
            "end_time": "41:58",
            "annotations": {
                "develop idea": "The speaker is expanding on a previous discussion about data interpretation and statistical meaning.",
                "ask question": "The speaker poses a question about the statistical interpretation of the algorithm's output.",
                "critical response": "The speaker is providing a critical view on how the 35% uncertainty should be interpreted."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:29-00:52",
            "transcript": "Right. You have to do the reproducibility, repeatability studies to get that. But that's telling you that the computer is only 35%. It's like you go to the your doctor's office and he says like, you know, you got 85% sure chance you have a chipped tooth, but I'm only 20% sure. How do you feel? So that's what but the AI has to also kind of do that. I I agree.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:58",
            "end_time": "42:21",
            "annotations": {
                "develop idea": "The speaker expands on the idea of needing to understand and quantify AI uncertainty.",
                "supportive response": "The speaker supports the discussion and ideas presented.",
                "offer feedback": "The speaker provides a way to think about and improve the understanding of AI outputs."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:52-01:17",
            "transcript": "Uh Shannon, that's a um, uh, I I think that's definitely what kind of outputs do you want? And I think that will differ for if you're doing um AI on biological images for discovery or are you doing it for a patient output. I'm going to ask um, um, more folks to talk here. I don't know what when do we finish? I just want to make sure we're not running out of time.",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:21",
            "end_time": "42:46",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by indicating a plan to solicit more input and expressing a desire to ensure they do not run out of time.",
                "encourage participation": "The speaker invites more participants to contribute their thoughts and opinions.",
                "clarify goal": "The speaker is clarifying the goals or objectives related to AI outputs, distinguishing between use cases."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:19-01:54",
            "transcript": "I always, you know, I mentioned I I like to think like a human and I think the inputs and the outputs should be very similar. I'm a big fan of handcrafted. In fact, I I think it's the world will not just be all deep learning. I grew up with handcrafted and I now incorporate deep learning and I merge them.",
            "speaking_duration": 35,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:48",
            "end_time": "43:23",
            "annotations": {
                "develop idea": "The speaker is expanding on her thoughts about AI development, handcrafted methods, and deep learning.",
                "signal expertise": "The speaker mentions her background with handcrafted and deep learning methods.",
                "offer feedback": "The speaker shares her viewpoint on the future of AI, which can be seen as providing feedback on current approaches."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:54-02:20",
            "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access, but then like we have to. We have to find a way to just get to that.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "43:23",
            "end_time": "43:49",
            "annotations": {
                "identify gap": "The speaker explicitly recognizes the lack of access to data or resources necessary for their research.",
                "supportive response": "The speaker agrees with Katie's point that accessing data is hard.",
                "clarify goal": "The speaker discusses the goal of facilitating research through better access to data or resources."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:20-02:25",
            "transcript": "Okay, yes, and when I say think like a human, I'm thinking more of input and output.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:49",
            "end_time": "43:54",
            "annotations": {
                "clarify goal": "The speaker is clarifying her previous statement about thinking like a human, specifically in terms of input and output, which relates to defining or clarifying objectives or expectations for AI development in imaging."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:26-03:26",
            "transcript": "Um, but if you think how radiologist are that their job is to interpret medical images. And what how do they get trained? First as a resident, they have a textbook and they go through that textbook and they learn this is what a cancer looks like. This that's handcrafted. Get a little hand waving here. And then they sit with their attending radiologist and they read day in and day out and they're told, oh, you're wrong. No, that's a false positive. That's the deep learning and that's of the radiologist brain. And then we have different structures of the brain. Some are really good at finding Waldo and weirds Waldo and some aren't. Maybe they shouldn't have been radiologist. Just like there's probably computer vision AI algorithms that way.",
            "speaking_duration": 60,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:55",
            "end_time": "44:55",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas by elaborating on the training of radiologists and comparing it to AI training.",
                "supportive response": "The speaker provides a positive evaluation of how radiologists learn.",
                "express humor": "The speaker makes a joke or analogy involving finding Waldo to make a point about variability in skills."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:26-03:37",
            "transcript": "And I I think the example of giving the AI algorithm an image that radio humans find easier to read could save you a lot of training time and data when you're doing your AI. How many of you train on medical images? I think Katie does and Shannon and Shiva.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:55",
            "end_time": "45:06",
            "annotations": {
                "propose new idea": "The speaker introduces the idea of using images that are easy for humans to read for training AI algorithms to save time and data.",
                "ask question": "The speaker asks how many of the participants train on medical images."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "03:37-03:39",
            "transcript": "We're using like a DICOM.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:06",
            "end_time": "45:08",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:39-04:26",
            "transcript": "A DICOM. But say for example with um breast MRI, you could have DICOM fields of the raw data, you could have it showing subtracted images after uptake of a contrast, you could have a image where you've collapsed it into a MIP. We find for example inputting the MIP gives you better performance than inputting just the subtraction image or and and things like if you have volume data, do you input the volume data or do you input the slices of the volume data. All those are before you even get to your algorithm and I don't know if people spend enough time on that. That's how I see it. Um, have you run into that?",
            "speaking_duration": 47,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:08",
            "end_time": "45:55",
            "annotations": {
                "develop idea": "expanding on the idea of preparing data for AI algorithms, discussing specifics of data types and their impact on algorithm performance",
                "ask question": "requesting information or experience from others in the group regarding their encounters with similar data preparation challenges",
                "encourage participation": "inviting others to share their experiences or thoughts"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:26-04:26",
            "transcript": "How do you decide what goes into your algorithm?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:55",
            "end_time": "45:55",
            "annotations": {
                "ask question": "The speaker is requesting information on how decisions are made regarding what goes into an algorithm."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:26-04:37",
            "transcript": "I mean between the volumetric and slices it's easy it depends how much volumetric examples I have. Usually I have like 10 volumetric examples and each one has hundreds of slices or thousands of slices and I go by slices.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:55",
            "end_time": "46:06",
            "annotations": {
                "develop idea": "The speaker is elaborating on his approach to using volumetric data versus slices in his work, providing a specific example based on the amount of volumetric examples he has."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:40-04:41",
            "transcript": "But the format.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:09",
            "end_time": "46:10",
            "annotations": {
                "ask question": "The speaker is seeking clarification or information about the format of the data."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:42-04:45",
            "transcript": "Oh you mean the way the data is stored in the format?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:11",
            "end_time": "46:14",
            "annotations": {
                "ask question": "The speaker is seeking clarification on the format of the data, which is a direct request for information."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:45-04:46",
            "transcript": "Right. What are well, not the format.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:14",
            "end_time": "46:15",
            "annotations": {
                "ask question": "The speaker is seeking clarification or information about what was previously discussed, indicated by 'Right. What are well, not the format.'"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:46-04:56",
            "transcript": "That's like application collaborator dependent, right? Uh, well for me at least it's uh depends what's application, so that tells me the format.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:15",
            "end_time": "46:25",
            "annotations": {
                "develop idea": "The speaker is expanding on their approach to considering data format in their work, indicating it depends on the application and collaborator."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:56-04:57",
            "transcript": "Right.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:25",
            "end_time": "46:26",
            "annotations": {
                "acknowledge contribution": "The speaker is acknowledging a prior statement.",
                "supportive response": "The speaker is expressing agreement with a prior statement."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "05:00-05:11",
            "transcript": "I think it's a little bit as a barrier because I don't think that you we have enough resources to answer some of those questions. Sometimes they're still driven by what you have access to.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:29",
            "end_time": "46:40",
            "annotations": {
                "identify gap": "The speaker explicitly mentions a lack of resources to answer some questions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:11-05:24",
            "transcript": "So if you were to ask me how do I figure out what to input to the network, my answer would be I sit with the radiologist. I sit with the domain expert on imaging. I sit with the human AI instrument.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:40",
            "end_time": "46:53",
            "annotations": {
                "develop idea": "The speaker is expanding on previous ideas by suggesting a practical approach to determining what to input to a network.",
                "offer feedback": "The utterance provides a suggestion for how to proceed (sitting with experts) which can be seen as a form of feedback."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:24-05:25",
            "transcript": "I use human human aided AI development.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:53",
            "end_time": "46:54",
            "annotations": {
                "develop idea": "The speaker is elaborating on their approach to AI development by mentioning that they use human-aided AI development."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "05:25-05:36",
            "transcript": "And not all of us are in a place where we can do that. Right? Like I'm not at a medical institution. And so how do I get that access? How do I that's not a resource I have.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:54",
            "end_time": "47:05",
            "annotations": {
                "ask question": "The speaker requests information on how to get access to certain resources.",
                "identify gap": "The speaker highlights a lack of access to medical institutions or domain experts as a limitation."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-05:36",
            "transcript": "Okay, so",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:05",
            "end_time": "47:05",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-05:37",
            "transcript": "Right.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:05",
            "end_time": "47:06",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:37-06:12",
            "transcript": "Okay, well that's that's major. To me, that's a barrier. You um AI developers need um um need that. I I get that access all the time that's why I like where I am, but um that's that's really important that the network network needs to connect the AI developer with the domain expert of that imaging task.",
            "speaking_duration": 35,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:06",
            "end_time": "47:41",
            "annotations": {
                "identify gap": "Maryellen Giger recognizes a gap in connecting AI developers with domain experts in imaging tasks.",
                "critical response": "Maryellen Giger expresses concern about the current state of AI development in imaging, calling it a barrier.",
                "encourage participation": "Maryellen Giger encourages connecting AI developers with domain experts, promoting collaboration."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:12-06:13",
            "transcript": "It it it will save you tons of time.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:41",
            "end_time": "47:42",
            "annotations": {
                "supportive response": "The speaker is expressing agreement and validation for a previous statement, indicating a supportive response."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:13-06:15",
            "transcript": "What about Shannon and Shiva? How do you get your images?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:42",
            "end_time": "47:44",
            "annotations": {
                "ask question": "The speaker is requesting information from Shannon and Shiva on how they obtain their images."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:15-06:17",
            "transcript": "Are you have domain expert issues?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:44",
            "end_time": "47:46",
            "annotations": {
                "ask question": "The speaker is requesting information about Shannon and Shiva's access to or issues with domain experts."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "06:18-07:14",
            "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, if you want coffee, I bring you coffee and then when you are sitting in the reading room just please, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access.",
            "speaking_duration": 56,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "47:47",
            "end_time": "48:43",
            "annotations": {
                "identify gap": "Shiva explicitly mentions a problem with accessing data or collaborating with hospitals, which is a gap in their research.",
                "propose new idea": "Shiva suggests that recognition by funding agencies or hospitals could help solve the access problem.",
                "supportive response": "Shiva agrees with Katie's statement about the difficulty in getting access, showing support for her viewpoint."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:14-07:14",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "48:43",
            "end_time": "48:43",
            "annotations": {
                "acknowledge contribution": "The speaker is verbally recognizing a prior statement or contribution by another group member."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:14-07:31",
            "transcript": "But then like we have to. We have to find a way to just get to that. So then if we had more infrastructure to provide a path for that, it could be really great.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "48:43",
            "end_time": "49:00",
            "annotations": {
                "propose new idea": "The speaker suggests having more infrastructure to provide a path for collaboration or data access.",
                "develop idea": "The speaker builds upon the discussion about challenges in data access and collaboration.",
                "identify gap": "The speaker implicitly recognizes a gap in current infrastructure or practices."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:31-07:32",
            "transcript": "Okay, this yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:00",
            "end_time": "49:01",
            "annotations": {
                "None": "The utterance 'Okay, this yeah.' is a minimal response that doesn't explicitly fit into any of the provided categories."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:32-07:32",
            "transcript": "I think",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:01",
            "end_time": "49:01",
            "annotations": {
                "None": "The utterance is too brief and does not explicitly convey enough information to apply a specific code from the provided codebook."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:32-07:33",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:01",
            "end_time": "49:02",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:33-07:34",
            "transcript": "Okay, good.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:02",
            "end_time": "49:03",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or satisfaction with the current state of the conversation, providing a positive but non-substantive response."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:34-07:34",
            "transcript": "Um",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:03",
            "end_time": "49:03",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:34-07:35",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:03",
            "end_time": "49:04",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:35-07:35",
            "transcript": "Okay, good.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:04",
            "end_time": "49:04",
            "annotations": {
                "Supportive response": "The speaker is expressing agreement or validation of a previous statement."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:35-07:36",
            "transcript": "We've got 20 minutes.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:04",
            "end_time": "49:05",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by mentioning the time left."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:36-07:37",
            "transcript": "Thankfully.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:05",
            "end_time": "49:06",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:37-07:38",
            "transcript": "I would not be able to throw that together.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:06",
            "end_time": "49:07",
            "annotations": {
                "express humor": "The speaker uses an idiomatic expression 'throw that together' in a way that can be considered humorous, indicating difficulty in completing a task."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:38",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:07",
            "end_time": "49:07",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:41",
            "transcript": "I think you're doing a great job here, Shannon. Shannon, where do you see things can be move merged?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:07",
            "end_time": "49:10",
            "annotations": {
                "supportive response": "The speaker is expressing a positive evaluation of Shannon's performance.",
                "encourage participation": "The speaker is inviting Shannon to share her thoughts on where things can be improved or merged."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:41-07:42",
            "transcript": "Where do you have the domain expert issue?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:10",
            "end_time": "49:11",
            "annotations": {
                "ask question": "The speaker is requesting information about domain expert issues.",
                "identify gap": "The question implies recognizing a gap in access to domain experts.",
                "encourage participation": "The speaker is inviting others to share their experiences."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:01-00:37",
            "transcript": "Yeah, that to me that's a night and day um that helps you. I I I um I always, you know, feel for you guys that in that situation. How about the biology people, the image people doing AI on bio imaging, biological imaging, cellular imaging. What's what's holding you up? You have access I would assume to biologist much easier than they have access to medical imaging people. Alex, do you have access to who you need to talk to? And then also Girgis, I can ask.",
            "speaking_duration": 36,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 11.1,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:30",
            "end_time": "52:06",
            "annotations": {
                "encourage participation": "The speaker encourages Alex and offers to ask Girgis about their access to necessary domain experts, inviting them to contribute.",
                "process management": "The speaker is managing the discussion by inquiring about challenges faced by subgroups within the team."
            }
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "00:38-00:45",
            "transcript": "Yeah, I think my limitations are how much data do I need and we already have that on there.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
            "start_time": "52:07",
            "end_time": "52:14",
            "annotations": {
                "identify gap": "The speaker explicitly mentions a limitation or gap in their current situation, which is the amount of data needed."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:46-00:49",
            "transcript": "Okay, so you have your domain experts. You have your biologist right there.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:15",
            "end_time": "52:18",
            "annotations": {
                "identify gap": "The speaker is pointing out that the person she is talking to already has access to biologists who can serve as domain experts, indicating that there is no gap in this area."
            }
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "00:50-00:51",
            "transcript": "Right. Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
            "start_time": "52:19",
            "end_time": "52:20",
            "annotations": {
                "supportive response": "The utterance expresses agreement with a prior statement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:51-00:53",
            "transcript": "Girgis, do you have that?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:20",
            "end_time": "52:22",
            "annotations": {
                "ask question": "The speaker is requesting information from Girgis about his access to domain experts or resources."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "00:53-02:39",
            "transcript": "Yeah, well, so so our our approach uh at least machine learning from a completely different perspective. So we collaborate with some folks here uh trying to understand how nanoparticles will accumulate into tumors and what that actually means. And the problem at least from the perspective of the the domain experts is not necessarily that yes, this is a tumor, but it's more about the technology that's being developed. So if you use a a certain type of particle or contrast agent and suggest that this is tumor selective, the interpretation that's being presented at least in the primary literature is very biased by a lot of um I guess you could you could say misinterpretation that's that's been perpetuated over a couple of decades. So people will assume that certain types of materials will always accumulate in tumors and if it does, then yes, we have a tumor. So the problem is not necessarily just on the on the image interpretation side, but it's more about the the contrast agent itself. And so the way that we approach it is that the input that we need needs to be built up as well. It's not just a contrast agent, but it's more using some nanotech experts to suggest that okay, well, this contrast agent will also accumulate similarly to another contrast agent. So you have to put um a second uh piece of information into the input of the algorithm itself to suggest that if you see this kind of a trend, this is a false positive. So you're teaching it what a false positive is based on the material that you're using as a contrast agent right from the very start from the get go so that you don't end up with false positives at the end. So it's we're kind of more on the front end of things and and and in my field the domain experts that are lacking is more on the on the material well nanobio interaction side of things.",
            "speaking_duration": 106,
            "nods_others": 1,
            "smile_self": 10.4,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:22",
            "end_time": "54:08",
            "annotations": {
                "develop idea": "Girgis is elaborating on their approach to machine learning, focusing on the challenges of nanoparticle accumulation in tumors and the need for nuanced input to their algorithms.",
                "signal expertise": "Girgis mentions collaboration with nanotechnology experts and their own work in machine learning, signaling expertise in these areas.",
                "identify gap": "Girgis identifies a gap in domain expertise, specifically in the area of nano-bio interactions, as a challenge in their field."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:40-02:47",
            "transcript": "So you're doing your AI based on knowledge of known biology and chemistry? Would that be correct wording?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:09",
            "end_time": "54:16",
            "annotations": {
                "ask question": "The speaker is seeking clarification or confirmation on whether the AI is based on known biology and chemistry."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "02:47-03:47",
            "transcript": "It's it's more about so it's it's hard for me to to explain without going into details. But let's let's take nanoparticle contrast agents um for optical imaging. That's one of the things that we look into. And there are clinical trials that suggest that you can use these contrast these nanoparticles as contrast agents for positive tumor detection and image guided surgery. And that's all very well and good. You can see the image, you can probably use AI to delineate the uh tumor boundary to be a little bit better. But there are secondary biological factors um that contribute to errors that haven't been considered right at the start. So we try and hit it on both ends, not just what the image actually tells us, but what the agent that we're administering, how that's going to interact with the tissue and how that then contributes to a false positive. And so then feeding in information about what false positive materials or materials that give false positives is actually going to look like when you finally get the image.",
            "speaking_duration": 60,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:16",
            "end_time": "55:16",
            "annotations": {
                "propose new idea": "The speaker suggests considering secondary biological factors to improve AI accuracy in imaging.",
                "develop idea": "The speaker expands on the idea by explaining the role of secondary biological factors in error contribution and suggesting a solution.",
                "signal expertise": "The speaker explicitly discusses their area of expertise related to nanoparticle contrast agents and optical imaging.",
                "identify gap": "The speaker identifies a lack of consideration for secondary biological factors in current approaches.",
                "offer feedback": "The speaker provides specific suggestions for improving the approach to AI-assisted imaging."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:49-04:14",
            "transcript": "So I always think of AI as having two types of components. One is where it's model driven where it has these physical limitations, chemistry limitations, but it when biology um where it's it's model driven and um the model is built on these principles. You could use deep learning in it, but in the end you have these constraints on it.",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:18",
            "end_time": "55:43",
            "annotations": {
                "develop idea": "The speaker is elaborating on her view of AI, explaining how she thinks of its components and the integration of deep learning within certain constraints.",
                "clarify goal": "The speaker is defining her perspective on AI, which relates to understanding objectives and expectations for AI development."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:14-04:52",
            "transcript": "The other type of AI is in general you can think of it as statistical, you know, it's the deep learning, it's um uh having the machine actually learn and I personally believe that in the future we need a mixture of these. I think it would be extremely interesting to have like um both types applied to your situation Girgis because you have you know, a lot of times it's hard to find the person with the model. You know, it's um but how do you want to bring that point up in this this Google Doc?",
            "speaking_duration": 38,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:43",
            "end_time": "56:21",
            "annotations": {
                "develop idea": "The speaker is expanding on the concept of AI types and their potential applications.",
                "ask question": "The speaker asks how to bring a point up in the Google Doc, seeking information or clarification.",
                "encourage participation": "The speaker invites Girgis to share thoughts, encouraging participation."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:52-04:53",
            "transcript": "Help us, where would you put it and how would you put it?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:21",
            "end_time": "56:22",
            "annotations": {
                "ask question": "The speaker is requesting information or guidance on how to proceed with documenting a point.",
                "process management": "The speaker is managing the flow of information and documentation by seeking input on how to incorporate a point into a document."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "04:54-05:00",
            "transcript": "I I guess it probably it probably ties in with the with the ground truth to a certain extent.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:23",
            "end_time": "56:29",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges a previously discussed concept, 'ground truth,' indicating recognition of its relevance to the current discussion."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "05:00-05:16",
            "transcript": "But maybe the generalizability part of things. And again, I I see it from a whole different perspective. I know a lot of folks here use um patient images, but I'm talking more about the generalizability again of the contrast agent and how that will behave.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:29",
            "end_time": "56:45",
            "annotations": {
                "identify gap": "Girgis explicitly recognizes a gap in the discussion regarding the generalizability of contrast agents and their behavior.",
                "develop idea": "Girgis expands on the idea of generalizability in the context of contrast agents."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:16-05:22",
            "transcript": "So it's something relationship of the model to the physics chemistry and biology of the imaging situation.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:45",
            "end_time": "56:51",
            "annotations": {
                "summarize conversation": "The speaker is summarizing a concept discussed in the conversation about the relationship of the model to the physics, chemistry, and biology of the imaging situation."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:22-05:23",
            "transcript": "I guess so.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:51",
            "end_time": "56:52",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:23-05:25",
            "transcript": "Sorry, where is my cursor?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:52",
            "end_time": "56:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:00-06:03",
            "transcript": "Well, I see a little red dock by the word generalizable.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:29",
            "end_time": "57:32",
            "annotations": {
                "process management": "This utterance manages the visual or document flow by commenting on a specific annotation or cue on the screen."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:04-06:10",
            "transcript": "Oh, that's that's not me. But yeah. Um sorry, I was I was trying to",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 16.7,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:33",
            "end_time": "57:39",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:10-06:11",
            "transcript": "Yeah, you sure can. Everybody can.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:39",
            "end_time": "57:40",
            "annotations": {
                "supportive response": "The speaker is expressing agreement and validation for a previous suggestion or idea, indicating a positive and inclusive attitude towards collaboration."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:11-06:23",
            "transcript": "Um sorry, the people are editing the presentation and I'm not able to make any changes. That's what I've been trying to figure out.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:40",
            "end_time": "57:52",
            "annotations": {
                "process management": "The speaker is discussing a challenge related to the collaborative process of editing a presentation, which is a part of managing group activities."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:23-06:34",
            "transcript": "So no one hits save. How's that? It kicks people in other groups. Shannon, if you want, I can add the names so that you can focus on the conversation.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:52",
            "end_time": "58:03",
            "annotations": {
                "process management": "Managing the meeting flow by suggesting a way to organize collaboration."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:34-06:39",
            "transcript": "Yeah, thank you added it and they all got lost.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:03",
            "end_time": "58:08",
            "annotations": {
                "acknowledge contribution": "verbally recognizes another group member's input",
                "critical response": "Questioning, challenging, or providing negative evaluation of ideas"
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:39-06:43",
            "transcript": "Yep. Yeah. Yeah, so I can do that.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:08",
            "end_time": "58:12",
            "annotations": {
                "None": "No relevant code applies to this utterance as it is a simple acknowledgment."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:43-06:46",
            "transcript": "Okay, thank you.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:12",
            "end_time": "58:15",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges and thanks another group member for their input or action."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:46-06:52",
            "transcript": "Yeah and are you able to open up your the slide deck to put in at least the final three points?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:15",
            "end_time": "58:21",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by requesting an action related to the slide deck.",
                "assign task": "The speaker is assigning a task to someone to update the slide deck."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:52-07:11",
            "transcript": "No, that's what I'm talking about. The Google Doc is fine. Please edit away there. It's the slide deck that keeps kicking me out every time I try to make an edit.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:21",
            "end_time": "58:40",
            "annotations": {
                "acknowledge contribution": "Shannon acknowledges the previous discussion and responds to it by providing more information about her experience with the Google Doc and slide deck.",
                "process management": "Shannon discusses the process of editing documents, specifically mentioning her issues with accessing and editing the slide deck."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:11-07:14",
            "transcript": "So what if you just take yeah, okay.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:40",
            "end_time": "58:43",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges a previous suggestion or contribution.",
                "supportive response": "The speaker is expressing agreement or support for a previous idea."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:14-07:34",
            "transcript": "Can you download the PowerPoint to your computer? Um I'm actually just going to draft I'm going to draft it out in the Google Doc. Okay. Okay. Um Now I forgot what um",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:43",
            "end_time": "59:03",
            "annotations": {
                "process management": "The speaker is managing the meeting flow and organizing the collaboration process by asking someone to download a PowerPoint and mentioning drafting in a Google Doc."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:20-07:21",
            "transcript": "You were going to mention something about generalizability.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:49",
            "end_time": "58:50",
            "annotations": {
                "acknowledge contribution": "Shannon Quinn acknowledges Maryellen Giger's previous point about generalizability and invites further discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:34-07:55",
            "transcript": "Yes, well model driven by the um physics chemistry and biology of the um uh contrast agents properties? I don't know if I got that right.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:03",
            "end_time": "59:24",
            "annotations": {
                "Develop idea": "Maryellen Giger is expanding on an idea by suggesting that models could be driven by the physics, chemistry, and biology of contrast agents' properties.",
                "Ask question": "She is seeking confirmation or clarification on her understanding of the concept with 'I don't know if I got that right.'"
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "07:56-07:58",
            "transcript": "Yeah, that that's that pretty much.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:25",
            "end_time": "59:27",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with the previous statement, showing support without adding new content."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:58-08:00",
            "transcript": "knowledge wrong?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:27",
            "end_time": "59:29",
            "annotations": {
                "ask question": "The speaker is seeking clarification or confirmation about a statement regarding knowledge.",
                "critical response": "The speaker is also expressing a critical view towards existing knowledge or statements made."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:08-08:09",
            "transcript": "Okay, good.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:37",
            "end_time": "59:38",
            "annotations": {
                "supportive response": "The utterance 'Okay, good.' expresses agreement or acknowledgment, indicating a positive evaluation of the previous discussion or statement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:09-08:17",
            "transcript": "So I think we we all as a group um um maybe uh Paris.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:38",
            "end_time": "59:46",
            "annotations": {
                "encourage participation": "The speaker is inviting Paris to contribute to the discussion or share their thoughts."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:18-08:21",
            "transcript": "Yeah, I think",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:47",
            "end_time": "59:50",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or alignment with a previous statement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:21-08:22",
            "transcript": "We got to bring this down to three bullets.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:50",
            "end_time": "59:51",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by suggesting to condense discussion points into three bullets."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:22-09:11",
            "transcript": "Uh, sure, maybe one comment that just to follow up to what you what was just discussed, which may be interesting is I totally agree with you that, you know, kind of the future lies in this hybrid approach where statistical learning or purely data driven learning will be interfaced with model based uh principles and domain knowledge. Now the question is to get us there, obviously, you know, one cannot expect that we can just take an algorithm developed to classify dogs and cats and that will work. So and also we cannot expect that the computer scientist will learn chemistry and biology and will actually develop this specialized system.",
            "speaking_duration": 49,
            "nods_others": 0,
            "smile_self": 10.2,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:51",
            "end_time": "60:40",
            "annotations": {
                "Supportive response": "Paris agrees with the previous speaker and supports the idea of a hybrid approach.",
                "Critical response": "He provides a critical perspective on the limitations of current machine learning approaches and the challenges in developing specialized systems.",
                "Develop idea": "Paris expands on the idea of a hybrid approach, discussing its potential and the challenges involved."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:11-09:23",
            "transcript": "So the only question is who do we train and how do we train them to work in this interface and contribute the tools that we need in the future.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:40",
            "end_time": "60:52",
            "annotations": {
                "encourage participation": "The speaker invites discussion on who to train and how to train them, encouraging participation and contribution of ideas from others."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "09:23-09:26",
            "transcript": "So you're saying the tools, the AI tools are not good enough?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:52",
            "end_time": "60:55",
            "annotations": {
                "ask question": "The speaker is seeking clarification on the current state of AI tools, asking for more information about their limitations."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:26-10:00",
            "transcript": "Well, I'm saying that that the way things have been working is we borrow a system that is successful in classifying dogs and cats and now we're trying to use it to segment cancer cells. And maybe that works to some extent, but if we want to sort of develop more specialized systems that bring in this domain knowledge and you know, um are tailored or more specialized to a given task, who is going to do this and who has the expertise to do this and how do we train people to actually have that expertise to to do that.",
            "speaking_duration": 34,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:55",
            "end_time": "61:29",
            "annotations": {
                "Critical response": "The speaker questions the current approach of borrowing systems from one domain and applying them to another, indicating a critical perspective on current methods.",
                "Propose new idea": "The speaker suggests a future direction of developing more specialized systems that incorporate domain knowledge.",
                "Ask question": "The speaker asks questions about who will develop these specialized systems and how they will be trained."
            }
        }
    ]
}