{
    "all_speakers": [
        "Maryellen Giger UChicago",
        "Ellen Sletten",
        "Ulugbek Kamilov",
        "Maryellen Giger",
        "Shiva Abbaszadeh",
        "Ping Wang",
        "Anna-Karin Gustavsson",
        "Ferdinand Schweser",
        "Sapun Parekh",
        "Uzay Emir",
        "Ulugbek Kamilov",
        "Samuel Achilefu",
        "Alexandra Basford",
        "Candace Fleischer",
        "Bot 5"
    ],
    "total_speaking_length": 3687,
    "all_data": [
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:00-00:23",
            "transcript": "minute of jotting down your thoughts. Do you all have the um slide, which imaging modalities are most compatible for simultaneously data acquisition and integration. Um and then we're going to do introductions, but first we're going to think for a minute. Can orthogonal methods provide both high resolution and deep tissue penetration and are there new combinations of imaging modalities.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:00",
            "end_time": "00:23",
            "annotations": {
                "ask question": "The speaker asks questions about imaging modalities, orthogonal methods, and new combinations.",
                "encourage participation": "The speaker invites the group to think and share their thoughts.",
                "process management": "The speaker guides the group's activity and manages the meeting flow."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:05",
            "transcript": "about 40 seconds more. So jot them down, type them.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 40,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:23",
            "end_time": "00:28",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by indicating a time frame and instructing the group to perform an action."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:54-01:24",
            "transcript": "Okay, so that was our minute of jotting down our own thoughts for use later in this conversation. So why don't we start with you've heard Sam and me tell you who we are. So maybe um and Sam, do you want to start since you oh you're going to sign off now. Okay, I just saw.",
            "speaking_duration": 30,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:17",
            "end_time": "01:47",
            "annotations": {
                "process management": "The speaker is managing the meeting flow, transitioning from individual brainstorming to group discussion.",
                "encourage participation": "The speaker invites Sam to contribute to the discussion, encouraging participation."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:25-01:31",
            "transcript": "Yes, and you can call me Beck. Uh let me change my name because they asked to put our full names there. So I put my full name.",
            "speaking_duration": 6,
            "nods_others": 1,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:48",
            "end_time": "01:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:32-02:08",
            "transcript": "Hi everyone. So I'm at Washington University in St. Louis or she, I'm in the Department of Computer Science, engineering, electrical systems engineering. Uh my focus is computational imaging, um which is essentially um with focus on biomedical imaging where um the goal is to use optimization and uh machine learning uh to process imaging data, so it's spatial temporal data. I'm pretty much modality agnostic, but I have worked with MRI, PET, uh light microscopy, fluorescence microscopy with many different modalities.",
            "speaking_duration": 36,
            "nods_others": 2,
            "smile_self": 83,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:55",
            "end_time": "02:31",
            "annotations": {
                "signal expertise": "The speaker explicitly states their own expertise and qualifications related to the task, mentioning their department, focus areas, and experience with various imaging modalities."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:08-02:12",
            "transcript": "Thank you. Um Ellen, I'm just going along the the squares.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 75,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:31",
            "end_time": "02:35",
            "annotations": {
                "process management": "This code applies because Maryellen Giger is managing the meeting flow by indicating she is proceeding along a list or agenda ('going along the squares')."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "02:13-02:38",
            "transcript": "My name is Ellen Sletten. I'm an assistant professor in chemistry and biochemistry at UCLA. Uh we work on optical imaging particularly focused on 1000 nanometers and above, so we call it the shortwave infrared, some people call it the near infrared too. Um and we've done a lot of probe development uh for this region and developed a excitation multiplexing based approach so we can do four color real time optical imaging in the mouse.",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:36",
            "end_time": "03:01",
            "annotations": {
                "signal expertise": "The speaker explicitly states her own qualifications and expertise in the field of chemistry and biochemistry at UCLA.",
                "develop idea": "The speaker briefly expands on her area of work, providing details about her focus on optical imaging and specific techniques."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:38-02:40",
            "transcript": "Thank you. Candace.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:01",
            "end_time": "03:03",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger verbally recognizes someone's input.",
                "encourage participation": "Maryellen Giger mentions Candace, potentially inviting her to contribute."
            }
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "02:41-03:01",
            "transcript": "Hi, I'm Candace Fleischer at Emory University um in Atlanta. Um my group primarily does in vivo MR spectroscopy and thermometry of the brain. Um so most of our models are in humans. We do some technical development work as well but primarily um applications of chemical and metabolic imaging in the brain.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:04",
            "end_time": "03:24",
            "annotations": {
                "signal expertise": "The speaker explicitly states their own expertise and qualifications related to the task, describing their work and background in MR spectroscopy and thermometry.",
                "develop idea": "The speaker is expanding on their introduction by providing details about their group's work and research focus."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:01-03:03",
            "transcript": "Thank you. Ping.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:24",
            "end_time": "03:26",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger acknowledges someone's contribution with 'Thank you'.",
                "encourage participation": "By saying 'Ping', Maryellen Giger encourages participation or at least acknowledges Ping's presence."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "03:05-04:07",
            "transcript": "Hi, um everyone. Uh I'm Ping Wang from uh Michigan State University. Um I was trained um as interventional radiologist and develop um interest in uh molecular imaging uh especially uh in diabetes area. Uh the research work uh in our uh lab focus on um uh using imaging method to check the uh transplanted eyelids or stem cell uh differentiate eyelid organoids for the type one diabetes. We also uh do um some work for the nano drug delivery uh targeting uh endogenous beta cells. The uh imaging modalities we uh use uh include um MRI, PET MRI, uh we use optical imaging a lot and uh uh recently we started use a new imaging modality um magnetic particle imaging. I look forward to talk to um everyone and work together on some uh great uh proposals.",
            "speaking_duration": 62,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:28",
            "end_time": "04:30",
            "annotations": {
                "encourage participation": "The speaker expresses his eagerness to collaborate with others on proposals."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:07-04:09",
            "transcript": "Thank you. Shiva.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:30",
            "end_time": "04:32",
            "annotations": {
                "encourage participation": "By saying 'Thank you. Shiva', Maryellen Giger is encouraging Shiva to participate or share their thoughts.",
                "process management": "This utterance helps in managing the meeting process by moving to the next person."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "04:10-04:39",
            "transcript": "Hi, this is Shiva. I'm assistant professor in University of California, Santa Cruz. My background is electrical engineering. I do work on radiation detection for um um X-ray, CT and positron emission tomography, how to improve their time resolution, energy resolution and depth of interaction. And then I do work on signal processing to improve the um image quality.",
            "speaking_duration": 29,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:33",
            "end_time": "05:02",
            "annotations": {
                "signal expertise": "The speaker explicitly states his own expertise and qualifications related to the task."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:39-04:43",
            "transcript": "Thank you. Ferdinand. Uh yeah.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:02",
            "end_time": "05:06",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "04:43-05:17",
            "transcript": "Uh yeah, I'm Ferdinand Schweser. Um I'm assistant professor in Department of Neurology at the University at Buffalo. But my training is in physics and uh I do I use physical models um to develop uh uh MRI methods that quantify tissue uh properties. and then we do a lot of translation of these techniques um into uh early clinical studies.",
            "speaking_duration": 34,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:06",
            "end_time": "05:40",
            "annotations": {
                "signal expertise": "The speaker explicitly states their own expertise, qualifications, and background in the field of physics and MRI methods."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "05:17-05:38",
            "transcript": "And uh my more neuroscience based research interest is in brain iron homeostasis. So I really focus on techniques that uh can specifically quantify brain iron. Uh I also have a second head I'm technical director for the imaging center um and there we develop um PET MRI hybrid techniques for pre clinical world and uh pre clinical MRI uh cell tracking and um and clinical MRI too.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:40",
            "end_time": "06:01",
            "annotations": {
                "develop idea": "The speaker is elaborating on their research interests, specifically in neuroscience and techniques for quantifying brain iron.",
                "signal expertise": "The speaker is explicitly stating their role and expertise, particularly in techniques related to MRI and neuroscience."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:39-05:41",
            "transcript": "Thank you. Anna Karen.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:02",
            "end_time": "06:04",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by moving from one participant to the next.",
                "encourage participation": "The speaker is inviting or acknowledging another participant, encouraging them to contribute."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "05:42-06:27",
            "transcript": "So hi. Um my name is Anna Karen and I'm an assistant professor at Rice University. Um in the chemistry department there, but I have a background in physics with optics and microscopy. So in our lab we are developing um microscopy techniques when it comes to fluorescence imaging, uh single molecule tracking and super resolution imaging. and our expertise is 3D tracking, 3D super resolution imaging uh by combining point function engineering, light sheet illumination and now we're starting to implement also microfluidics in the mix as well.",
            "speaking_duration": 45,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:05",
            "end_time": "06:50",
            "annotations": {
                "develop idea": "The speaker is elaborating on her lab's work and providing more details about their research focus.",
                "signal expertise": "The speaker is explicitly stating her own and her lab's expertise in specific areas of research."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "06:27-06:29",
            "transcript": "Uh so a lot of the work is on the methods development side.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:50",
            "end_time": "06:52",
            "annotations": {
                "develop idea": "The speaker is expanding on their previous statement about their work focus, providing more details about the direction of their research."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "06:29-06:30",
            "transcript": "Um but also working on various applications.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:52",
            "end_time": "06:53",
            "annotations": {
                "develop idea": "The speaker is expanding on their previous statement about the work they are doing, specifically mentioning they are working on various applications."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "06:30-06:32",
            "transcript": "In collaboration with biologist and biomedicine.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:53",
            "end_time": "06:55",
            "annotations": {
                "None": "No relevant code directly applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:32-06:33",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:55",
            "end_time": "06:56",
            "annotations": {
                "acknowledge contribution": "The speaker is verbally recognizing another group member's input."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:33-06:33",
            "transcript": "Uh uh.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:56",
            "end_time": "06:56",
            "annotations": {
                "None": "No relevant code applies to this utterance as it is a minimal acknowledgment and does not explicitly fit any of the provided codes."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "06:34-07:17",
            "transcript": "Yeah, uh but something but quick close. Um yeah, so I'm at UT Austin here. Professor in biomedical engineering and my lab works mostly on chemical imaging and non linear fluorescence. So we do a lot of vibrational scopic imaging to look at how molecules interact and how that is perturbed particularly in protein protein interactions and networks that are related to cancer for extra cellular matrices and bio polymer networks like um skeletal filaments in cells.",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:57",
            "end_time": "07:40",
            "annotations": {
                "signal expertise": "The speaker explicitly states their position as a professor in biomedical engineering and describes their lab's focus areas.",
                "develop idea": "The speaker elaborates on their lab's work, providing details about their research focus on chemical imaging, non-linear fluorescence, and vibrational scopic imaging."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "07:17-07:18",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:40",
            "end_time": "07:41",
            "annotations": {
                "None": "No relevant code applies to this utterance as it is a brief expression of gratitude and does not explicitly fit into any of the categories provided."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:18-07:21",
            "transcript": "And you say, did I say that right?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:41",
            "end_time": "07:44",
            "annotations": {
                "ask question": "The speaker is seeking clarification or confirmation on a previous statement, which is a direct question."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:22-07:23",
            "transcript": "Uzay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:45",
            "end_time": "07:46",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:24-07:58",
            "transcript": "Thank you so much. So my name is Uzay and I'm assistant professor at the School of Health Science at University. And I'm I'm electrical engineer but I have been doing biomedical imaging since I graduated. So and I'm MRI physicist so I am developing new techniques to answer questions, biological questions that my colleagues ask and try to translate them to clinical application. It starts from bench to bedside.",
            "speaking_duration": 34,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:47",
            "end_time": "08:21",
            "annotations": {
                "signal expertise": "The speaker explicitly states their own qualifications and expertise in biomedical imaging and as an MRI physicist.",
                "develop idea": "The speaker elaborates on their work in developing new techniques for biomedical imaging and translating them to clinical applications."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:58-08:00",
            "transcript": "Thank you.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:21",
            "end_time": "08:23",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:00-08:01",
            "transcript": "And",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:23",
            "end_time": "08:24",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Alexandra Basford",
            "timestamp": "08:08-08:17",
            "transcript": "I I'm a guest. I'm a program officer for the and group and very excited to hear um about what is exciting and new in bioimaging. Thanks.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:31",
            "end_time": "08:40",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:17-08:18",
            "transcript": "Okay. Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:40",
            "end_time": "08:41",
            "annotations": {
                "acknowledge contribution": "The speaker is verbally recognizing someone's input.",
                "supportive response": "The utterance also expresses a positive or agreeing sentiment."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:18-08:25",
            "transcript": "And we also have Ed and Megan, but we I know yesterday we didn't go through introductions if you think we should, jump in.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:41",
            "end_time": "08:48",
            "annotations": {
                "process management": "This code applies because Maryellen Giger is managing the meeting flow by suggesting that Ed and Megan introduce themselves.",
                "encourage participation": "This code applies because Maryellen Giger is inviting Ed and Megan to participate by suggesting they 'jump in' if they think it's appropriate."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:25-08:25",
            "transcript": "Nope.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:48",
            "end_time": "08:48",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:25-08:26",
            "transcript": "Okay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:48",
            "end_time": "08:49",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:26-08:45",
            "transcript": "Um uh we're going to start with some of those questions, but if you have another idea and question, we can bring that in. Also, I'm pretty excited just hearing the the mix of folks here. We go from nano to micro to macro, we're stationary, we're temporal.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:49",
            "end_time": "09:08",
            "annotations": {
                "process management": "The speaker is guiding the meeting's progression by suggesting they start with some questions.",
                "encourage participation": "The speaker invites others to contribute ideas and questions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:45-09:21",
            "transcript": "Um so I think we've got everything covered, but since this is multimodal, let's see where we can bring these two together. Usually when I hear multimodal, I think of PET CT or PET MR, but um we can also uh my dream is to have a multimodal but across scale type imaging where you could do the nano, the micro. um and the macro. But um how about um you all the experts um comments on um what do you think is the next wave for multimodal imaging? what's your dream with it?",
            "speaking_duration": 36,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "09:08",
            "end_time": "09:44",
            "annotations": {
                "develop idea": "The speaker expands on the concept of multimodal imaging, moving from traditional understandings to a broader concept across different scales.",
                "ask question": "The speaker asks for comments on what others think is the next wave for multimodal imaging and their dreams for it.",
                "encourage participation": "The speaker invites the experts to share their thoughts and opinions on multimodal imaging."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "09:21-09:23",
            "transcript": "Uh who can I start with?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "09:44",
            "end_time": "09:46",
            "annotations": {
                "encourage participation": "The speaker is inviting others to contribute to the discussion, indicating a desire to hear their thoughts or suggestions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "09:24-09:24",
            "transcript": "Ellen looks like she's thinking there.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "09:47",
            "end_time": "09:47",
            "annotations": {
                "encourage participation": "Maryellen Giger is inviting Ellen to contribute to the conversation by suggesting she looks like she's thinking."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:25",
            "transcript": "with the group I we did yesterday, we opened up a Google Drive and they kept notes and then condensed it down to what would go on the slide. First I have to ask, I uh no one can do that twice, so if you did it before, don't raise your hand. And do I have a volunteer? Or I'll do the Hollywood squared blinded pick like I did yesterday. Okay.",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 15,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:23",
            "end_time": "10:48",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by referring to a previous activity and suggesting methods for selecting a volunteer.",
                "encourage participation": "The speaker invites group members to volunteer for a task."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:26-00:28",
            "transcript": "I can volunteer actually.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:49",
            "end_time": "10:51",
            "annotations": {
                "process management": "The speaker is facilitating the meeting process by volunteering for a task."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:29-00:34",
            "transcript": "Great. Excellent Beck. Thank you. I was just going to um",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:52",
            "end_time": "10:57",
            "annotations": {
                "supportive response": "The speaker expresses agreement and validation for Beck's contribution.",
                "None": "The second part of the utterance ('I was just going to um') seems to be a transition or incomplete thought and does not fit into another code category."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "00:34-01:56",
            "transcript": "So I guess I I just want to I just want to make a comment uh because um I've been working with uh so we we're working on this pre clinical pet MRI and uh it it maybe a little bit uh cautious comment that uh there's always the hope that if you combine multiple techniques that you gain something out of it. But uh I think the key is to have an application where you really need to do both techniques at the same time where you get something out of doing it at the at the same time. For example, pet MRI uh there are not really many applications where you actually need pet MRI. Uh many applications you can do pet and then you do an MRI after that and combining the techniques always is linked to uh or most of the time is linked to a degradation of the performance of the involved techniques. So you really need I mean, I I found it personally to very challenging to find applications. And for example, we submitted a grant uh for uh uh photoacoustic tomography to be integrated into our MRI. already have preliminary data at the time we just couldn't find uh application, killer application. The grant was not funded because they said okay what do you want to do with it? I mean why do you need it? Why can't you do it sequential? So I think that's really important.",
            "speaking_duration": 82,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:57",
            "end_time": "12:19",
            "annotations": {
                "develop idea": "Ferdinand is expanding on the concept of multimodal imaging, specifically discussing the challenges and considerations of combining techniques like PET MRI.",
                "offer feedback": "Ferdinand is providing specific suggestions and insights based on his experience with preclinical PET MRI, indicating challenges in finding applications where combining techniques is necessary and mentioning the potential degradation of performance.",
                "identify gap": "Ferdinand mentions the challenge of finding applications where combining techniques like PET MRI is necessary, highlighting a gap in the current research or application of multimodal imaging."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:57-02:04",
            "transcript": "That's a good point. Yeah, do we start with the hammer and find the application or do we look at the problem and find the new hammer?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:20",
            "end_time": "12:27",
            "annotations": {
                "ask question": "The speaker is asking a question about the approach to research in multimodal imaging, seeking insight on whether to start with a technique or a problem.",
                "clarify goal": "The speaker is also slightly clarifying or questioning the goal of research in multimodal imaging, though this is less directly applicable."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "02:04-02:29",
            "transcript": "I very much agree with that. also I spend some time also in the super resolution thing as well and had a fair number of heated arguments with people who are really serious in that field about what are you doing, what are you learning? and same with my field often wondering like, you know, is the western blot enough or do you really need the sub cellular resolution that I'm providing you? You know, and I think that's a I struggle with that question a lot when I'm writing grants.",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:27",
            "end_time": "12:52",
            "annotations": {
                "supportive response": "The speaker expresses agreement with Ferdinand Schweser's comment.",
                "develop idea": "The speaker expands on the idea by sharing personal experiences with super-resolution imaging.",
                "identify gap": "The speaker discusses the gap between the resolution provided by certain techniques and what is needed."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "02:30-03:00",
            "transcript": "I I mean in case of pet MR though, I would say that there is a the big benefit of having uh them together is the co registration and that's going to be in multi modality that's going to be a problem that we're going to hit each time, especially when they're close close resolution instruments rather than, you know, super resolution microscopy versus MRI thing, right?",
            "speaking_duration": 30,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:53",
            "end_time": "13:23",
            "annotations": {
                "develop idea": "The speaker expands on the idea of combining PET and MRI, mentioning co-registration as a benefit.",
                "supportive response": "The speaker provides a positive view on combining PET and MRI, highlighting its potential.",
                "offer feedback": "The speaker offers specific considerations and challenges for multimodal imaging, providing feedback on the approach."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "03:01-03:03",
            "transcript": "Yeah, that's a killer application, right? cardiac cardiac uh where you have movement.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:24",
            "end_time": "13:26",
            "annotations": {
                "Supportive response": "The speaker is expressing agreement and validation of a previous point.",
                "Develop idea": "The speaker is building on a previous idea by providing a specific example (cardiac imaging with movement).",
                "Offer feedback": "The speaker provides a specific example as feedback, further developing the idea."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:04-03:13",
            "transcript": "Exactly. So there are kind of killer apps for those where you can actually, you know, use MR for guiding pet, but not like joint fusion or something. Yeah.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:27",
            "end_time": "13:36",
            "annotations": {
                "develop idea": "Beck Kamilov is expanding on the idea of using multimodal imaging techniques, specifically discussing the potential of using MR for guiding PET.",
                "supportive response": "Beck Kamilov provides a nuanced perspective that is generally in agreement with the challenges and considerations in multimodal imaging.",
                "offer feedback": "Beck Kamilov provides specific feedback on the use of MR and PET, discussing potential applications and limitations."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "03:14-03:42",
            "transcript": "Yeah. but billions went into the development of the technology. You have to pay $7 million or something to get such a technology and then the only application that you find is uh cardiac triggering basically or I mean I I'm there are not so many applications actually where it's essential. And and if you just think uh motion correction is the application for pet MRI, okay, maybe, but I think when people started integrating the technology, they had much higher hopes for it.",
            "speaking_duration": 28,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:37",
            "end_time": "14:05",
            "annotations": {
                "critical response": "Ferdinand Schweser is questioning, challenging, and providing a negative evaluation of the ideas and hopes for PET MRI technology.",
                "develop idea": "He is expanding and elaborating on the existing idea of combining PET and MRI technologies, discussing the practical applications and challenges."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:43-03:45",
            "transcript": "So would you have to ask um",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:06",
            "end_time": "14:08",
            "annotations": {
                "None": "No relevant code directly applies to this utterance"
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "03:45-03:47",
            "transcript": "I just want to add I just want to um some disc discussions.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:08",
            "end_time": "14:10",
            "annotations": {
                "encourage participation": "The speaker is expressing a desire to contribute to the discussion, indicating an attempt to participate and encourage their own involvement."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "03:47-04:46",
            "transcript": "Um, I I do think there's uh applications. The bottleneck uh for pet MRI is um people use it like a sequential uh scanning because there's no uh probes actually can be detected simultaneously from pet and MRI. That's a problem. Uh, for the pet MRI because uh people put them together uh just because they're complimentary to each other. MRI has very high special resolution.",
            "speaking_duration": 59,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:10",
            "end_time": "15:09",
            "annotations": {
                "develop idea": "The speaker is expanding on a previous idea or discussion about PET MRI, specifically addressing a challenge with the technology.",
                "identify gap": "The speaker identifies a bottleneck in PET MRI technology, specifically the lack of probes that can be detected simultaneously from PET and MRI.",
                "critical response": "The speaker does provide a critical perspective on how PET MRI is currently used (sequential scanning) and points out a problem with this approach."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "04:46-04:46",
            "transcript": "Oh sorry.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:09",
            "end_time": "15:09",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "04:47-04:48",
            "transcript": "can I uh sorry.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:10",
            "end_time": "15:11",
            "annotations": {
                "None": "No relevant code directly applies to this utterance as it is primarily a polite interruption or request to speak."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:49-04:53",
            "transcript": "Yes. And I just want to make sure Beck is um getting all this down Beck. I don't know if you want to go open up",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:12",
            "end_time": "15:16",
            "annotations": {
                "process management": "Maryellen Giger is managing the flow of information by ensuring Beck is capturing all the discussion points.",
                "encourage participation": "Maryellen Giger is involving Beck by checking if Beck wants to open up or continue with note-taking."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:54-04:56",
            "transcript": "you guys want me to share the screen? I can share.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:17",
            "end_time": "15:19",
            "annotations": {
                "process management": "The speaker is offering to share his screen to facilitate the discussion or presentation, which is an act of managing the meeting's flow or tools."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:57-05:03",
            "transcript": "If you open you could are you type what are you typing into? Here. A Google Doc. Okay.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:20",
            "end_time": "15:26",
            "annotations": {
                "ask question": "The speaker is asking for information or clarification on how to collaboratively work on a document, specifically if someone is typing into a Google Doc.",
                "process management": "The speaker is facilitating the collaboration process by inquiring about the method of document sharing or editing."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:03-05:03",
            "transcript": "Here.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:26",
            "end_time": "15:26",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "05:04-05:07",
            "transcript": "I I just want I haven't finished. I'm sorry.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:27",
            "end_time": "15:30",
            "annotations": {
                "process management": "The speaker is attempting to manage the conversation flow by indicating they haven't finished speaking."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "05:07-05:07",
            "transcript": "Oh sorry.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:30",
            "end_time": "15:30",
            "annotations": {
                "None": "The utterance is a simple expression of apology without any additional content that could be coded according to the provided definitions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:09-05:16",
            "transcript": "So we're going to get right back to you Ping but maybe Beck if you can share the link to the Google Drive and that way people can add stuff.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:32",
            "end_time": "15:39",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by asking Beck to share a link to the Google Drive to facilitate group participation and organization."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:17-05:17",
            "transcript": "Yeah, definitely.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:40",
            "end_time": "15:40",
            "annotations": {
                "Supportive response": "The utterance 'Yeah, definitely.' expresses agreement or confirmation, which is a positive evaluation or validation of what was previously said."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:18-05:28",
            "transcript": "Okay. Does that sound good? All right. And that way you don't have to share it because it's it I think it's harder to see but I can crunch up all of you on one side of my screen and open up the Google Drive.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:41",
            "end_time": "15:51",
            "annotations": {
                "Supportive response": "The speaker is facilitating the group process and expressing a positive sentiment towards the proposed solution.",
                "Process management": "The speaker is organizing how the group will work together, suggesting a method for sharing information.",
                "Encourage participation": "The speaker is creating an environment for group members to participate by suggesting a collaborative approach."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "05:28-05:30",
            "transcript": "Should I go back?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:51",
            "end_time": "15:53",
            "annotations": {
                "process management": "The speaker is inquiring about their role or positioning in the conversation, which relates to managing the discussion flow."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:31-05:34",
            "transcript": "Yes, put in yeah, if you put the link in the chat, that's probably easiest.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:54",
            "end_time": "15:57",
            "annotations": {
                "process management": "The speaker is suggesting a more efficient way to share a link to a Google Drive document, thereby managing the flow of information within the group."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:35-05:40",
            "transcript": "Thank you. And Ping we didn't forget about you. We're going back to you right now but I just needed to do some logistics. Okay.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "15:58",
            "end_time": "16:03",
            "annotations": {
                "process management": "The speaker is managing the meeting flow, indicating a transition and explaining the reason for the temporary pause.",
                "acknowledge contribution": "The speaker acknowledges Ping, showing that she hasn't been forgotten, which helps in managing group dynamics."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "05:41-07:01",
            "transcript": "Yeah, um for example for the cell transplantation and the nano drug delivery, we do need uh like uh for beta cell endogenous beta cell uh targeted uh drug delivery. We do need the high resolution. Also we want to have the higher uh sensitivity to detect the nano drugs and especially for the endogenous beta cells like only 2%, less than 2% of the whole uh pancreatic pancreatic tissue. So the problem now is like probably I think the chemist need to like work more on the synthesize and design for the nano particle or whatever probes or tracers, uh you can put together uh and can be detected by by both like MRI and pet. Now, um for example, we're trying to uh label the cells for the MRI and pet. I I work on the pre clinical uh scanner for pet MRI uh for tracing the tracking the cells. We give you an example, we label the cells with iron oxide nano particle, so it can can be detected by MRI. Um, we're trying to uh like also put some radio labeling on the nano particle or just direct label the cells. But it's kind of difficult um because because the pet um uh the the the the I mean the the limitation for the half lifetime also uh for the for the labeling uh because because um I mean that's some problem uh for the chemist. I do think there's applications and I I agree uh um for some comments uh it's it's very expensive if just use it for diagnosis uh in clinic. I mean, um people will just say why why don't you do the sequential scanning? What's the point to do it simultaneously? If you can co co register the images together anyway. Yeah.",
            "speaking_duration": 80,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "16:04",
            "end_time": "17:24",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas about PET MRI, discussing its applications and challenges.",
                "identify gap": "The speaker identifies a gap in current technology, specifically the need for better probes or tracers for PET MRI.",
                "offer feedback": "The speaker offers feedback on the challenges of using PET MRI for certain applications, suggesting areas for improvement."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "07:01-07:01",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "17:24",
            "end_time": "17:24",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:01-07:01",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "17:24",
            "end_time": "17:24",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:01-07:01",
            "transcript": "What?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "17:24",
            "end_time": "17:24",
            "annotations": {
                "ask question": "Maryellen Giger is requesting information or clarification as indicated by her question 'What?'."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:01-07:02",
            "transcript": "Yes.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "17:24",
            "end_time": "17:25",
            "annotations": {
                "None": "No relevant code applies to this utterance in a meaningful way that adds significant value beyond acknowledgment."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:02-08:44",
            "transcript": "Thank you so much. So um I think I I was in a optical group yesterday and I was at the microscopic level imaging person and I couldn't find a channel to intervene to discussions here. I we do have the optical people. I think we are talking in the microscopic level and they might have the same problem. So I think we should try to think uh my mentor was always saying how we are going to do this mesoscopic scale to microscopic scale translation. So I think that is that is the even though we are doing MRI, we are far from anything that is come to the neurons and it cellular level. So they are indirect measurements at the end of the day, we will be far from anything that underlying physiology or what is happening in the cellular level. So that is going to be the eventual consequence of using MRI, pet and all those things. Yes, they are powerful, they are clinically useful, but uh we need to try to make the bridge between the very high resolution between the uh microscopic measurements that we do with the MRI. So the way how I do see that for example, try to use the optical imaging that might be so if we are going to think about the multi modality, we should do um small animal models and that we can try to figure out that for example, optical contrast that might generate us different contrast with MRI and and then we can use it to pinpoint the problems that we are looking for. For example, we can do I don't know so the iron they they cause scattering in optical imaging and they use this for example, we can inject those iron into the animal and try to use that iron contrast in the MRI modality and see what it is causing because all entire functional MRI is relying on uh paramagnetic effects of the deoxyhemoglobin which is very strictly iron contrast. So maybe we can amplify the uh signal intensity using this iron of the creative or insanity ideas so",
            "speaking_duration": 102,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "17:25",
            "end_time": "19:07",
            "annotations": {
                "propose new idea": "The speaker proposes using small animal models to bridge the gap between microscopic and macroscopic imaging, suggesting a new approach to multimodal imaging.",
                "develop idea": "The speaker elaborates on using optical imaging and iron-based contrast agents to enhance MRI signal intensity, building upon existing ideas.",
                "identify gap": "The speaker identifies a gap in current imaging capabilities, particularly in directly observing neurons and cellular levels with techniques like MRI."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:44-08:45",
            "transcript": "So we",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "A Google Docs document titled \"Recorder for Multimodal Imaging\" is shared. The document contains notes from Ferdinand, Sapun, and Beck.",
            "start_time": "19:07",
            "end_time": "19:08",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:00-00:40",
            "transcript": "of going from the nano to the micro to the macro. the other thing is seems to be we first need to identify some major use cases, some major problems that would benefit from going through the scales and then we have to ask the question, do we need to worry about spatial registration and temporal registration and how does that complicate it. So I'm thinking where in this Candace, do you see um uh your work fitting and where might it be expanded um if you had this capability.",
            "speaking_duration": 40,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:23",
            "end_time": "21:03",
            "annotations": {
                "develop idea": "The speaker is elaborating on the concept of multiscale imaging, discussing its potential and challenges.",
                "ask question": "The speaker asks Candace about her work and how it might fit into or be expanded by the capability of multiscale imaging.",
                "encourage participation": "The speaker directly asks Candace for her thoughts and opinions, inviting her participation."
            }
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "00:40-02:30",
            "transcript": "Yeah, I guess um, I'm not sure about my specific work, but when I think of really big challenges in the field, um, I think of like just huge things, like if we could fix tomorrow we'd change medicine. So, you know, why why is medicine still not personalized? Why do we throw the same hammer at every patient and hope that we'll get something. And then related to that, we do so much imaging, especially in the clinical setting where we do, let's say we do a CT and we're like we're not sure, we better go back and do an MRI, we're not sure, maybe we need an intervention, we need to go back again. And related to that, we have a lot of data in in the clinical case that we throw away. So if we think about complementary imaging, um, you know, if I'm thinking of like huge ideas, what if we had every technique in a single instrument and we sample everything sparsely, so we take, you know, micro scale, nano scale, fluorescence, optical, whatever whatever your favorite technique is in in a modular way and we never needed to throw away data and if the MRI wasn't successful, we also had sparse CT data or we had sparse optical fluorescence data on the cellular level. And I guess it's not particularly, I mean it's related to what I do in in a clinical setting, but I think I think that's what I think of the big problem is we do so much extremely expensive, like prohibitively expensive imaging and we don't even get what we want most of the time and we don't even get cellular or microscopic data on what's actually going on in the diseases. So I I don't have a good application case, but I think if I'm thinking about big problems in the field, that those are the big problems that I see like I I wasn't sure how big we're supposed to be thinking, but if I'm thinking yeah, what do I want to push a button to change today, that would be it.",
            "speaking_duration": 110,
            "nods_others": 1,
            "smile_self": 10.0,
            "smile_other": 10.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:03",
            "end_time": "22:53",
            "annotations": {
                "identify gap": "The speaker highlights gaps in current medical practices, such as the need for personalized medicine and more efficient use of imaging data.",
                "critical response": "The speaker questions current practices in medicine and imaging, expressing dissatisfaction with the status quo."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "02:30-02:54",
            "transcript": "And I also you know, it's a minor point but using data from clinical scanners, sometimes you can't even get it because of proprietary software on that clinical scanner and if you could get to the raw data, you could do more of what you want to do. And so um uh so Ellen, what are you thinking about? I see your head shaking.",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:53",
            "end_time": "23:17",
            "annotations": {
                "encourage participation": "The speaker invites Ellen to share her thoughts by saying 'And so um uh so Ellen, what are you thinking about? I see your head shaking.'",
                "None": "No other code seems to directly apply besides encourage participation, as the primary function is to invite discussion rather than perform another action described in the codebook."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "02:54-03:38",
            "transcript": "Yeah, I I really wanted to second essentially everything you said and that we have these beautiful tools to look at cellular processes and then we just really can't extend them even well into animal models. And if we could use multimodal approaches to take starting what already works so well in cells and be able to, you know, translate to mice, translate to, you know, maybe even some intermediate mammal before getting to humans. I think that that would be really impactful just from the basic science to get us to really understand molecular processes even in animal models before thinking about the clinic.",
            "speaking_duration": 44,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:17",
            "end_time": "24:01",
            "annotations": {
                "develop idea": "The speaker expands on existing ideas about using multimodal approaches for extending research from cellular to animal models.",
                "identify gap": "The speaker identifies a gap in current capabilities: extending cellular process tools into animal models.",
                "supportive response": "The speaker agrees with and positively evaluates previous ideas."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:38-03:43",
            "transcript": "And I'm trying to make sure everyone has a chance to um bring their thoughts forward.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:01",
            "end_time": "24:06",
            "annotations": {
                "encourage participation": "The speaker is inviting others to share their thoughts, ensuring everyone has a chance to contribute.",
                "process management": "The speaker is managing the discussion flow by ensuring everyone gets a chance to speak."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:43-04:33",
            "transcript": "but at any of those who have already spoken, um, if you um, you know, kind of maybe use the hand or um, just start talking. But I think it's really important um to get all these aspects. I think we have key points forming. Um, uh, how about a more of a discussion on use cases? What are the use cases that, you know, let's say you someone said we'll go work on taking the molecular um cellular imaging and move it into mice. What use case pops out? What because sometimes the problem drives the next development. Um, Shiva, do you have a use case or Sampoon, what do you folks think?",
            "speaking_duration": 50,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:06",
            "end_time": "24:56",
            "annotations": {
                "encourage participation": "The speaker invites participants to share their thoughts and ideas, specifically asking Shiva and Sampoon for their input.",
                "identify gap": "The speaker is seeking use cases for moving molecular or cellular imaging into mice, indicating a recognition of a gap in current applications or research.",
                "develop idea": "The speaker is expanding on the discussion by suggesting a focus on use cases and exploring how multimodal imaging can address specific challenges."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "04:33-06:00",
            "transcript": "Uh, yeah, I totally second that that I like kind of almost every night I ask myself that why I'm doing what I'm doing because to me like working towards the problem statement especially from like for me developing hardware is really important and then like regarding that I wish that for example if I had a multimodal imaging modality that I could just like image a spiking of the neuron because you know like kind of this is like from before my father passed away like I got interested to learn about Alzheimer disease then I was like doing pit and then I was like oh maybe I should like now push the sensitivity of pit to be able to do more dynamic pits but then I was like okay still I'm not able to you know like image a spiking of the neuron and then now I'm just trying to learn about what kind of combination of other modality like I can leverage to like see how like to image functioning of the brain. So then like that that is kind of like as if a question for the group that what do you think guys if you wanted to like image a spiking of the neuron in the brain, what imaging modality or what are the combination that could be good.",
            "speaking_duration": 87,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:56",
            "end_time": "26:23",
            "annotations": {
                "ask question": "Shiva is explicitly asking the group for their thoughts on how to image neuronal spikes, which is a clear request for information or expertise.",
                "identify gap": "Shiva identifies a gap in current imaging capabilities (imaging neuronal spikes).",
                "encourage participation": "Shiva is inviting the group to share their thoughts."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:00-06:01",
            "transcript": "Nick, that's great.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:23",
            "end_time": "26:24",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or positive evaluation for something said by Nick."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:01-06:02",
            "transcript": "Sorry, go ahead.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:24",
            "end_time": "26:25",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:02-06:05",
            "transcript": "No, no. I I'm more than happy for people to speak up.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:25",
            "end_time": "26:28",
            "annotations": {
                "supportive response": "Expressing agreement and positive sentiment towards encouraging participation.",
                "encourage participation": "Explicitly inviting others to contribute their thoughts or ideas."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "06:05-06:52",
            "transcript": "I I think that the one the not necessarily exactly what I do. I mean, we do some of this, but not honestly a lot of it is I think that there's this intravital, you know, multiphoton microscopy that people do when they want to image exactly, you know, the functioning of the brain in a small animal like a a mouse or a rodent. I I I've even heard some people trying to do this now at the scale of a monkey. I don't know if somebody here is trying to do that. I don't know if they're going to get their protocol approved.",
            "speaking_duration": 47,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:28",
            "end_time": "27:15",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges the work of others in intravital multiphoton microscopy.",
                "encourage participation": "The speaker invites others to share their work or thoughts on the topic.",
                "ask question": "The speaker asks if others are working on similar projects, particularly at the scale of a monkey."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "06:52-07:36",
            "transcript": "But I mean, you're always kind of limited with this sort of, let's call it a millimeter, right? Like it's not going to happen past a millimeter with visible radiation. And a millimeter is pushing it. Those are the world class research labs that can get to like 1.2 millimeters. But I think it's really hard to get that cellular level resolution at a centimeter deep and you might want to do that. Like when I think I don't know, when Candace was talking, I just had this weird, I don't know, imagination in my head where I'm like somebody on a bed and then they're in a scanner and you've got like 30 probes on them to get every sort of level of imaging that you want and how many of those are really feasible.",
            "speaking_duration": 44,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:15",
            "end_time": "27:59",
            "annotations": {
                "identify gap": "The speaker explicitly discusses the limitations and challenges of current imaging techniques, particularly in achieving cellular level resolution at deeper tissue depths, which aligns with identifying gaps in current capabilities."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "07:36-07:48",
            "transcript": "Right? The clinical ones are definitely feasible because you can pay $5 million to go to a hospital tomorrow if you need to and and get imaging whether good, bad or ugly, it can be done at least.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:59",
            "end_time": "28:11",
            "annotations": {
                "supportive response": "The speaker expresses agreement with previous statements about the feasibility of certain imaging techniques in clinical settings.",
                "critical response": "The speaker critiques the feasibility of imaging techniques by pointing out the high cost associated with accessing them in hospitals."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "07:48-08:48",
            "transcript": "But the optical ones I really think are challenged at that problem. We really do well at working at cover slips and single cells and subcellular things and nano domains like what Anika does and you know, so what I do, but we aren't really good at looking at really big samples. Like I got to be honest. Yeah, and can I add to Sapoon's am I pronounced right? Yeah. Okay. Um, I think I'm I'm really not limited about the resolution because right now there are laminar FMRIs they can go down to the sub millimeter resolution to get the laminar brain activation using seven Tesla scanners and it is getting very common in the occipital cortex using the advanced technology and even if you go to do even higher fields, you can reduce so there's reason uh I framed that mesoscopic to microscopic level so and at this level the functional activation can be detected from human brain is sub millimeter level. So that allows us to map the laminar levels of the brain activation.",
            "speaking_duration": 60,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:11",
            "end_time": "29:11",
            "annotations": {
                "Develop idea": "The speaker is elaborating on the capabilities and limitations of optical imaging techniques, building on previous discussions.",
                "Identify gap": "The speaker identifies a gap in the capability of optical imaging to look at really big samples.",
                "Signal expertise": "The speaker is sharing their expertise in optical imaging and its applications."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:00-00:25",
            "transcript": "that it is it is the it is it's providing unique opportunity to see these things at the same time with optical imaging and that provides useful information and MRI and you can pinpoint really important features together with that. So I I don't think the technical wise it is it is pretty open if we use the devices as appropriate as possible.",
            "speaking_duration": 25,
            "nods_others": 1,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:23",
            "end_time": "30:48",
            "annotations": {
                "develop idea": "The speaker is elaborating on the benefits of combining optical imaging and MRI.",
                "supportive response": "The speaker is expressing agreement and a positive evaluation of the idea of combining optical imaging and MRI.",
                "offer feedback": "The speaker is providing a suggestion for how to move forward, implying that the technical aspects are manageable if the devices are used appropriately."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:25-00:26",
            "transcript": "Yeah, I would",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:48",
            "end_time": "30:49",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "00:26-00:27",
            "transcript": "Anna, oh, go ahead.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:49",
            "end_time": "30:50",
            "annotations": {
                "encourage participation": "Ellen invites Anna to contribute to the discussion, encouraging her participation.",
                "supportive response": "Ellen's statement is supportive as it encourages Anna to share her thoughts."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "00:27-02:01",
            "transcript": "Yeah, I would like to chime in kind of coming from the other side of things, you know, going from the molecular nanoscale and our problem is really scaling up, right? How do we push that technology into tissues to make it, you know, we even starting with tissue slices from from patients from hospitals. Um, and there are a few different considerations, right? You have the scattering and the limitations from optics, you know, how how do we improve adaptive optics and combine that to be able to image with high resolution deeper and deeper into tissues. Um, and then you come to the other aspect of the field of you just, you know, becoming larger and larger when we're typically imaging a single cell, right? Even a single cell is large for us. How do you need higher throughput methods, data, you know, data analysis, online analysis to kind of zoom in on what aspects or what parts of the sample should we kind of zoom in on. Um, do you want to do tiling to really get, you know, all of it or is it enough to have other modalities guide, you know, take a close view at this particular section. So yeah, those are some thoughts, both the scaling up, high throughput, online image analysis, very fast acquisitions and data handling with the adaptive optics and really improving and pushing what can be done when it comes to how how deep, how thick can we image.",
            "speaking_duration": 94,
            "nods_others": 0,
            "smile_self": 20.21,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:50",
            "end_time": "32:24",
            "annotations": {
                "identify gap": "The speaker identifies gaps in current imaging capabilities, especially in scaling up from molecular to tissue levels.",
                "supportive response": "The utterance is supportive, engaging with the challenges discussed and sharing thoughts.",
                "summarize conversation": "The speaker summarizes and discusses key considerations in advancing multimodal imaging technology."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:01-02:04",
            "transcript": "I like that I sorry.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 33.33,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:24",
            "end_time": "32:27",
            "annotations": {
                "supportive response": "The speaker expresses agreement or validation for a previous statement."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "02:04-02:04",
            "transcript": "Yeah, please.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:27",
            "end_time": "32:27",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:04-02:06",
            "transcript": "in go ahead.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:27",
            "end_time": "32:29",
            "annotations": {
                "supportive response": "The utterance 'in go ahead' is a positive and encouraging response, supporting the continuation of discussion.",
                "encourage participation": "The utterance 'in go ahead' invites or encourages someone to proceed with their thoughts or comments, promoting participation."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "02:07-02:28",
            "transcript": "No, yeah, it's just kind of at what point are we good enough so that we can switch over to a different modality that is better at the larger scale, right? How how far can we push it from from the smallest scale until it's good enough to kind of or that that can be guided by some other modalities.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 23.81,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:30",
            "end_time": "32:51",
            "annotations": {
                "ask question": "The speaker explicitly asks questions about the limitations and potential of imaging modalities.",
                "develop idea": "The speaker is elaborating on the challenges and considerations of using different imaging modalities at various scales.",
                "identify gap": "The speaker touches upon the limitations of current modalities, implying a recognition of gaps in current imaging capabilities."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:28-03:25",
            "transcript": "Yeah, I think you bring up a really good point. A lot of times we look at multimodality so that we get two different two different types of characteristics say of a patient simultaneously where they're co-registered in time and and space. However, you you noted um tiling or um and we've looked at it even using AI to, you know, you find a suspicious area on at one spatial resolution, say MRI or X-ray or something, and you use AI on that to go down into your scale. So you're using either humans to go find that area or AI, but you're zooming down into the higher spatial resolution. So it's multimodality at two different scales, not simultaneous imaging, but having one guide the other. Uh I think that's that's that's one of the different ways of looking at multimodal. Are you using it simultaneously, you're using it one to get to the other. And I know Ellen has something to say.",
            "speaking_duration": 57,
            "nods_others": 0,
            "smile_self": 10.53,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:51",
            "end_time": "33:48",
            "annotations": {
                "develop idea": "The speaker is expanding on the concept of multimodality, discussing its applications and methods.",
                "summarize conversation": "The speaker is summarizing the conversation about multimodality, highlighting different approaches and considerations."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "03:26-04:07",
            "transcript": "Oh yeah, I was I was maybe going to make a more of a pitch for optical and I think that we can do beyond one millimeter and it's really all about kind of signal to noise and like what your background is and so thinking about imaging in regions where you have little background, thinking about, you know, probes that turn on um and you know, we haven't really talked about that that I feel like that is simplest maybe for optical, but it's definitely possible for MRI as well and you know, that will kind of been really enhance some of this sensitivity uh issues.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 12.2,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:49",
            "end_time": "34:30",
            "annotations": {
                "propose new idea": "The utterance suggests exploring optical imaging capabilities beyond one millimeter.",
                "develop idea": "The speaker expands on optical imaging, discussing signal to noise ratio, background, and potential applications."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "04:07-04:07",
            "transcript": "Um.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:30",
            "end_time": "34:30",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "04:07-04:38",
            "transcript": "But in terms of what the discussion we were just having and like complementary aspects, I I think the temporal aspect of these imaging modalities is also very distinct and you know, optical is really fast and then you know, so if you wanted to look at things in in real time, you would be able to do that. Um, and then maybe if you really need better penetration at a later time point, you know, this would be another place where things like optical and MRI I think would be nice compliments.",
            "speaking_duration": 31,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:30",
            "end_time": "35:01",
            "annotations": {
                "supportive response": "The utterance provides a positive evaluation for combining optical and MRI imaging modalities.",
                "develop idea": "The speaker expands on the idea of using different imaging modalities for complementary benefits."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:39-04:40",
            "transcript": "Can I also throw something in?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:02",
            "end_time": "35:03",
            "annotations": {
                "encourage participation": "The speaker is seeking permission to contribute to the discussion, which can be seen as an indirect way of encouraging participation by seeking an opportunity to add to the conversation."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:40-05:13",
            "transcript": "Uh I think one thing we can think about in the context of multimodality is uh so one thing we're the way we're thinking right now in this discussion is we're thinking about images, right? You get this image in very high nanoscale resolution, you get another one at millimeter scale and we're trying to bridge. Another way to think about the information content, right? Uh what I mean by this is that maybe when we work with multimodality, what we want to extract from the modalities are not necessarily images, right?",
            "speaking_duration": 33,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:03",
            "end_time": "35:36",
            "annotations": {
                "develop idea": "The speaker is expanding on the existing discussion about multimodality by suggesting a shift in perspective towards considering the information content extracted from different modalities, not just images."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:13-05:46",
            "transcript": "But some kind of information that now can be correlated at a at a more abstract level. So I don't necessarily want to correlate pixels but say I want to use it for clinical diagnostics. So if I see something in a molecular level, can there be patterns that could be seen at uh say MRI level and then can we kind of bridge them at a more abstract level saying if I observe certain things.",
            "speaking_duration": 33,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:36",
            "end_time": "36:09",
            "annotations": {
                "propose new idea": "The speaker suggests correlating information at a more abstract level across different imaging modalities for clinical diagnostics.",
                "develop idea": "The speaker expands on the concept of multimodality by suggesting a focus on abstract level correlations rather than direct image comparisons.",
                "ask question": "The speaker inquires about the possibility of observing patterns at an MRI level that correlate with molecular level observations."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:46-05:47",
            "transcript": "That's what humans do, right?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:09",
            "end_time": "36:10",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or validation for the preceding discussion, reflecting on how humans correlate information from different sources."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:47-05:50",
            "transcript": "We look at those images and I go there is some issue.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:10",
            "end_time": "36:13",
            "annotations": {
                "critical response": "The speaker identifies an issue with the images they are examining.",
                "None": "No"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:50-05:51",
            "transcript": "I correlated to something else there is some issue.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:13",
            "end_time": "36:14",
            "annotations": {
                "develop idea": "Beck Kamilov is trying to correlate information from different imaging modalities, building upon existing ideas.",
                "critical response": "He is pointing out an issue, implying that current approaches may not be fully integrated or satisfactory."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:51-05:51",
            "transcript": "And then I decide.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:14",
            "end_time": "36:14",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:51-05:55",
            "transcript": "But that's something in principle that could be done with AI ML.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:14",
            "end_time": "36:18",
            "annotations": {
                "develop idea": "The speaker expands on a previously mentioned idea by suggesting AI and ML could enable certain capabilities in multimodal imaging."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:55-06:00",
            "transcript": "Yes, I I think it's like a third use case, general use case. I I I very very good um.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:18",
            "end_time": "36:23",
            "annotations": {
                "supportive response": "The utterance expresses agreement and a positive sentiment towards the discussion on use cases, indicating a supportive response."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:00-06:11",
            "transcript": "you know, in fact that's I'm more of an AI imager than an imager. Um, I should say and you know, we merge.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:23",
            "end_time": "36:34",
            "annotations": {
                "signal expertise": "The speaker mentions being 'more of an AI imager than an imager', which can be seen as signaling her expertise or background in AI applications in imaging."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:11-06:23",
            "transcript": "Where do you do the fusion? That's the question. Do you fuse when you're image? Do you fuse by um relating by um post imaging relating.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:34",
            "end_time": "36:46",
            "annotations": {
                "ask question": "Requesting information or clarification on the process of fusing or integrating data from different imaging modalities.",
                "process management": "Managing the flow of discussion to steer it towards methodological considerations of multimodal imaging.",
                "clarify goal": "Seeking clarity on the objectives or methods of multimodal imaging, specifically about when and how data fusion occurs."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:23-06:30",
            "transcript": "Or do you fuse at the feature level that you've brought out about something which you can do at multiple um things.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:46",
            "end_time": "36:53",
            "annotations": {
                "Ask question": "The utterance is a question about fusing data at the feature level.",
                "Develop idea": "The utterance expands on the idea of data fusion in multimodal imaging."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:30-06:31",
            "transcript": "I think um uh.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:53",
            "end_time": "36:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:31-06:33",
            "transcript": "fusion aspect might be.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:54",
            "end_time": "36:56",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:33-06:34",
            "transcript": "Good to think about.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:56",
            "end_time": "36:57",
            "annotations": {
                "supportive response": "The speaker is expressing a positive sentiment towards the discussion or ideas presented, indicating agreement or validation."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:34-06:35",
            "transcript": "Yeah, I think so.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:57",
            "end_time": "36:58",
            "annotations": {
                "Supportive Response": "The speaker is expressing agreement or validation with a previous statement.",
                "Acknowledge Contribution": "The speaker is verbally recognizing a previous contribution, even though it's a brief agreement."
            }
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "06:41-07:48",
            "transcript": "back I really like that idea because I was going to suggest what if so we always train our AI models on our modality and then some outcome or disease or or cellular change. But what if we train our AI models using cellular or microscopic or nanoscale data to predict what we see with MR or microscopic images. So what if we actually train the models between modalities and I think that's a really broad thing. Actually that was something I would love to work on is for example, I get I I take an MRI image of a patient, then we do a biopsy. I take the sample, I send it to you, you train your image and can you predict my MR image? I think that would be a great use case. I would love to work on something like that. And I think that's really broadly impactful, right? Could we predict from what we see in the cell, which we do anyways, we do pathology on all of our patients, you know, especially if there's a tumor, what if we took that and then could predict and I don't even have to do a $2,000 MRI scan. Um, I don't know, this is one idea. I I would be interested in working on something like that. I'm not sure if we're supposed to be talking about really concrete proposal ideas, but",
            "speaking_duration": 67,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:04",
            "end_time": "38:11",
            "annotations": {
                "propose new idea": "Candace suggests a new approach for training AI models using cellular or microscopic data to predict MRI images."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "07:49-07:51",
            "transcript": "I would like to build on that idea.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:12",
            "end_time": "38:14",
            "annotations": {
                "develop idea": "The speaker is expressing a desire to build upon a previous idea, indicating an expansion or elaboration of existing suggestions."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "07:51-07:52",
            "transcript": "I'd like to move it one step further even.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:14",
            "end_time": "38:15",
            "annotations": {
                "encourage participation": "The speaker is expressing interest in further developing an idea, which encourages continued participation in the discussion."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "07:52-08:13",
            "transcript": "So assume you have some histopathological biopsy or something and you correlate that with the MRI that you also acquire in that region before or you train the model or whatever.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:15",
            "end_time": "38:36",
            "annotations": {
                "develop idea": "The speaker is expanding on a concept of correlating different types of medical data.",
                "offer feedback": "The speaker is suggesting a way to approach the issue of data correlation.",
                "clarify goal": "The speaker is discussing a goal of effectively using data from different sources."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "08:13-08:57",
            "transcript": "And then you could use the MRI and look for the same pattern on a spatial scale and then basically predict from that again the pathology throughout the brain or see where you have a similar pattern in the brain. So you go basically across scales and combine really the methods um because if for example if you would do microscopic technique of whatever neuron firing or something, you could image only a certain a very small percentage of the brain and you can only relate you can only correlate MRI say uh with the microscopy technique at that special location.",
            "speaking_duration": 44,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:36",
            "end_time": "39:20",
            "annotations": {
                "develop idea": "The speaker is expanding on the idea of combining MRI and microscopic techniques across scales to predict pathology.",
                "identify gap": "The speaker highlights the limitation of microscopic techniques in correlating with MRI data across the brain.",
                "offer feedback": "The speaker provides a perspective on how to improve or combine methods for better pathology prediction."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "08:57-08:57",
            "transcript": "Yeah, I",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:20",
            "end_time": "39:20",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "08:57-09:00",
            "transcript": "I I totally agree.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:20",
            "end_time": "39:23",
            "annotations": {
                "None": "The utterance is a simple agreement without adding new content to the discussion."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "09:00-09:31",
            "transcript": "I think in clinic actually as Candace said, um, you can get your, um, like a like histology, you don't need to do the MRI, but actually in clinic it's opposite. So patients get MRI, they want to get the histology because it's like a I mean invasive procedure.",
            "speaking_duration": 31,
            "nods_others": 0,
            "smile_self": 12.9,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:23",
            "end_time": "39:54",
            "annotations": {
                "acknowledge contribution": "The speaker references and builds upon a prior statement by Candace.",
                "develop idea": "The speaker expands on the discussion by providing insights into clinical practices regarding MRI and histology."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "09:31-09:35",
            "transcript": "So so if you can get MRI and predict the histology, that's going to be a",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:54",
            "end_time": "39:58",
            "annotations": {
                "develop idea": "The speaker is expanding on the concept of using MRI for predicting histology.",
                "supportive response": "The speaker is expressing agreement or support for the idea of predicting histology with MRI.",
                "identify gap": "Implicitly identifying a gap in current capabilities (predicting histology non-invasively)."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "09:35-09:37",
            "transcript": "very brilliant, yeah, approach.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:58",
            "end_time": "40:00",
            "annotations": {
                "Supportive Response": "The speaker is expressing agreement and positive evaluation for the idea discussed.",
                "None": "No other relevant code applies to this utterance as it primarily serves as a supportive comment."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "09:37-09:38",
            "transcript": "I totally agree.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:00",
            "end_time": "40:01",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with a prior statement, showing support without adding new content."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "09:38-09:38",
            "transcript": "I really like this idea.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:01",
            "end_time": "40:01",
            "annotations": {
                "Supportive response": "Expressing agreement or positive evaluation for the idea proposed by Candace Fleischer."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:01-00:28",
            "transcript": "we have this N dimensional plot of all the characteristics and limitations of all the modalities. I I want to point out that I I think you know one of the things we we use the term virtual biopsy where we hope to uh you know because you in for example in a screening situation, for example with breast cancer, you can't biopsy people in a screening situation, right?",
            "speaking_duration": 27,
            "nods_others": 0,
            "smile_self": 11,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:24",
            "end_time": "40:51",
            "annotations": {
                "summarize conversation": "The speaker references a previous discussion about modalities and their characteristics.",
                "develop idea": "The speaker discusses the concept of virtual biopsy in the context of screening situations."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:28-00:42",
            "transcript": "But you can image. But if you can relate that to subsequent biopsies on a different population, then when you do the imaging, you can extract out features, you can predict if it's cancer or not and that's why it's called virtual biopsy.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:51",
            "end_time": "41:05",
            "annotations": {
                "develop idea": "The speaker is elaborating on the concept of virtual biopsy and its implications for predicting cancer, which involves expanding on an existing idea through explanation and example."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:42-01:01",
            "transcript": "So I but it's it's um it's still slowly crossing over to um uh clinical use and that's I think a very important area and I just say one more thing and then I'm going to give it back to you is one of the features is heterogeneity. Cancer is very heterogeneous.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:05",
            "end_time": "41:24",
            "annotations": {
                "clarify goal": "The speaker adds a point about heterogeneity in cancer, contributing to understanding the goals or aspects of the discussion.",
                "process management": "The speaker indicates she will give the floor back, managing the discussion flow."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "01:01-01:09",
            "transcript": "So in histopathology and and looking at the genomics, they look at the the heterogeneity within the tumor.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:24",
            "end_time": "41:32",
            "annotations": {
                "clarify goal": "The speaker is clarifying or expanding on the concept of studying tumor heterogeneity through histopathology and genomics, which relates to defining or clarifying objectives or outcomes of the research."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "01:09-01:18",
            "transcript": "And we can look at the heterogeneity within a breast MRI. You can look at the heterogeneity of the uptake which is related to the angiogenesis.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:32",
            "end_time": "41:41",
            "annotations": {
                "develop idea": "The speaker is expanding on the concept of using MRI to observe heterogeneity, relating it to angiogenesis.",
                "supportive response": "The speaker is providing a positive evaluation of using MRI for observing heterogeneity."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "01:19-01:39",
            "transcript": "But and and so we know how to do both of those, but then to relate them to cross the scale needs a massive data set of patients that have both. And in fact in the histology instead of a tiny piece of tissue, you could actually do it's almost like a bread slice through the organ.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:42",
            "end_time": "42:02",
            "annotations": {
                "develop idea": "The speaker expands on the idea that correlating imaging data with histology data requires a significant amount of data.",
                "identify gap": "The utterance implicitly identifies a gap in current research - the lack of a massive data set that includes both imaging and histology data for correlating across scales.",
                "offer feedback": "The utterance provides a suggestion for an alternative approach in histology, like doing a 'bread slice' through the organ."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "01:39-01:57",
            "transcript": "And you get this massive histology and I think the folks here who are doing microscopy do that, but now it's a big piece of tissue, you have the entire tumor, you can look at the heterogeneity of your um uh um tissue and relate it to the heterogeneity which you see in your MRI or.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:02",
            "end_time": "42:20",
            "annotations": {
                "develop idea": "The speaker is expanding on existing ideas about using massive histology and MRI to study tumor heterogeneity, elaborating on how these methods can complement each other."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "01:57-02:13",
            "transcript": "ultrasound or something. There are different types of heterogeneity, but it's that heterogeneity keeps popping up across scales even though it's heterogeneity of different things. So I think you guys are on something here.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:20",
            "end_time": "42:36",
            "annotations": {
                "develop idea": "The speaker is expanding on the idea of heterogeneity and its relevance across different imaging scales and modalities.",
                "summarize conversation": "The speaker is summarizing the key points discussed, specifically highlighting the issue of heterogeneity."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "02:13-02:14",
            "transcript": "Okay, more thoughts.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:36",
            "end_time": "42:37",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "02:14-02:20",
            "transcript": "Um I would like to add a counter argument to this because what we are discussing all is the",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:37",
            "end_time": "42:43",
            "annotations": {
                "critical response": "Uzay Emir explicitly states his intention to add a counterargument to the discussion, indicating a critical stance towards the ideas presented."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "02:20-02:25",
            "transcript": "structural deformation has already happened and you can see on the images.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:43",
            "end_time": "42:48",
            "annotations": {
                "critical response": "The speaker is pointing out that structural deformation can be observed on the images, which may challenge or add a new perspective to previous discussions."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "02:25-02:28",
            "transcript": "most of the time.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:48",
            "end_time": "42:51",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with a previous statement."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "02:28-02:40",
            "transcript": "So because when you don't have any anatomical feature changes MRI becomes useless and then you need to go another uh opportunity.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:51",
            "end_time": "43:03",
            "annotations": {
                "None": "No relevant code perfectly applies to this utterance"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "02:40-03:03",
            "transcript": "So and then you do have the so it is still clinically useful. I am not saying this is what we need to do, but it is still really not helping us to early diagnostic or understanding what's happening at the beginning.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:03",
            "end_time": "43:26",
            "annotations": {
                "develop idea": "The speaker is expanding on the discussion about the limitations and clinical utility of imaging techniques.",
                "identify gap": "The speaker highlights a gap in current imaging capabilities, specifically in early diagnosis and understanding disease beginnings.",
                "critical response": "The speaker critiques current imaging techniques for not aiding in early diagnosis."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:03-03:35",
            "transcript": "So that is that's I do find difficulties uh about this because for example I do have a glioma case which I was able to predict everything and I even though histology fails antibody tests for the glioma patients and then later on they do the DNA sequence and they always come back to confirm my results from the beginning.",
            "speaking_duration": 32,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:26",
            "end_time": "43:58",
            "annotations": {
                "develop idea": "expanding on the discussion by providing a concrete example from his work related to the potential of multimodal approaches",
                "signal expertise": "explicitly stating his experience and success with predicting glioma cases",
                "offer feedback": "providing a specific example that offers insight into the challenges and potential of multimodal imaging approaches"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:35-03:41",
            "transcript": "But this is really not exciting because there is already a chunk of tissue that is already deformed.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:58",
            "end_time": "44:04",
            "annotations": {
                "Critical response": "The speaker expresses a critical view or disappointment about a specific situation or outcome.",
                "Identify gap": "The speaker highlights a limitation or challenge (tissue deformation)."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:41-03:47",
            "transcript": "and I do localize it easily, but even there isn't anything so you will you will never be able to do the biopsy.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:04",
            "end_time": "44:10",
            "annotations": {
                "identify gap": "The speaker is pointing out a limitation in medical imaging and diagnostics, specifically that even when a condition can be localized, it may not be possible to perform a biopsy.",
                "critical response": "The utterance implies a critical view of current medical capabilities, highlighting a significant limitation."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:47-04:05",
            "transcript": "You will never be able to do histopathology because there isn't any clinical findings that confirms that only the symptoms the patient has and the clinician will never try to get let's try to sample it without having any additional confirmation. So and again we are getting far from the uh this optical imaging what helping us to understand uh and try to figure out early diagnostic features and try to change the treatment or try to intervene as quick as possible.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:10",
            "end_time": "44:28",
            "annotations": {
                "offer feedback": "The speaker is providing feedback on the current state of medical practice, particularly in the context of early diagnostic features and intervention."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:05-04:15",
            "transcript": "Yes. And I I think we have to push optical imaging, you know, but we also have to accept that it's going to have its limitations and that's why we have",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:28",
            "end_time": "44:38",
            "annotations": {
                "supportive response": "Expressing agreement and a positive view towards optical imaging."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:15-04:24",
            "transcript": "radiographic x-ray, we have um pet, we have um spec, we have MRI, we have ultrasound and how do we link them together because um",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:38",
            "end_time": "44:47",
            "annotations": {
                "develop idea": "The speaker is building upon the context of multimodal imaging by listing various modalities and questioning how to link them.",
                "ask question": "The speaker is seeking information on how to integrate or link the mentioned imaging modalities.",
                "identify gap": "The speaker's question implies a recognition of a current limitation in effectively linking or integrating different imaging modalities."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:24-04:34",
            "transcript": "in the end none of those will handle everything. Um at least my opinion.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:47",
            "end_time": "44:57",
            "annotations": {
                "summarize conversation": "The speaker summarizes the discussion by highlighting that none of the imaging modalities will handle everything, expressing a conclusion based on the conversation."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:34-04:40",
            "transcript": "But um um I uh and and I think everything is task based and disease based.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:57",
            "end_time": "45:03",
            "annotations": {
                "supportive response": "The utterance expresses agreement and alignment with the discussion, emphasizing task and disease-based considerations.",
                "summarize conversation": "It reflects on the conversation by highlighting a key point about task-based and disease-based approaches."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:40-04:51",
            "transcript": "Optical imaging may be great in diagnosing say say skin lesions, but it's not going to help in some of the deep tissue stuff.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:03",
            "end_time": "45:14",
            "annotations": {
                "clarify goal": "The speaker clarifies the appropriate applications and limitations of optical imaging in medical diagnostics.",
                "develop idea": "The speaker expands on existing ideas about the use and limitations of optical imaging."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:51-05:01",
            "transcript": "So how do we how do we decide what's best for what organ, what disease and all that. Um but that's that's maybe pushing this too far.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:14",
            "end_time": "45:24",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:01-05:14",
            "transcript": "But maybe we should go back up um um back when you have time to I just don't want you to run out of time. I know we still have a half hour.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:24",
            "end_time": "45:37",
            "annotations": {
                "process management": "The speaker is explicitly managing the meeting time, indicating awareness of the remaining time and a desire to pace the discussion accordingly."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:14-05:23",
            "transcript": "But if you want to look at um you have your main points at the very start at the beginning of yours, your key. So you got two so far addressing.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:37",
            "end_time": "45:46",
            "annotations": {
                "process management": "The speaker is managing the discussion flow by referring back to previous points made by others, ensuring that the conversation stays on track and that all key points are addressed."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:23-05:26",
            "transcript": "Yeah, because we're kind of rolling over. I'm just summarizing the",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:46",
            "end_time": "45:49",
            "annotations": {
                "summarize conversation": "Beck explicitly mentions summarizing the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:26-05:26",
            "transcript": "Okay, great, great.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:49",
            "end_time": "45:49",
            "annotations": {
                "None": "The utterance 'Okay, great, great.' is a brief expression of agreement or acknowledgement that does not explicitly fit into any of the provided codes."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:26-05:30",
            "transcript": "I'm doing clustering as we go along.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:49",
            "end_time": "45:53",
            "annotations": {
                "process management": "The speaker is describing his action of organizing information as the conversation progresses."
            }
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "05:30-05:31",
            "transcript": "No, excellent.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:53",
            "end_time": "45:54",
            "annotations": {
                "Supportive response": "The speaker is expressing a positive evaluation ('excellent')."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:31-05:40",
            "transcript": "I think your two points are right on. Um folks, um is um is there a way of taking from all this discussion another point?",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:54",
            "end_time": "46:03",
            "annotations": {
                "supportive response": "The speaker expresses agreement with previous points, showing support.",
                "encourage participation": "The speaker invites others to contribute more ideas, encouraging participation."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "05:40-05:57",
            "transcript": "From me the question for me the important question I mean thinking big is is great uh but uh we for me the question is what is achievable really.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:03",
            "end_time": "46:20",
            "annotations": {
                "ask question": "The utterance contains a question about what is achievable, seeking information about the feasibility of the ideas being discussed.",
                "critical response": "The utterance has a critical tone regarding the practicality of the ideas presented, emphasizing the need to consider what is achievable."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "05:57-06:05",
            "transcript": "And uh of course I mean yeah, I would like to do uh microscopy in a living human uh throughout the brain and zoom in on every uh cell that I can do.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:20",
            "end_time": "46:28",
            "annotations": {
                "propose new idea": "Ferdinand expresses a desire for a new capability in imaging technology, specifically microscopy in a living human throughout the brain.",
                "identify gap": "Ferdinand's statement implies a recognition of current limitations in imaging technology, specifically the inability to perform such detailed microscopy."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "06:05-06:11",
            "transcript": "That's the ultimate goal and maybe in a thousand years we can do that.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:28",
            "end_time": "46:34",
            "annotations": {
                "express humor": "The speaker makes a humorous comment about the achievability of future goals in a thousand years, implying that the goal is far off or perhaps unachievable."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "06:11-06:29",
            "transcript": "But uh what is achievable? Because yeah, if you if we don't see anything on MRI, if there's no change, we can we can throw AI at it and correlate it with a pathology, the result will be nonsense.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:34",
            "end_time": "46:52",
            "annotations": {
                "ask question": "The speaker starts with 'what is achievable,' which is a clear question about the feasibility of certain goals or approaches.",
                "critical response": "The speaker is providing a critical view of over-relying on AI for correlations without visible changes on MRI.",
                "identify gap": "The speaker is highlighting a gap in what is achievable with current technology and methods, specifically concerning the use of AI for analyzing MRI results in correlation with pathology."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "06:29-06:32",
            "transcript": "It may work in our cohort, but it will be nonsense.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:52",
            "end_time": "46:55",
            "annotations": {
                "critical response": "The speaker is questioning the applicability and validity of an approach across different cohorts.",
                "offer feedback": "The speaker is providing a specific critique of an approach, highlighting its potential limitations."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "06:32-06:33",
            "transcript": "because if there's no change",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:55",
            "end_time": "46:56",
            "annotations": {
                "identify gap": "The speaker highlights a gap in dealing with cases where there are no observable changes in imaging data.",
                "critical response": "The speaker critiques the approach of correlating imaging data with pathology when there are no observable changes."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "06:33-06:35",
            "transcript": "on the MRI it's not going to work.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:56",
            "end_time": "46:58",
            "annotations": {
                "identify gap": "The speaker highlights a limitation of MRI, implying a gap in what it can achieve.",
                "critical response": "The speaker is expressing a negative view on the utility of MRI for a particular purpose."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "06:35-06:37",
            "transcript": "So what is an achievable goal here?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:58",
            "end_time": "47:00",
            "annotations": {
                "ask question": "The speaker is requesting information or clarification on achievable goals.",
                "clarify goal": "The speaker is seeking to understand or define what objectives are achievable."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:37-06:37",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:00",
            "end_time": "47:00",
            "annotations": {
                "supportive response": "The utterance expresses agreement or validation for previous statements."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "06:37-06:38",
            "transcript": "I would like to encourage.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:00",
            "end_time": "47:01",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:38-06:38",
            "transcript": "Go ahead, you say.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:01",
            "end_time": "47:01",
            "annotations": {
                "encourage participation": "The speaker is inviting someone to contribute to the discussion by saying 'Go ahead, you say.'"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "06:38-06:55",
            "transcript": "My padlets for cancer, there is one case I intentionally put that clinical scan failed and they come to me and can you do this seven Tesla spectroscopy on this patient. I did and the first scan I said this is IDH2 mutation patient based on the features.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:01",
            "end_time": "47:18",
            "annotations": {
                "signal expertise": "The speaker is sharing a personal experience that demonstrates his expertise in using seven Tesla spectroscopy to identify specific patient conditions.",
                "develop idea": "The speaker is providing a concrete example that builds upon the existing discussion, showing how a technique can be applied in a real-world scenario."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "06:55-07:05",
            "transcript": "And then they do the biopsy. The biopsy failed because lack of information, lack of sample and then the neurosurgeon took the extreme case and do the complete resection.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:18",
            "end_time": "47:28",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:05-07:12",
            "transcript": "And they do the DNA sequencing and it ended up IDH2 mutation and there weren't any anatomical changes.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:28",
            "end_time": "47:35",
            "annotations": {
                "None": "No relevant code directly applies to this utterance as it primarily shares a specific case detail without explicitly introducing new ideas, asking questions, or engaging in discussions that fit the other codes."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:12-07:30",
            "transcript": "The only thing that uh the symptoms and the doctor told me that this temporal lobe might be the problem. So what I'm saying is we need to really the capacity and you need to use the right tool, right method and then to understand the physiology really well.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:35",
            "end_time": "47:53",
            "annotations": {
                "signal expertise": "The speaker is explicitly stating his own experience and qualifications related to the task by sharing a case and insights.",
                "offer feedback": "The speaker provides specific suggestions for improvement or modification of existing approaches by emphasizing the need for the right tools and methods.",
                "clarify goal": "The speaker is defining, clarifying, or seeking clarity on objectives by highlighting the importance of understanding physiology really well."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "07:30-07:41",
            "transcript": "So that is I always try to share it. Yes, the tools are have really powerful, but this has to be driven by mesoscope mesoscopic scales.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:53",
            "end_time": "48:04",
            "annotations": {
                "supportive response": "The speaker is expressing a positive view on the tools and emphasizing the importance of a mesoscopic approach.",
                "encourage participation": "Uzay Emir is encouraging a perspective on how to approach the use of tools.",
                "clarify goal": "Uzay Emir is reflecting on the goal or approach (mesoscopic scales)."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:00-00:04",
            "transcript": "over the break, but I don't want anybody excluded in this this discussion.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:23",
            "end_time": "50:27",
            "annotations": {
                "encourage participation": "invites someone else in the group to contribute their expertise, opinions or ideas"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:04-00:13",
            "transcript": "A quick side information, not every country and not every city will be able to have 70 Tesla MRI scanners. So we have to keep that in mind.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 66.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:27",
            "end_time": "50:36",
            "annotations": {
                "critical response": "The speaker highlights a limitation in the accessibility of 7 Tesla MRI scanners, implying that not all locations can afford or have access to such technology.",
                "identify gap": "The speaker identifies a gap in the availability of 7 Tesla MRI scanners across different countries and cities, suggesting a limitation in global access to this technology."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:13-00:13",
            "transcript": "Sure.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:36",
            "end_time": "50:36",
            "annotations": {
                "supportive response": "The utterance 'Uzay Emir: Sure.' expresses agreement with a previous statement, which is a positive evaluation and supportive response."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:13-00:17",
            "transcript": "Yes, we are in the middle of we are country.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:36",
            "end_time": "50:40",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:17-00:23",
            "transcript": "You'll have it in St. Louis where we have it, you'll have it in maybe Boston, but that's another thing to take into account.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:40",
            "end_time": "50:46",
            "annotations": {
                "supportive response": "The speaker is providing a comment that acknowledges the situation regarding the availability of high-field MRI scanners in certain locations.",
                "identify gap": "The speaker highlights a gap in the accessibility of high-field MRI scanners across different locations."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:23-00:30",
            "transcript": "But we need to be insane this group of people, right? So push the limits.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:46",
            "end_time": "50:53",
            "annotations": {
                "Express humor": "The speaker is making a joke about needing to be 'insane' to push limits, which is a humorous way of encouraging boldness and innovation.",
                "Encourage participation": "The speaker is encouraging the group to be bold and push limits, which can be seen as inviting participation in a creative or innovative way."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:31-00:31",
            "transcript": "Right.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:54",
            "end_time": "50:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:31-00:31",
            "transcript": "So.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:54",
            "end_time": "50:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:31-00:31",
            "transcript": "So.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:54",
            "end_time": "50:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:31-00:31",
            "transcript": "So.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:54",
            "end_time": "50:54",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:31-00:34",
            "transcript": "So the reason I'm bringing up, what the reason I'm bringing it up.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:54",
            "end_time": "50:57",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:34-00:55",
            "transcript": "There might be a cheaper alternative that potentially can be correlated in somehow with seven Tesla Tesla but can be deployed in a countries that cannot have a seven Tesla Tesla scanner or in a region that cannot have a Tesla scanner. And you know, that's something to keep in mind for multimodality, the the cost and the invasiveness.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 33.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:57",
            "end_time": "51:18",
            "annotations": {
                "propose new idea": "The speaker introduces the consideration for cheaper alternatives in multimodal imaging.",
                "develop idea": "The speaker expands on the concept of multimodal imaging by considering cost and invasiveness.",
                "identify gap": "The speaker highlights the gap in accessibility and cost of advanced imaging technologies."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:55-01:36",
            "transcript": "So one of your key points might be all these aspects of imaging that um help create the next generation of imaging but also limit it and that, you know, there multiple um folks here have pointed out, you know, the spatial and temporal resolution, the the cost, the um um uh invasiveness.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:18",
            "end_time": "51:59",
            "annotations": {
                "summarize conversation": "The speaker is summarizing previous discussions about the aspects of imaging that create the next generation of imaging but also limit it.",
                "develop idea": "The speaker is developing the idea by highlighting specific limitations (spatial and temporal resolution, cost, invasiveness) that have been discussed."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:36-01:45",
            "transcript": "And then there's also the um part on um uh which is related to the cost is the uh socio economic situation in which that uh imaging system uh might uh not be able to exist.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:59",
            "end_time": "52:08",
            "annotations": {
                "develop idea": "The speaker is expanding on previous ideas by mentioning cost and socio-economic factors as crucial considerations for imaging systems.",
                "identify gap": "The utterance highlights the gap in accessibility of imaging systems due to socio-economic situations."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:45-01:52",
            "transcript": "Um so but now I think we should just dream. You know, if we came up with the best one, um what could we do that?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:08",
            "end_time": "52:15",
            "annotations": {
                "Ask question": "The speaker asks a question to prompt discussion on potential applications or benefits.",
                "Encourage participation": "The speaker invites the group to imagine and discuss possibilities."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:52-02:03",
            "transcript": "Uh should we work on your key points or keep going in the full discussion? Someone um do the key points summarize um all that um we've been talking about. And Beck, you've been doing a great job.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:15",
            "end_time": "52:26",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by suggesting to focus on key points or continue the discussion and by asking for a summary of key points.",
                "summarize conversation": "The speaker requests a summary of key points discussed, indicating an effort to consolidate information."
            }
        },
        {
            "speaker": "Anna-Karin Gustavsson",
            "timestamp": "02:04-02:22",
            "transcript": "Even though it's primarily mesoscopic to microscopic, but to some extent also microscopic to mesoscopic, um to bridging that gap as well. I don't know if we want to have that as a key point, but that's another consideration.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 33.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:27",
            "end_time": "52:45",
            "annotations": {
                "develop idea": "The speaker is expanding on the existing discussion about multimodal imaging by suggesting another consideration for their objectives, which involves bridging the gap between mesoscopic and microscopic imaging."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "02:23-02:41",
            "transcript": "I think that general idea of fusion is a very nice one. It's it's quite quite prevalent actually even in within a modality. People take, you know, three different views and fuse them to get more information. I I guess actually people in have been doing that for quite some time, I think.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:46",
            "end_time": "53:04",
            "annotations": {
                "Supportive Response": "The speaker is expressing agreement and positive evaluation of the idea of fusion in imaging.",
                "Develop Idea": "The speaker is expanding on the idea of fusion by mentioning its prevalence and application within a single modality."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:44-03:02",
            "transcript": "Right. and and actually the reason people do a lot of fusion is to merge structural morphology with um you know, physiology. Um and that's why people have pet CTs in a way. Um but you can I think you can fuse it at the image level um or at the uh feature level.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 11.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "53:07",
            "end_time": "53:25",
            "annotations": {
                "develop idea": "The speaker is expanding on the idea of fusion in imaging, explaining its purpose and possible levels of fusion.",
                "clarify goal": "The speaker is discussing the goals and purposes behind fusing different imaging modalities."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "03:06-03:15",
            "transcript": "Right. and then building a model for that that you know, could be equivalence like what a classifier would be would be, I don't know, that seems like it would have some value.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "53:29",
            "end_time": "53:38",
            "annotations": {
                "propose new idea": "The speaker introduces a new idea of building a model that could serve as an equivalence to a classifier.",
                "ask question": "The speaker seeks validation or feedback on the proposed idea."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:19-03:47",
            "transcript": "I I really like thinking that direction. It's kind of, you know, you can extract certain characteristic, like interpretable characteristics from each image for that modality, right? You say, oh, you know, I'm trying to diagnose this, I have this structural information and you know, I can get features that tell me something about this diseases and later we can classify based on those features. Uh, for another modality, it could be a related type of features and and later you can kind of work in the feature level.",
            "speaking_duration": 28,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "53:42",
            "end_time": "54:10",
            "annotations": {
                "supportive response": "The speaker is expressing agreement and positive evaluation for the direction of discussion on multimodal imaging and feature extraction."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:48-03:55",
            "transcript": "So let me ask Ellen, is this answering your big dream of multimodal?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:11",
            "end_time": "54:18",
            "annotations": {
                "ask question": "Maryellen is explicitly asking Ellen a question about her vision for multimodal imaging.",
                "clarify goal": "Maryellen is seeking to understand if the current discussion aligns with Ellen's goals or vision for multimodal imaging.",
                "encourage participation": "By directly asking Ellen for her thoughts, Maryellen is encouraging her to participate in the discussion."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "04:00-04:32",
            "transcript": "I think we're getting at a lot of them. Um, you know, ultimately, I would like to think on more of a diagnostic, you know, before a patient has symptoms and you know, I think that if we could get things at the molecular level and have a cheap diagnostic and maybe that does have to be multimodal, um that would allow more screening.",
            "speaking_duration": 32,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:23",
            "end_time": "54:55",
            "annotations": {
                "develop idea": "Ellen is expanding on the concept of diagnostics and multimodal imaging.",
                "clarify goal": "Ellen discusses her vision for a diagnostic tool.",
                "offer feedback": "Ellen provides her view on what would be beneficial."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "04:32-04:32",
            "transcript": "That's something that we haven't.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:55",
            "end_time": "54:55",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:33-04:37",
            "transcript": "So getting molecular information at the screening time.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:56",
            "end_time": "55:00",
            "annotations": {
                "clarify goal": "The speaker is reiterating the importance of obtaining molecular information at the screening time, which aligns with and possibly summarizes the group's objectives in discussing multimodal imaging applications.",
                "summarize conversation": "The utterance can also be seen as summarizing a key point of discussion, which is about the goals and aspirations in the field of multimodal imaging."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "04:38-04:54",
            "transcript": "Well, I think we've sort of touched upon it is the molecular information, right? That is the early signals that we're going to be able to read out on. So how can we think about doing that in a cheap, non-invasive way that would allow more screening.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:01",
            "end_time": "55:17",
            "annotations": {
                "supportive response": "The speaker expresses agreement and encouragement, promoting further discussion on how to achieve molecular information in a cheap and non-invasive way.",
                "offer feedback": "The speaker provides a perspective on how to approach the issue of obtaining molecular information for early screening in a cost-effective and non-invasive manner."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:54-04:54",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:17",
            "end_time": "55:17",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "04:54-05:03",
            "transcript": "Yeah, I think that actually item like combination of the tree it could like solve what I I was getting at.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:17",
            "end_time": "55:26",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or a positive sentiment towards an idea or concept previously discussed."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "05:03-05:17",
            "transcript": "It's just like I was thinking that how we are able to have access, you know, to that data set to be able to do like item two, but yeah.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 21.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:26",
            "end_time": "55:40",
            "annotations": {
                "ask question": "The speaker is inquiring about the accessibility of a dataset to work on 'item two'."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "05:17-05:17",
            "transcript": "we could, right?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:40",
            "end_time": "55:40",
            "annotations": {
                "acknowledge contribution": "The speaker is verbally recognizing a previous idea or suggestion.",
                "supportive response": "The speaker is expressing agreement or validation for the previous statement."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "05:17-05:18",
            "transcript": "Yes.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:40",
            "end_time": "55:41",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with a previous statement."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "05:18-05:18",
            "transcript": "That's the point of all of us.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:41",
            "end_time": "55:41",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges the collective input or effort.",
                "supportive response": "The speaker expresses agreement or support for the discussion."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "05:18-05:18",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:41",
            "end_time": "55:41",
            "annotations": {
                "None": "The utterance is a simple affirmation without adding new content or explicitly fitting into any provided code category."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:18-05:30",
            "transcript": "Yeah. That's why we we're quite a a diverse group here. I mean, there's some of us, I'm I'm an AI person. There seems to be some other folks here AI meaning merging of techniques using mathematical methods.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:41",
            "end_time": "55:53",
            "annotations": {
                "signal expertise": "The speaker mentions being an 'AI person', signaling their expertise in AI.",
                "supportive response": "The utterance has a positive tone, reflecting on the group's diversity and the integration of different techniques."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:30-05:36",
            "transcript": "Um and there's acquisition people both at the optical uh you know, across all scales.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:53",
            "end_time": "55:59",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-05:44",
            "transcript": "I I think that's the benefit of this uh group. Um so when on number two, you have multimodality by using AI to fuse.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:59",
            "end_time": "56:07",
            "annotations": {
                "Develop idea": "The speaker is expanding on the concept of multimodality and its potential through AI.",
                "Supportive response": "The speaker expresses a positive view on the group and the concept of using AI for multimodality.",
                "Summarize conversation": "The speaker summarizes a point about the group's benefits and mentions an aspect of multimodality."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:44-05:53",
            "transcript": "What about where how about using multidata to guide the next layer? You know, I think how to zoom in. I think it was Anna Karin talked about that was that Ellen, someone. Okay.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:07",
            "end_time": "56:16",
            "annotations": {
                "develop idea": "The speaker is expanding on an idea related to using multidata to guide further analysis."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "05:54-06:16",
            "transcript": "Yeah, I think that actually item like combination of the tree it could like solve what I I was getting at. It's just like I was thinking that how we are able to have access, you know, to that data set to be able to do like item two, but yeah.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 18.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:17",
            "end_time": "56:39",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with a previous statement or idea.",
                "acknowledge contribution": "The speaker is acknowledging a previous contribution or idea, showing awareness of the discussion context."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "06:17-06:17",
            "transcript": "we could, right?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:40",
            "end_time": "56:40",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or confirmation of a previous idea or suggestion."
            }
        },
        {
            "speaker": "Sapun Parekh",
            "timestamp": "06:17-06:21",
            "transcript": "That's the point of all of us. Yes. Yeah.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:40",
            "end_time": "56:44",
            "annotations": {
                "acknowledge contribution": "The speaker is acknowledging a point made.",
                "supportive response": "The utterance expresses agreement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:21-06:33",
            "transcript": "That's why we we're quite a a diverse group here. I mean, there's some of us, I'm I'm an AI person. There seems to be some other folks here AI meaning merging of techniques using mathematical methods.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:44",
            "end_time": "56:56",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:33-06:40",
            "transcript": "Um and there's acquisition people both at the optical uh you know, across all scales.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:56",
            "end_time": "57:03",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:40-06:52",
            "transcript": "I think that's the benefit of this uh group. Um So when on number two, you have multimodality by using AI to fuse.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:03",
            "end_time": "57:15",
            "annotations": {
                "summarize conversation": "The speaker summarizes a key point about the benefit of using AI to fuse multimodal data."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:52-07:01",
            "transcript": "What about where how about using multidata to guide the next layer? You know, I think how to zoom in. I think it was Anna Karin talked about that was that Ellen, someone. Okay.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:15",
            "end_time": "57:24",
            "annotations": {
                "propose new idea": "The speaker suggests using multidata to guide the next layer, introducing a new approach.",
                "ask question": "The speaker requests opinions or suggestions on the idea."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:01-07:09",
            "transcript": "Uh how do we bring that in? Is that a is that additional one to number two to fuse or guide over here?",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:24",
            "end_time": "57:32",
            "annotations": {
                "process management": "The speaker is managing the flow of discussion and seeking clarity on how to integrate an idea into their framework.",
                "clarify goal": "The speaker is also seeking to understand how to bring an idea into their discussion, which relates to clarifying goals or objectives of their discussion."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:10-07:15",
            "transcript": "I think we should brought that by fuse or guide or make it separate.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:33",
            "end_time": "57:38",
            "annotations": {
                "process management": "The speaker is suggesting how to organize or manage the discussion on fusion or guidance of multimodal imaging data.",
                "offer feedback": "The speaker provides a suggestion for organizing ideas, which can be seen as offering feedback on the discussion process."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:15-07:15",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:38",
            "end_time": "57:38",
            "annotations": {
                "None": "The utterance is a brief acknowledgment that does not add significant content to the conversation."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:00-00:07",
            "transcript": "Well, for now it's too much, but in the future potentially it will be uh something we can handle.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:23",
            "end_time": "60:30",
            "annotations": {
                "supportive response": "The speaker is expressing a positive but cautious attitude towards the discussion, acknowledging potential future feasibility."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "00:07-00:23",
            "transcript": "But what I mean is on MRI we get one single number per scan for that voxel cube and then we are we know that on the microscopic level we have so much data. So and now we try to map these two, it's impossible.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:30",
            "end_time": "60:46",
            "annotations": {
                "signal expertise": "Ferdinand Schweser is explicitly stating his own expertise and knowledge with MRI technology, discussing its limitations.",
                "identify gap": "Ferdinand is explicitly recognizing the gap between the data provided by MRI technology and the detailed data available at the microscopic level."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:23-00:26",
            "transcript": "So we need to restrict the by the way.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:46",
            "end_time": "60:49",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:26-00:39",
            "transcript": "You you're saying like even MRI, you do quantitative MRI, you don't get one scan, you do different, you know, I don't know, recall echoes and then you try to you try to get molecular information then by using some biophysical model on that MRI data. So you can explore it in a richer way too.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:49",
            "end_time": "61:02",
            "annotations": {
                "Develop Idea": "The speaker explains and expands on the idea of using quantitative MRI to obtain molecular information, detailing the process of doing different scans and applying biophysical models.",
                "Propose New Idea": "The speaker suggests exploring MRI data in a richer way, implying a new approach to data analysis."
            }
        },
        {
            "speaker": "Ferdinand Schweser",
            "timestamp": "00:39-01:06",
            "transcript": "I think the goal in the MRI field is really to acquire a very high set of parameters in a very short time and then fuse them to get to the high number of parameters and characterize the tissue. That's the that's the far goal for MRI, I think. But still you would have to figure out how to how to reduce the parameter space to predict the microscopic level somehow.",
            "speaking_duration": 27,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:02",
            "end_time": "61:29",
            "annotations": {
                "develop idea": "The speaker is expanding on an existing idea by discussing its goals and challenges in the context of MRI.",
                "ask question": "The speaker poses a question about how to reduce the parameter space to predict the microscopic level.",
                "signal expertise": "The speaker shares their perspective on the goals and challenges in the MRI field, indicating their expertise."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "01:06-02:34",
            "transcript": "So we've had a lot of discussion on different limitations, you know, we're hearing some here, um, both in the actual acquisitions and then how do we map them? You say you brought up limitations, you know, and how do we push, you know, optical imaging more across the different scales, but all of this feeds into a dream. What what what would you want? You know, you have those limitations. Uh, for example, uh, uh, say in the old days we could only image um with say 1 millimeter pixels. But we could dream, we could say, but we really want to image at 0.2 millimeter pixels. And then we go back and we we push um the technology, the detector system or the sources or or the reconstruction or the AI part of the interpretation. So now take those limitations that you have in your mind, but convert them to I wish I had this. And I I think some of because this is a great team here of different modality, different scales and also different use. Some of you are right in the clinical area, other ones are at the bench. Um, and we're we're actually trying to do multi uh fusion of that. Um, so Ellen, where do you see this going? Help us here.",
            "speaking_duration": 88,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:29",
            "end_time": "62:57",
            "annotations": {
                "summarize conversation": "The speaker summarizes the discussion on limitations and their impact on the team's goals.",
                "encourage participation": "The speaker invites team members to contribute their thoughts and ideas.",
                "clarify goal": "The speaker encourages the team to think about and articulate their goals if current limitations were overcome."
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "02:35-02:57",
            "transcript": "I mean, I'm in the in the probe making space and I feel like a lot of the discussions we're having can be solved by responsive probes. And if we can have responsive probes that work throughout all the modalities, then you're going to be able to get molecular information and then you can pick the time scale you want and you can pick the depth penetration you need.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:58",
            "end_time": "63:20",
            "annotations": {
                "propose new idea": "Ellen introduces the concept of responsive probes that could work across all modalities.",
                "develop idea": "She elaborates on the benefits of such probes, including getting molecular information and flexibility in time scale and depth penetration.",
                "signal expertise": "Ellen explicitly states her area of expertise as 'probe making space'."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:00-03:09",
            "transcript": "So Ellen is going to keep working on probes and then she's going to team up with people are going to be pushing the detector system. Um, how is that going to help?",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:23",
            "end_time": "63:32",
            "annotations": {
                "ask question": "The speaker asks for clarification on the benefits or outcomes of a proposed plan involving Ellen's work on probes and collaboration on the detector system."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:10-04:33",
            "transcript": "Yes, I will give you an example, for example, optical imaging. Raman spectroscopy is quite important for cancer detection during intraoperative scans. It is in place, people are using this Raman spectroscopy to identify the certain mutations during the operation with using the neuro navigators and you can get the same information from the MRI. And for example, you can figure out the Raman spectroscopy signal intensity. So that's all have so when when Ellen highlighted the probes, for example, this can be another probe to do to using the optical information of the tissue during the real time and you can merge it with different types of MRI contrast as as has been highlighted by the Ferdinand and the Lubec and and and that can be merged easily because you do have the all spatial information that comes from the clinical scan during the operation and you do have the optical information and and then you can merge the optical properties with with clinical findings and later on you can merge because it's going to be very well marked with the histopathological information as well. So then you can go back to histology and DNA sequencing and you can have the big data and go to do canonical analysis and find what is interesting.",
            "speaking_duration": 83,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:33",
            "end_time": "64:56",
            "annotations": {
                "develop idea": "expanding on existing ideas by providing a specific example of Raman spectroscopy's application and its integration with MRI",
                "acknowledge contribution": "referencing Ellen's mention of probes and building upon that idea",
                "offer feedback": "suggesting how optical information can be merged with MRI contrast for medical diagnostics"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:33-04:36",
            "transcript": "So you're actually talking to number two in in um the key points that um Beck has put up.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "64:56",
            "end_time": "64:59",
            "annotations": {
                "summarize conversation": "The speaker references and summarizes a previous point made by Beck, indicating an understanding of the discussion and pointing to specific key points."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:36-04:51",
            "transcript": "Of you're now we're fusing the knowledge that we have from the clinical scans with all their limitations with what we're seeing at the bench.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "64:59",
            "end_time": "65:14",
            "annotations": {
                "summarize conversation": "The speaker summarizes the discussion about integrating knowledge from clinical scans and bench observations."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:51-04:56",
            "transcript": "And then trying to move those closer so the bench becomes clinical. Um.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "65:14",
            "end_time": "65:19",
            "annotations": {
                "summarize conversation": "The utterance summarizes a goal discussed in the conversation, which is to bridge the gap between basic research and clinical applications.",
                "clarify goal": "The utterance clarifies the goal of making basic research (the bench) applicable in clinical settings."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:56-04:58",
            "transcript": "What have we missed?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "65:19",
            "end_time": "65:21",
            "annotations": {
                "code name": "ask question",
                "explanation": "The utterance explicitly asks a question about what has been missed in the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:58-05:00",
            "transcript": "Shiva.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "65:21",
            "end_time": "65:23",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:00-05:03",
            "transcript": "We missed anything or Ping.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "65:23",
            "end_time": "65:26",
            "annotations": {
                "ask question": "The speaker is seeking information or confirmation.",
                "encourage participation": "The speaker is inviting further input from the group, especially mentioning Ping."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:03-05:05",
            "transcript": "You know, you guys have been a little quiet for a while.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "65:26",
            "end_time": "65:28",
            "annotations": {
                "encourage participation": "The speaker invites group members to contribute to the discussion, encouraging participation."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "05:53-05:59",
            "transcript": "Um I I totally agree on that um probe uh discussion.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:16",
            "end_time": "66:22",
            "annotations": {
                "supportive response": "The speaker expresses agreement with the previous discussion about probes, showing a positive evaluation without adding new content."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:59-06:00",
            "transcript": "I mean.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:22",
            "end_time": "66:23",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:00-06:01",
            "transcript": "Okay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:23",
            "end_time": "66:24",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:01-06:07",
            "transcript": "Actually, you know what? Maybe we should put it as one of the key points, as a separate key point.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:24",
            "end_time": "66:30",
            "annotations": {
                "process management": "Beck Kamilov is suggesting a way to organize the discussion points by recommending that an idea be put as a separate key point.",
                "supportive response": "Beck is engaging with the discussion and suggesting a constructive way to highlight important points."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:07-06:10",
            "transcript": "Yeah, there's no one saying you only could have three key points. You can have a fourth one.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:30",
            "end_time": "66:33",
            "annotations": {
                "Supportive response": "The speaker is supportive by suggesting flexibility in the number of key points.",
                "Process management": "The speaker is managing the discussion process by commenting on key points.",
                "Encourage participation": "The speaker encourages participation by suggesting additional key points can be included."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:10-06:11",
            "transcript": "It's just that likes the number three.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:33",
            "end_time": "66:34",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:11-06:17",
            "transcript": "Okay, well we're we're we're merge one. How about we merge two?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:34",
            "end_time": "66:40",
            "annotations": {
                "process management": "The speaker is suggesting to merge two points, which is an action to manage the discussion flow and organization."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:17-06:20",
            "transcript": "No, I'm just joking. I put the four.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:40",
            "end_time": "66:43",
            "annotations": {
                "Express humor": "The speaker makes a joke about adding a fourth point to the list."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:23-06:27",
            "transcript": "Across scales, right? across scales and modalities.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:46",
            "end_time": "66:50",
            "annotations": {
                "summarize conversation": "The speaker is summarizing or reflecting on the discussion about multimodal imaging and the importance of considering different scales."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:27-06:30",
            "transcript": "Chemical probes, right? Or you know.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:50",
            "end_time": "66:53",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or acknowledgment of a previous suggestion about using chemical probes in multimodal imaging."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:30-06:31",
            "transcript": "Yes, right.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:53",
            "end_time": "66:54",
            "annotations": {
                "supportive response": "The speaker is expressing agreement with a previous statement.",
                "acknowledge contribution": "The speaker is acknowledging a previous statement made by someone else."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:31-06:33",
            "transcript": "Designer designer chemical probes to.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:54",
            "end_time": "66:56",
            "annotations": {
                "propose new idea": "The speaker introduces the concept of 'designer chemical probes' as a potential approach or solution for advancing multimodal imaging."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:33-06:34",
            "transcript": "Data reduction.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:56",
            "end_time": "66:57",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:34-06:34",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:57",
            "end_time": "66:57",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:34-06:35",
            "transcript": "Which is.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:57",
            "end_time": "66:58",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:35-06:43",
            "transcript": "Which is um fusion too, you know, like the AI of tech what you find at one scale related to what you find at the other, but use data reduction and AI to do it.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "66:58",
            "end_time": "67:06",
            "annotations": {
                "develop idea": "The speaker is elaborating on the concept of fusion, specifically mentioning the use of AI and data reduction to relate findings across scales."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "00:00-00:53",
            "transcript": "design the probe adapt to multiple imaging modality is equal important as like put the modality together like instrument together for the application for the new new modality imaging I can I can have example people trying to combine MRI and MPI together magnetic particle imaging actually they they are also very competitive to complementary to each other MRI has higher resolution has higher sensitivity.",
            "speaking_duration": 53,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:23",
            "end_time": "71:16",
            "annotations": {
                "propose new idea": "The speaker introduces a new perspective on approaching multimodal imaging by emphasizing the importance of designing probes that can adapt to multiple imaging modalities.",
                "develop idea": "The speaker elaborates on this idea by providing an example of combining MRI and MPI, discussing their complementary characteristics.",
                "signal expertise": "The speaker demonstrates expertise in imaging modalities, specifically mentioning MRI and MPI, and their applications."
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "00:53-01:33",
            "transcript": "I talk to the CEO of the MPI producer in United States. Actually there there are two major company one is magnetic insight based in California and the other one in Europe broker. I mean they don't they don't do the hybrid now but there's a group in Europe they trying to combine these two together.",
            "speaking_duration": 40,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "71:16",
            "end_time": "71:56",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "01:33-01:33",
            "transcript": "Mhm.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "71:56",
            "end_time": "71:56",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "01:34-01:39",
            "transcript": "Okay, and and Shiva, did you want uh so are we on track?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "71:57",
            "end_time": "72:02",
            "annotations": {
                "process management": "The utterance manages the discussion flow by seeking confirmation on their track.",
                "ask question": "The utterance is a question, seeking confirmation or feedback from Shiva."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:42-01:43",
            "transcript": "Shiva, we don't hear you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "72:05",
            "end_time": "72:06",
            "annotations": {
                "encourage participation": "The speaker is inviting Shiva to contribute or check if there's an issue with Shiva's audio."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:44-02:57",
            "transcript": "Yes, like part of the like my problem was like how we can go like non invasively for diagnostic purpose to deep tissue especially since mostly I do x-ray pets so then I was wondering like in order to go deeper in tissue so then like what the group is thinking for diagnostic is the pass to go like in human because still I think that so many of the signaling pathway as if you know you want to like like you know what is happening you know in human especially that I I have done some plant imaging that is just like the environment of like one root of the plant is really important how all the plants together like the the sphere of the root as a group how they work together so then as if I want to see still how brain as a whole not in a small area is functioning and I want to go deeper but then how can I see the brain deep in the tissue what is the best approach?",
            "speaking_duration": 73,
            "nods_others": 0,
            "smile_self": 0.08,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "72:07",
            "end_time": "73:20",
            "annotations": {
                "ask question": "The speaker is asking for the group's thoughts on the best approach for diagnostic purposes, especially for imaging deep tissue.",
                "identify gap": "The speaker highlights the limitation of current imaging methods in penetrating deep tissue non-invasively.",
                "encourage participation": "The speaker is seeking input from the group on the best approach."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:01-03:11",
            "transcript": "Right, all of these need to be then customized to specific anatomical parts, clinical questions. Um.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:24",
            "end_time": "73:34",
            "annotations": {
                "Develop idea": "The speaker is contributing to the discussion by highlighting the need for customization of imaging approaches to specific anatomical parts and clinical questions.",
                "Process management": "The speaker is guiding the discussion towards practical considerations for implementing multimodal imaging.",
                "Clarify goal": "The speaker is highlighting the need to tailor imaging approaches to specific anatomical parts and clinical questions, relating to defining or clarifying goals."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:12-03:18",
            "transcript": "Uh Beck, are you um set for uh to read back with what you have there on the key points?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:35",
            "end_time": "73:41",
            "annotations": {
                "process management": "Managing the meeting flow by checking if Beck is ready to share key points."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:18-03:19",
            "transcript": "Yes, so should I read?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:41",
            "end_time": "73:42",
            "annotations": {
                "ask question": "The speaker is requesting clarification or confirmation on whether they should read something."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:19-03:20",
            "transcript": "They look good.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:42",
            "end_time": "73:43",
            "annotations": {
                "supportive response": "The speaker is expressing agreement or a positive evaluation of the key points presented."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:20-03:20",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:43",
            "end_time": "73:43",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:23-03:25",
            "transcript": "Yes, you well well in the next.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:46",
            "end_time": "73:48",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:25-03:26",
            "transcript": "But we have.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:48",
            "end_time": "73:49",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:26-03:29",
            "transcript": "I need to put it in the slides, right? I I'm going to put it in.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:49",
            "end_time": "73:52",
            "annotations": {
                "process management": "The speaker is discussing the action of putting information into the slides, indicating management of meeting flow or content."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:29-03:34",
            "transcript": "Right, so you've got three minutes to uh but I think your cut point, your key points up here.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:52",
            "end_time": "73:57",
            "annotations": {
                "process management": "The speaker is managing the meeting flow by mentioning a time constraint and suggesting a point to conclude or summarize key points."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:34-03:35",
            "transcript": "Also, do I need to edit the same PowerPoint that's shared or do I?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "73:57",
            "end_time": "73:58",
            "annotations": {
                "process management": "The speaker is asking about the procedure for editing a shared PowerPoint document, which relates to managing the workflow or process of document editing."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:38-03:39",
            "transcript": "Yeah, I need to edit the.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:01",
            "end_time": "74:02",
            "annotations": {
                "process management": "The speaker is discussing the need to edit, which is related to managing the flow or organization of information or content."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:39-03:43",
            "transcript": "I think it's the um it's on that um Google Drive and you go just go to slide whatever and paste it in there.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:02",
            "end_time": "74:06",
            "annotations": {
                "process management": "The speaker is providing instructions on how to access and contribute to a shared Google Drive document, which relates to managing meeting flow and organization."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:43-03:44",
            "transcript": "Yeah, I just.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:06",
            "end_time": "74:07",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:52-03:54",
            "transcript": "Sounds good. I'm going to do it right away.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:15",
            "end_time": "74:17",
            "annotations": {
                "supportive response": "The speaker is expressing agreement and commitment to performing an action, showing a positive and supportive attitude towards the discussion outcome."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:55-03:57",
            "transcript": "I think it's around slide 42.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:18",
            "end_time": "74:20",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:05-04:06",
            "transcript": "Yep, multimodal imaging. Okay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:28",
            "end_time": "74:29",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:08-04:14",
            "transcript": "Okay, so what he what Beck has as key points good for everyone?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:31",
            "end_time": "74:37",
            "annotations": {
                "process management": "The speaker is managing the discussion flow by seeking confirmation on the key points identified by Beck."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:15-04:17",
            "transcript": "Okay, I saw a thumbs up, excellent.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:38",
            "end_time": "74:40",
            "annotations": {
                "supportive response": "The speaker is expressing agreement and validation of the group's input without adding new content."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:17-04:22",
            "transcript": "Okay, if somebody needs to edit, feel do your edit now or stay quiet forever.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:40",
            "end_time": "74:45",
            "annotations": {
                "process management": "The speaker is instructing the group on how to proceed with editing, managing the meeting flow."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:22-04:23",
            "transcript": "Yes.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:45",
            "end_time": "74:46",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:23-04:51",
            "transcript": "Um you you you all should be able to get multiple proposals out of this discussion. That means it was a good I really wish we had a lot more time a lot in the same group to really think more about all the questions that came up uh I almost feel the time is too short to really carve out and and focus the discussions on something.",
            "speaking_duration": 28,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "74:46",
            "end_time": "75:14",
            "annotations": {
                "process management": "The speaker is commenting on the discussion process, specifically mentioning the time constraint and the wish for more time to explore the questions raised."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:51-05:17",
            "transcript": "That's a good point. But you you the fellows have additional time where and you have your break you have you have your what's it called? You have your other sessions at night where you could just you do your mini breakout or you could also just create your own group. Um uh and and start a discussion.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "75:14",
            "end_time": "75:40",
            "annotations": {
                "process management": "The speaker is suggesting ways to utilize the meeting time, including breaks and nighttime sessions, for mini breakouts or group discussions, which involves managing the meeting flow."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:17-05:17",
            "transcript": "And.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "75:40",
            "end_time": "75:40",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ping Wang",
            "timestamp": "05:32-05:33",
            "transcript": "I cannot see any uh.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "75:55",
            "end_time": "75:56",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:40-05:40",
            "transcript": "See what.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:03",
            "end_time": "76:03",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:41-05:43",
            "transcript": "We're we're about to close in 53 seconds.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:04",
            "end_time": "76:06",
            "annotations": {
                "process management": "The speaker is indicating that the discussion is about to close due to time constraints, managing the meeting flow."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:43-05:48",
            "transcript": "Oh, I think he pressed the button. He left the breakout. So we're 45 seconds.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:06",
            "end_time": "76:11",
            "annotations": {
                "process management": "The speaker is noting the time remaining in the session, which is an aspect of managing the meeting flow."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:51-05:54",
            "transcript": "Do you guys see the edit on the slide?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:14",
            "end_time": "76:17",
            "annotations": {
                "ask question": "The speaker is requesting information about whether others can see an edit made on a shared slide."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:54-05:54",
            "transcript": "I do.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:17",
            "end_time": "76:17",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:56-06:01",
            "transcript": "Oh, on the slide I haven't checked but I've been on your Google. Let me let me.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:19",
            "end_time": "76:24",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:01-06:04",
            "transcript": "And somebody check on the slide, is it only me who sees it or?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:24",
            "end_time": "76:27",
            "annotations": {
                "ask question": "The speaker is asking others to verify if they can see the content on the shared slide.",
                "process management": "The speaker is managing the flow of information by ensuring that everyone can see the shared slide."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:04-06:04",
            "transcript": "Let me let me.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:27",
            "end_time": "76:27",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Bot 5",
            "timestamp": "06:06-06:07",
            "transcript": "I'm checking now.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:29",
            "end_time": "76:30",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:07-06:08",
            "transcript": "Uh yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:30",
            "end_time": "76:31",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Ellen Sletten",
            "timestamp": "06:08-06:11",
            "transcript": "Putting our names in, so.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:31",
            "end_time": "76:34",
            "annotations": {
                "process management": "Ellen Sletten is taking an action to manage the process of the meeting or task by putting their names in."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "06:11-06:17",
            "transcript": "Okay guys, I'm leaving last 20. See you later.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:34",
            "end_time": "76:40",
            "annotations": {
                "process management": "Uzay Emir is managing his participation in the meeting by announcing his departure."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:17-06:17",
            "transcript": "See you later.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:40",
            "end_time": "76:40",
            "annotations": {
                "None": "No relevant code applies to this utterance"
            }
        },
        {
            "speaker": "Samuel Achilefu",
            "timestamp": "00:00-00:15",
            "transcript": "to Washington University in St. Louis. I work in the area of cancer imaging, molecular imaging in particular and in interventional radiology as well. So I look forward to your ideas and brainstorming sessions.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:17",
            "end_time": "76:32",
            "annotations": {
                "signal expertise": "The speaker explicitly states his own expertise in the area of cancer imaging, molecular imaging, and interventional radiology.",
                "encourage participation": "The speaker invites others to contribute their ideas and participate in brainstorming sessions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:18-00:41",
            "transcript": "So I'm Mary Ellen Giger from University of Chicago. I'm in radiology and medical physics and I um work in AI and medical imaging. I've done it for multiple decades um both in development, uh research, effects of different parameters as well as translation to clinical through um translational FDA work.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "76:35",
            "end_time": "76:58",
            "annotations": {
                "signal expertise": "The speaker explicitly states her own expertise and qualifications related to the task, mentioning her background in radiology, medical physics, AI, and medical imaging."
            }
        }
    ]
}