{
    "all_speakers": [
        "Mini Das",
        "Kristen Maitland",
        "Larry Cheng",
        "Joyoni Dey",
        "Mark Sellmyer",
        "Benjamin Bartelle",
        "Ulugbek Kamilov",
        "Brian Pogue",
        "Shiva Abbaszadeh",
        "Uzay Emir",
        "Morteza Mahmoudi",
        "Andrew Feig"
    ],
    "total_speaking_length": 3480,
    "all_data": [
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:00-00:10",
            "transcript": "Brian, do you want me to start off with the logistics part at the beginning and then we can kind of tag team on the um discussion and then maybe if you want to help wrap up at the end? Does that sound like a plan?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:00",
            "end_time": "00:10",
            "annotations": {
                "propose decision": "Kristen proposes a plan for how she and Brian will structure the meeting, suggesting she starts with logistics, they tag team the discussion, and Brian wraps up, and then asks if that sounds like a plan.",
                "assign task": "Kristen is assigning Brian the task of helping to wrap up the meeting at the end."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "00:11-00:12",
            "transcript": "Right. Yeah.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:11",
            "end_time": "00:12",
            "annotations": {
                "express agreement": "Brian agrees with Kristen's proposed plan to structure the meeting."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:12-00:56",
            "transcript": "Okay. Um so hopefully we have everyone in. Um so first off we need well maybe I'll just read it. So we're doing 3D imaging and tomography and I'll just read the questions that were posed to us. What are the bottlenecks that prevent rapid analysis of 3D image data sets? Pet and X-ray CT are widely used, but are there other imaging modalities that lend themselves to 3D analysis as well? What technological advances are needed to make these practical? Can multimodal approaches be used to take advantage of the best properties of each method? And so first um task is to identify um a recorder reporter. Is there anyone that would like to volunteer?",
            "speaking_duration": 44,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:12",
            "end_time": "00:56",
            "annotations": {
                "explain or define term or concept": "The speaker explains that they are doing 3D imaging and tomography, providing context for the subsequent discussion.",
                "present new idea": "The speaker introduces the questions that were posed to them regarding 3D imaging analysis, which sets the stage for the discussion.",
                "assign task": "The speaker assigns the task of being a recorder/reporter and asks for a volunteer."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "00:59-01:02",
            "transcript": "I did last time, so I'm not doing it. I did yesterday.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:59",
            "end_time": "01:02",
            "annotations": {
                "reject idea": "Benjamin rejects the idea of being the recorder/reporter, referencing his recent prior service in that role."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:03-01:05",
            "transcript": "I did it right before.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:03",
            "end_time": "01:05",
            "annotations": {
                "reject idea": "Beck rejects the task of being the recorder/reporter, referring to having done it recently."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "01:06-01:11",
            "transcript": "And we can attest it is a great job. It's very fun. Yeah, highly rewarding.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:06",
            "end_time": "01:11",
            "annotations": {
                "express humor": "Benjamin is making a joke about being the recorder/reporter, implying it's not a desirable task by saying it's 'very fun' and 'highly rewarding' after he and Beck declined to volunteer.",
                "acknowledge contribution": "Benjamin acknowledges Beck's contribution as a recorder/reporter by saying 'And we can attest it is a great job.'"
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:11-01:12",
            "transcript": "I recommend.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:11",
            "end_time": "01:12",
            "annotations": {
                "express agreement": "Beck is agreeing with Benjamin's statement that being a recorder is a great job and highly rewarding."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "01:12-01:14",
            "transcript": "Yeah, absolutely should do it.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:12",
            "end_time": "01:14",
            "annotations": {
                "express agreement": "Benjamin agrees with Beck and encourages someone else to volunteer as a recorder reporter."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:15-01:21",
            "transcript": "If we don't have a volunteer, then I have a random way to pick.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:15",
            "end_time": "01:21",
            "annotations": {
                "propose decision": "Kristen is proposing a decision to pick someone randomly if no one volunteers to be the recorder/reporter."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:22-01:39",
            "transcript": "Okay, I can I can volunteer um if there is nobody else, but after we discuss maybe if someone else wants to, we can also decide that. We've done that in the past uh so after the discussion maybe someone else will say, hey, I'd like to do it. So until then I can take notes.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:22",
            "end_time": "01:39",
            "annotations": {
                "assign task": "Mini Das volunteers to take notes until someone else volunteers, assigning herself the task of note-taking temporarily.",
                "encourage particpatioin": "Mini Das suggests that someone else might volunteer after the discussion, encouraging others to participate in the task of note-taking."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:39-02:11",
            "transcript": "Fantastic. Okay, and I did set up a um Google Doc that we can use to keep track of things rather than um doing it in the main document. So I will share that here. I will try to share that here. Um and that way everyone can um take a look. Please let me know if you can't access it. Um and we can use it together to keep track and we can um contribute to Mini's recording and then um be able to",
            "speaking_duration": 32,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Kristen Maitland shared her screen. The screen content is not visible.",
            "start_time": "01:39",
            "end_time": "02:11",
            "annotations": {
                "acknowledge contribution": {
                    "Code Name": "acknowledge contribution",
                    "Explanation": "Kristen acknowledges Mini's contribution of volunteering to be the recorder."
                },
                "expand on existing idea": {
                    "Code Name": "expand on existing idea",
                    "Explanation": "Kristen expands on the idea of recording by mentioning the Google Doc setup for tracking and collaboration."
                }
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:00-00:11",
            "transcript": "group some of the discussions based on the interests of each of us. Okay, so I will give you one minute and I will mute myself as well.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:11",
            "end_time": "02:22",
            "annotations": [
                {
                    "propose decision": "The speaker is suggesting a way to organize the discussion based on individual interests."
                },
                {
                    "assign task": "The speaker assigns herself the task of muting herself and giving the group one minute."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "00:13-00:16",
            "transcript": "What was our group number to see the question in the slide?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 1.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:24",
            "end_time": "02:27",
            "annotations": {
                "ask clarifying question": "Shiva is asking for information (group number) to understand the question presented on the slide, indicating a need for clarification."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:17-00:20",
            "transcript": "Oh, it's uh 3.5.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:28",
            "end_time": "02:31",
            "annotations": {
                "explain or define term or concept": "Kristen Maitland is clarifying the group number in response to Shiva's question."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "00:20-00:20",
            "transcript": "Thanks.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:31",
            "end_time": "02:31",
            "annotations": {
                "acknowledge contribution": "Shiva acknowledges Kristen's contribution of providing the group number."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "00:23-00:25",
            "transcript": "Slide number 50.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:34",
            "end_time": "02:36",
            "annotations": {
                "explain or define term or concept": "Mini Das is clarifying which slide to refer to, which is slide number 50."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:27-00:30",
            "transcript": "Uh, it's oh yeah.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:38",
            "end_time": "02:41",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland acknowledges Mini Das's contribution of providing the slide number."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "00:30-00:34",
            "transcript": "It's also in the Google Docs that yeah.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:41",
            "end_time": "02:45",
            "annotations": {
                "expand on existing idea": "Joyoni Dey is adding to the previous discussion about where to find the group number and question, mentioning that it's also available in the Google Docs."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "00:40-00:43",
            "transcript": "Andrew, you've joined for the one minute of silence.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:51",
            "end_time": "02:54",
            "annotations": {
                "express humor": "Brian makes a humorous remark about Andrew joining during the group's one minute of silence, likely intended as a lighthearted observation."
            }
        },
        {
            "speaker": "Andrew Feig",
            "timestamp": "00:43-00:46",
            "transcript": "That's okay. Several of the other will be quiet.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:54",
            "end_time": "02:57",
            "annotations": {
                "express humor": "Andrew makes a joke about others being quiet, following Brian's comment about him joining during a minute of silence, suggesting he's making light of the situation."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "00:46-00:49",
            "transcript": "All good.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 1.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:57",
            "end_time": "03:00",
            "annotations": {
                "express agreement": "Brian Pogue expresses agreement with Andrew's statement that several others will be quiet, indicating acceptance of the situation."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:20-00:31",
            "transcript": "Okay, so I will call out names in alphabetical order so you can introduce yourself and then give your area of interest related to this topic. So we'll start with Shiva.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:09",
            "end_time": "01:20",
            "annotations": {
                "assign task": "Kristen assigns the task of introducing themselves and their area of interest to each member as she calls their name.",
                "explain or define term or concept": "Kristen explains the process of the introductions, clarifying that members should introduce themselves and their area of interest related to the topic.",
                "encourage particpatioin": "Kristen is encouraging participation by calling out names and asking them to introduce themselves and their area of interest."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "00:31-00:55",
            "transcript": "Hi, this is Shiva Abbaszadeh. I'm assistant professor in University of California Santa Cruz. My background is electrical engineering and I do work on radiation detection, basically for X-ray CT and positron emission tomography and then how from the hardware and signal processing aspect we can improve the image quality in these modalities.",
            "speaking_duration": 24,
            "nods_others": 1,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:20",
            "end_time": "01:44",
            "annotations": {
                "explain or define term or concept": "The speaker explains their background and research area, clarifying their expertise for the group.",
                "present new idea": "The speaker introduces their work on improving image quality in X-ray CT and positron emission tomography through hardware and signal processing, which is a novel concept in the context of the meeting."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:56-00:58",
            "transcript": "Thank you. Benjamin.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:45",
            "end_time": "01:47",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges Shiva's introduction, signaling a transition to the next participant."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "00:59-01:37",
            "transcript": "Hi, my name is Benjamin Bartelle. Um, my I'm an assistant professor at Arizona State University. Uh, my goal is uh non-invasive to non-invasively resolve and manipulate the neuroimmune system. I primarily do that with MRI uh and develop methods called molecular FMRI. So that means designing molecular probes usually through synthetic biology methods to bring molecular specificity to the MRI signal and my my target is largely the neuroimmune interactions um occurring in a living mouse.",
            "speaking_duration": 38,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:48",
            "end_time": "02:26",
            "annotations": {
                "explain or define term or concept": "Benjamin explains his research goal of non-invasively resolving and manipulating the neuroimmune system, specifying his methods using MRI and molecular FMRI, which clarifies his area of expertise for the group."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:37-01:39",
            "transcript": "Thank you. Larry.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:26",
            "end_time": "02:28",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges the previous speaker's introduction before moving on to the next person."
            }
        },
        {
            "speaker": "Larry Cheng",
            "timestamp": "01:40-02:41",
            "transcript": "Hi, my name is Larry. I'm assistant professor at Penn State University. My background is in mechanical engineering. I'm trying to apply the deformable structure and devices for the health monitoring and imaging of the human health condition, more continuous monitoring activities. And we have been interested in the stretch or acoustic photoacoustic wave for the brain imaging and electrical impedance tomography to complement the MRI for the fast imaging capabilities as well as the remote monitoring in term of the mesh surface for the microwave scattering so that we can do that behind the obstacles and that could be also a unique application with the physical implementation of the machine learning imaging with that modality.",
            "speaking_duration": 61,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:29",
            "end_time": "03:30",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is introducing their background and research interests, which involves explaining their approach to health monitoring and imaging using deformable structures and devices."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:41-02:43",
            "transcript": "Thank you. Mini.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:30",
            "end_time": "03:32",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges the previous speaker's introduction before moving on to the next person."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:43-03:33",
            "transcript": "Hi, this is Mini Das from University of Houston. I'm an associate professor in physics and biomedical engineering. My background is applied physics, optical sciences and some of the recent work has been in looking at using light transport model or electromagnetic transport models in conjunction with advanced detectors to to come up with methods for identifying new contrast mechanism, for example, phase changes of X-rays rather than simple absorption and then looking at more recently also multimodality and near infrared optical imaging where the inverse problem is very ill conditioned and how can you potentially improve those those kind of problems.",
            "speaking_duration": 50,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:32",
            "end_time": "04:22",
            "annotations": {
                "present new idea": "Mini Das introduces the idea of using light transport models or electromagnetic transport models in conjunction with advanced detectors to identify new contrast mechanisms, such as phase changes of X-rays rather than simple absorption, which is a novel concept not previously mentioned by others.",
                "expand on existing idea": "Mini Das expands on the idea of multimodality and near infrared optical imaging, building on the general topic of imaging modalities discussed by others by mentioning the ill-conditioned inverse problem and potential improvements.",
                "explain or define term or concept": "Mini Das explains the concept of identifying new contrast mechanisms, giving the example of phase changes of X-rays rather than simple absorption to clarify the type of contrast mechanism she is referring to."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:33-03:35",
            "transcript": "Thank you. Joyoni.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:22",
            "end_time": "04:24",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges Mini's contribution after Mini introduced herself and her research interests."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "03:36-05:24",
            "transcript": "Hi, I'm a physics faculty at LSU. I teach at the medical physics. My research is also in phase contrast X-ray and I'm trying to develop a phase contrast mammography system as well as a CT system is contrast. And I also I have worked in the past on spec reconstruction, iterative reconstruction with motion correction and also novel MPG sorry multipinol geometries and stuff like that. So I the just relevant to this topic what I'm kind of interested right now I would be interested is to have a iterative reconstruction method for phase contrast with the raw interferometric data. So as you know that phase contrast you have to derive so from the projections you have to derive the you know the attenuation image, the phase image and the scatter image and then you reconstruct and so if I could do it from the raw interference patterns it's very challenging because of the very computational requirements. Okay it's very high computational requirements. And I'm also interested in deep learning methods for that like for some of these reconstruction methods. And also I think that will help our phase contrast in in correcting some of the errors due to large you know grating artifacts. So you know like it can learn a lot of things that ordinary reconstruction methods would not. And as for just a quick addition that no that's okay yeah I think that's enough.",
            "speaking_duration": 108,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:25",
            "end_time": "06:13",
            "annotations": [
                {
                    "present new idea": "The speaker introduces the idea of using an iterative reconstruction method for phase contrast with raw interferometric data, which is a novel approach not previously discussed in the introductions."
                },
                {
                    "explain or define term or concept": "The speaker explains that in phase contrast imaging, one has to derive the attenuation, phase, and scatter images from the projections before reconstruction, providing context for the challenges involved."
                },
                {
                    "present new idea": "The speaker presents the idea of using deep learning methods for reconstruction and correcting errors due to grating artifacts in phase contrast imaging, which is a new suggestion."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:30-05:33",
            "transcript": "Okay, thank you. Um, Uzay.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:19",
            "end_time": "06:22",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is calling on the next person, Uzay, to introduce themselves and their area of interest, continuing the round-robin introductions."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "05:34-05:56",
            "transcript": "Hello. Uh my name is Uzay and I'm assistant professor at the School of Health Science Purdue University. And my focus of research is developing novel imaging techniques for pre-clinical and clinical MRI that spans from application from top to bottom of the body.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:23",
            "end_time": "06:45",
            "annotations": {
                "explain or define term or concept": "The speaker is defining their area of research as developing novel imaging techniques for pre-clinical and clinical MRI, which clarifies their expertise for the group."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:56-05:58",
            "transcript": "Thank you. Beck.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:45",
            "end_time": "06:47",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland acknowledges the previous speaker's introduction before moving on to the next person."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "05:59-07:12",
            "transcript": "Hi everyone. So I'm an assistant professor at in computer science and also in EE at Washington University in St. Louis. Um what I do is I do um algorithms for for image processing in different levels. So we do image analysis, image reconstruction and artifact correction, classification registration. Uh so in the topics uh in this um group uh so I do work on um X-ray CT for scientific imaging where uh some of the issue we look at is uh uh registration of um uh um um of measurements of tomograms. We do work I do have a project on increasing SNR computationally for pet. Uh one on um incorporating multiple light scattering into uh optical tomography uh so um label free optical tomography and another one is building optical coherence tomography but by scanning different angles instead of just by using uh uh look at one side. Uh so those are the projects I do but I do all my work is essentially computational with a lot of deep learning in it.",
            "speaking_duration": 73,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:48",
            "end_time": "08:01",
            "annotations": {
                "explain or define term or concept": "The speaker explains their research focus, which includes algorithms for image processing, image analysis, image reconstruction, artifact correction, classification, and registration.",
                "present new idea": "The speaker presents several projects, including increasing SNR computationally for PET, incorporating multiple light scattering into optical tomography, and building optical coherence tomography by scanning different angles.",
                "provide supporting evidence": "The speaker supports their introduction by listing specific projects they are working on, such as X-ray CT for scientific imaging and optical coherence tomography."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:12-07:14",
            "transcript": "Great. Thank you.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:01",
            "end_time": "08:03",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland acknowledges the previous speaker's contribution after they introduced themselves and their research interests."
            }
        },
        {
            "speaker": "Morteza Mahmoudi",
            "timestamp": "07:14-08:28",
            "transcript": "Hi everyone. My name is Morteza Mahmoudi and I'm an assistant professor at Michigan State University. So my research is focused on nanomedicine and regenerative medicine. From nanomedicine point of view, we basically develop magnetic based contrast agents for MRI basically we can track nanoparticles themselves or like we use them for cell therapy applications. Um another part of the research that we do is like imaging the nanobio interfaces where nanoparticles basically interact with biological fluids and the proteins and other like biomolecules come to their surfaces. So for that purpose we use cryo transmission electron microscopy which with combined with imaging technique to get a 3D structure of the nanoparticles.",
            "speaking_duration": 74,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:03",
            "end_time": "09:17",
            "annotations": {
                "present new idea": "Morteza introduces his research focus on nanomedicine and regenerative medicine, which is a novel concept in the context of the introductions.",
                "explain or define term or concept": "Morteza explains his research on developing magnetic-based contrast agents for MRI to track nanoparticles and image nanobio interfaces, clarifying his specific area of expertise.",
                "provide supporting evidence": "Morteza supports his research by mentioning the use of cryo transmission electron microscopy combined with imaging techniques to get a 3D structure of nanoparticles, providing details about his methods."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:28-08:32",
            "transcript": "Thank you. And last but not least, Mark.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "09:17",
            "end_time": "09:21",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is inviting Mark to introduce himself and his area of interest, similar to how she invited others previously."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "08:33-09:13",
            "transcript": "Fair enough. Um, so I'm Mark Sellmeyer. I'm an assistant professor, my third year at UPenn. Um, I am chemical biologist and synthetic biologist. So we develop small molecule tools for biologists and um on the molecular imaging front try to make new diagnostics or approaches that let us both image and control gene and cell therapies. Um, I do uh deal one day a week of clinical nuclear radiology and um have been the PI on clinical protocols before that translate molecular imaging approaches.",
            "speaking_duration": 40,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "09:22",
            "end_time": "10:02",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is defining their background and expertise as a chemical biologist and synthetic biologist, which is relevant to the group's discussion on imaging."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "09:13-09:14",
            "transcript": "Great.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:02",
            "end_time": "10:03",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges the previous speaker's contribution after they introduced themselves and their research interests."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "09:14-09:44",
            "transcript": "Thank you. Well, we have an exciting mix of different modalities and different scales and both technology application and maybe contrast. Um, so I think I will first just open it up if anybody wants to respond based on what they've heard from someone else, um,",
            "speaking_duration": 30,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:03",
            "end_time": "10:33",
            "annotations": {
                "express enthusiasm": "Kristen expresses excitement about the diverse mix of modalities, scales, technology, application, and contrast represented by the participants.",
                "encourage particpatioin": "Kristen encourages participants to respond based on what they've heard from others, opening the floor for discussion."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "09:44-09:44",
            "transcript": "I'll give it a few seconds.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:33",
            "end_time": "10:33",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is encouraging participation by giving the team a few seconds to respond to what they've heard from others."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "09:44-09:44",
            "transcript": "Go ahead.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:33",
            "end_time": "10:33",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is encouraging someone to speak up and contribute to the discussion."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "09:45-10:00",
            "transcript": "Well we're talking. Uh I mean it was really surprising how the previous sessions had a lot of convergences. There was a lot of um agreeance on the need for reporter genes, a lot of agreeance on multimodal approaches and I thought I thought all that",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:34",
            "end_time": "10:49",
            "annotations": {
                "express agreement": "Benjamin expresses agreement with the previous sessions, noting the convergences and agreeance on the need for reporter genes and multimodal approaches."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "00:10-00:54",
            "transcript": "I'll say that, you know, on this my my 30 seconds of thinking about the very first um question is that yeah, pet and CTR are already reconstructed very well and you know, have the software platforms that are easily amenable to scroll through an imaging set.",
            "speaking_duration": 44,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "10:59",
            "end_time": "11:43",
            "annotations": {
                "provide supporting evidence": "The speaker states that PET and CT are already reconstructed very well and have software platforms that are easily amenable to scroll through an imaging set, providing evidence related to the first question.",
                "expand on existing idea": "The speaker is expanding on the discussion of imaging modalities by stating that PET and CT are already reconstructed very well and have software platforms that are easily amenable to scroll through an imaging set."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "00:54-01:04",
            "transcript": "sort of like imaging probe readout on one scroll side and pathologic, you know, um IHC or whatever on the other and be able to correlate.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "11:43",
            "end_time": "11:53",
            "annotations": {
                "expand on existing idea": "Building on the previous discussion about the need for multimodal approaches, this utterance expands on that idea by suggesting a way to correlate imaging probe readouts with pathologic data."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "01:04-01:24",
            "transcript": "I think in my world, you know, one of the challenges is like if we um have a probe that shows uptake in one part of the tumor. Um, you know, how do you go back and then validate that that uptake was really become from the target that you set out to at the very beginning.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "11:53",
            "end_time": "12:13",
            "annotations": {
                "present new idea": "Mark introduces the challenge of validating probe uptake in tumors, which is a novel problem presented to the group.",
                "explain or define term or concept": "Mark explains the challenge of validating if the probe uptake in a tumor is actually from the intended target, clarifying a key issue in his research area."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "01:24-01:57",
            "transcript": "Um, that can be for tumor heterogeneity, but I also think about it for like some of our infectious disease probes where like it's not a nicely matted tumor that's, you know, growing in a circle and you can pinpoint the spot, it's like interpolating amongst among the cells and among the normal um tissues of the person for an infection. And so there the challenge is even harder. So, um, getting path to be a little more 3D would be lovely.",
            "speaking_duration": 33,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:13",
            "end_time": "12:46",
            "annotations": {
                "expand on existing idea": "He is expanding on the previous discussion about imaging probes and challenges in validating their uptake, particularly in the context of tumor heterogeneity and infectious disease.",
                "present new idea": "He introduces the idea of improving pathology to be more 3D to better validate probe uptake in heterogeneous environments."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:59-02:17",
            "transcript": "I think that's a great point about tumor heterogeneity whether um our currently available 3D imaging systems are allowing us to capture this correctly uh and that the limitations comes from uh signal corruption for the most part.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:48",
            "end_time": "13:06",
            "annotations": {
                "acknowledge contribution": "Mini Das acknowledges Mark Sellmyer's point about tumor heterogeneity.",
                "ask clarifying question": "Mini Das asks whether current 3D imaging systems are correctly capturing tumor heterogeneity, which seeks clarification on the limitations of current systems.",
                "provide supporting evidence": "Mini Das supports her question by stating that limitations come from signal corruption, providing a reason for the potential inadequacy of current 3D imaging systems."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:17-02:30",
            "transcript": "It could be scatter or the need to correct them accurately. But I was wondering if if multimodality could help in that regard maybe if anyone has thoughts on I I I was intrigued by that last point.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:06",
            "end_time": "13:19",
            "annotations": {
                "explain or define term or concept": "The phrase \"It could be scatter or the need to correct them accurately\" explains a potential limitation of current 3D imaging systems, which is signal corruption.",
                "ask clarifying question": "Mini Das is asking if multimodality could help with tumor heterogeneity, building on Mark Sellmyer's point about the challenges of validating probe uptake in tumors.",
                "acknowledge contribution": "Mini Das acknowledges Mark Sellmyer's point about tumor heterogeneity by saying she was intrigued by that last point."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:30-02:47",
            "transcript": "I think uh it was presented in I don't remember the group now, but where uh there was a discussion on targeting uh and then my thought was region of interest reconstruction.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:19",
            "end_time": "13:36",
            "annotations": {
                "expand on existing idea": "Mini Das is building on the previous discussion about targeting by adding the idea of region of interest reconstruction, which could potentially address the challenges of tumor heterogeneity.",
                "present new idea": "Mini Das introduces the idea of region of interest reconstruction, which was not explicitly mentioned before in the conversation."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:47-03:16",
            "transcript": "If you could uh for example have a targeting with one probe then we know that well, this is around the area that's of interest and then for example your your your data data that you really want to deal with uh you know that everything else is kind of not of interest maybe it would help data reduction maybe.",
            "speaking_duration": 29,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "13:36",
            "end_time": "14:05",
            "annotations": {
                "expand on existing idea": "Mini is expanding on the idea of targeting, suggesting that if one probe targets a specific area, it can help identify the region of interest and reduce data.",
                "present new idea": "Mini presents a new idea of using the targeted area to reduce the amount of data needed for analysis, suggesting that areas outside the target are less important.",
                "propose decision": "Mini proposes a decision to use targeting with one probe to identify the area of interest and reduce the amount of data needed for analysis."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "03:16-03:16",
            "transcript": "That was kind of what I was trying to say at that time when we just moved on.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:05",
            "end_time": "14:05",
            "annotations": {
                "acknowledge contribution": "Mini Das is acknowledging that she was trying to convey a specific idea earlier in the conversation, but the discussion moved on before she could fully express it."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:17-03:19",
            "transcript": "was in our group. I think I was.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:06",
            "end_time": "14:08",
            "annotations": {
                "acknowledge contribution": "Beck acknowledges that the discussion Mini is referring to happened in his group, recognizing Mini's input."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "03:19-03:25",
            "transcript": "It was it was I think I don't remember the number now, but that's correct.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:08",
            "end_time": "14:14",
            "annotations": {
                "acknowledge contribution": "Mini Das acknowledges that Beck Kamilov was in the group being discussed, recognizing his input to the conversation."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "03:25-03:34",
            "transcript": "Yes, if if that would be an interesting uh idea to think in that yes and data reduction with multimodality.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:14",
            "end_time": "14:23",
            "annotations": {
                "express agreement": "Mini Das expresses agreement with the idea of data reduction with multimodality, which was previously discussed in the group.",
                "expand on existing idea": "Mini Das expands on the existing idea of data reduction with multimodality, building upon the previous discussion about targeting and region of interest reconstruction."
            }
        },
        {
            "speaker": "Larry Cheng",
            "timestamp": "03:35-04:57",
            "transcript": "Yeah, I'm not sure whether this is a proper example, but well was trying to look at how we can do the uh balance between the temporal space resolution for the brain imaging. And we were looking at the functional MRI and optical imaging and they are each advantageous for certain aspects, but um by looking at the photo acoustic it seems to be better when we have the input signal from optical and attenuation will be um less concerned when we don't need to worry about the uh signal signal out from that uh skull attenuation by looking at the acoustic signature and this will actually enable us to push this imaging down to uh actually 1 millimeter down into the brain tissue. So, uh I think this is a combination of the optical and acoustic for the acoustic photo acoustic imaging. And maybe for the other things, I was also thinking about to use uh certain uh contrast agents and this is really something people have been looking at with uh maybe a different application for photo uh optogenetics operation and they seem to be able to get those non particle inside the brain. So maybe they can also be combined to uh help the multimodality imaging.",
            "speaking_duration": 82,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:24",
            "end_time": "15:46",
            "annotations": [
                {
                    "expand on existing idea": "Larry is expanding on the idea of multimodality imaging, which was previously discussed, by providing an example of using functional MRI and optical imaging for brain imaging and suggesting photoacoustic imaging as a better alternative due to its advantages in temporal and spatial resolution."
                },
                {
                    "provide supporting evidence": "Larry provides supporting evidence for the use of photoacoustic imaging by mentioning that it allows pushing imaging down to 1 millimeter into the brain tissue due to the combination of optical and acoustic signals."
                },
                {
                    "expand on existing idea": "Larry expands on the idea of multimodality imaging by suggesting the use of contrast agents and optogenetics operation, building upon the previous discussion of combining different imaging modalities."
                }
            ]
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "05:00-05:04",
            "transcript": "Mini regarding to your uh questions.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:49",
            "end_time": "15:53",
            "annotations": {
                "acknowledge contribution": "Uzay acknowledges Mini's prior questions, recognizing her input in the discussion."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "05:04-05:15",
            "transcript": "that we discussed with Blueberg in the same session. So I uh I think that's come from probing things is uh I give an example for that.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:53",
            "end_time": "16:04",
            "annotations": {
                "expand on existing idea": "Uzay refers back to a discussion with Blueberg in the same session, indicating he is expanding on a previously mentioned idea related to probing things.",
                "provide supporting evidence": "Uzay mentions that he gave an example for the idea, suggesting he is providing supporting evidence to strengthen the idea."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "05:15-05:30",
            "transcript": "For example, the glioma patients I was discussing about that. So you you open the brain, you do have a sample right in front of you and you tailor your uh optical imaging technique that's sensitive to the certain enzyme.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "16:04",
            "end_time": "16:19",
            "annotations": {
                "expand on existing idea": "Uzay is expanding on a previous discussion about probing techniques, specifically referencing the glioma patient example he discussed with Blueberg in the same session.",
                "provide supporting evidence": "Uzay provides an example of glioma patients where optical imaging techniques can be tailored to be sensitive to specific enzymes when a brain sample is available."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "05:30-06:25",
            "transcript": "And you do get the information and you might find some corresponding things non invasive imaging modality coming from MRI, path contrast or whatever you do think. And then you do get since it is already open for histological analysis, you can take the pathology and do do DNA sequencing and do do so this dimension reduction is coming from that because there will be a massive amount of data is coming. So then one of our colleagues during that discussion suggested that to tailor the optical imaging to certain things and then this enzyme enzyme specific uh optical imaging or it can be tailored. I'm not an optical person, so I'm not an expert, so I really don't want to make uneducated uh assumptions, but that is how that uh tailored approach come up. Am I right Blueberg? So am I missing or",
            "speaking_duration": 55,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "16:19",
            "end_time": "17:14",
            "annotations": {
                "expand on existing idea": "Uzay is expanding on the idea of tailoring optical imaging to specific enzymes, which was previously discussed with Blueberg, and how this approach can be combined with other imaging modalities like MRI and pathology for dimension reduction.",
                "provide supporting evidence": "Uzay provides the example of glioma patients where the brain is open, allowing for optical imaging tailored to specific enzymes, followed by histological analysis and DNA sequencing, to support the idea of dimension reduction.",
                "ask clarifying question": "Uzay asks Blueberg if he is correct in his explanation and if he is missing anything, seeking confirmation and clarification on the previously discussed idea."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:25-06:26",
            "transcript": "No, you completely.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:14",
            "end_time": "17:15",
            "annotations": {
                "express agreement": "Beck explicitly agrees with Uzay's summary of the discussion with Blueberg in the previous session."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:26-06:35",
            "transcript": "It was Ellen, if some if you're interested to talk to her, Ellen was a person who brought it up and she said she's very interested in that area. she has specifically said it.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:15",
            "end_time": "17:24",
            "annotations": {
                "acknowledge contribution": "Beck acknowledges that Ellen was the person who brought up the idea, recognizing her contribution to the discussion."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "06:35-06:36",
            "transcript": "maybe maybe Brian can.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:24",
            "end_time": "17:25",
            "annotations": {
                "encourage particpatioin": "Mini Das is encouraging Brian to participate in the discussion, likely to get his input on the topic being discussed."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "06:36-07:37",
            "transcript": "comment on this uh near infrared diffuse optical imaging, the problem with the 3D uh the problem itself has been, you know, well known to be very ill conditioned problem. And uh I looked at it sometime ago for breast imaging and you know, there are ways to ways to make it improve it by for example adding some information uh we had uh we were looking at using for example ultrasound uh localization. But more recently what I'm seeing is you are people are moving towards saying instead of accurate quantitation or finding exact volumetric concentration, let's look at fluctuations uh that happen uh well when when I guess this is more for brain imaging now we are talking if. So Brian, could you comment on I haven't looked at what was the evolution and how what's what's happening now with the exact quantitation part has it been done or given up or what's what's where is the field in that regard.",
            "speaking_duration": 61,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:25",
            "end_time": "18:26",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker explains that near infrared diffuse optical imaging has a 3D problem that is well known to be very ill conditioned."
                },
                {
                    "expand on existing idea": "The speaker expands on the idea of near infrared diffuse optical imaging by mentioning past work using ultrasound localization to improve it and current trends of focusing on fluctuations instead of accurate quantitation."
                },
                {
                    "encourage particpatioin": "The speaker encourages Brian to comment on the current state of exact quantitation in near infrared diffuse optical imaging."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "07:37-08:22",
            "transcript": "Yeah, I mean I think most work has been done in functional near infrared, you know, to to to couple to MR. So that's a multimodality, right, where you get the structure from MR and then temporal dynamics from near infrared. Um, certainly a lot going on. Um, we've we've we've spent a lot of time trying to do image guided spectroscopy with diffuse light and that's possible. So that's sort of a hybrid approach, right, where you've got the structure from CT or ultrasound or MRI and then layer in that as a a priori guide to the optical spectroscopy because you know optics is terrible, right? It's really blurry and",
            "speaking_duration": 45,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "18:26",
            "end_time": "19:11",
            "annotations": {
                "expand on existing idea": "Brian is responding to Mini's question about near infrared diffuse optical imaging and expands on the idea by mentioning that most work has been done in functional near infrared to couple to MR.",
                "explain or define term or concept": "Brian explains that using MR to get structure and near infrared for temporal dynamics is a multimodality approach.",
                "provide supporting evidence": "Brian provides supporting evidence by stating that they have spent a lot of time trying to do image-guided spectroscopy with diffuse light, which is a hybrid approach using structure from CT, ultrasound, or MRI to guide optical spectroscopy."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:22-08:30",
            "transcript": "Diffuse optics anyway, it's really terrible. I'm intrigued by the idea of trying to get pathologic level information from a",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:11",
            "end_time": "19:19",
            "annotations": {
                "express frustration": {
                    "Explanation": "Brian expresses frustration with diffuse optics by stating that it is \"really terrible\", indicating a dissatisfaction with its limitations."
                },
                "express enthusiasm": {
                    "Explanation": "Brian expresses enthusiasm by saying he is intrigued by the idea of getting pathologic level information, showing excitement about this potential direction."
                }
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:30-08:44",
            "transcript": "from MR scan like through an endoscope or something. Um, optics is tough though, right? Because either it's diffuse or it's microscopic.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:19",
            "end_time": "19:33",
            "annotations": {
                "present new idea": "Brian Pogue presents a new idea of getting pathologic level information from an MR scan through an endoscope, which hasn't been discussed before in this specific context.",
                "explain or define term or concept": "Brian Pogue explains that optics is tough because it's either diffuse or microscopic, clarifying the challenges associated with optical imaging."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:44-08:44",
            "transcript": "There's almost no in between.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:33",
            "end_time": "19:33",
            "annotations": {
                "explain or define term or concept": "This utterance explains the limitations of optics in imaging, stating that it is either diffuse or microscopic, implying a lack of intermediate options."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "08:45-08:45",
            "transcript": "So the",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:34",
            "end_time": "19:34",
            "annotations": {
                "None": "This utterance is incomplete and does not express a complete idea, question, or statement, so no code applies."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "08:45-08:45",
            "transcript": "So the",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:34",
            "end_time": "19:34",
            "annotations": {
                "None": "The utterance is incomplete and does not express a complete thought or idea."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "09:18-09:18",
            "transcript": "Because of the",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:07",
            "end_time": "20:07",
            "annotations": {
                "None": "The utterance is incomplete and does not express a complete idea, question, or statement."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "09:29-09:36",
            "transcript": "diffusing kind of gets rid of most adaptive optics uh in my experience.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:18",
            "end_time": "20:25",
            "annotations": {
                "explain or define term or concept": "Brian is explaining the limitations of diffuse optics by stating that it interferes with adaptive optics, which is a concept related to improving image quality."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "09:38-09:41",
            "transcript": "because of the the way wave is modeled or because of the",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:27",
            "end_time": "20:30",
            "annotations": {
                "ask clarifying question": "Beck is asking a clarifying question about why adaptive optics are difficult to use with diffuse light, building on Brian's statement that 'diffusing kind of gets rid of most adaptive optics'."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "09:41-09:46",
            "transcript": "So where where does where do you lose that adaptivity in the optics?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:30",
            "end_time": "20:35",
            "annotations": {
                "ask clarifying question": "Beck is asking Brian to clarify where the adaptivity is lost in optics, following Brian's statement that diffusion gets rid of most adaptive optics."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "00:00-00:07",
            "transcript": "banana shape path. So you have a source and detector at the same plane, you're collecting maybe the reflected or you could do transmit it.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:49",
            "end_time": "20:56",
            "annotations": {
                "explain or define term or concept": "Mini Das is explaining the concept of the 'banana shape path' in diffuse optics, describing the relative positions of the source and detector and the types of light collected, which provides context for the discussion on near-infrared diffuse optical imaging."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:08-00:20",
            "transcript": "Yeah, as far as I understand like optical coherence kind of uses coherence to kind of select where you do and then there is um um there's another technique. What's Oh yeah, photoacoustic, right? And where they use uh acoustic wave to zoom.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:57",
            "end_time": "21:09",
            "annotations": {
                "explain or define term or concept": "The speaker explains how optical coherence uses coherence to select where to image, and then transitions to explaining photoacoustic imaging.",
                "present new idea": "The speaker introduces photoacoustic imaging as another technique that uses acoustic waves to zoom, which is a new idea in the context of the discussion about optical imaging techniques."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "00:20-00:22",
            "transcript": "Right, there is.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:09",
            "end_time": "21:11",
            "annotations": {
                "express agreement": "Mini Das agrees with Beck Kamilov's statement about photoacoustic imaging using acoustic waves to zoom, indicating agreement with the previous turn."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:22-00:30",
            "transcript": "Now, seems like there's almost uh so when you want to you go to a diffuse regime, okay, of course, we lose because of scattering everything.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:11",
            "end_time": "21:19",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining the implications of working in a diffuse regime in optics, which relates to the scattering of light.",
                "express agreement": "The speaker is agreeing with the prior discussion about the challenges of diffuse optics, specifically that scattering causes loss of information."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:30-00:42",
            "transcript": "But then if there is some form of selectivity you can impact there, right? Where you can get information and then you can combine that with adaptive optics to kind of focus there.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:19",
            "end_time": "21:31",
            "annotations": {
                "expand on existing idea": "Building on the discussion about optical imaging techniques and their limitations, Beck suggests that if there's a way to achieve some selectivity in the diffuse regime, it could be combined with adaptive optics to improve focus, expanding on the idea of improving optical imaging.",
                "present new idea": "Beck presents the idea of combining selectivity in the diffuse regime with adaptive optics to improve focus, which is a novel approach to address the limitations of diffuse optical imaging discussed earlier."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:42-01:00",
            "transcript": "There was like a very nice nature communication paper, I think last year where guys were trying to go in depth by trying to do adaptive optics and compensating for diffusion. I mean the images didn't look so great, but the claims sounded good.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:31",
            "end_time": "21:49",
            "annotations": {
                "provide supporting evidence": "Beck mentions a Nature Communications paper about adaptive optics compensating for diffusion, providing a reference to support the discussion on improving optical imaging.",
                "offer constructive criticism": "Beck critiques the paper by saying \"the images didn't look so great\", providing a negative assessment of the results while still acknowledging the potential of the claims."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:00-01:04",
            "transcript": "sort of approaches with like a guide star type refocusing, that kind of thing.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:49",
            "end_time": "21:53",
            "annotations": {
                "expand on existing idea": "Brian Pogue is expanding on the discussion about optical imaging techniques, specifically mentioning \"guide star type refocusing\" as a potential approach, building upon the previous discussion of adaptive optics and compensating for diffusion."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:05-01:17",
            "transcript": "No, that that's the thing. So it's kind of trying to imitate guided star, but there is no real guided star. It's more like using adaptive optics and rejection of scatter by using scattering model at different depths, so there is no specific guided star.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:54",
            "end_time": "22:06",
            "annotations": {
                "expand on existing idea": "Beck is expanding on Brian Pogue's mention of 'guide star type refocusing' by clarifying that the approach imitates a guide star but doesn't use a real one, instead using adaptive optics and a scattering model.",
                "explain or define term or concept": "Beck is explaining the concept of an approach that imitates a guided star by using adaptive optics and rejection of scatter by using a scattering model at different depths.",
                "reject idea": "Beck rejects the idea that the approach uses a real guided star."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:18-01:18",
            "transcript": ".",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:07",
            "end_time": "22:07",
            "annotations": [
                {
                    "None": "No code applies to this utterance."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "01:22-01:57",
            "transcript": "larger question about that. So we want as someone who's spent their entire life on MRI. We want optics because the wealth of probes, right? The specific labeling, sensors, ratiometric imaging, that is that that's why we want and the resolution I suppose. But if we didn't need that, if we had MR specific sensors, if we had pet specific probes and you didn't you didn't need those those sensor technologies that are already established, what's left for optics? Just the resolution?",
            "speaking_duration": 35,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:11",
            "end_time": "22:46",
            "annotations": [
                {
                    "present new idea": "The speaker is presenting a hypothetical scenario where MRI and PET have the same probe capabilities as optics, questioning the remaining value of optics beyond resolution, which introduces a novel thought experiment."
                },
                {
                    "ask clarifying question": "The speaker is asking what the remaining value of optics would be if MRI and PET had the same probe capabilities, seeking clarification on the unique advantages of optics."
                }
            ]
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:57-01:58",
            "transcript": "Cost. I would say cost.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:46",
            "end_time": "22:47",
            "annotations": {
                "provide supporting evidence": "Beck is providing a reason why optics is still relevant by stating that it is more cost effective than MRI or PET, answering Benjamin's question about what is left for optics if MRI and PET had specific probes."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:59-01:59",
            "transcript": "Cost.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:48",
            "end_time": "22:48",
            "annotations": {
                "provide supporting evidence": "Brian Pogue is providing a reason why optics is still relevant, supporting Beck Kamilov's statement that cost is a factor."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "02:01-02:05",
            "transcript": "MR cost and then it's a speed also. I guess the speed.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:50",
            "end_time": "22:54",
            "annotations": {
                "provide supporting evidence": "Beck is providing supporting evidence for why optics is still relevant by stating that MRI has a higher cost and is slower than optics, which supports the previous question of what is left for optics if MR and PET had specific probes."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:05-02:16",
            "transcript": "Also I guess non radiological. There are there is a big group of people interested in probing without ionizing radiation. Of course MR does not have that, but the cost is much less, right?",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:54",
            "end_time": "23:05",
            "annotations": {
                "provide supporting evidence": "Mini Das provides evidence for the value of non-ionizing radiation methods by stating that there is a big group of people interested in probing without ionizing radiation, which supports the discussion about the benefits of optics compared to MRI and PET.",
                "explain or define term or concept": "Mini Das explains the concept of non-radiological imaging, clarifying that it involves probing without ionizing radiation, which is relevant to the ongoing discussion about the advantages of different imaging modalities.",
                "express agreement": "Mini Das expresses agreement with the previous speakers by stating that the cost is much less, which supports the idea that cost is a benefit of optics compared to MRI."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "02:17-02:19",
            "transcript": "And also dimensionality.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:06",
            "end_time": "23:08",
            "annotations": {
                "expand on existing idea": "This utterance adds 'dimensionality' to the list of advantages of optics (over MRI) that were previously mentioned, such as cost, speed and non-radiological nature."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "02:19-02:34",
            "transcript": "So it's just portable, you can take it depending on what device you are having and that's making it feasible. You can get into the surgery room and get immediate response what the tumor is before you take the biopsies.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:08",
            "end_time": "23:23",
            "annotations": {
                "expand on existing idea": "Uzay is expanding on the discussion about the advantages of optics by adding that it is portable and can be used in the surgery room to get immediate responses about the tumor before taking biopsies, building on the previous discussion about cost, speed, and non-radiological aspects of optics.",
                "provide supporting evidence": "Uzay provides supporting evidence for the advantages of optics by stating that it can be used in the surgery room to get immediate responses about the tumor before taking biopsies, supporting the idea that it is feasible and portable."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "02:34-02:43",
            "transcript": "So you can identify this with this Raman spectroscopies and those things it has been shown. So it is powerful when it comes to do this kind of diagnostic purposes.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:23",
            "end_time": "23:32",
            "annotations": {
                "provide supporting evidence": "The utterance provides Raman spectroscopies as evidence for identifying something, suggesting its power for diagnostic purposes, building on the previous discussion about the feasibility and power of portable devices like Raman spectroscopies for diagnostic purposes.",
                "express enthusiasm": "The utterance expresses enthusiasm by stating that Raman spectroscopies are \"powerful\" for diagnostic purposes, building on the previous discussion about the feasibility and power of portable devices like Raman spectroscopies for diagnostic purposes."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "02:44-03:11",
            "transcript": "So the multi spectral aspect of it is also the the thing that you want, right? you bring upscopy, I was talking about sensors. The fact that light is multi spectral means it's never going to go away. You can't replace it with ultrasound. I don't even think you can replace it with optoacoustics just because your readout is always funnel through that um one channel pipeline of the the acoustics.",
            "speaking_duration": 27,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:33",
            "end_time": "24:00",
            "annotations": {
                "expand on existing idea": "Benjamin is expanding on the discussion about the advantages of optics by highlighting the multi-spectral aspect of light, which is a unique advantage over ultrasound and optoacoustics, building on the previous discussion about the benefits of optics.",
                "express agreement": "Benjamin agrees that the multi-spectral aspect of light is a desirable feature, as indicated by his statement 'So the multi spectral aspect of it is also the the thing that you want, right?'"
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "03:11-03:12",
            "transcript": "I just bring that because I think that's the pernicious problem of it.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:00",
            "end_time": "24:01",
            "annotations": {
                "None": "This utterance does not fit into any of the defined codes, as it is a concluding remark without introducing new ideas, expanding on existing ones, or proposing decisions."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "03:13-03:30",
            "transcript": "Well, you know, your your question made me think about, you know, what about pet CT? I mean that that's actually pretty pretty awesome. Pet CT works really well. It's got, you know, in principle pet has molecular tracers for all kinds of targets.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:02",
            "end_time": "24:19",
            "annotations": {
                "present new idea": "Brian Pogue introduces the idea of using PET/CT as a solution, which hasn't been explicitly discussed in the immediate prior turn, to address the challenges of imaging and molecular tracers.",
                "express enthusiasm": "Brian Pogue expresses enthusiasm for PET/CT by stating that it is \"pretty awesome\" and \"works really well.\""
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "03:30-03:38",
            "transcript": "And yet it's really not widely used that much. And presumably due to cost.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:19",
            "end_time": "24:27",
            "annotations": {
                "provide supporting evidence": "The statement \"And yet it's really not widely used that much\" supports the previous discussion about the potential of PET CT, suggesting that despite its potential, its usage is limited, and the following statement \"And presumably due to cost\" provides a reason for this limitation.",
                "explain or define term or concept": "The phrase \"And presumably due to cost\" explains why PET CT is not widely used, providing a potential reason related to economic factors."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "03:39-03:40",
            "transcript": "But it's also not multi spectral.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:28",
            "end_time": "24:29",
            "annotations": {
                "expand on existing idea": "Benjamin is expanding on Brian's point about PET/CT by pointing out a limitation of PET/CT, which is that it is not multi-spectral, building on the discussion of the advantages of multi-spectral imaging."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "03:40-03:41",
            "transcript": "Mini.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:29",
            "end_time": "24:30",
            "annotations": [
                {
                    "acknowledge contribution": "Joyoni acknowledges Mini by calling her name, but does not agree or expand on her ideas."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "03:41-05:11",
            "transcript": "I had a question like uh in say for example in X-ray uh lot of like say mammography, okay? So you have content scatter and uh you use scatter grid to take out the content scatter, but nowadays you have these um you know, modeling methods where you iteratively as you like even in the projection, you know, as you iteratively get the thickness, you actually model the scatter. It can be fast Monte Carlo, it can be some linear model of the scatter. Have you seen that kind of work for um like light?",
            "speaking_duration": 90,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:30",
            "end_time": "26:00",
            "annotations": [
                {
                    "ask clarifying question": "The speaker is asking if similar scatter modeling methods used in X-ray mammography are also used in light-based imaging, seeking clarification on existing techniques."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "05:12-05:14",
            "transcript": "Uh you you're talking about optical now?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:01",
            "end_time": "26:03",
            "annotations": {
                "ask clarifying question": "Mini Das is asking Joyoni Dey to confirm if the previous question was about optical imaging, seeking clarification on the context of the question."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "05:14-05:18",
            "transcript": "Yeah, optical like, you know, for optical scatter iterative.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "26:07",
            "annotations": [
                {
                    "ask clarifying question": "Joyoni is asking Mini if she is referring to optical scatter iterative methods, clarifying the context of the discussion."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "05:18-05:35",
            "transcript": "There are people working on scatter modeling scatter and even using that for imaging in depth. There's there's a new range of papers coming in that regard. Uh so yeah, there are people working on that uh we haven't looked at it in that.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:07",
            "end_time": "26:24",
            "annotations": {
                "provide supporting evidence": "The speaker mentions that there are people working on scatter modeling and using it for imaging in depth, and that there's a new range of papers coming in that regard, providing evidence to support the idea that scatter modeling is being used in optical imaging.",
                "acknowledge contribution": "The speaker acknowledges the previous question about scatter modeling in optical imaging."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "05:36-06:15",
            "transcript": "It seems to be like lot of the just two more minutes like yeah, so if if it seems to me lot of the answers to this is like this current catch word deep learning. So like I know CT denoising is done by deep learning. Scatter if I give a lot of you know, scatter grid with scatter grid and with like with scatter, it can possibly learn correcting the scatter.",
            "speaking_duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:25",
            "end_time": "27:04",
            "annotations": {
                "provide supporting evidence": "The speaker supports the idea of using deep learning by mentioning that CT denoising is already done using deep learning, suggesting its potential for scatter correction as well.",
                "expand on existing idea": "The speaker expands on the idea of using deep learning for scatter correction in X-ray imaging, building upon the previous discussion about scatter and iterative modeling methods.",
                "present new idea": "The speaker presents the idea of using deep learning to correct for scatter, which is a novel approach not explicitly mentioned before in the conversation."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "06:15-06:36",
            "transcript": "Um I know I I have done some work on correcting some physical errors due to that's more of a calibration problem, it's a easier problem to solve like you know, like grating based. But you know, and deep learning the thing is after you train with millions of data after that it's fast. You just throw in one set of data and out comes you know, a cleaned image.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:04",
            "end_time": "27:25",
            "annotations": [
                {
                    "provide supporting evidence": "The speaker mentions their past work on correcting physical errors, which supports the idea that deep learning can be used for image correction, building on the previous discussion about scatter correction in optical imaging."
                },
                {
                    "expand on existing idea": "The speaker expands on the idea of using deep learning for image correction by explaining that after training with a large dataset, the process becomes fast, building on the previous discussion about scatter correction in optical imaging."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "06:36-06:36",
            "transcript": "It's easy, you know, like like the computation wise it's not that hard.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:25",
            "end_time": "27:25",
            "annotations": {
                "express enthusiasm": "Joyoni expresses enthusiasm about the computational ease of using deep learning after training, building on the prior discussion of deep learning for scatter correction and image cleaning."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "06:36-06:37",
            "transcript": "Yeah, that's a good point.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:25",
            "end_time": "27:26",
            "annotations": {
                "acknowledge contribution": "Mini acknowledges Joyoni's point about deep learning being a potential solution for scatter correction and other imaging challenges."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:37-07:06",
            "transcript": "I just wanted to say yeah, actually there are people doing the scatter correction in optical tomography and what so I have worked on it and published several papers on this, but the I see the one I like the most, which is I find fascinating is when you do model the scattering process itself as a convolutional neural network.",
            "speaking_duration": 29,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:26",
            "end_time": "27:55",
            "annotations": [
                {
                    "expand on existing idea": "Beck is expanding on Joyoni's idea about scatter correction by stating that people are working on scatter correction in optical tomography, and he has worked on it and published papers on this."
                },
                {
                    "present new idea": "Beck presents the idea of modeling the scattering process itself as a convolutional neural network, which is a novel approach not previously mentioned."
                }
            ]
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:06-07:07",
            "transcript": "Yeah, exactly.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:55",
            "end_time": "27:56",
            "annotations": {
                "express agreement": "The speaker is agreeing with the previous statement about modeling the scattering process as a convolutional neural network."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "07:08-07:14",
            "transcript": "They are my exactly. But it's object dependent, so you have to uh.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:57",
            "end_time": "28:03",
            "annotations": [
                {
                    "expand on existing idea": "The speaker is building on the previous discussion about using convolutional neural networks for scatter correction in optical tomography, adding that the approach is object-dependent."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "07:15-07:17",
            "transcript": "It's a little bit of a chicken and egg problem.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:04",
            "end_time": "28:06",
            "annotations": {
                "express frustration": "Mini expresses frustration with the scatter correction in optical tomography, referring to it as a \"chicken and egg problem\", implying a circular dependency or difficulty in solving it."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "07:17-07:17",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:06",
            "end_time": "28:06",
            "annotations": {
                "express agreement": "Joyoni agrees with Mini's previous point about the chicken and egg problem of scatter correction."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "07:18-07:23",
            "transcript": "You find the you have to start somewhere with some approximation, I guess.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:07",
            "end_time": "28:12",
            "annotations": {
                "expand on existing idea": "Mini is expanding on the discussion about scatter correction in optical tomography and the challenges of object dependence, suggesting that one must begin with some approximation to address the chicken and egg problem."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "07:23-07:30",
            "transcript": "We are looking a little bit into this for uh X-ray uh scatter.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:12",
            "end_time": "28:19",
            "annotations": {
                "expand on existing idea": "Mini is expanding on the discussion about scatter correction, mentioning that they are also exploring it for X-ray scatter, building upon the previous discussion about scatter correction in optical tomography and deep learning methods."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "07:30-07:50",
            "transcript": "Yeah. X-ray scatter, I know that they have some in the clinic like prime by, you know, Siemens. They have already for mammography at least even for the projection and assume they have to assume something about that equation, so they assume like a water mu, like average attenuation to for the correction of the scatter.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:19",
            "end_time": "28:39",
            "annotations": {
                "provide supporting evidence": "The speaker is providing supporting evidence by mentioning that Siemens has implemented X-ray scatter correction in mammography in the clinic, which supports the idea of scatter correction being a viable approach.",
                "expand on existing idea": "The speaker is expanding on the existing idea of X-ray scatter correction by providing details on how it is implemented in clinical settings, specifically mentioning Siemens' approach and the assumption of average water attenuation.",
                "explain or define term or concept": "The speaker explains the concept of X-ray scatter correction by describing how Siemens assumes a water mu (average attenuation) for scatter correction in mammography."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "07:50-07:50",
            "transcript": "Sorry, Mini, what say that?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:39",
            "end_time": "28:39",
            "annotations": [
                {
                    "ask clarifying question": "Joyoni asks Mini to repeat or clarify what she said, indicating a need for further explanation."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "07:51-07:51",
            "transcript": "I'm done.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:40",
            "end_time": "28:40",
            "annotations": {
                "None": "This utterance does not fit into any of the defined codes as it is simply a statement of completion."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "07:51-07:52",
            "transcript": "Oh okay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:40",
            "end_time": "28:41",
            "annotations": {
                "acknowledge contribution": "The speaker acknowledges the previous speaker's point, but does not agree or expand on it."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "07:52-07:54",
            "transcript": "I I'm just waiting for other ideas to note now.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:41",
            "end_time": "28:43",
            "annotations": {
                "encourage particpatioin": "Mini Das is encouraging others to share their ideas, indicating she is open to hearing more perspectives on the topic."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "08:00-08:11",
            "transcript": "We did a like my master student did recently a simple version of this because I'm working on this uh uh with a new my extra system has this MPG which is so the regular uh the regular um interferometry systems have this something called analyzer which is also acts as a scatter grid.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:49",
            "end_time": "29:00",
            "annotations": [
                {
                    "expand on existing idea": "The speaker is building on the discussion about scatter correction in imaging, mentioning their master student's work on a simple version of this, expanding on the topic of scatter correction that was previously discussed."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "08:11-08:30",
            "transcript": "So they don't have that much scatter. But my system to preserve the dose, I'm not using that um analyzer. So I will now have to correct for scatter and the scatter is in the the zeroth harmonic, the in the attenuation image, not so much in the uh small angle scatter or the, you know, or the phase image.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:00",
            "end_time": "29:19",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is explaining the role of the analyzer in their X-ray system and how its absence necessitates scatter correction."
                },
                {
                    "expand on existing idea": "The speaker is building on the previous discussion about scatter correction by explaining how their system differs and where the scatter is most prominent."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "08:30-09:23",
            "transcript": "So I have to correct it. So we are we apply a simpler algorithm than like a fast Monte Carlo for the breast images like, you know, I just use a linear model and we did MLM reconstruction that works at least in simulated images from giant Monte Carlo simulated images. It seems to work. Now we are trying to do it for actual experiments. So um so I'm just saying that we can potentially try similar things for uh but it is object dependent and so it has to be a iterative process.",
            "speaking_duration": 53,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:19",
            "end_time": "30:12",
            "annotations": [
                {
                    "expand on existing idea": "Joyoni is expanding on the previous discussion about scatter correction by describing the simpler algorithm they use, a linear model with MLM reconstruction, for breast images, building on the topic of scatter correction in imaging."
                },
                {
                    "provide supporting evidence": "Joyoni provides supporting evidence by stating that the linear model with MLM reconstruction works in simulated images, strengthening the idea that this approach is viable for scatter correction."
                }
            ]
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:00-00:57",
            "transcript": "optical diffraction tomography, but it was not reflection. So some people are interested in reflection mode in optical diffraction tomography, it was transmission of light. Now, in there there is no real depth, but it's a multicellular organisms who are collecting across and then we're using multiple scattering to get higher resolution images. And then another context where I worked on it is more like subsurface, right, imaging, so we're underground. So it's a higher uh it's more used in in oil exploration or archaeological, there they also have a scattering of of wave. But it's exactly the same model in fact. Used but in the reflection regime. Right now I'm starting something with optical well they're building a new type of optical coherence but in fact a tomography where there is a sample rotation.",
            "speaking_duration": 57,
            "nods_others": 3,
            "smile_self": 25,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:49",
            "end_time": "31:46",
            "annotations": [
                {
                    "explain or define term or concept": "Beck is explaining what optical diffraction tomography is by stating that it is not reflection, but transmission of light, which clarifies the concept for the group."
                },
                {
                    "expand on existing idea": "Beck expands on the concept of optical diffraction tomography by describing its application in multicellular organisms and subsurface imaging, adding details about its use in oil exploration and archaeology."
                },
                {
                    "present new idea": "Beck presents a new idea by mentioning that they are starting something with optical coherence tomography where there is a sample rotation, introducing a novel approach not previously discussed."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "00:58-01:03",
            "transcript": "What's the scale of that system? We're we talking about small samples and microscopy or we're talking larger?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:47",
            "end_time": "31:52",
            "annotations": {
                "ask clarifying question": "Benjamin asks about the scale of the system Beck Kamilov mentioned, inquiring whether it's for small samples/microscopy or larger applications, seeking clarification on the system's application."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:04-01:15",
            "transcript": "it's going to be microscopy. but it's going to be more than diffraction tomography. so it's not going to be just like few cells, but they want to do like a bigger kind of objects, but it's still going to be microscopy level.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:53",
            "end_time": "32:04",
            "annotations": [
                {
                    "expand on existing idea": "Beck is expanding on his previous description of optical coherence tomography by specifying the scale of the system he is working on, clarifying that it will be microscopy but for larger objects than just a few cells."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:16-02:30",
            "transcript": "I can I can mention one development that's happening right now in CT. maybe it's of interest for others. it's in spectral CT where photon counting or spectral detectors we are we are we are looking at and Anushiva also knows about this. Uh so you know, there is a big interest in using spectral data for separating material properties. Uh this could be for multiple contrast agents, it could be for density classification. Uh but one thought could be someone else has an idea related to this. Uh you know, how could you use this information? Um maybe as a prior information or or as for a combined multimodality. Here we are we are looking into these problems. So if you have ideas on this, I'd be very interested in learning more. Uh I've thought about ideas on combining with ultrasound. I think pet is another one. But I'm also very interested in thinking about optical properties. Uh how can you use this information? Um yeah, I I don't want to keep going but the idea if that if if that ignites any thought on in anyone we can.",
            "speaking_duration": 74,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:05",
            "end_time": "33:19",
            "annotations": {
                "present new idea": "Mini introduces the development of spectral CT with photon counting for separating material properties, which hasn't been explicitly discussed before.",
                "explain or define term or concept": "Mini explains spectral CT involves photon counting or spectral detectors and is used for separating material properties, providing clarity on the technology.",
                "encourage particpatioin": "Mini encourages others to share their ideas on how to use spectral CT information, specifically asking for thoughts on combining it with other modalities or using it as prior information."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:31-02:37",
            "transcript": "And and many you you you were that's particularly in reference to multispectral X-ray detectors, is that right?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:20",
            "end_time": "33:26",
            "annotations": {
                "ask clarifying question": "Brian is asking Mini to confirm if his understanding of her previous statement about spectral CT refers specifically to multispectral X-ray detectors, seeking clarification on the scope of her comment."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:37-02:51",
            "transcript": "Yes, you can do it with either at the detector end or you can separate it by by by I guess eliminating with different bandwidth of X-ray, but then you have to do it multiple times. But at the detector end you can do it with one shot. Yeah.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:26",
            "end_time": "33:40",
            "annotations": {
                "explain or define term or concept": "The speaker explains two ways to achieve spectral CT: using detectors that separate photons by energy or by using different X-ray bandwidths, which clarifies the concept of spectral CT.",
                "expand on existing idea": "The speaker expands on the concept of spectral CT, building on the previous discussion about spectral CT and photon counting detectors.",
                "express agreement": "The speaker agrees with Brian Pogue's question about multispectral X-ray detectors, confirming that the discussion is about that topic."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:52-03:41",
            "transcript": "But uh the thought I was having is more also in regards to uh would something like that help with combining with optical uh with a very low dose for example CT, right? since I picked up this near infrared back again, I'm seeing all the problems I saw before and I haven't seen solutions. Only solution I'm seeing is you can do the differential contrast easily, but you have to generate the differential contrast. In some problems the contrast occurs like in brain imaging, you're doing a task and or or you could you could be like doing something and there is a natural contrast in blood volume change, right? There is that's happening. But all problems don't lend to those contrast. So how do you how do you tackle this problem, right?",
            "speaking_duration": 49,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:41",
            "end_time": "34:30",
            "annotations": [
                {
                    "ask clarifying question": "Brian is asking if spectral CT could help with combining optical imaging with low-dose CT, building on the discussion about spectral CT initiated by Mini."
                },
                {
                    "express frustation": "Brian expresses frustration about the persistent problems with near-infrared imaging, indicating a lack of solutions to the challenges he has previously encountered."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "03:41-03:44",
            "transcript": "I'm I'm happy to complain about that aspect of MRI.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:30",
            "end_time": "34:33",
            "annotations": {
                "express humor": "The speaker is making a lighthearted comment about complaining about MRI, which is a form of humor."
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "03:44-03:45",
            "transcript": "What about do we use uh MR contrast agents?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:33",
            "end_time": "34:34",
            "annotations": {
                "present new idea": "Joyoni is suggesting a new idea of using MR contrast agents, which hasn't been explicitly discussed in the immediate prior turn, though MRI has been mentioned."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "03:45-03:46",
            "transcript": "Oh, absolutely. Sure.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:34",
            "end_time": "34:35",
            "annotations": {
                "express agreement": "Benjamin agrees with Joyoni's question about using MR contrast agents, confirming that they do use them."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "03:46-04:34",
            "transcript": "If you can get a fold change with your contrast agent, like you are you're styling. But for sensors and things like that, that's one of the things that's limited. Nanoparticles can have a large signal change, but once you get them in vivo, they don't fill the whole volume of your imaging of your sort of imaging voxel. So even if you got a threefold signal change from a from a nanoparticle, it's only taking up a small percentage of your voxel and so it ends up just being a few percent signal at the end. always.",
            "speaking_duration": 48,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "34:35",
            "end_time": "35:23",
            "annotations": [
                {
                    "expand on existing idea": "The speaker is expanding on the previous discussion about MR contrast agents, discussing the limitations of sensors and nanoparticles in achieving a significant signal change in vivo, building on the previous discussion about contrast agents in MRI."
                },
                {
                    "offer constructive criticism": "The speaker is offering constructive criticism by pointing out the limitations of using nanoparticles as contrast agents in MRI due to their inability to fill the entire imaging voxel, which reduces the overall signal change, building on the previous discussion about contrast agents in MRI."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "04:34-04:34",
            "transcript": "I was.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:23",
            "end_time": "35:23",
            "annotations": [
                {
                    "Mini Das (U. Houston)": "I'm done."
                },
                {
                    "acknowledge contribution": "The speaker is acknowledging Mini's previous statement, but not necessarily agreeing or expanding on it."
                }
            ]
        },
        {
            "speaker": "Morteza Mahmoudi",
            "timestamp": "04:34-05:57",
            "transcript": "Yeah, I was I was about to make comment about like. So it depends on like how many basically first of all it depends on the like what you want to image. For example, if you want to image a cell, then it depends on how many nanoparticles basically gets into the cells. So it define basically the resolution. But the other interesting aspect about nanoparticles is that the validity of the like the signal is okay, but it's not it it may not correspond with like what you're looking for. For example, we label like some cells with iron oxide nanoparticles and that cells we basically um put the reporter gene to basically activate that with luciferase. So we can also get a bioluminescence image of the of the cells that we inject them. So what happens was that even though when the cells are dead, you get the signal from oxide nanoparticles for like a few days. So when using nanoparticles, you can increase concentration, but at the same time you need to make sure that it's safe and you need to make sure that they don't affect the like the functionality of the cells or like activate some like uh I don't know something like apoptotic like pathways there. So for nanoparticles, I would say we always need another modality just to make sure that what we see is real.",
            "speaking_duration": 83,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:23",
            "end_time": "36:46",
            "annotations": [
                {
                    "expand on existing idea": "Building on the discussion about MR contrast agents and their limitations, the speaker expands on the topic by discussing how the number of nanoparticles affects resolution when imaging cells."
                },
                {
                    "provide supporting evidence": "The speaker provides supporting evidence by describing an experiment where cells labeled with iron oxide nanoparticles still showed a signal even after the cells were dead, highlighting the need for another modality to confirm the signal's validity."
                },
                {
                    "offer constructive criticism": "The speaker offers constructive criticism by pointing out that while nanoparticles can increase concentration, it's crucial to ensure their safety and avoid affecting cell functionality, suggesting a need for caution and further investigation."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "05:58-06:00",
            "transcript": "In terms of using them as a die.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:47",
            "end_time": "36:49",
            "annotations": {
                "expand on existing idea": "This utterance builds upon the previous discussion about using nanoparticles as contrast agents in MRI, specifically focusing on their application as a dye."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:00-06:17",
            "transcript": "as not just to detect their presence, but to use sort of aggregation based sensors and things like that. They work very well in vitro, but to view them in a living animal, um that experience you have to have a zero baseline to start with and then you can only image within a single um session.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:49",
            "end_time": "37:06",
            "annotations": {
                "expand on existing idea": "Building on the previous discussion about nanoparticles and their limitations in MRI, this utterance expands on the challenges of using them as aggregation-based sensors in living animals, highlighting the need for a zero baseline and single-session imaging.",
                "provide supporting evidence": "The speaker supports their point by stating that aggregation based sensors work well in vitro, but to view them in a living animal, you have to have a zero baseline to start with and then you can only image within a single session."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "06:17-06:17",
            "transcript": "So.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:06",
            "end_time": "37:06",
            "annotations": {
                "None": "This utterance does not contain any information."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:17-06:17",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:06",
            "end_time": "37:06",
            "annotations": {
                "express agreement": "The speaker explicitly agrees with the previous statement."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "06:17-06:20",
            "transcript": "Benjamin, can you comment on in MRI currently.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:06",
            "end_time": "37:09",
            "annotations": {
                "encourage particpatioin": "Mini is inviting Benjamin to share his thoughts or expertise on MRI, given the context of the conversation."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:20-06:20",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:09",
            "end_time": "37:09",
            "annotations": {
                "express agreement": "Benjamin agrees with Mini's question about MRI."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "06:20-06:30",
            "transcript": "What are the applications where the contrast agent is not needed or not used?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:09",
            "end_time": "37:19",
            "annotations": {
                "ask clarifying question": "Mini Das is asking Benjamin a question to get more information about MRI applications, following a discussion about contrast agents in MRI."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:30-06:30",
            "transcript": "Uh I I don't know.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:19",
            "end_time": "37:19",
            "annotations": {
                "None": "This utterance does not fit any of the codes in the codebook, as it is simply a statement of not knowing the answer to a question."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "06:30-06:30",
            "transcript": "Or typically is it always used with contrast agent at this point?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:19",
            "end_time": "37:19",
            "annotations": {
                "ask clarifying question": "Mini is asking Benjamin to clarify whether MRI always requires the use of a contrast agent, following a discussion about the limitations of contrast agents in MRI."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "06:30-07:32",
            "transcript": "MRI is there an application where contrast agent is not required? Yeah, I would say probably only maybe 20 to 30% of MRI scans are with contrast. The bulk of them are meant to um do things like diagnosis stroke requires no contrast. diffusion weighted imaging, T2 weighted imaging can can make the stroke diagnosis. A lot of MRI right now is basically anatomic so that stroke is one where there's like functional data coming from the diffusion, but um the rest of them are mostly anatomy. So lumbar spine MRIs to look for whether or not there's a narrowed narrow frame where the nerve is coming out to say that's why this person's having, you know, pain. So they're it's pretty much workhorse anatomic technique with um high end contrast enhancement used for like tumor characterization, infection characterization. Um uh you don't even need it to do like gallbladder, you know, MRCP to characterize the biliary system. So and I think.",
            "speaking_duration": 62,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:19",
            "end_time": "38:21",
            "annotations": {
                "explain or define term or concept": "The speaker explains that many MRI scans do not require contrast agents, providing examples such as stroke diagnosis, diffusion weighted imaging, and lumbar spine MRIs, which are primarily anatomic techniques.",
                "provide supporting evidence": "The speaker supports the claim that contrast agents are not always required in MRI by giving specific examples of MRI applications where contrast is not needed, such as stroke diagnosis using diffusion weighted imaging and T2 weighted imaging."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "07:32-07:32",
            "transcript": "Enter it.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:21",
            "end_time": "38:21",
            "annotations": {
                "express agreement": "The speaker is agreeing with the previous statement made by Mark Sellmyer about MRI applications where contrast agents are not required."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "07:32-07:33",
            "transcript": "Yeah, go ahead.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:21",
            "end_time": "38:22",
            "annotations": {
                "encourage particpatioin": "This utterance encourages Mini Das to comment, as she was about to speak."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "07:33-08:10",
            "transcript": "Oh, and and the big push in that is so the the machine learning approaches they take is okay, well how can we sort of automatically score these things and just do pathology with a computer. It always ends up being some like this thing is slightly larger here and so by doing PCA, we can now have like a fast way of of seeing that that thing is slightly smaller. But it all comes back to like just training against the human eye.",
            "speaking_duration": 37,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:22",
            "end_time": "38:59",
            "annotations": {
                "expand on existing idea": "Building on the discussion about MRI and contrast agents, the speaker expands on the current trend of using machine learning to automate the scoring and analysis of MRI images, particularly in anatomic applications.",
                "offer constructive criticism": "The speaker critiques the current machine learning approaches in MRI, suggesting that they often rely on simple anatomical features and are ultimately trained against human visual assessment, implying a need for more sophisticated methods."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "00:00-00:48",
            "transcript": "contrast enhance space, as Mark was saying, the predominant contrast agent used in MRI is your blood, right? Like that's what we're looking at. We're looking at blood flow, we're looking at a bleed, etc. Now in the in the contrast enhance space, it's not as commonly used because it's not that necessary, but uh these gadolinium agents and these targeted agents, they're highly limited because they are they have to carry a large molecule around with them. So they're highly limited to mostly vascular targets. We're looking for some vascular marker of whatever that is, or we're counting on um your agent leaking out of the blood to to mark whatever you're going for. And that's again very limiting in in the standard sort of T1, T2 uh regime.",
            "speaking_duration": 48,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:49",
            "end_time": "41:37",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker explains that in contrast-enhanced MRI, blood is the predominant contrast agent, clarifying a key concept in MRI imaging."
                },
                {
                    "expand on existing idea": "The speaker expands on the discussion about MRI contrast agents, detailing the limitations of gadolinium and targeted agents, building upon the previous discussion about contrast agents in MRI."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "00:48-01:30",
            "transcript": "For us for for making sensors which are almost exclusively used um just as proof of concept papers and sometimes in model organisms. Those things almost always are administered either like continual IV or being directly infused into the brain or being infused into whatever space they want to be in just because they have they're these macro molecular complexes and the only way to get them to work is to pump everything you need into the spot you're looking for. And in those situations it's almost like there's no reason to do that 3D because you know where you're putting it. It's uh it's almost academic to say that the imaging is not invasive because the delivery is definitely not uh invasive.",
            "speaking_duration": 42,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:37",
            "end_time": "42:19",
            "annotations": {
                "expand on existing idea": "Building on the discussion about contrast agents in MRI, the speaker elaborates on the limitations of sensors, particularly in vivo, explaining that they often require direct infusion due to their macromolecular nature, making 3D imaging less relevant.",
                "offer constructive criticism": "The speaker critiques the practical application of sensors in MRI, pointing out that their invasive delivery methods often negate the non-invasive nature of the imaging itself, suggesting a limitation in the current approach."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:30-01:36",
            "transcript": "Can I um I'm just going to interrupt for a second and Mini um how's the scribing going? Are you are you",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:19",
            "end_time": "42:25",
            "annotations": [
                {
                    "ask clarifying question": "Brian is asking Mini about the progress of her note-taking, seeking an update on her scribing efforts during the meeting."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:37-01:40",
            "transcript": "Yeah, I'm taking",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:26",
            "end_time": "42:29",
            "annotations": {
                "acknowledge contribution": "Mini is responding to Brian's question about how the scribing is going, acknowledging his question."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:37-01:40",
            "transcript": "just noticed the Google Doc has nothing in it. So I'm just going",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:26",
            "end_time": "42:29",
            "annotations": [
                {
                    "assign task": "Brian is likely assigning the task of scribing to Mini, as he is checking on the progress of the Google Doc."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:40-01:45",
            "transcript": "No, no, no. I'm I'm taking I'm taking manual notes, but I can't write on the Google Doc too.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:29",
            "end_time": "42:34",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Mini is responding to Brian's question about how the scribing is going, acknowledging his concern about the empty Google Doc."
                }
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:45-01:47",
            "transcript": "Okay. Very retro of you. Yeah.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:34",
            "end_time": "42:36",
            "annotations": {
                "express humor": "Brian Pogue makes a lighthearted comment about Mini Das taking manual notes instead of using the Google Doc, expressing humor."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:47-01:50",
            "transcript": "Hopefully everybody will pop out in the end.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:36",
            "end_time": "42:39",
            "annotations": {
                "express humor": "The speaker expresses humor by saying \"Hopefully everybody will pop out in the end\", which is a lighthearted way to end the discussion."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:50-01:50",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:39",
            "end_time": "42:39",
            "annotations": {
                "acknowledge contribution": "Brian acknowledges the previous speaker's turn, but does not agree or expand on the point."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:51-02:15",
            "transcript": "I'm relying on the collective memory here of everyone. Okay. But I guess",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:40",
            "end_time": "43:04",
            "annotations": {
                "express humor": "Mini Das makes a humorous comment about relying on everyone's collective memory, after Brian Pogue noticed the Google Doc was empty, suggesting she was taking notes manually."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:56-01:59",
            "transcript": "I'm just wondering if we should start putting in sort of a",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:45",
            "end_time": "42:48",
            "annotations": {
                "encourage particpatioin": "Brian Pogue is encouraging participation by suggesting a course of action for the group, implicitly inviting others to contribute to the discussion."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:59-02:15",
            "transcript": "I should bring up the post point uh of uh what what are the bottlenecks in rapid analysis. We don't have to follow the the bullet point but when when I I assume they're talking about human analysis or machine analysis, maybe we can have some point on that since it's one of the bullet points there.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:48",
            "end_time": "43:04",
            "annotations": {
                "present new idea": {
                    "Explanation": "Mini introduces the topic of bottlenecks in rapid analysis, which hasn't been explicitly discussed in the immediate prior turn, though it is related to the overall discussion of imaging modalities and analysis."
                },
                "ask clarifying question": {
                    "Explanation": "Mini asks for clarification on whether the 'rapid analysis' refers to human or machine analysis, seeking to narrow the scope of the discussion."
                }
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:21-02:24",
            "transcript": "Well there's a comment from Mark here too about bottlenecks and rapid analysis.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:10",
            "end_time": "43:13",
            "annotations": {
                "acknowledge contribution": "Brian acknowledges Mark's comment about bottlenecks in rapid analysis, recognizing his input to the discussion."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "02:25-02:33",
            "transcript": "Uh I just put in there what what the questions were posed in there. There there's no useful information other than what we're supposed to be thinking about.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:14",
            "end_time": "43:22",
            "annotations": [
                {
                    "acknowledge contribution": "The speaker is acknowledging the questions that were posed, but not agreeing or expanding on them."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:34-02:37",
            "transcript": "Okay, got you. So refocusing effort.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:23",
            "end_time": "43:26",
            "annotations": [
                {
                    "acknowledge contribution": "Brian acknowledges that he understands Mark's previous comment about the questions posed, but that there was no useful information in it."
                }
            ]
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "02:37-02:39",
            "transcript": "There's um go ahead. Sorry.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:26",
            "end_time": "43:28",
            "annotations": [
                {
                    "encourage particpatioin": "Beck Kamilov encourages someone else to speak by saying \"go ahead\"."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "02:41-03:21",
            "transcript": "I I have another question another thing point sorry I kind of bring up these new points at the last minute I'm so sorry but uh it just when it occurs to me so I can't help it but somebody said that uh what other imaging modalities lend themselves to 3D analysis as well. I know that ultrasound micro bubbles are useful but I don't know if that's useful for microscopy. Anybody has any thoughts or we can quickly skim over that. Like it's a very high contrast mechanism.",
            "speaking_duration": 40,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:30",
            "end_time": "44:10",
            "annotations": [
                {
                    "ask clarifying question": "The speaker is asking what other imaging modalities lend themselves to 3D analysis, indicating they are seeking more information on the topic that was brought up by someone else."
                },
                {
                    "encourage particpatioin": "The speaker is encouraging participation by asking if anyone has any thoughts on the topic of imaging modalities for 3D analysis."
                }
            ]
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:22-03:46",
            "transcript": "I mean another one I was thinking which has a big challenge it's one project I have is like light sheet microscopy. I don't know if anybody worked with it. Uh so that can be done as a tomography setup where you take you know orthogonal views to each other or even several views and the challenge is you have a data problem. So they do a 3D scan every two seconds over several weeks to watch how organism grows.",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:11",
            "end_time": "44:35",
            "annotations": {
                "present new idea": "Beck introduces light sheet microscopy as another imaging modality for 3D analysis, which is a new topic in the discussion.",
                "expand on existing idea": "Beck expands on the idea of imaging modalities that lend themselves to 3D analysis, which was brought up by Joyoni Dey in the previous utterance.",
                "provide supporting evidence": "Beck mentions that light sheet microscopy is a project he is working on, providing a real-world example to support the idea.",
                "explain or define term or concept": "Beck explains that light sheet microscopy can be done as a tomography setup where orthogonal views are taken, clarifying the method for the group."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:46-04:07",
            "transcript": "So now nobody's going to sit and look at it. I mean, maybe somebody will but across not across the whole week. So how to find and analyze that data set in a way that for biologist it's meaningful and they can kind of easily scan through it to find important parts in it and so on. That's kind of a different challenge but it's also 3D challenge, 3D plus time.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:35",
            "end_time": "44:56",
            "annotations": [
                {
                    "present new idea": "Beck is presenting the challenge of analyzing large light sheet microscopy datasets, which involves finding meaningful ways for biologists to scan through the data, which is a new problem presented to the group."
                },
                {
                    "ask clarifying question": "Beck is asking how to find and analyze the data set in a way that is meaningful for biologists, which is a question that needs to be addressed."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "04:07-04:17",
            "transcript": "Well and and you need labels too to get um 3D light sheet microscopy working. Yeah. Sometimes. Yeah. Most times yes.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:56",
            "end_time": "45:06",
            "annotations": {
                "provide supporting evidence": "Brian Pogue states that labels are needed to get 3D light sheet microscopy working, providing information to support the use of labels in this technique, which was brought up by Beck in the previous utterance."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "04:18-04:41",
            "transcript": "I was thinking if we can convert that problem to some sort of computer vision task because I do lots of work on like anomaly detection and then like",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:07",
            "end_time": "45:30",
            "annotations": {
                "present new idea": "Shiva is suggesting a new approach to the problem by converting it into a computer vision task, which is a novel concept in the current discussion."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "04:41-05:24",
            "transcript": "in order to do like really real time uh processing so that if you're gathering so much data and then you don't want to have them all save in the memory, you are able to uh like kind of like as if um get your system to learn what is the spatial temporal uh changes in a normal condition and then uh like have your network train so that kind of look for anomaly and then kind of have the output to the system to tell the user that okay this is the data that is important and then they are classifier that from the memory and pipelining point of view, they are very compatible to be implemented, you know, to the FPGA so that you can connect directly the output of your detector like ADC to the FPGA.",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:30",
            "end_time": "46:13",
            "annotations": [
                {
                    "present new idea": "Shiva introduces the idea of using anomaly detection with a trained network to identify important data in real-time, addressing the data overload issue raised by Beck regarding light sheet microscopy data analysis."
                },
                {
                    "expand on existing idea": "Shiva expands on the idea of using computer vision for analyzing large datasets by suggesting a specific approach involving anomaly detection and real-time processing using FPGAs, building upon Beck's challenge of analyzing light sheet microscopy data."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "05:24-05:35",
            "transcript": "So then like if I can learn more about, you know, that problem, maybe we have like some good discussion to go and see how like the anomaly detection task can be apply in order to reduce the data in your application.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:13",
            "end_time": "46:24",
            "annotations": {
                "encourage particpatioin": "Shiva encourages further discussion and collaboration on applying anomaly detection to reduce data in the application, building on the previous discussion about light sheet microscopy data analysis."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "05:45-06:07",
            "transcript": "Yeah, that's already become very popular in for two photon um functional imaging. So people are doing um G camp, which is this calcium sensitive um fluorophore and they'll image this whole field of tens of thousands of neurons",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:34",
            "end_time": "46:56",
            "annotations": [
                {
                    "expand on existing idea": "This utterance expands on the previous discussion about 3D analysis and light sheet microscopy by mentioning two-photon functional imaging as another popular technique in that space."
                },
                {
                    "explain or define term or concept": "The speaker explains the term 'G camp' by defining it as a calcium-sensitive fluorophore."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:07-06:26",
            "transcript": "and they'll train in specific activities and then use a classifier to kind of build out what is the typical response to that. And then once they have their classifier laid out, then they'll they'll start challenging that stimuli with different things and they'll look for the shifts in the network using that anomaly detection.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:56",
            "end_time": "47:15",
            "annotations": [
                {
                    "expand on existing idea": "This utterance expands on Shiva's idea of using anomaly detection by describing how it's used in two-photon functional imaging to classify typical responses and then look for shifts in the network."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:26-06:35",
            "transcript": "But they're it's it's surprising because they do these and it's just this like um MATLAB support vector machines model and they still get really interesting stuff out of it. Yeah, I think there's a lot of of growth for that.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:15",
            "end_time": "47:24",
            "annotations": {
                "expand on existing idea": "This utterance expands on the previous speaker's idea of using anomaly detection for light sheet microscopy data by providing an example of how it's used in two-photon functional imaging with GCaMP and support vector machines.",
                "express enthusiasm": "The speaker expresses enthusiasm for the potential growth of anomaly detection methods in imaging analysis."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "06:36-06:37",
            "transcript": "I think it's coming, you know.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:25",
            "end_time": "47:26",
            "annotations": {
                "express enthusiasm": "The speaker expresses optimism about the future application of anomaly detection in imaging, building on the previous discussion about using computer vision techniques for real-time processing and anomaly detection in light sheet microscopy data."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "06:37-06:41",
            "transcript": "because like last year",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:26",
            "end_time": "47:30",
            "annotations": {
                "None": "No code applies to this utterance."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "06:41-07:10",
            "transcript": "Zylinx uh like kind of give out a uh FPGA that has three 32 billion transistor is almost as much as you know the neurons in our brain and it's 80k. So it's not so super expensive and then like even before we had to have all the list data and then do the processing, but now the technology is like really tough time of flight pit that maybe soon we can get rid of even image reconstruction.",
            "speaking_duration": 29,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:30",
            "end_time": "47:59",
            "annotations": {
                "present new idea": "The speaker presents the idea of using FPGAs with a large number of transistors to potentially eliminate image reconstruction in time-of-flight PET, which is a novel concept not previously discussed.",
                "expand on existing idea": "This utterance expands on the previous discussion about using computer vision and anomaly detection for analyzing large datasets from light sheet microscopy by suggesting a specific hardware implementation (FPGA) and its potential application to time-of-flight PET.",
                "express enthusiasm": "The speaker expresses enthusiasm about the potential of new FPGA technology to revolutionize image processing in time-of-flight PET."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:10-07:17",
            "transcript": "So I think that regarding the question for our topic that how we can like go fast and then like kind of kind of reduce amount of the data.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:59",
            "end_time": "48:06",
            "annotations": {
                "present new idea": "Shiva is presenting a new idea about how to address the question of going fast and reducing the amount of data, which is a novel concept in the current discussion."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:17-07:21",
            "transcript": "I'm excited that kind of from the hardware point of view.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:06",
            "end_time": "48:10",
            "annotations": {
                "express enthusiasm": "The speaker expresses excitement about the hardware perspective, indicating enthusiasm."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:21-07:35",
            "transcript": "the technology is at a point that soon we are going to see more advances regarding the data processing and then, you know, just like combining the data in a real time format.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:10",
            "end_time": "48:24",
            "annotations": {
                "express enthusiasm": "Shiva expresses excitement about the advancements in technology and their potential for data processing and real-time data combination, building on her previous points about FPGA and real-time processing."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:40-07:41",
            "transcript": "Another thing I was thinking",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:29",
            "end_time": "48:30",
            "annotations": {
                "present new idea": "Beck is about to introduce a new idea, as indicated by the phrase \"Another thing I was thinking\", but the idea itself is not yet presented."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "07:41-07:43",
            "transcript": "Okay, sorry.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:30",
            "end_time": "48:32",
            "annotations": [
                {
                    "acknowledge contribution": "Brian Pogue is acknowledging that he is interrupting the speaker, Beck Kamilov."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "07:43-07:43",
            "transcript": "I",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:32",
            "end_time": "48:32",
            "annotations": [
                {
                    "None": "This utterance is incomplete and does not express any idea, question, or statement that can be coded."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "07:44-07:44",
            "transcript": "I was going to say",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:33",
            "end_time": "48:33",
            "annotations": {
                "encourage particpatioin": "Brian Pogue is about to speak, likely to contribute to the discussion, so this utterance is encouraging participation."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "07:44-08:06",
            "transcript": "you know, we have 15 minutes so let me try something here. I'd like uh each of us to think where could we have the most impact? You know, of all the topics we've discussed, you know, where could you um what most interests you and what do you think that would have the most impact and we could just go through and have people and then I'm going to have you write it down on the Google Doc to help out.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:33",
            "end_time": "48:55",
            "annotations": [
                {
                    "encourage particpatioin": "Brian is encouraging everyone to think about where they could have the most impact, inviting them to contribute their thoughts on the topics discussed."
                },
                {
                    "propose decision": "Brian is proposing a new direction for the discussion, suggesting that each person reflect on where they could have the most impact."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "08:06-08:12",
            "transcript": "I started writing on the Google Doc the notes I have. Okay. Do you see?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:55",
            "end_time": "49:01",
            "annotations": [
                {
                    "ask clarifying question": "Mini Das is asking if others can see the notes she has started writing on the Google Doc, seeking confirmation that her contribution is visible."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:12-08:14",
            "transcript": "Do you see anything right now?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:01",
            "end_time": "49:03",
            "annotations": {
                "ask clarifying question": "Brian is asking Mini if she can see the notes he is referring to on the Google Doc, which is a request for confirmation."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "08:14-08:14",
            "transcript": "Yep.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:03",
            "end_time": "49:03",
            "annotations": {
                "express agreement": "Mini Das is explicitly agreeing with Brian Pogue who asked if she sees anything on the Google Doc."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:15-08:16",
            "transcript": "Yeah, so there's sort of a couple categories there, yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:04",
            "end_time": "49:05",
            "annotations": [
                {
                    "acknowledge contribution": "Brian acknowledges Mini's contribution of writing notes on the Google Doc, but he is not agreeing or expanding on it."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "08:16-08:21",
            "transcript": "I feel like I can probably contribute most to the scatter connection.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:05",
            "end_time": "49:10",
            "annotations": [
                {
                    "express enthusiasm": "The speaker expresses enthusiasm about contributing to scatter correction, indicating a positive feeling towards this area."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "08:21-08:27",
            "transcript": "And um but uh as far as I had the most impact that I think what Dr. Shiva last um uh said was very interesting like most impactful.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:10",
            "end_time": "49:16",
            "annotations": [
                {
                    "acknowledge contribution": "The speaker acknowledges Shiva's contribution by stating that what Shiva said was very interesting and impactful, recognizing the value of Shiva's input."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:27-08:30",
            "transcript": "Okay, so get you get you to jot that down.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:16",
            "end_time": "49:19",
            "annotations": {
                "assign task": "Brian Pogue is assigning the task of writing down their thoughts on the Google Doc to someone, likely Joyoni Dey, based on the prior utterance."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "08:36-08:39",
            "transcript": "Would it be possible to share the link for the Google Doc?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:25",
            "end_time": "49:28",
            "annotations": [
                {
                    "ask clarifying question": "Uzay is asking for the link to the Google Doc, which is a request for information to clarify how to access the document."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "00:00-00:03",
            "transcript": "I I am typing just a second just because Dr.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 66.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:49",
            "end_time": "50:52",
            "annotations": [
                {
                    "acknowledge contribution": "Joyoni acknowledges Shiva's contribution by saying that what Shiva said was very interesting."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "00:03-00:11",
            "transcript": "Yeah, yeah, so we're all going to collectively help you, Minnie. We're we're it's going to be nine people writing the summary notes here.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 25.0,
            "smile_other": 66.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:52",
            "end_time": "51:00",
            "annotations": [
                {
                    "encourage particpatioin": "Brian encourages the group to help Mini with the scribing task, inviting them to contribute to the Google Doc."
                }
            ]
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "00:11-00:12",
            "transcript": "Also the uh",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:00",
            "end_time": "51:01",
            "annotations": [
                {
                    "encourage particpatioin": "The utterance is cut off, but it seems like Joyoni is about to encourage someone else to participate in the discussion."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "00:12-00:22",
            "transcript": "So who else? Where where else could you think that the maximum impact would be?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:01",
            "end_time": "51:11",
            "annotations": [
                {
                    "encourage particpatioin": "Brian is explicitly asking for others to contribute their thoughts on where the maximum impact could be, encouraging participation from the group."
                }
            ]
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "00:22-01:24",
            "transcript": "I I can talk I I'm typing so I I can also talk. You know, as I kind of got to at the very beginning, my my issue is that there is a lot of data there's a lot of information that can be from pathology about the different biochemical processes that are in a tissue. It could also be a little bit at a higher scale like what cells are present in that tissue. So a little larger scale, cellular micron level or micrometer level. Um, and then how do you take that data set, that 3D data set from pathology across the tissue, you know, tissue clearing technique, whatever it is that gave you really nice resolution and correlate that with the the MRI signals, the spectroscopic signal, the pet signal and build this like map of like what what is actually going on? Is is the is the imaging signal reflective of some of the more detailed pathology.",
            "speaking_duration": 62,
            "nods_others": 1,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:11",
            "end_time": "52:13",
            "annotations": [
                {
                    "present new idea": "Mark introduces the idea of correlating 3D pathology data with imaging signals (MRI, PET, spectroscopic) to build a map of biochemical processes in tissue, which is a novel concept in the context of the discussion."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:25-01:26",
            "transcript": "Yeah, or even could you use like machine learning to sort of learn",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:14",
            "end_time": "52:15",
            "annotations": [
                {
                    "expand on existing idea": "Brian Pogue is building upon the previous discussion about the challenges and potential solutions in imaging modalities, particularly in correlating imaging signals with detailed pathology, by suggesting the use of machine learning."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:26-01:33",
            "transcript": "what the underlying causes of the MR signature is.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:15",
            "end_time": "52:22",
            "annotations": {
                "explain or define term or concept": "Brian is prompting the group to consider how machine learning could be used to understand the relationship between MR signatures and their underlying causes, which is a conceptual question about the interpretation of imaging data."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:35-01:36",
            "transcript": "So you're going to write that out?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:24",
            "end_time": "52:25",
            "annotations": {
                "assign task": {
                    "Explanation": "Brian Pogue is assigning the task of writing out the idea to Mark Sellmyer, who was just speaking."
                }
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "01:36-01:36",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:25",
            "end_time": "52:25",
            "annotations": {
                "express agreement": "The speaker is agreeing with Brian Pogue's previous statement about using machine learning to learn the underlying causes of the MR signature."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:37-01:38",
            "transcript": "Okay, five words.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:26",
            "end_time": "52:27",
            "annotations": {
                "encourage particpatioin": "Brian Pogue is encouraging Mark to summarize his thoughts concisely, prompting him to participate in the discussion."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:43-01:44",
            "transcript": "Maybe 10.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:32",
            "end_time": "52:33",
            "annotations": {
                "encourage particpatioin": "Brian Pogue is encouraging Mark to be concise while writing down his thoughts on the Google Doc, which is a form of encouraging participation."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:45-01:45",
            "transcript": "Anybody else?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:34",
            "end_time": "52:34",
            "annotations": {
                "encourage particpatioin": "Brian Pogue is encouraging other members of the group to contribute their thoughts on where they think the maximum impact would be, following Mark Sellmyer's contribution."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:50-01:58",
            "transcript": "And you know, this can be specific to your expertise base or just what you think is going to be have the maximum impact.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:39",
            "end_time": "52:47",
            "annotations": {
                "encourage particpatioin": "Brian Pogue is encouraging the participants to share their thoughts on where they could have the most impact, building on the previous discussion about bottlenecks and rapid analysis."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "01:58-03:20",
            "transcript": "I can get in here. So I I do find this question actually from the beginning a little bit broad because each modality has strength for different types of diseases. So you can't use one modality for all types of diseases you will end up and that's obvious. And for example, you lung imaging with MRI without using hyperpolarize it is it is really difficult and but you can get very well x-rays and CTs from for lung imaging. So that is my main problem. So it is disease specific. And the second thing if what what I would like to do is most likely to increase the accuracy accuracy because MRI, I'm an MRI physicist, multi contrast, flexible contrast acquisition. So you can tailor the spins depending on however you want and generate the different contrast for different parameters. So you do have million parameters and it all affects the contrast. So that you can tailor the acquisition for lung imaging, but that doesn't necessarily mean it's going to be very better than x-ray. It can come close enough, maybe. Uh, but that is the limitation. We all know that. So that is most likely I might contribute to this question in a way that I can accelerate and the acquisition and increase the accuracy of the findings.",
            "speaking_duration": 82,
            "nods_others": 0,
            "smile_self": 20.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:47",
            "end_time": "54:09",
            "annotations": [
                {
                    "express alternative decision": "The speaker expresses an alternative perspective on the question posed by Brian, suggesting it's too broad because different modalities are better suited for different diseases, contrasting with the idea of a universal solution.",
                    "expand on existing idea": "The speaker expands on their initial point by discussing the limitations of MRI for lung imaging compared to X-rays and CTs, and then proposes to focus on increasing the accuracy and speed of MRI acquisitions."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "03:20-03:24",
            "transcript": "Okay, so five if you can summarize that in five to 10 words.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:09",
            "end_time": "54:13",
            "annotations": {
                "assign task": {
                    "Explanation": "Brian asks Uzay to summarize his point in five to ten words, assigning him the task of condensing his previous statement."
                }
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "03:27-03:29",
            "transcript": "I think the I think the Google Doc crashed.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:16",
            "end_time": "54:18",
            "annotations": {
                "express frustration": "Mark expresses frustration that the Google Doc crashed, which is hindering the group's ability to collaborate on summarizing their discussion."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "03:31-03:31",
            "transcript": "Really?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:20",
            "end_time": "54:20",
            "annotations": {
                "ask clarifying question": "Benjamin is responding to Mark's statement that the Google Doc crashed, and he is asking for confirmation."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:33-03:34",
            "transcript": "No, I am writing.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:22",
            "end_time": "54:23",
            "annotations": {
                "express agreement": "The speaker is confirming that they are currently writing on the Google Doc, in response to a comment about the Google Doc crashing."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:36-03:39",
            "transcript": "I think you just crashed the whole Google. You cannot even search anymore.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:25",
            "end_time": "54:28",
            "annotations": {
                "express humor": "Beck Kamilov makes a joke about someone crashing the Google Doc, expressing humor in the conversation."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:43-03:44",
            "transcript": "I can write.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:32",
            "end_time": "54:33",
            "annotations": {
                "express agreement": "Uzay is agreeing to write on the Google Doc, which Mini was having trouble with, and others were offering to help with."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "03:52-03:55",
            "transcript": "I think maybe couple of people tried to open it at the same time, I don't know.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:41",
            "end_time": "54:44",
            "annotations": {
                "express humor": "Mini Das makes a lighthearted comment about the Google Doc crashing, possibly due to multiple people accessing it simultaneously, which expresses humor."
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "03:58-04:02",
            "transcript": "I can see anonymous fox and anonymous bat and anonymous blob fish.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:47",
            "end_time": "54:51",
            "annotations": {
                "express humor": "Mark makes a humorous observation about the anonymous users in the Google Doc, likely to lighten the mood."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:03-04:05",
            "transcript": "I see anonymous rhino. It might be you.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:52",
            "end_time": "54:54",
            "annotations": {
                "express humor": "The speaker is making a lighthearted comment, suggesting that another participant might be the \"anonymous rhino\" in the Google Doc, which is humorous in the context of collaborative document editing."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "04:09-04:18",
            "transcript": "What else? We talked about uh we talked a lot about optical systems about diffuse measurement versus microscopy.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:58",
            "end_time": "55:07",
            "annotations": {
                "None": "This utterance does not fit any of the codes in the codebook because it is a general statement summarizing the discussion."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "04:18-04:33",
            "transcript": "I like to build off I like to think about multimodality systems to reduce the the the need for the data intensiveness or maybe even make the problem better condition in one one or the other.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:07",
            "end_time": "55:22",
            "annotations": {
                "present new idea": "Mini Das introduces the idea of using multimodality systems to reduce data intensiveness or improve problem conditioning, which is a novel concept not explicitly discussed before in this specific way.",
                "expand on existing idea": "This utterance expands on the existing idea of multimodality, which has been discussed previously in the conversation, by suggesting its potential to reduce data intensiveness or improve problem conditioning.",
                "express enthusiasm": "Mini Das expresses enthusiasm for the idea of building off of and thinking about multimodality systems."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "04:33-04:34",
            "transcript": "Okay. Do you want to jot that down on the",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:22",
            "end_time": "55:23",
            "annotations": {
                "encourage particpatioin": "Brian is encouraging someone to write down their thoughts on the Google Doc, which Mini is using to take notes."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "04:34-04:39",
            "transcript": "Excel or the the Google Doc?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:23",
            "end_time": "55:28",
            "annotations": {
                "assign task": {
                    "Explanation": "Brian is assigning the task of jotting down notes to either the Excel sheet or the Google Doc."
                }
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "04:40-05:03",
            "transcript": "To build off something was saying that like no one disease or organ, there's no one size fits all answer to that. And we see that a lot in our in model organisms. Uh, we we talked about light sheet microscopy.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:29",
            "end_time": "55:52",
            "annotations": [
                {
                    "expand on existing idea": "Benjamin is building on Uzay's previous point that each modality has strengths for different types of diseases, stating that there is no one size fits all answer for any disease or organ."
                },
                {
                    "acknowledge contribution": "Benjamin acknowledges the previous discussion about light sheet microscopy."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "05:03-06:02",
            "transcript": "You're not going to use light sheet microscopy to diagnose neurodegenerative disorder in a person, right? But it is an incredible tool for looking at model organisms. It's it takes advantage of just the host of light based technologies we have available and we wouldn't have biomedical research without that. So how do you connect these clinically accessible imaging modalities like MRI where you can't see anything. You can see structures, you can tag a few things, maybe some spectroscopy, but compared to what light can do, it's just the the tiniest scratch, um, mechanistically speaking. So how do you relate those two imaging modalities to get the maximum value from an a a research and analytical modality and a more clinically accessible or clinically relevant modality. I think for me that's that's always been my sort of challenge, uh, coming up as was trained as a as a biologist and then went into biophysics. How do you connect those two things?",
            "speaking_duration": 59,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:52",
            "end_time": "56:51",
            "annotations": [
                {
                    "reject idea": "The speaker rejects the idea of using light sheet microscopy to diagnose neurodegenerative disorders in a person, implying it's not suitable for that purpose.",
                    "express enthusiasm": "The speaker expresses enthusiasm for light sheet microscopy as an incredible tool for looking at model organisms.",
                    "present new idea": "The speaker presents a new idea about how to connect clinically accessible imaging modalities like MRI with research and analytical modalities to get the maximum value from both."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "06:03-06:06",
            "transcript": "That that sounds similar sort of to what Mark was saying, I think a little bit of",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:52",
            "end_time": "56:55",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Brian acknowledges that his statement is similar to what Mark was saying, recognizing Mark's input."
                }
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:07-06:09",
            "transcript": "I think it's it's a good idea, that's why.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:56",
            "end_time": "56:58",
            "annotations": [
                {
                    "express agreement": "Benjamin explicitly agrees with a prior idea, stating that it is a good idea."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "06:10-06:11",
            "transcript": "Yeah, yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:59",
            "end_time": "57:00",
            "annotations": {
                "express agreement": "Brian Pogue is agreeing with Benjamin Bartelle's previous statement, indicating alignment in their thinking."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "06:11-06:12",
            "transcript": "Anybody who has to interact with with uh",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:00",
            "end_time": "57:01",
            "annotations": [
                {
                    "encourage particpatioin": "Brian Pogue is trying to get more people to speak up and contribute to the discussion, as the group is trying to determine where they could have the most impact."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:12-06:26",
            "transcript": "pathology and then they go into the deal with the radiologist and you're like, you're saying this gray blob is is the the root of the mechanism behind whatever that disease we're talking about it. It's an extremely frustrating experience.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:01",
            "end_time": "57:15",
            "annotations": {
                "express frustation": "Benjamin expresses frustration about the disconnect between detailed pathology findings and the less specific information radiologists can provide, highlighting the limitations of current imaging techniques in capturing the complexity of disease mechanisms."
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "06:28-07:05",
            "transcript": "because then you go back to the biologist and like here's a, you know, extremely rich data set with a thousand different transcripts all labeled in 3D space and we still don't know what the mechanism is. And to see that huge dichotomy and those scales of data and the just the richness of the data set you have, it's it's just the gap is like overwhelming to to see.",
            "speaking_duration": 37,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:17",
            "end_time": "57:54",
            "annotations": {
                "express frustration": "Benjamin expresses frustration about the disconnect between rich biological data and the lack of mechanistic understanding, building on the previous discussion about relating clinical imaging modalities to research modalities."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "07:05-07:05",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:54",
            "end_time": "57:54",
            "annotations": [
                {
                    "express agreement": "Brian Pogue says \"Yeah\" in response to Benjamin Bartelle's statement, indicating agreement."
                }
            ]
        },
        {
            "speaker": "Larry Cheng",
            "timestamp": "07:06-08:04",
            "transcript": "Just like to build on the existing discussion, uh, we might be looking at a subset of the population or disease application where more concerned about the free moving human body rather than those um, you know, given location or given time point. So I think what we can contribute is uh, is there's um, further development with a need for the long-term and continuous monitoring capability, we can make that try to be uh conformal and deployed onto the body and to allow for the uh long-term longitudinal study of the uh disease because sometimes when we have this one a snapshot measurement, it might be limited, but when we correlate the information your long run or uh from multiple time points, that will certainly provide much more uh useful information.",
            "speaking_duration": 58,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:55",
            "end_time": "58:53",
            "annotations": [
                {
                    "expand on existing idea": "Larry is building on the previous discussion about imaging modalities and their limitations by suggesting a focus on long-term, continuous monitoring of freely moving individuals, which addresses the limitations of snapshot measurements mentioned earlier."
                },
                {
                    "present new idea": "Larry introduces the idea of conformal devices deployed on the body for long-term longitudinal studies, which is a novel approach not explicitly discussed before."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:04-08:04",
            "transcript": "Mhm.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:53",
            "end_time": "58:53",
            "annotations": {
                "acknowledge contribution": "The utterance \"Mhm\" acknowledges the previous speaker's contribution, Larry Cheng, without expressing agreement or expanding on the idea."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:06-08:07",
            "transcript": "Okay. I'll drop that on the Google.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:55",
            "end_time": "58:56",
            "annotations": {
                "assign task": {
                    "Explanation": "Brian Pogue is assigning himself the task of adding the notes to the Google document, which Mini Das was previously doing manually."
                }
            }
        },
        {
            "speaker": "Larry Cheng",
            "timestamp": "08:08-08:10",
            "transcript": "Yeah, please do, yeah.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:57",
            "end_time": "58:59",
            "annotations": {
                "express agreement": "The speaker is agreeing with Brian Pogue's offer to jot down his previous statement on the Google Doc."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "08:10-08:27",
            "transcript": "As we're doing that, I would I guess maybe push you to think about what's the bottleneck and what's the solution, you know, if you could maybe try to flush it out a little bit, you know, what in each of these problem areas or applications, what's the bottleneck and what's the solution, you know?",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:59",
            "end_time": "59:16",
            "annotations": {
                "encourage particpatioin": {
                    "Explanation": "Brian Pogue is encouraging the group to think about the bottlenecks and solutions related to the discussed topics, inviting further contributions."
                }
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "08:28-09:59",
            "transcript": "So to me the bottleneck especially since I'm really interested in Mark's idea is that like is still although funding agency they are starting to give like more opportunities for sharing data, but then like as if there is not enough platform that give all of those like kind of clinical images and then all of those physiological, pathological images so that people that they are working, they can just make the connection and then use these tools in order to kind of from nanoscale to go to kind of like more of the clinical data to me.",
            "speaking_duration": 91,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:17",
            "end_time": "60:48",
            "annotations": {
                "expand on existing idea": "Mini is expanding on Mark's idea about correlating pathology data with imaging signals, by discussing the bottleneck of data sharing platforms.",
                "present new idea": "Mini presents the idea that there is a lack of platforms that provide clinical, physiological, and pathological images for researchers to connect nanoscale data to clinical data."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "00:02-00:54",
            "transcript": "Yeah, just like accessing data and then doing more like virtual clinical trial that like I'm really glad that FDA and NIH they started doing that more and more. But then I think more of the like I see the bottleneck is to have a like access access uniformly to data and then by that I mean like as if it should be data set from all the companies, all the like kind of images of those the company, they don't share the software, but um that's why it should be something that it can be standardized across the different modalities and across different, you know, protocols. So that's why I see that in my field that could be a bottleneck.",
            "speaking_duration": 52,
            "nods_others": 3,
            "smile_self": 10,
            "smile_other": 30,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:51",
            "end_time": "61:43",
            "annotations": [
                {
                    "expand on existing idea": "The speaker is expanding on the previous discussion about bottlenecks in rapid analysis, specifically focusing on data access and virtual clinical trials."
                },
                {
                    "express agreement": "The speaker expresses agreement with the FDA and NIH's efforts to promote virtual clinical trials."
                },
                {
                    "present new idea": "The speaker introduces the idea of standardized data access across different modalities and protocols to address the bottleneck in their field."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "00:54-01:00",
            "transcript": "Kristen, what's the slide number? I will start entering in the slides, I think. Shall I?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:43",
            "end_time": "61:49",
            "annotations": [
                {
                    "assign task": "Mini Das is assigning herself the task of entering information into the slides, offering to take on the responsibility of documenting the discussion."
                },
                {
                    "ask clarifying question": "Mini Das is asking Kristen for the slide number, seeking clarification to proceed with the task of entering information."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:01-01:03",
            "transcript": "I think um 55?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:50",
            "end_time": "61:52",
            "annotations": [
                {
                    "ask clarifying question": "Brian is asking Mini to confirm the slide number, likely to reference a specific point or topic in the presentation."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:03-01:03",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:52",
            "end_time": "61:52",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Mini Das is acknowledging Brian Pogue's previous statement, but not necessarily agreeing or expanding on it."
                }
            }
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "01:03-01:04",
            "transcript": "55.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:52",
            "end_time": "61:53",
            "annotations": [
                {
                    "acknowledge contribution": "The speaker is acknowledging the slide number requested by another participant."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:05-01:07",
            "transcript": "I don't think we have a lot of time left.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:54",
            "end_time": "61:56",
            "annotations": [
                {
                    "express frustation": "Mini expresses frustration that the group does not have much time left in the meeting."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:07-01:13",
            "transcript": "I think there was competing Google Docs, Mark. you were saying you only saw yours. There was a",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:56",
            "end_time": "62:02",
            "annotations": [
                {
                    "acknowledge contribution": "Brian acknowledges Mark's previous statement about only seeing his own Google Doc, indicating he is aware of Mark's contribution to the discussion."
                }
            ]
        },
        {
            "speaker": "Mark Sellmyer",
            "timestamp": "01:13-01:17",
            "transcript": "I was I was putting it in the PowerPoint.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:02",
            "end_time": "62:06",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Mark acknowledges that Mini is putting the notes in the PowerPoint, recognizing her contribution to the discussion."
                }
            }
        },
        {
            "speaker": "Joyoni Dey",
            "timestamp": "01:18-01:27",
            "transcript": "So Dr. Shiva, did you want to write down your points on the doc? I I really appreciated.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:07",
            "end_time": "62:16",
            "annotations": [
                {
                    "encourage particpatioin": "Joyoni encourages Shiva to write down her points on the document, inviting her to contribute to the discussion."
                },
                {
                    "acknowledge contribution": "Joyoni acknowledges Shiva's contribution by expressing appreciation for her points."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:27-01:32",
            "transcript": "Yeah, we've got one minute, so it's probably best to just transcribe them over into the PowerPoint now.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:16",
            "end_time": "62:21",
            "annotations": [
                {
                    "propose decision": "Brian suggests transcribing the notes into the PowerPoint due to the limited time left, proposing a concrete action for the group."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:32-01:37",
            "transcript": "Let's copy and paste to the PowerPoint. If somebody's doing it, I won't do it, so we don't",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:21",
            "end_time": "62:26",
            "annotations": [
                {
                    "propose decision": "Mini suggests copying and pasting to the PowerPoint, proposing a concrete action for the group to take regarding the notes."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:37-01:38",
            "transcript": "Oh, you're not",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:26",
            "end_time": "62:27",
            "annotations": {
                "None": "No code applies to this utterance."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:39-01:40",
            "transcript": "Can I just do the numbered uh points?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:28",
            "end_time": "62:29",
            "annotations": [
                {
                    "propose decision": "Kristen proposes to focus on the numbered points, suggesting a specific direction for the discussion."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:40-01:40",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:29",
            "end_time": "62:29",
            "annotations": [
                {
                    "express agreement": "Brian Pogue is agreeing with a previous statement, but the specific statement is not clear from the immediate context."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:40-01:44",
            "transcript": "Okay. I can copy it over.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:29",
            "end_time": "62:33",
            "annotations": {
                "assign task": "Kristen offers to copy the notes over to the PowerPoint, taking on the responsibility for this task."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:44-01:50",
            "transcript": "And I would say if anyone wants to make additions, just do it in directly in the PowerPoint.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:33",
            "end_time": "62:39",
            "annotations": {
                "encourage particpatioin": "Mini Das encourages others to contribute by adding their additions directly to the PowerPoint presentation, inviting further input and collaboration."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:50-01:51",
            "transcript": "Thanks.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:39",
            "end_time": "62:40",
            "annotations": [
                {
                    "acknowledge contribution": "Kristen Maitland acknowledges the contributions of the participants after a long round of introductions."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "01:51-01:55",
            "transcript": "Mini, you're you're it for the reporting note, so",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:40",
            "end_time": "62:44",
            "annotations": {
                "assign task": {
                    "Explanation": "Brian assigns Mini the task of taking notes for the report, as indicated by \"Mini, you're it for the reporting note\"."
                }
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "01:55-02:02",
            "transcript": "I hope we we haven't reviewed it, but I'll try to make it",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:44",
            "end_time": "62:51",
            "annotations": [
                {
                    "express enthusiasm": "Mini expresses hope, indicating a positive sentiment towards completing the task of reviewing the notes."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:02-02:04",
            "transcript": "You're gonna it's gonna be beautiful. It's gonna be beautiful.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:51",
            "end_time": "62:53",
            "annotations": [
                {
                    "express enthusiasm": "Brian expresses enthusiasm for Mini's efforts in creating the reporting notes, encouraging her that the final product will be beautiful."
                }
            ]
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:04-02:04",
            "transcript": "You'll do great.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:53",
            "end_time": "62:53",
            "annotations": {
                "express enthusiasm": "Mini expresses enthusiasm and encouragement to Brian, who is tasked with reporting the notes from the session."
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:04-02:06",
            "transcript": "Yeah.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:53",
            "end_time": "62:55",
            "annotations": {
                "express agreement": "Brian Pogue says \"Yeah\" in response to Mini Das's statement, indicating agreement."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:06-02:08",
            "transcript": "Okay, yeah.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:55",
            "end_time": "62:57",
            "annotations": [
                {
                    "express agreement": "Mini Das is expressing agreement with the previous statement, likely related to the ongoing discussion about summarizing notes and preparing the report."
                }
            ]
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "02:09-02:10",
            "transcript": "We have faith in you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "Thumbs up",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:58",
            "end_time": "62:59",
            "annotations": {
                "express enthusiasm": "The speaker expresses encouragement and support towards Mini Das, who is tasked with reporting the notes from the session."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:10-02:16",
            "transcript": "Kristen, are have you? It's I I don't see any updates on the slide. Should I do it?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:59",
            "end_time": "63:05",
            "annotations": [
                {
                    "ask clarifying question": "Mini is asking Kristen if she has updated the slides, seeking clarification on the progress of the task."
                },
                {
                    "assign task": "Mini is offering to update the slides herself, suggesting a task assignment to herself if Kristen hasn't done it yet."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:16-02:18",
            "transcript": "Um Okay.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:05",
            "end_time": "63:07",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Brian acknowledges the previous turn, but does not agree or expand on it."
                }
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:18-02:18",
            "transcript": "There you go.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:07",
            "end_time": "63:07",
            "annotations": [
                {
                    "express agreement": "Mini Das is likely expressing agreement or acknowledgement that Kristen Maitland has updated the slides, as Mini was previously concerned about the lack of updates."
                }
            ]
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:18-02:20",
            "transcript": "Just popped in.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:07",
            "end_time": "63:09",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Brian acknowledges that Kristen has added the notes to the slides, recognizing her contribution to the task."
                }
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:20-02:24",
            "transcript": "Okay, let's review this and see if we are all happy with what's there.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:09",
            "end_time": "63:13",
            "annotations": {
                "propose decision": {
                    "Explanation": "Mini Das proposes a decision for the group to review the content and confirm satisfaction, following a discussion about bottlenecks in rapid analysis and potential solutions."
                }
            }
        },
        {
            "speaker": "Brian Pogue",
            "timestamp": "02:32-02:37",
            "transcript": "Well, good good working with you all and best of luck in your breakout sessions after this.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:21",
            "end_time": "63:26",
            "annotations": {
                "express enthusiasm": "Brian Pogue expresses enthusiasm by saying \"good good working with you all and best of luck in your breakout sessions after this.\", which indicates a positive sentiment and encouragement."
            }
        },
        {
            "speaker": "Mini Das",
            "timestamp": "02:37-02:38",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:26",
            "end_time": "63:27",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Mini Das is acknowledging Kristen Maitland's previous statement, which was thanking everyone for their contributions."
                }
            }
        },
        {
            "speaker": "Benjamin Bartelle",
            "timestamp": "02:38-02:38",
            "transcript": "Thank you.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:27",
            "end_time": "63:27",
            "annotations": [
                {
                    "acknowledge contribution": "Benjamin is acknowledging Kristen's facilitation of the discussion by saying thank you."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:00-00:21",
            "transcript": "the next task, we're going to take one minute of silence for you to think about this topic, and then I'm going to have you each introduce yourselves to each other. you probably have interacted with some of each other so far, but of particular note, we want to think about the areas within this topic that need research and so maybe with your introduction you can give",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 14,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "62:38",
            "end_time": "62:59",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is explaining the task for the next part of the meeting, which involves a period of silent reflection followed by introductions focusing on research needs within the topic."
                }
            ]
        }
    ]
}