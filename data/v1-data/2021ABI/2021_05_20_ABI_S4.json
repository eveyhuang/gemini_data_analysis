{
    "all_speakers": [
        "Richard Wiener",
        "Maryellen Giger",
        "Katy Keenan",
        "Maryellen Giger UChicago",
        "Sandra Laney",
        "Gergis Obaid",
        "Alexandra Walsh",
        "Shiva Abbaszadeh",
        "Ulugbek Kamilov",
        "Jim Mitchell",
        "Lu Wei",
        "Paris Perdikaris",
        "Girgis Obaid",
        "Carolyn Bayer",
        "Shannon Quinn"
    ],
    "total_speaking_length": 3172,
    "all_data": [
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:07-00:17",
            "transcript": "Uh for the person who just joined, uh we're taking a minute to uh go through the topics and jot down a few ideas for discussion on our own.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:07",
            "end_time": "00:17",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining the current activity to someone who just joined the meeting, clarifying what 'we're taking a minute to do' means in this context.",
                "assign task": "The speaker is assigning the task of jotting down ideas for discussion to the team members."
            }
        },
        {
            "speaker": "Sandra Laney",
            "timestamp": "00:17-00:34",
            "transcript": "Okay, that gives me a great opportunity to just say that I'm here as a butterfly on the wall as an observer. I'm from the a foundation and um I will actually be jumping off so no offense to anybody, but I have to jump off at at the top of the hour. Thanks.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 18,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:17",
            "end_time": "00:34",
            "annotations": {
                "explain or define term or concept": "The speaker explains their role as 'a butterfly on the wall as an observer', clarifying their presence as a non-participating observer.",
                "acknowledge contribution": "The speaker is acknowledging the opportunity to speak, but not agreeing or expanding on any prior idea.",
                "assign task": "The speaker is assigning the task of understanding their limited participation to the team members."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:34-00:36",
            "transcript": "Okay, great.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:34",
            "end_time": "00:36",
            "annotations": {
                "express agreement": "Maryellen expresses agreement with Sandra's statement about observing and leaving the meeting early."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:36-01:11",
            "transcript": "So I think that's about a minute. So hopefully you'll be able to jot some notes down and the next thing we want to do is do a brief introduction. For example, I will give you mine. I'm Mary Ellen Giger, I'm at the University of Chicago. My research is in biomedical engineering and I do this for medical reasons to develop new diagnostic but also in biology with cellular data to help um facilitate discoveries. Carolyn, can you introduce yourself? You got 30 seconds.",
            "speaking_duration": 35,
            "nods_others": 0,
            "smile_self": 11,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:36",
            "end_time": "01:11",
            "annotations": {
                "assign task": "Maryellen assigns the task of introducing herself to Carolyn, directing her to speak next.",
                "encourage particpatioin": "Maryellen encourages Carolyn to participate by asking her to introduce herself.",
                "explain or define term or concept": "Maryellen introduces herself as an example of the brief introduction she is requesting from others."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "01:12-01:29",
            "transcript": "Yeah, I'm Carolyn Bayer. Um my research is in photoacoustic imaging. Um I'm at Tulane University. Um much of our work is focused on imaging the placenta for pregnancy and development. Um but nice meeting everyone.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:12",
            "end_time": "01:29",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:00-00:16",
            "transcript": "Washington University in St. Louis. My area is computational imaging, but I focus on biomedical imaging. A lot of the things I do focuses on image reconstruction, restoration and sometimes data acquisition, but not hardware, just software.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 7,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:29",
            "end_time": "01:45",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining their area of expertise and the specific focus within that area, defining the scope of their work for the team."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:16-00:17",
            "transcript": "Okay, thank you, Katie.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:45",
            "end_time": "01:46",
            "annotations": {
                "acknowledge contribution": "Maryellen acknowledges Katie's introduction, showing recognition of her input."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "00:21-00:53",
            "transcript": "Hi, I'm at the National Institute of Standards and Technology. NIST's first role in imaging was around for MRI and validating results across centers. So we try to use quantitative techniques. We don't always get the same answer when we try them places. And now we're expanding into more validation of some of these techniques and also exploring what's possible at lower magnetic field strengths.",
            "speaking_duration": 32,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:50",
            "end_time": "02:22",
            "annotations": {
                "explain or define term or concept": "The speaker explains NIST's role in imaging, specifically MRI validation across centers, to provide context about their work.",
                "expand on existing idea": "The speaker expands on NIST's role by mentioning their current expansion into validating techniques and exploring lower magnetic field strengths, building upon the initial description of their work."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:53-00:57",
            "transcript": "Thank you and Shiva, I'm going to cross my Hollywood squares here.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:22",
            "end_time": "02:26",
            "annotations": {
                "express humor": "Maryellen makes a joke about crossing her \"Hollywood squares\", which is a reference to the game show, to express humor."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "00:58-01:04",
            "transcript": "Hi, this is Shiva. I'm from University of California, Santa Cruz. So I do work on instrumentation for positron emission tomography and x-ray imaging.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:27",
            "end_time": "02:33",
            "annotations": {
                "explain or define term or concept": "Shiva is explaining her area of expertise, which is instrumentation for positron emission tomography and x-ray imaging, to provide context for the group."
            }
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "01:04-01:20",
            "transcript": "And then I'm really interested in like improving sensitivity and then quantitative accuracy of these imaging modalities.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:33",
            "end_time": "02:49",
            "annotations": {
                "present new idea": "Jim introduces his interest in improving sensitivity and quantitative accuracy of imaging modalities, which is a new focus not explicitly mentioned by others before.",
                "expand on existing idea": "Jim's statement builds upon the previous discussion about imaging techniques and validation, adding a specific interest in improving sensitivity and quantitative accuracy."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:20-01:24",
            "transcript": "Thank you, Shayna.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:49",
            "end_time": "02:53",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger acknowledges Shayna's introduction, recognizing her input to the conversation."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:28-01:30",
            "transcript": "You referring to me? I'm Shannon.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:57",
            "end_time": "02:59",
            "annotations": {
                "ask clarifying question": "Shannon asks if Maryellen was referring to her, seeking clarification on the intended recipient of the previous statement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:30-01:31",
            "transcript": "Shannon.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:59",
            "end_time": "03:00",
            "annotations": {
                "acknowledge contribution": "Maryellen acknowledges Shannon's presence after Shannon clarified that she was being referred to, recognizing her participation in the meeting."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:31-01:31",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:00",
            "end_time": "03:00",
            "annotations": {
                "express agreement": "Shannon Quinn is explicitly agreeing with Maryellen Giger that she is referring to her."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:31-01:34",
            "transcript": "I got a new floor. I'm Shannon.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 66,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:00",
            "end_time": "03:03",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "01:35-01:57",
            "transcript": "I'm Shannon Quinn, I'm an assistant professor in computer science and cell bio at University of Georgia. I work in biomedical imaging and computational modeling of cellular and subcellular systems. I develop new artificial intelligence techniques for a unified representation of spatial and temporal signals and I work in the construction of open source software for domain scientists.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:04",
            "end_time": "03:26",
            "annotations": {
                "explain or define term or concept": "Shannon is introducing herself and her background, which serves to explain her expertise and role in the collaboration.",
                "present new idea": "Shannon mentions developing new artificial intelligence techniques for a unified representation of spatial and temporal signals, which is a novel concept introduced by her.",
                "expand on existing idea": "Shannon expands on her work in biomedical imaging by adding that she works in computational modeling of cellular and subcellular systems."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:58-02:00",
            "transcript": "Gergis.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:27",
            "end_time": "03:29",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger acknowledges Gergis's presence in the meeting, but does not agree or expand on any idea."
            }
        },
        {
            "speaker": "Gergis Obaid",
            "timestamp": "02:01-02:25",
            "transcript": "Hi yes, so I'm Gergis Obaid. I'm assistant professor at University of Texas at Dallas. Been here about a year. I work predominantly on molecular targeted nanoparticles for photodynamic cancer therapy.",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:30",
            "end_time": "03:54",
            "annotations": {
                "explain or define term or concept": "Gergis is explaining his role and research area to the group, defining his focus on molecular targeted nanoparticles for photodynamic cancer therapy, which is a concept that may be new to some members."
            }
        },
        {
            "speaker": "Gergis Obaid",
            "timestamp": "02:25-02:25",
            "transcript": "Thank you, Alex.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:54",
            "end_time": "03:54",
            "annotations": {
                "acknowledge contribution": "Gergis acknowledges Alex's contribution, likely for introducing him."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:25-02:29",
            "transcript": "Thank you, Alex.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:54",
            "end_time": "03:58",
            "annotations": {
                "acknowledge contribution": "Maryellen is verbally recognizing Alex's input after he spoke, but not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "02:29-02:52",
            "transcript": "Hi, I'm Alex. I'm at Texas A&M University and I do optical microscopy. Mostly looking at label free stuff, so molecules that are already in your cells like NADH and FAD to study cellular metabolism. And we do that for a variety of applications including drug response in cancer and studying laser tissue interactions.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 8,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:58",
            "end_time": "04:21",
            "annotations": {
                "explain or define term or concept": "The speaker explains that they are looking at label free stuff, which are molecules already in cells like NADH and FAD, to study cellular metabolism, clarifying the type of microscopy they use."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:52-02:53",
            "transcript": "Thank you and Lou.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:21",
            "end_time": "04:22",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger is acknowledging Lou's upcoming introduction, similar to how she acknowledged previous speakers."
            }
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "02:56-03:22",
            "transcript": "I am Lou Wei. I'm assistant professor of chemistry here at Caltech. We perform optical imaging, particular vibrational microscopy on biological cells and we're interested in small molecule imaging mostly understanding the metabolic activities.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:25",
            "end_time": "04:51",
            "annotations": {}
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "03:22-03:22",
            "transcript": "Thank you and Paris.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:51",
            "end_time": "04:51",
            "annotations": {
                "acknowledge contribution": "Lu Wei is acknowledging Maryellen Giger's contribution of introducing him, but not agreeing or expanding on any ideas."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:23-03:24",
            "transcript": "Thank you and Paris.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:52",
            "end_time": "04:53",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger is acknowledging Paris's introduction, but not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "03:25-03:40",
            "transcript": "Hello, I'm at the University of Pennsylvania. My expertise is in computational science and machine learning. And basically I'm developing computational methods for modeling and simulation of biological systems with a focus on cardiovascular flows.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:54",
            "end_time": "05:09",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining his expertise in computational science and machine learning, providing context for his contributions to the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:40-03:51",
            "transcript": "Thank you and we have five visitors which I was told hop in and out. Um if you would mind to say something you can or else we're going to get right to the purpose.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:09",
            "end_time": "05:20",
            "annotations": {
                "encourage particpatioin": "Maryellen is inviting the five visitors to introduce themselves if they wish to participate."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:51-03:51",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:20",
            "end_time": "05:20",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger acknowledges the previous speaker's introduction, signaling a transition to the next speaker or topic."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:51-04:06",
            "transcript": "We'll get right to the purpose. So, we have um oh next order is we need a recorder and who would also then present in three minutes for the group.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:20",
            "end_time": "05:35",
            "annotations": {
                "propose decision": "The utterance proposes the need for a recorder and someone to present in three minutes, suggesting a concrete choice for the group to make regarding meeting logistics."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:06-04:22",
            "transcript": "Um, I could do it randomly or we can have a volunteer. Um you you should be able to get to the Google Drive and um this is great training when you're facilitating in your senior career cycle.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:35",
            "end_time": "05:51",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:26-04:35",
            "transcript": "Okay, should I close my eyes and pick on the screen and I end up on Shannon. Congratulations.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 55,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:55",
            "end_time": "06:04",
            "annotations": {
                "express humor": "Maryellen makes a joke about randomly selecting someone to present, congratulating Shannon in advance, which expresses humor."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:37-04:37",
            "transcript": "So we're looking at",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:06",
            "end_time": "06:06",
            "annotations": {
                "explain or define term or concept": "Shannon is likely going to explain or define a term or concept, as indicated by the phrase \"So we're looking at\", which suggests she is about to introduce a topic or concept."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:37-04:40",
            "transcript": "So we're looking at",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:06",
            "end_time": "06:09",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging someone to participate by indicating that they are about to start looking at something together, likely prompting the other person to contribute their thoughts."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:40-04:40",
            "transcript": "the PowerPoint deck?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:09",
            "end_time": "06:09",
            "annotations": {
                "ask clarifying question": "Shannon asks a clarifying question to confirm if they should be looking at the PowerPoint deck, given Maryellen's previous statement about 'looking at'."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:40-04:47",
            "transcript": "Yes, so if you go to the and it's the if you you continue to around slide 20 or so you should you should find it should say um",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:09",
            "end_time": "06:16",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "04:54-04:55",
            "transcript": "It's 17 right now.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:23",
            "end_time": "06:24",
            "annotations": {
                "explain or define term or concept": "Shannon is clarifying the slide number in the PowerPoint deck that Maryellen is referring to, ensuring everyone is on the same page."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:55-05:01",
            "transcript": "Um, no probably a little past 20. 23.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:24",
            "end_time": "06:30",
            "annotations": {
                "explain or define term or concept": "Maryellen is clarifying the slide number in the PowerPoint deck that Shannon should be looking at, providing a more precise location than the previous estimate."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:02-05:03",
            "transcript": "Ah, yes.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:31",
            "end_time": "06:32",
            "annotations": {
                "express agreement": "Shannon Quinn expresses agreement after Maryellen Giger directed her to slide 23 in the PowerPoint deck."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:03-05:06",
            "transcript": "Okay. 20, 24 in fact. So yeah.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:32",
            "end_time": "06:35",
            "annotations": {
                "acknowledge contribution": "Shannon is acknowledging Maryellen's guidance on the slide number to look at in the PowerPoint deck."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:07-05:10",
            "transcript": "Is it supposed to be a separate recorder and um reporter?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:36",
            "end_time": "06:39",
            "annotations": {
                "ask clarifying question": "Maryellen is asking a question to clarify whether the roles of recorder and reporter should be held by different people, which is relevant to the meeting's organization."
            }
        },
        {
            "speaker": "Sandra Laney",
            "timestamp": "05:11-05:14",
            "transcript": "So is one taking the notes and one reporting?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:40",
            "end_time": "06:43",
            "annotations": {
                "ask clarifying question": "Sandra is asking to clarify if the roles of note-taker and reporter are separate, following Maryellen's request for a recorder and presenter."
            }
        },
        {
            "speaker": "Richard Wiener",
            "timestamp": "05:15-05:27",
            "transcript": "One one person can do it and one person can do both, I think. Yeah, and you can take the notes, you don't have to put the notes into the PowerPoint yet, you can take those, share it with people, they can add and then can condense them into the PowerPoint so that there's one slide.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:44",
            "end_time": "06:56",
            "annotations": {}
        },
        {
            "speaker": "Richard Wiener",
            "timestamp": "05:27-05:27",
            "transcript": "Sounds good.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:56",
            "end_time": "06:56",
            "annotations": {
                "confirm decision": "Richard confirms the decision that one person can take notes and another can report, or one person can do both."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:27-05:33",
            "transcript": "Okay, are you are you okay with that, Shannon?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:56",
            "end_time": "07:02",
            "annotations": {
                "confirm decision": "Maryellen is checking if Shannon is okay with the suggestion that one person can take notes and report, which was just discussed."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:33-05:33",
            "transcript": "Yep.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:02",
            "end_time": "07:02",
            "annotations": {
                "confirm decision": "Shannon confirms that she is okay with taking notes and reporting, as suggested by Richard."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:33-05:36",
            "transcript": "Okay, great, thank you.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:02",
            "end_time": "07:05",
            "annotations": {
                "express agreement": "Maryellen expresses agreement with Shannon's willingness to take on the task of both recorder and reporter, as discussed in the previous turns."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-06:15",
            "transcript": "So now let's go in the beginning of the session, you all had the one minute to kind of collect your thoughts on the topics and we will start with the three bullets that are listed, but if any of you think that there's a major other bullet that you think would be useful to look into, we can go there too. One thing I drew from listening to all your introductions, we all do computational science.",
            "speaking_duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:05",
            "end_time": "07:44",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:15-06:19",
            "transcript": "Um, uh and it seems that some are at more of a macro scale, some are at micro scale.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:44",
            "end_time": "07:48",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining the different scales at which the computational science is being applied, macro and micro, to summarize the introductions."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:19-06:24",
            "transcript": "Um, and probably some work in 2D and some in 3D. But we all do computational science of images at one point.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:48",
            "end_time": "07:53",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:24-06:36",
            "transcript": "So I I think we're um all in this together. So let's start with the first one, um 3D imaging can yield massive data sets too large to quantitate and fully scrutinize manually.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:53",
            "end_time": "08:05",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:36-06:41",
            "transcript": "What data are required to effectively train AI ML algorithms to assess these data sets.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:05",
            "end_time": "08:10",
            "annotations": {
                "ask clarifying question": "Maryellen is asking what data is required to train AI/ML algorithms, seeking clarification on the necessary data inputs given the context of 3D imaging producing large datasets."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:41-06:45",
            "transcript": "So how many of you do work with massive data sets?",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:10",
            "end_time": "08:14",
            "annotations": {
                "ask clarifying question": "Maryellen is initiating the discussion on the topic of 3D imaging and massive datasets, and she is asking how many people work with massive datasets to gauge the group's experience with the topic."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:46-06:49",
            "transcript": "I know I do. Big, yeah.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:15",
            "end_time": "08:18",
            "annotations": {
                "express agreement": "Maryellen agrees with the implicit question of whether people work with massive datasets, based on the previous turn where she asked \"So how many of you do work with massive data sets?\"."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:50-06:50",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:19",
            "end_time": "08:19",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:58-07:00",
            "transcript": "Um, I have well.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:27",
            "end_time": "08:29",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:00-01:05",
            "transcript": "uh data or model adaptation to different data, right? So, uh what do I mean by this? So you train your data uh on one type of data set, say, you know, you do MRI scan, uh it has certain artifact patterns, you train the model on that. Now you apply to something else and we know that it doesn't work very well if, you know, you applied it to a configuration doesn't work. Now there are a bunch of ideas out there, uh you know, in in the computer vision community in the machine learning community where people try to bridge those things, but it's still not we don't yet have, you know, killer technology that allows us, you know, we don't understand both the limits of how we can adapt the models to different applications. At the same time, you know, what's the best way to do the adaptation of the models that we already pre-trained to a new application, right? So deep learning models are not traditional software in the sense that I can go and just edit it. It's all in the weights of the training thing. So how do we reuse, adapt uh those models.",
            "speaking_duration": 65,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "11:29",
            "end_time": "12:34",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:06-01:22",
            "transcript": "So how do we use metrology to appropriately measure how we're doing in our development as well as in the end product so that it is generalizable? I think that's what you were getting at as well as say unbiased and fair.",
            "speaking_duration": 16,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:35",
            "end_time": "12:51",
            "annotations": {
                "ask clarifying question": "The speaker is asking how to use metrology to measure development and the end product to ensure generalizability, unbiasedness, and fairness, seeking clarification on how to achieve these goals.",
                "acknowledge contribution": "The speaker acknowledges that her question relates to the previous speaker's point about data or model adaptation."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "01:23-01:23",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:52",
            "end_time": "12:52",
            "annotations": {
                "express agreement": "Beck Kamilov agrees with Maryellen Giger's summarization of his previous points about using metrology to measure development and ensure generalizability, fairness, and lack of bias."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:24-01:24",
            "transcript": "Are those major topics that",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "12:53",
            "end_time": "12:53",
            "annotations": {
                "ask clarifying question": "Maryellen is asking if the topics discussed are major topics, seeking confirmation and clarity on the direction of the conversation."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:32-01:52",
            "transcript": "I think we should add kind of explainability to it too because in order to like uh focus more about the second part that what data are required to effectively train as we try to model and then create kind of some explanation to take away from that black box of how the algorithm is working.",
            "speaking_duration": 20,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:01",
            "end_time": "13:21",
            "annotations": {}
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:52-02:22",
            "transcript": "And then make it more explainable is going to help us to see what are the different information that the data is leading to give us our accurate output and then as we learn and as we try to make it more explainable, that's become a tools for us to just try to focus in the information that we need.",
            "speaking_duration": 30,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:21",
            "end_time": "13:51",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:22-02:26",
            "transcript": "Okay, I I agree explainability and then to the end user interpretability.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:51",
            "end_time": "13:55",
            "annotations": {
                "express agreement": "Maryellen explicitly agrees with Shiva's point about the importance of explainability in AI/ML models, building on the previous discussion about training AI/ML algorithms and adapting models to different datasets.",
                "expand on existing idea": "Maryellen expands on Shiva's idea of explainability by adding the concept of interpretability for the end user, building on the previous discussion about training AI/ML algorithms and adapting models to different datasets."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:27-02:42",
            "transcript": "So, um Shannon, would you want to share your screen and we could all pull it over so we can still see each other, but that way we can give you is that useful or not? I don't know what notes you're taking, that's why.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with handwritten notes and diagrams. The notes include items like 'UV cross talk' and 'Mary write paper on TOF'. There are also some chemical structures drawn on the board.",
            "start_time": "13:56",
            "end_time": "14:11",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:43-02:50",
            "transcript": "I'm I'm unfortunately on Zoom on an iPad and taking notes on a desktop with the monitors right behind it.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:12",
            "end_time": "14:19",
            "annotations": {
                "express frustration": "Shannon expresses frustration about her current setup, being on Zoom on an iPad while taking notes on a desktop, which seems inconvenient for screen sharing."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:50-02:52",
            "transcript": "Ah.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:19",
            "end_time": "14:21",
            "annotations": {
                "acknowledge contribution": "Maryellen Giger is acknowledging Shannon's previous statement about her setup with the iPad and desktop, but is not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "02:54-03:03",
            "transcript": "So, um I could turn it into a Google Doc that I can then share a link to with everybody in here if that would be preferable.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:23",
            "end_time": "14:32",
            "annotations": {
                "propose decision": "Shannon proposes to turn her notes into a Google Doc and share the link, offering a concrete choice for the group on how to share the notes."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:03-03:22",
            "transcript": "Because I like seeing everyone while we're having a discussion and I know I can kind of make the slide part very small and still see you all. Um but I think we need that visual feedback.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:32",
            "end_time": "14:51",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging participation by expressing her preference for seeing everyone during the discussion, suggesting it aids visual feedback and thus, better engagement."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:22-03:24",
            "transcript": "So do you do you all want to do a uh Google Drive?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:51",
            "end_time": "14:53",
            "annotations": {
                "propose decision": "Maryellen is suggesting a concrete choice for the group, which is to use a Google Drive for sharing notes, following Shannon's explanation of her note-taking setup."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:24-03:26",
            "transcript": "Or do you want someone to",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:53",
            "end_time": "14:55",
            "annotations": {
                "encourage particpatioin": "Maryellen is asking a question to encourage someone else to contribute to the discussion about how to share notes."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:26-03:30",
            "transcript": "I'm comfortable with the Google Drive, uh Google Doc, Google Doc.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:55",
            "end_time": "14:59",
            "annotations": {
                "express agreement": "Beck Kamilov expresses agreement with the suggestion of using a Google Doc, which was proposed by Maryellen Giger as a way to share notes during the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:30-03:45",
            "transcript": "Right, Google Doc, I'm sorry. So if you send that link in the chat, we can just click on it and then it's as if we're viewing the screen. That would be useful because",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "14:59",
            "end_time": "15:14",
            "annotations": {
                "confirm decision": "Maryellen confirms the decision to use a Google Doc for note-taking, which was previously suggested by Shannon and agreed upon by Beck.",
                "explain or define term or concept": "Maryellen clarifies that she meant 'Google Doc' instead of 'Google Drive', ensuring everyone understands the tool being discussed.",
                "express enthusiasm": "Maryellen expresses that using the Google Doc would be useful for the discussion."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "03:45-03:45",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:14",
            "end_time": "15:14",
            "annotations": {
                "express agreement": "Beck Kamilov agrees with Maryellen Giger's suggestion to use a Google Doc for note-taking, which was proposed in the previous turn."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:45-03:46",
            "transcript": "Um",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:14",
            "end_time": "15:15",
            "annotations": {
                "None": "This utterance does not fit any of the codes in the codebook because it is an incomplete sentence and does not express any idea, question, or action."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:46-04:24",
            "transcript": "Does anyone have any other thoughts on the first bullet which is in a way kind of our discussion blended into the third bullet? You know, we talked about um what kind of errors, you know, if we think about errors that are acceptable, those are quantitated by the metrology of the system. how are you going to measure the performance? How are you going to measure the variation of your system? How will you measure how unbiased or general your system is?",
            "speaking_duration": 38,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "15:15",
            "end_time": "15:53",
            "annotations": {
                "encourage particpatioin": "Maryellen is asking if anyone has any other thoughts, encouraging others to contribute to the discussion.",
                "expand on existing idea": "Maryellen is elaborating on the first bullet point by connecting it to the third and discussing errors, performance measurement, variation, bias, and generalization, building upon the initial topic of 3D imaging and massive datasets.",
                "explain or define term or concept": "Maryellen is explaining the concept of acceptable errors and how they are quantified by the metrology of the system."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "04:25-04:56",
            "transcript": "Yeah, I think I feel like since we're often imaging biological processes and looking at clinical images, um really knowing what ground truth is, um can be very challenging. Um it's not, you know, often the result might be correlated to pathology for example, if you're looking at cancer, but you don't really know that that pathology is accurate either.",
            "speaking_duration": 31,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "15:54",
            "end_time": "16:25",
            "annotations": {
                "present new idea": "The speaker introduces the challenge of knowing the ground truth when imaging biological processes and clinical images, which is a novel point in the discussion.",
                "provide supporting evidence": "The speaker supports the idea that knowing the ground truth is challenging by mentioning that pathology, which is often correlated to the result, may not always be accurate."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "04:57-05:07",
            "transcript": "Um do you think Carolyn that it's like having uh the expert lead on it or are you um like what would make it more true?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "16:26",
            "end_time": "16:36",
            "annotations": {
                "ask clarifying question": "Katy is asking Carolyn a clarifying question about what would make the ground truth more accurate when imaging biological processes and clinical images, after Carolyn mentioned the challenge of knowing what ground truth is."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "05:08-05:15",
            "transcript": "Um probably better images, right? Like since we're we're all looking at it with the image lens, right?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "16:37",
            "end_time": "16:44",
            "annotations": {
                "expand on existing idea": "Carolyn is expanding on the previous discussion about the challenges of knowing the ground truth when imaging biological processes and clinical images, suggesting that better images would improve the situation.",
                "provide supporting evidence": "Carolyn supports her idea by stating that they are all looking at the problem through the \"image lens\", implying that the quality of the images is a fundamental factor in their work."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:19-05:25",
            "transcript": "Yeah, when I think of imaging, I think of both acquisition and interpretation.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "16:48",
            "end_time": "16:54",
            "annotations": {
                "explain or define term or concept": "Maryellen is defining what she means by 'imaging' to include both acquisition and interpretation, clarifying the scope of the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:25-06:16",
            "transcript": "I think we have to go back to the application and what is the task? And I think the truth um I'm going to throw this out. So a lot of us probably do segmentation, right? And then you ask, well how do you evaluate it? Well, maybe you use a dice coefficient or something like that. But it there's also the more broader picture saying, well, my segment works depending on my final truth, which might be based on pathology.",
            "speaking_duration": 51,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "16:54",
            "end_time": "17:45",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:16-06:23",
            "transcript": "Um, just what do you think?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a stone wall with the words 'TULANE UNIVERSITY' carved into it. The background is slightly blurred.",
            "start_time": "17:45",
            "end_time": "17:52",
            "annotations": {
                "encourage particpatioin": "Maryellen Giger is asking for someone's opinion on the topic being discussed, which is related to ground truth in imaging and its evaluation, encouraging participation from the group."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "06:24-07:38",
            "transcript": "Well, I kind of I kind of agree with Carolyn's point about the uh ground truth, like what really is the ground truth? Um the way I see it is multiplexing the uh final yes no answer. So the input, let's say for example if it was histology, getting the manual input of the pathologist as well as some maybe molecular markers of the histological sections could be, you know, proteomics in addition to some genomic data, multiplexing the ground truth, well, getting working closer towards a ground truth by multiplexing the outputs at the end in order to train the intermediate. In my opinion is the best because I don't really know if there really is going to be a ground truth at that point because everything to a certain extent is either uh subjective to the observer if there's a pathologist or to uh experimental bias or fluctuations if you're going to get false positives or false negatives in the in the markers or the genomics themselves. So yeah, I'm I'm a little bit I'm kind of leaning more towards having building up the information at the at the end first in order to then bridge that gap because if you don't have that then it doesn't really make sense.",
            "speaking_duration": 74,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "17:53",
            "end_time": "19:07",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:38",
            "transcript": "Sounds good.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:07",
            "end_time": "19:07",
            "annotations": {
                "confirm decision": "Maryellen Giger confirms a decision that was previously proposed, indicating agreement and finalization."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:39-07:40",
            "transcript": "Um",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:08",
            "end_time": "19:09",
            "annotations": {
                "None": "No code applies to this utterance."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:41-08:21",
            "transcript": "I maybe I want to also bring up one thing. There is an interesting thing, the concept, right? Um in the so if you have errors in your ground truth and those errors are not systematic, meaning if you average them out across the whole data set, right? And then they average out to be a very small quantity, you can in principle train still with this form of errors and your model will not learn. So there is an interesting technical question there, what kind of errors are tolerable in the training data.",
            "speaking_duration": 40,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:10",
            "end_time": "19:50",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:21-08:21",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:50",
            "end_time": "19:50",
            "annotations": {
                "express agreement": "Maryellen agrees with the point that there are tolerable errors in the training data, which was brought up by Beck in the previous turn."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:22-08:55",
            "transcript": "Yeah, I think we need to train and test with messy data because that's what the real world is. And sometimes, you know, we can do initial development, it's we do initial development of a filter in continuous domain, um but then when we go to actual image domain is pixelated and quantized, it doesn't quite work, but it gets you maybe 80, 85% there. Um, you know, we start in the ideal world and then um make it work in the messy real world.",
            "speaking_duration": 33,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "19:51",
            "end_time": "20:24",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "08:56-09:16",
            "transcript": "And by the way, anything like changes like this you just mentioned that pixelation changes. Those are the systematic things that you could in principle incorporate to this as non-trainable elements or adaptable elements of machine learning models.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:25",
            "end_time": "20:45",
            "annotations": {
                "expand on existing idea": "Beck expands on Maryellen's point about pixelation in real-world images by suggesting that these systematic changes can be incorporated as non-trainable or adaptable elements in machine learning models, building upon the discussion of training and testing with messy data.",
                "provide supporting evidence": "Beck provides a potential solution to the problem of pixelation changes in real-world images, suggesting incorporating them as non-trainable or adaptable elements in machine learning models, which supports the idea of adapting models to different data."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "09:16-09:17",
            "transcript": "So",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:45",
            "end_time": "20:46",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "00:00-00:41",
            "transcript": "This is a major problem. I mean this problem and even uh it um the aspects about um the generalizability, um the bias that biases an AI is is really important. Um, what would you need to make this dream work? And I'm going to ask Lou. What what would take uh well maybe um you're more imaging than AI, right? Yeah, so I I well, you could take a pass if you want, but go ahead if you want to.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 15,
            "smile_other": 3,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:29",
            "end_time": "22:10",
            "annotations": {}
        },
        {
            "speaker": "Lu Wei",
            "timestamp": "00:41-02:45",
            "transcript": "Right, yeah, so I I'm more of imaging than AI. I'm here actually um trying to learn some um questions or or abilities for AI that could help us to interpretate uh imaging and do imaging segmentation. So um I'm new to the AI field. We're trying to adopting uh different networks for um um training and uh one part of the research in my lab is we do uh label free imaging um such that there's um a ton of uh images but not so much specific contrast. So we're trying to use an AI to allow us to uh do specific imaging. Um so I guess the question I have is uh there are a lot of different networks out there. Um well with with or specifically with very fine um um um differences. Um but there's not much of the benchmark um to allow us to compare um unless we're trying to use our own data to train it and then um to compare with of course different uh um um basically to adopt each of the techniques and compare it with our own data. Um before that there's really no way to know specifically what would be the best candidate for us. Um and also another thing um related to um I guess the uh um um validity of the interpretation is uh what kind of signal noise ratios do we need as both training set and also the prediction set and um is there any uh limitations on resolutions um that we should be aware of um before we do the um training. So so I guess I'm here more of to uh looking to the possibilities and asking questions then then providing some of the insights. Sorry about that.",
            "speaking_duration": 124,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 1,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:10",
            "end_time": "24:14",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "02:45-03:00",
            "transcript": "Well no, I think that's very useful. You're telling us what you want and some of us in it in AI research and development kind of have to um work to uh uh give that to you. We we need to understand the end user.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:14",
            "end_time": "24:29",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:00-03:43",
            "transcript": "Because you know, earlier we talked about this pipeline of the AI pipeline, we we talked about for example segmentation, do you measure it while you're segmenting it or you look at the end point and the end point depends on the end user. And even if um even if it's an autonomous AI system, there's an end user somewhere. Somewhere it's affecting it and I think uh this field is still very young because a lot of the work being done is very um very focused.",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:29",
            "end_time": "25:12",
            "annotations": {
                "expand on existing idea": "The speaker expands on the previously discussed AI pipeline, specifically segmentation, and how its evaluation depends on the end user.",
                "explain or define term or concept": "The speaker explains that the endpoint of the AI pipeline depends on the end user, even in autonomous systems, to clarify the importance of the end user perspective.",
                "present new idea": "The speaker introduces the idea that the AI field is still very young because a lot of the work being done is very focused, which is a novel concept in the context of the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "03:43-04:56",
            "transcript": "You know, you'll read the papers it was for this task with this database, maybe from different institutions, but it's just the the needle in a in a big haystack of all the other questions going on in medicine and biology. Um, but we can but many of the techniques, many of the metrology, the way to evaluate them, you know, how do you get around ground truth? Those I think there's um, I don't want to say a menu, but there is I think a short list and for me, um, though I have a lot of things that I would like in the world, I would like everyone to have access to this really clear short list of how how do I do all these things. Um, oh one of the things um I I don't want to forget before time goes by is we should look at bullet number two. And to me can can we extend our AI pipeline so it's very long, so it starts with acquisition, starts with the patient. In fact, someone thing by us is called closed loop imaging where this is that this is the what the patient needs, the patient gets it all the way to getting it and then doing the interpretation. To me that's you have to extend your AI to go through that entire pipeline.",
            "speaking_duration": 73,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "25:12",
            "end_time": "26:25",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:56-04:56",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:25",
            "end_time": "26:25",
            "annotations": {}
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "04:56-04:57",
            "transcript": "Yes, that makes me so happy.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:25",
            "end_time": "26:26",
            "annotations": {
                "express enthusiasm": "The speaker expresses excitement and optimism, indicated by the statement \"Yes, that makes me so happy,\" which suggests a positive reaction to the preceding discussion about extending the AI pipeline."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "04:57-05:03",
            "transcript": "Oh, okay. Interesting. Okay, we have a happy group here. Good.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:26",
            "end_time": "26:32",
            "annotations": {}
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "05:03-05:50",
            "transcript": "Yeah, I'm very excited to read, you know, like papers and then there are different groups that now thinking about kind of uh reconstructing the image, you know, using AI directly. And then since I usually work on kind of limited angle problem, so then I really uh think about how AI can just like really give us more information and then how we can even to interpret data that they are low dose and then we get kind of the information of higher dose. So I think that's um regarding this part, the question number two, I I think it's a very exciting time in the field and I'm really happy to learn and then implement them in my like research.",
            "speaking_duration": 47,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:32",
            "end_time": "27:19",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:50-05:54",
            "transcript": "Great. So maybe optimizing along the pipeline individually and then the whole item.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:19",
            "end_time": "27:23",
            "annotations": {
                "propose decision": {
                    "Explanation": "Maryellen suggests optimizing the AI pipeline both individually and as a whole, proposing a concrete choice for the group to consider."
                }
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "05:54-06:05",
            "transcript": "Which includes acquisition and interpretation and then interpretation is by AI or human or AI aided human. But so patient um coming in for an imaging exam all the way to deciding the treatment.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:23",
            "end_time": "27:34",
            "annotations": {
                "expand on existing idea": "Maryellen expands on the idea of optimizing the AI pipeline, adding that it includes acquisition and interpretation, whether by AI, human, or AI-aided human, and extends from the patient's initial imaging exam to the final treatment decision, building upon the previous discussion about extending the AI pipeline.",
                "present new idea": "Maryellen presents the new idea of considering the entire process from patient exam to treatment as part of the AI pipeline, which hasn't been explicitly mentioned in this comprehensive way before.",
                "explain or define term or concept": "Maryellen clarifies that the interpretation stage of the AI pipeline can involve AI, humans, or AI-aided humans, explaining the different possibilities for how the interpretation is done."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "06:05-06:17",
            "transcript": "We got to do all that together as opposed we got everyone doing little niches here and there. So um that would be good. So yes, back.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:34",
            "end_time": "27:46",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:20-06:43",
            "transcript": "Uh I think one thing to think about in that context and you know, I'm very excited about that problem as well about, you know, the whole pipeline doing, but we need to think also about fragility of the system. Again, it comes back to generalization.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "27:49",
            "end_time": "28:12",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "06:43-06:43",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:12",
            "end_time": "28:12",
            "annotations": {
                "express agreement": "Beck Kamilov says \"Right\", which indicates agreement with the previous statement made by Maryellen Giger about the importance of considering the entire AI pipeline from patient to treatment."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:44-07:39",
            "transcript": "There's a question around like um there's kind of a high barrier to entry as far as solving those sorts of problems because you want to have access to all the data types in order to solve that sort of problem. And uh like when you operate at a single institution, you're limited to the vendor system that you have access to. Or uh you know, in medical imaging when the vendors develop something, they're pulling it off of all of their own image sets and then it's not generalizable to the other vendors. So when I was, you know, thinking about the first bullet point, it was like uh like what data is required? I mean, you kind of want all the things. Uh and so I think that's a big challenge is how to and then how do we get it to people? Um there's a lot of access issues.",
            "speaking_duration": 55,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "28:13",
            "end_time": "29:08",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:39-07:41",
            "transcript": "So we want all the data.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:08",
            "end_time": "29:10",
            "annotations": {
                "express agreement": "Maryellen is agreeing with Katy's point in the previous turn that solving the problem of generalizability requires access to all data types."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:41-07:54",
            "transcript": "That's one of the they asked us what do we want? We want all the data and we you you there technically we could do a lot. We are limited by data and culture I would say. The giving of data, the sharing of data even.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:10",
            "end_time": "29:23",
            "annotations": {
                "present new idea": "Maryellen introduces the idea that the group wants 'all the data' to solve problems, which hasn't been explicitly stated before, framing it as a requirement.",
                "express frustration": "Maryellen expresses frustration that they are limited by data and culture, specifically the giving and sharing of data, which is hindering their progress.",
                "expand on existing idea": "Maryellen expands on Katy's point about the data needed to solve problems, stating that they want all the data but are limited by data access and sharing culture, building on the previous discussion about data limitations."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:54-07:54",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:23",
            "end_time": "29:23",
            "annotations": {
                "express agreement": "The utterance 'Right' expresses agreement with the previous statement made by Katy Keenan about the need for all data to solve problems related to AI in imaging."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "07:54-08:04",
            "transcript": "But if we had a massive method or so we we can do that. I saw Paris shaking his head. I think big mistake. So what are you thinking about?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:23",
            "end_time": "29:33",
            "annotations": {
                "encourage particpatioin": "Maryellen Giger saw Paris shaking his head and then asked him what he was thinking about, inviting him to contribute to the discussion."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "08:04-08:04",
            "transcript": "Oh.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:33",
            "end_time": "29:33",
            "annotations": {
                "acknowledge contribution": "The speaker is acknowledging the previous speaker's point, but not necessarily agreeing or expanding on it, as Maryellen Giger just asked Paris what he was thinking about."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:09-09:01",
            "transcript": "Uh it's a great discussion so far. I mean I'm a little bit on the less optimistic side on the front that you know, data and AI by alone will address all those issues. And perhaps one thing to think about is how we integrate domain knowledge into this pipeline in a way that is informative and gives us the right sort of prior information we need.",
            "speaking_duration": 52,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "29:38",
            "end_time": "30:30",
            "annotations": {}
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:01-09:01",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:30",
            "end_time": "30:30",
            "annotations": {
                "express agreement": "Paris explicitly agrees with the prior statement about the limitations of data and AI alone, and the need to integrate domain knowledge."
            }
        },
        {
            "speaker": "Maryellen Giger UChicago",
            "timestamp": "09:02-09:14",
            "transcript": "Yes, I to me domain knowledge, domain expertise, what you know, all of us here if we're in imaging and AI in biology or medicine, we are working in an interdisciplinary field.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:31",
            "end_time": "30:43",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:20",
            "transcript": "have many you all are smart, you all have great AI technologies, but I think we're looking at the issues of how do we bring it all together? Um, um, to me, that's the challenge. Alex, I haven't put you on the spot. I'm sorry, you're right in the middle of my screen and I keep going.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:29",
            "end_time": "31:49",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "The speaker acknowledges the intelligence and AI capabilities of the group members, recognizing their contributions to the field."
                },
                "present new idea": {
                    "Explanation": "The speaker introduces the idea of bringing all the AI technologies together to address the challenges in the field, which is a novel concept in the context of the discussion."
                },
                "encourage particpatioin": {
                    "Explanation": "The speaker directly addresses Alex, apologizing for not including him in the discussion and inviting him to participate."
                }
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:21-00:22",
            "transcript": "Zoom has a question, no, Jim?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:50",
            "end_time": "31:51",
            "annotations": {
                "encourage particpatioin": "Beck Kamilov encourages Jim to participate by asking if he has a question, after Maryellen Giger had been calling on other participants."
            }
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "00:23-00:51",
            "transcript": "Yeah, I have I have a question quickly. I know in other domains, um, you know, I know a lot about the Tesla autopilot work. The crowd sourcing of images and and so on has helped them a lot to improve that. Is there crowd sourcing going on here and and and where do those images end up residing that everybody could have access to the same large set of images?",
            "speaking_duration": 28,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Raising Hand",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:52",
            "end_time": "32:20",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:51-01:47",
            "transcript": "Uh, there is crowd sourcing in radiology. They do it at radiology meetings and also across the web where they they recruit some one project had over 180 radiologists who did multiple annotations on uh chest images. So they can do it. So and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to",
            "speaking_duration": 56,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:20",
            "end_time": "33:16",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:47-02:02",
            "transcript": "so and that's what I think I meant by technically all we can do a lot. It it it it we're in a very technical field and we're hindered by data and culture. Um, your other question even in um cellular images, many of you are in cellular. I don't know you talk about your experience there and I'm going to ask Alex about that, but you have to people sit and circle cells. crazy just to create data and that gets back to bullet one. How many cells do you have to circle to have enough data to algorithm. Um, but yes, the crowd sourcing it does it does exist, but it's it's not on a massive um scale. Good point, Jim. And sorry I didn't see your hand ready. So I'm used to this, not the stationary one that they have on. Alex.",
            "speaking_duration": 75,
            "nods_others": 0,
            "smile_self": 30.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:16",
            "end_time": "33:31",
            "annotations": {}
        },
        {
            "speaker": "Jim Mitchell",
            "timestamp": "02:03-02:04",
            "transcript": "Thank you back.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:32",
            "end_time": "33:33",
            "annotations": {
                "acknowledge contribution": "The speaker is acknowledging Beck's contribution for pointing out that Jim had a question."
            }
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "02:04-03:35",
            "transcript": "Yeah, we do a lot of circling cells. Um, yeah, we do auto fluorescence imaging, so it's low very low signal to noise and that creates a challenge for automated ways to process our data. And so we can see the patterns, but it's very hard to train traditional pipelines to do the segmentation. So that's why we've been working with AI. And actually, I really like Paris's point and you worded that much better than I was going to. Um, but my first interactions with AI and microscopy was stuff to for noise removal and um improving resolution and lowering laser power and stuff and I was just blown away by that work. And but I have right the same we know we know physical and biological boundaries on these conditions and I would like to see more integration of that into AI like if I'm segmenting a cell and it puts the nucleus, you know, right up against the edge of the cell, that's probably not where the nucleus is, right? It's more in the center. So how can we incorporate these things that we know um are are biological or physical boundaries and have the AI say like flag that oh that can't be right. Let's try again. Um, I think that gets into your errors, you know, what errors do we tolerate and how can we improve and minimize those.",
            "speaking_duration": 91,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:33",
            "end_time": "35:04",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:36-04:00",
            "transcript": "I that's a a very good point. Um, when when I find when training AI, you should take advantage of a priori knowledge as well as what image are you inputting? Yes, one could say if I have infinite amount of data, infinite amount of truth, I can train it if I I just let it chug away, right?",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:05",
            "end_time": "35:29",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "The phrase \"that's a very good point\" acknowledges Alex's prior contribution about integrating biological and physical boundaries into AI."
                },
                "expand on existing idea": {
                    "Explanation": "Maryellen expands on Alex's point about integrating domain knowledge into AI by suggesting taking advantage of a priori knowledge and the input image during AI training."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:00-04:16",
            "transcript": "But we don't have that especially in um the medical biomedical field, you know, you know, for things like image net, there's lots of pictures of cats and dogs and cars and light poles and all, but we don't have a lot of that annotated in the medical field even though we're generating so many medical images per day.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:29",
            "end_time": "35:45",
            "annotations": {
                "provide supporting evidence": "The utterance provides supporting evidence for the challenges in training AI in the medical field by contrasting it with the availability of annotated data in other fields like ImageNet, where there are abundant labeled images of common objects.",
                "expand on existing idea": "This utterance expands on the existing idea of the challenges in training AI for medical imaging, which was previously discussed in the context of ground truth and data limitations."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:16-04:30",
            "transcript": "Um, and I I I I appreciate um these comments on the a priori because we we need to help the AI. I you know, sometimes I tell my students think like a human because if you know that um image presentation A is better for the human to look at than image presentation B.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:45",
            "end_time": "35:59",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:30-05:13",
            "transcript": "Why give the AI raw data? In a way, you're you're training in files, the training of all these humans has they have been reading images for many, many years. So how many of you in a sense consider what image am I giving to the AI and do you sometimes do the preprocessing to help the AI learn because you have limited data?",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "35:59",
            "end_time": "36:42",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining the concept of using preprocessed images instead of raw data for AI training, drawing an analogy to how humans are trained to read images over many years.",
                "present new idea": "Maryellen introduces the idea of preprocessing images before feeding them to AI, suggesting it can help the AI learn better with limited data.",
                "ask clarifying question": "Maryellen is asking how many of the participants consider what image they are giving to the AI and if they preprocess the data to help the AI learn, seeking to understand the current practices of the group."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:13-05:13",
            "transcript": "Caroline, what do you think of that?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:42",
            "end_time": "36:42",
            "annotations": {
                "encourage particpatioin": "Maryellen Giger is directly asking Caroline for her opinion, encouraging her to contribute to the discussion."
            }
        },
        {
            "speaker": "Carolyn Bayer",
            "timestamp": "05:13-06:05",
            "transcript": "Yeah, no, so I was nodding because um so I I'm also focused more on the imaging and instrumentation side. Um, but I work with collaborators that um do more of the sort of machine learning or, you know, neural network development. And um, you know, that's that definitely resonates that you have sometimes picked a data set to show a specific thing, right? Um, and that data set obviously then may not be representative of what that algorithm is actually going to encounter.",
            "speaking_duration": 52,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:42",
            "end_time": "37:34",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:06-06:21",
            "transcript": "So if we had our database, our messy database, we could include both, we can include them of different spatial resolution, we can include AI to do the reconstruction. Um, so Shannon, how's this list coming? It looks good. Looks longer than three minutes. It looks really good.",
            "speaking_duration": 15,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:35",
            "end_time": "37:50",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:31-06:34",
            "transcript": "I'm trying to get the main points.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:00",
            "end_time": "38:03",
            "annotations": {
                "acknowledge contribution": "Shannon is acknowledging the request to summarize the discussion, but not agreeing or expanding on it."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:34-06:41",
            "transcript": "Okay. Um, do you want us to go through? Do you want to kind of summarize for us and then we can so so the topic here is",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:03",
            "end_time": "38:10",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:41-07:01",
            "transcript": "um what's the next big thing for this field? How can you what would be your dream of where it would go and um uh near the and I'll tell you how I've been trying to do my dream models.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:10",
            "end_time": "38:30",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:01-07:03",
            "transcript": "Is it the open question?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:30",
            "end_time": "38:32",
            "annotations": {
                "ask clarifying question": "Beck Kamilov is asking if the current topic of discussion is the \"open question\" that Maryellen Giger mentioned, seeking confirmation on the discussion's focus."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:03-07:07",
            "transcript": "That's is it a clinical question? What do you mean on the",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:32",
            "end_time": "38:36",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:07-07:14",
            "transcript": "I'm sorry. like are we discussing big big should we kind of",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:36",
            "end_time": "38:43",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:14-07:34",
            "transcript": "I think one thing that just was coming to my mind while we're discussing is like it would be amazing to have a recipe of how much data we need for a task. There is no recipe, you know, like you come to a problem, you say, I want to segment this thing.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:43",
            "end_time": "39:03",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:34-07:44",
            "transcript": "So, your collaborator asks, how much should I measure? Yeah. How much should I collect? Can anybody here answer?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:03",
            "end_time": "39:13",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:44-07:54",
            "transcript": "Okay, now, how about if you know some prior information about the problem, say nucleus is in that position or that. Now, can this help me cut the data and by how much?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:13",
            "end_time": "39:23",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:54-07:54",
            "transcript": "Well",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:23",
            "end_time": "39:23",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "07:54-07:54",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:23",
            "end_time": "39:23",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:55-08:01",
            "transcript": "I guess I guess for me I actually want to take it one step further and almost",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:24",
            "end_time": "39:30",
            "annotations": {
                "expand on existing idea": "Shannon is building upon the previous discussion about data requirements and expressing a desire to extend the conversation further."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:01-08:04",
            "transcript": "almost take data out of the equation entirely and",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:30",
            "end_time": "39:33",
            "annotations": {
                "present new idea": "Shannon is introducing a novel concept of minimizing the reliance on data, which has not been previously discussed in the conversation."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:04-08:10",
            "transcript": "let me let me explain a bit where we've been talking a lot about",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:33",
            "end_time": "39:39",
            "annotations": {
                "explain or define term or concept": "Shannon is about to explain something, likely related to the ongoing discussion about data requirements for AI in imaging."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "08:10-09:54",
            "transcript": "you know, we need a lot of data, we need a lot of ground truth. Given an infinite amount of data, um that was an interesting point to me because I still wonder like would the model still learn what we wanted to learn? And I'm not I hesitate before answering and I feel like that hesitation by itself says that even our models aren't quite there yet and that maybe more data isn't exactly the problem that we're looking at. Maybe I just I keep I keep thinking of like these new methods involving self-supervised learning and few shot learning and anomaly detection where it's less about how much data you can throw at the problem and more about how we can build this architecture that without it becoming kind of a handcrafted algorithm has very specific features that it looks for. And so as a result, you don't need this lengthy training process, you don't need terabytes and terabytes of data, but what you can have to again sort of inform the end user if they don't have enough data is some sort of uncertainty quantification at the end. So for instance, if you're trying to do some kind of segmentation and you have your data set, you don't necessarily need to do a kind of calculation of how much data do I need, you just kind of give it to the algorithm, the algorithm does its few shot semi or self-supervised training and then at the end of that spits out, okay, here's the segmentation that I did and here's my certainty that it's correct.",
            "speaking_duration": 104,
            "nods_others": 0,
            "smile_self": 20.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:39",
            "end_time": "41:23",
            "annotations": {}
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "09:54-09:58",
            "transcript": "Do do we also need the certainty on the certainty so that we can trust the certainty?",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:23",
            "end_time": "41:27",
            "annotations": {
                "ask clarifying question": "Beck is asking a question to clarify Shannon's point about uncertainty quantification, specifically if there needs to be a measure of certainty for the certainty itself to ensure trustworthiness."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:00-00:18",
            "transcript": "actually talk about having, you know, let's say the algorithm says, uh, you have 65% chance of having cancer, I am 35% sure and I am a slightly biased algorithm. So those are the three outputs I usually like, um, because",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 11,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:29",
            "end_time": "41:47",
            "annotations": {
                "expand on existing idea": "Maryellen is expanding on the idea of uncertainty quantification that Shannon introduced, adding the concept of algorithm bias to the uncertainty output.",
                "present new idea": "Maryellen introduces the idea of an algorithm providing three outputs: the probability of a condition (e.g., cancer), the algorithm's certainty in that probability, and a statement about the algorithm's bias, which is a novel concept in the discussion."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:19-00:22",
            "transcript": "Well I agree with that but I don't trust the 35%. How would I trust that 35",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:48",
            "end_time": "41:51",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:22-00:23",
            "transcript": "All right, but that's what the 35",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:51",
            "end_time": "41:52",
            "annotations": {
                "explain or define term or concept": "Maryellen is about to explain what the 35% certainty means in the context of the algorithm's output, building on the previous discussion about uncertainty quantification."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "00:23-00:29",
            "transcript": "that's what the 35% except if it actually has a true statistical meaning that's non Gaussian and I don't know.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:52",
            "end_time": "41:58",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:29-00:52",
            "transcript": "Right. You have to do the reproducibility, repeatability studies to get that. But that's telling you that the computer is only 35%. It's like you go to the your doctor's office and he says like, you know, you got 85% sure chance you have a chipped tooth, but I'm only 20% sure. How do you feel? So that's what but the AI has to also kind of do that. I I agree.",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "41:58",
            "end_time": "42:21",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:52-01:17",
            "transcript": "Uh Shannon, that's a um, uh, I I think that's definitely what kind of outputs do you want? And I think that will differ for if you're doing um AI on biological images for discovery or are you doing it for a patient output. I'm going to ask um, um, more folks to talk here. I don't know what when do we finish? I just want to make sure we're not running out of time.",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:21",
            "end_time": "42:46",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "01:19-01:54",
            "transcript": "I always, you know, I mentioned I I like to think like a human and I think the inputs and the outputs should be very similar. I'm a big fan of handcrafted. In fact, I I think it's the world will not just be all deep learning. I grew up with handcrafted and I now incorporate deep learning and I merge them.",
            "speaking_duration": 35,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:48",
            "end_time": "43:23",
            "annotations": {}
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:54-02:20",
            "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access, but then like we have to. We have to find a way to just get to that.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "43:23",
            "end_time": "43:49",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:20-02:25",
            "transcript": "Okay, yes, and when I say think like a human, I'm thinking more of input and output.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:49",
            "end_time": "43:54",
            "annotations": {
                "explain or define term or concept": "Maryellen is clarifying what she means by \"think like a human\", stating that she is referring to the input and output of the AI system, not necessarily the internal workings."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:26-03:26",
            "transcript": "Um, but if you think how radiologist are that their job is to interpret medical images. And what how do they get trained? First as a resident, they have a textbook and they go through that textbook and they learn this is what a cancer looks like. This that's handcrafted. Get a little hand waving here. And then they sit with their attending radiologist and they read day in and day out and they're told, oh, you're wrong. No, that's a false positive. That's the deep learning and that's of the radiologist brain. And then we have different structures of the brain. Some are really good at finding Waldo and weirds Waldo and some aren't. Maybe they shouldn't have been radiologist. Just like there's probably computer vision AI algorithms that way.",
            "speaking_duration": 60,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:55",
            "end_time": "44:55",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:26-03:37",
            "transcript": "And I I think the example of giving the AI algorithm an image that radio humans find easier to read could save you a lot of training time and data when you're doing your AI. How many of you train on medical images? I think Katie does and Shannon and Shiva.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:55",
            "end_time": "45:06",
            "annotations": {}
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "03:37-03:39",
            "transcript": "We're using like a DICOM.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:06",
            "end_time": "45:08",
            "annotations": {
                "explain or define term or concept": "The utterance explains the term DICOM, which is relevant to the discussion about medical imaging data."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:39-04:26",
            "transcript": "A DICOM. But say for example with um breast MRI, you could have DICOM fields of the raw data, you could have it showing subtracted images after uptake of a contrast, you could have a image where you've collapsed it into a MIP. We find for example inputting the MIP gives you better performance than inputting just the subtraction image or and and things like if you have volume data, do you input the volume data or do you input the slices of the volume data. All those are before you even get to your algorithm and I don't know if people spend enough time on that. That's how I see it. Um, have you run into that?",
            "speaking_duration": 47,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:08",
            "end_time": "45:55",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining different types of DICOM fields and image processing techniques (subtracted images, MIP) in the context of breast MRI data, clarifying the options available for inputting data into AI algorithms.",
                "provide supporting evidence": "The speaker mentions that inputting MIP (Maximum Intensity Projection) images gives better performance than inputting just the subtraction image, providing empirical evidence based on their experience.",
                "ask clarifying question": "The speaker ends the utterance by asking if others have run into the same issues regarding data preprocessing and its impact on AI algorithm performance, seeking to understand if others have similar experiences."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:26-04:26",
            "transcript": "How do you decide what goes into your algorithm?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:55",
            "end_time": "45:55",
            "annotations": {
                "ask clarifying question": "Maryellen is asking a question to understand the decision-making process behind selecting inputs for an algorithm, following a discussion about preprocessing images to help AI learn with limited data."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:26-04:37",
            "transcript": "I mean between the volumetric and slices it's easy it depends how much volumetric examples I have. Usually I have like 10 volumetric examples and each one has hundreds of slices or thousands of slices and I go by slices.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:55",
            "end_time": "46:06",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:40-04:41",
            "transcript": "But the format.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:09",
            "end_time": "46:10",
            "annotations": {
                "ask clarifying question": "Maryellen is asking for clarification on the format of the data being used for the algorithm, following a discussion about the choice between volumetric data and slices."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:42-04:45",
            "transcript": "Oh you mean the way the data is stored in the format?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:11",
            "end_time": "46:14",
            "annotations": {
                "ask clarifying question": "Beck is asking for clarification on what Maryellen meant by 'format', specifically if she is referring to the way the data is stored."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:45-04:46",
            "transcript": "Right. What are well, not the format.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:14",
            "end_time": "46:15",
            "annotations": {
                "ask clarifying question": "Maryellen is asking about what data to input into the algorithm, and is now clarifying that she is not asking about the format of the data, but something else."
            }
        },
        {
            "speaker": "Ulugbek Kamilov",
            "timestamp": "04:46-04:56",
            "transcript": "That's like application collaborator dependent, right? Uh, well for me at least it's uh depends what's application, so that tells me the format.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:15",
            "end_time": "46:25",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:56-04:57",
            "transcript": "Right.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:25",
            "end_time": "46:26",
            "annotations": {}
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "05:00-05:11",
            "transcript": "I think it's a little bit as a barrier because I don't think that you we have enough resources to answer some of those questions. Sometimes they're still driven by what you have access to.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:29",
            "end_time": "46:40",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:11-05:24",
            "transcript": "So if you were to ask me how do I figure out what to input to the network, my answer would be I sit with the radiologist. I sit with the domain expert on imaging. I sit with the human AI instrument.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:40",
            "end_time": "46:53",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining her process for determining the appropriate input for a neural network, which involves consulting with domain experts.",
                "provide supporting evidence": "Maryellen is providing her method of consulting with radiologists and domain experts as a way to determine the best input for a network, supporting the idea that domain knowledge is important."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:24-05:25",
            "transcript": "I use human human aided AI development.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:53",
            "end_time": "46:54",
            "annotations": {
                "explain or define term or concept": "Maryellen is explaining her approach to AI development, which involves human input and collaboration, building on the previous discussion about the importance of domain expertise and understanding the end user's needs."
            }
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "05:25-05:36",
            "transcript": "And not all of us are in a place where we can do that. Right? Like I'm not at a medical institution. And so how do I get that access? How do I that's not a resource I have.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:54",
            "end_time": "47:05",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-05:36",
            "transcript": "Okay, so",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:05",
            "end_time": "47:05",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:36-05:37",
            "transcript": "Right.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:05",
            "end_time": "47:06",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:37-06:12",
            "transcript": "Okay, well that's that's major. To me, that's a barrier. You um AI developers need um um need that. I I get that access all the time that's why I like where I am, but um that's that's really important that the network network needs to connect the AI developer with the domain expert of that imaging task.",
            "speaking_duration": 35,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:06",
            "end_time": "47:41",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Maryellen acknowledges Katy's point about the lack of access to domain experts as a major barrier for AI developers."
                },
                "present new idea": {
                    "Explanation": "Maryellen presents the idea that a network is needed to connect AI developers with domain experts in imaging tasks, which hasn't been explicitly stated before."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:12-06:13",
            "transcript": "It it it will save you tons of time.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:41",
            "end_time": "47:42",
            "annotations": {
                "express enthusiasm": "Maryellen expresses enthusiasm that connecting AI developers with domain experts will save time."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:13-06:15",
            "transcript": "What about Shannon and Shiva? How do you get your images?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:42",
            "end_time": "47:44",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:15-06:17",
            "transcript": "Are you have domain expert issues?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:44",
            "end_time": "47:46",
            "annotations": {
                "ask clarifying question": "Maryellen is asking Shannon and Shiva if they are having issues related to access to domain experts, following a discussion about the importance of domain expertise in AI development."
            }
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "06:18-07:14",
            "transcript": "No, but like you basically we find like we have a still problem. That's why I think that for example, if like funding agency they could recognize that and even in the hospital they could recognize that because sometimes I do work with a hospital that their main focus is not like research. So I'm just like, you know, running after radiologist and I tell them that, you know, if you want coffee, I bring you coffee and then when you are sitting in the reading room just please, you know, like let me come and then we go through some information. But what you mentioned is just really the critical path for the success of what I'm doing is still I second Katie that is hard to get access.",
            "speaking_duration": 56,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "47:47",
            "end_time": "48:43",
            "annotations": {}
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:14-07:14",
            "transcript": "Yes.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "48:43",
            "end_time": "48:43",
            "annotations": {}
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "07:14-07:31",
            "transcript": "But then like we have to. We have to find a way to just get to that. So then if we had more infrastructure to provide a path for that, it could be really great.",
            "speaking_duration": 17,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a whiteboard with notes related to the discussion, including points about NSF cancer research, energy levels, and UV cross talk. The content remains static throughout the segment.",
            "start_time": "48:43",
            "end_time": "49:00",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:31-07:32",
            "transcript": "Okay, this yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:00",
            "end_time": "49:01",
            "annotations": {
                "express agreement": "Maryellen is agreeing with Shiva's statement about the need for infrastructure to provide a path to access data and domain experts, which is a critical path for success."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:32-07:32",
            "transcript": "I think",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:01",
            "end_time": "49:01",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:32-07:33",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:01",
            "end_time": "49:02",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:33-07:34",
            "transcript": "Okay, good.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:02",
            "end_time": "49:03",
            "annotations": {
                "express agreement": "Maryellen is explicitly agreeing with the previous statement made by Shiva about the need for infrastructure to provide a path for AI developers to connect with domain experts."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:34-07:34",
            "transcript": "Um",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:03",
            "end_time": "49:03",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:34-07:35",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:03",
            "end_time": "49:04",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:35-07:35",
            "transcript": "Okay, good.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:04",
            "end_time": "49:04",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:35-07:36",
            "transcript": "We've got 20 minutes.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:04",
            "end_time": "49:05",
            "annotations": {
                "None": "This utterance does not fit into any of the codes provided in the codebook, as it is simply stating the remaining time."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:36-07:37",
            "transcript": "Thankfully.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:05",
            "end_time": "49:06",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:37-07:38",
            "transcript": "I would not be able to throw that together.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:06",
            "end_time": "49:07",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:38",
            "transcript": "Okay.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:07",
            "end_time": "49:07",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:38-07:41",
            "transcript": "I think you're doing a great job here, Shannon. Shannon, where do you see things can be move merged?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:07",
            "end_time": "49:10",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:41-07:42",
            "transcript": "Where do you have the domain expert issue?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:10",
            "end_time": "49:11",
            "annotations": {
                "ask clarifying question": "Maryellen is asking Shannon to clarify if she has issues accessing domain experts, following a discussion about the importance of domain expertise in AI development and Katy Keenan's statement about not having access to medical experts."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:01-00:37",
            "transcript": "Yeah, that to me that's a night and day um that helps you. I I I um I always, you know, feel for you guys that in that situation. How about the biology people, the image people doing AI on bio imaging, biological imaging, cellular imaging. What's what's holding you up? You have access I would assume to biologist much easier than they have access to medical imaging people. Alex, do you have access to who you need to talk to? And then also Girgis, I can ask.",
            "speaking_duration": 36,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 11.1,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:30",
            "end_time": "52:06",
            "annotations": {}
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "00:38-00:45",
            "transcript": "Yeah, I think my limitations are how much data do I need and we already have that on there.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
            "start_time": "52:07",
            "end_time": "52:14",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:46-00:49",
            "transcript": "Okay, so you have your domain experts. You have your biologist right there.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:15",
            "end_time": "52:18",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Maryellen acknowledges that Alex has access to domain experts and biologists, recognizing his input in the discussion."
                }
            }
        },
        {
            "speaker": "Alexandra Walsh",
            "timestamp": "00:50-00:51",
            "transcript": "Right. Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "Alex Walsh is sharing her screen. The screen shows a landscape image of Black Gap Wildlife Management Area with various plants and mountains in the background.",
            "start_time": "52:19",
            "end_time": "52:20",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "00:51-00:53",
            "transcript": "Girgis, do you have that?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:20",
            "end_time": "52:22",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging Girgis to participate in the discussion, likely asking if he has access to the domain experts he needs, similar to the previous discussion with Alex."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "00:53-02:39",
            "transcript": "Yeah, well, so so our our approach uh at least machine learning from a completely different perspective. So we collaborate with some folks here uh trying to understand how nanoparticles will accumulate into tumors and what that actually means. And the problem at least from the perspective of the the domain experts is not necessarily that yes, this is a tumor, but it's more about the technology that's being developed. So if you use a a certain type of particle or contrast agent and suggest that this is tumor selective, the interpretation that's being presented at least in the primary literature is very biased by a lot of um I guess you could you could say misinterpretation that's that's been perpetuated over a couple of decades. So people will assume that certain types of materials will always accumulate in tumors and if it does, then yes, we have a tumor. So the problem is not necessarily just on the on the image interpretation side, but it's more about the the contrast agent itself. And so the way that we approach it is that the input that we need needs to be built up as well. It's not just a contrast agent, but it's more using some nanotech experts to suggest that okay, well, this contrast agent will also accumulate similarly to another contrast agent. So you have to put um a second uh piece of information into the input of the algorithm itself to suggest that if you see this kind of a trend, this is a false positive. So you're teaching it what a false positive is based on the material that you're using as a contrast agent right from the very start from the get go so that you don't end up with false positives at the end. So it's we're kind of more on the front end of things and and and in my field the domain experts that are lacking is more on the on the material well nanobio interaction side of things.",
            "speaking_duration": 106,
            "nods_others": 1,
            "smile_self": 10.4,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:22",
            "end_time": "54:08",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "02:40-02:47",
            "transcript": "So you're doing your AI based on knowledge of known biology and chemistry? Would that be correct wording?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:09",
            "end_time": "54:16",
            "annotations": {
                "ask clarifying question": "Maryellen is asking for confirmation that her understanding of Girgis's approach to AI development, which incorporates knowledge of biology and chemistry, is accurate."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "02:47-03:47",
            "transcript": "It's it's more about so it's it's hard for me to to explain without going into details. But let's let's take nanoparticle contrast agents um for optical imaging. That's one of the things that we look into. And there are clinical trials that suggest that you can use these contrast these nanoparticles as contrast agents for positive tumor detection and image guided surgery. And that's all very well and good. You can see the image, you can probably use AI to delineate the uh tumor boundary to be a little bit better. But there are secondary biological factors um that contribute to errors that haven't been considered right at the start. So we try and hit it on both ends, not just what the image actually tells us, but what the agent that we're administering, how that's going to interact with the tissue and how that then contributes to a false positive. And so then feeding in information about what false positive materials or materials that give false positives is actually going to look like when you finally get the image.",
            "speaking_duration": 60,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:16",
            "end_time": "55:16",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "03:49-04:14",
            "transcript": "So I always think of AI as having two types of components. One is where it's model driven where it has these physical limitations, chemistry limitations, but it when biology um where it's it's model driven and um the model is built on these principles. You could use deep learning in it, but in the end you have these constraints on it.",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:18",
            "end_time": "55:43",
            "annotations": {
                "present new idea": {
                    "Explanation": "Maryellen introduces a novel concept of AI having two types of components: one model-driven with physical and chemical limitations, and another built on biological principles, which hasn't been explicitly discussed in this manner before."
                },
                "expand on existing idea": {
                    "Explanation": "Maryellen expands on the idea of incorporating domain knowledge into AI, building on previous discussions about the importance of a priori knowledge and constraints in AI models."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:14-04:52",
            "transcript": "The other type of AI is in general you can think of it as statistical, you know, it's the deep learning, it's um uh having the machine actually learn and I personally believe that in the future we need a mixture of these. I think it would be extremely interesting to have like um both types applied to your situation Girgis because you have you know, a lot of times it's hard to find the person with the model. You know, it's um but how do you want to bring that point up in this this Google Doc?",
            "speaking_duration": 38,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:43",
            "end_time": "56:21",
            "annotations": {
                "explain or define term or concept": "The speaker explains the two types of AI: statistical (deep learning) and model-driven (physical limitations), to clarify the different approaches to AI.",
                "express enthusiasm": "The speaker expresses enthusiasm about the idea of applying both types of AI to Girgis' situation, indicating excitement about the potential of this approach.",
                "encourage particpatioin": "The speaker encourages Girgis to bring up the point in the Google Doc, inviting him to contribute his perspective to the discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "04:52-04:53",
            "transcript": "Help us, where would you put it and how would you put it?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:21",
            "end_time": "56:22",
            "annotations": {
                "encourage particpatioin": "Maryellen is encouraging someone to contribute to the Google Doc, seeking their input on where and how to incorporate a specific point."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "04:54-05:00",
            "transcript": "I I guess it probably it probably ties in with the with the ground truth to a certain extent.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:23",
            "end_time": "56:29",
            "annotations": {
                "expand on existing idea": "Girgis is building upon the previous discussion about ground truth, suggesting his point relates to that topic."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "05:00-05:16",
            "transcript": "But maybe the generalizability part of things. And again, I I see it from a whole different perspective. I know a lot of folks here use um patient images, but I'm talking more about the generalizability again of the contrast agent and how that will behave.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:29",
            "end_time": "56:45",
            "annotations": {
                "expand on existing idea": "Girgis is expanding on the previous discussion about generalizability, but applying it to the context of contrast agents rather than patient images, building on the topic of generalizability that was already brought up.",
                "acknowledge contribution": "Girgis acknowledges that others are using patient images, which is a recognition of their work, but he is not agreeing or expanding on their specific approaches."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:16-05:22",
            "transcript": "So it's something relationship of the model to the physics chemistry and biology of the imaging situation.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:45",
            "end_time": "56:51",
            "annotations": {
                "explain or define term or concept": "This utterance is defining the relationship between the model and the physics, chemistry, and biology of the imaging situation, which is a concept being discussed."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "05:22-05:23",
            "transcript": "I guess so.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:51",
            "end_time": "56:52",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "05:23-05:25",
            "transcript": "Sorry, where is my cursor?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:52",
            "end_time": "56:54",
            "annotations": {
                "express humor": "Shannon Quinn expresses humor by apologizing for not knowing where her cursor is, which is a lighthearted comment in the context of sharing her screen."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:00-06:03",
            "transcript": "Well, I see a little red dock by the word generalizable.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:29",
            "end_time": "57:32",
            "annotations": {
                "acknowledge contribution": "Maryellen acknowledges Shannon's cursor position on the Google Doc, recognizing her contribution to the shared document."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:04-06:10",
            "transcript": "Oh, that's that's not me. But yeah. Um sorry, I was I was trying to",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 16.7,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:33",
            "end_time": "57:39",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:10-06:11",
            "transcript": "Yeah, you sure can. Everybody can.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:39",
            "end_time": "57:40",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:11-06:23",
            "transcript": "Um sorry, the people are editing the presentation and I'm not able to make any changes. That's what I've been trying to figure out.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:40",
            "end_time": "57:52",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:23-06:34",
            "transcript": "So no one hits save. How's that? It kicks people in other groups. Shannon, if you want, I can add the names so that you can focus on the conversation.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:52",
            "end_time": "58:03",
            "annotations": {}
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:34-06:39",
            "transcript": "Yeah, thank you added it and they all got lost.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:03",
            "end_time": "58:08",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:39-06:43",
            "transcript": "Yep. Yeah. Yeah, so I can do that.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:08",
            "end_time": "58:12",
            "annotations": {}
        },
        {
            "speaker": "Katy Keenan",
            "timestamp": "06:43-06:46",
            "transcript": "Okay, thank you.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:12",
            "end_time": "58:15",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "06:46-06:52",
            "transcript": "Yeah and are you able to open up your the slide deck to put in at least the final three points?",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:15",
            "end_time": "58:21",
            "annotations": {
                "assign task": "Maryellen is assigning Shannon the task of opening the slide deck and adding the final three points, following up on Shannon's role as the designated note-taker and reporter."
            }
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "06:52-07:11",
            "transcript": "No, that's what I'm talking about. The Google Doc is fine. Please edit away there. It's the slide deck that keeps kicking me out every time I try to make an edit.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:21",
            "end_time": "58:40",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:11-07:14",
            "transcript": "So what if you just take yeah, okay.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:40",
            "end_time": "58:43",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:14-07:34",
            "transcript": "Can you download the PowerPoint to your computer? Um I'm actually just going to draft I'm going to draft it out in the Google Doc. Okay. Okay. Um Now I forgot what um",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:43",
            "end_time": "59:03",
            "annotations": {}
        },
        {
            "speaker": "Shannon Quinn",
            "timestamp": "07:20-07:21",
            "transcript": "You were going to mention something about generalizability.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:49",
            "end_time": "58:50",
            "annotations": {
                "ask clarifying question": "Shannon is asking Maryellen to elaborate on her previous point about generalizability, seeking further information on the topic."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:34-07:55",
            "transcript": "Yes, well model driven by the um physics chemistry and biology of the um uh contrast agents properties? I don't know if I got that right.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:03",
            "end_time": "59:24",
            "annotations": {
                "explain or define term or concept": "Maryellen is trying to define or explain the concept of a model being driven by the physics, chemistry, and biology of contrast agents, which is a concept that Girgis was discussing in the prior turn."
            }
        },
        {
            "speaker": "Girgis Obaid",
            "timestamp": "07:56-07:58",
            "transcript": "Yeah, that that's that pretty much.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:25",
            "end_time": "59:27",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "07:58-08:00",
            "transcript": "knowledge wrong?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:27",
            "end_time": "59:29",
            "annotations": {
                "ask clarifying question": "Maryellen is asking if she got the knowledge wrong, seeking confirmation or correction on her understanding of the previous discussion about model-driven AI and contrast agents."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:08-08:09",
            "transcript": "Okay, good.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:37",
            "end_time": "59:38",
            "annotations": {
                "express agreement": "Maryellen Giger is expressing agreement with a prior statement, likely in response to the ongoing discussion."
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:09-08:17",
            "transcript": "So I think we we all as a group um um maybe uh Paris.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:38",
            "end_time": "59:46",
            "annotations": {}
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:18-08:21",
            "transcript": "Yeah, I think",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:47",
            "end_time": "59:50",
            "annotations": {}
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "08:21-08:22",
            "transcript": "We got to bring this down to three bullets.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:50",
            "end_time": "59:51",
            "annotations": {}
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "08:22-09:11",
            "transcript": "Uh, sure, maybe one comment that just to follow up to what you what was just discussed, which may be interesting is I totally agree with you that, you know, kind of the future lies in this hybrid approach where statistical learning or purely data driven learning will be interfaced with model based uh principles and domain knowledge. Now the question is to get us there, obviously, you know, one cannot expect that we can just take an algorithm developed to classify dogs and cats and that will work. So and also we cannot expect that the computer scientist will learn chemistry and biology and will actually develop this specialized system.",
            "speaking_duration": 49,
            "nods_others": 0,
            "smile_self": 10.2,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:51",
            "end_time": "60:40",
            "annotations": {}
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:11-09:23",
            "transcript": "So the only question is who do we train and how do we train them to work in this interface and contribute the tools that we need in the future.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:40",
            "end_time": "60:52",
            "annotations": {
                "propose decision": {
                    "Explanation": "This utterance proposes a concrete choice for the group to consider: who should be trained and how to train them to work at the interface of data-driven and model-based approaches, which is a decision about future training strategies."
                }
            }
        },
        {
            "speaker": "Maryellen Giger",
            "timestamp": "09:23-09:26",
            "transcript": "So you're saying the tools, the AI tools are not good enough?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:52",
            "end_time": "60:55",
            "annotations": {
                "ask clarifying question": "Maryellen is asking Paris to confirm if he means that the current AI tools are inadequate, following his statement about the need for a hybrid approach and specialized systems."
            }
        },
        {
            "speaker": "Paris Perdikaris",
            "timestamp": "09:26-10:00",
            "transcript": "Well, I'm saying that that the way things have been working is we borrow a system that is successful in classifying dogs and cats and now we're trying to use it to segment cancer cells. And maybe that works to some extent, but if we want to sort of develop more specialized systems that bring in this domain knowledge and you know, um are tailored or more specialized to a given task, who is going to do this and who has the expertise to do this and how do we train people to actually have that expertise to to do that.",
            "speaking_duration": 34,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:55",
            "end_time": "61:29",
            "annotations": {}
        }
    ]
}