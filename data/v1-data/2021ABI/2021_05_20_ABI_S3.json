{
    "all_speakers": [
        "Kristen Macland",
        "Kristen Maitland",
        "Matt Lew",
        "Stefan Wilhelm",
        "Shiva Abbaszadeh",
        "Vivian Qian Lu",
        "Luke Mortensen",
        "Aseema Mohanty",
        "Sixian You",
        "Dylan Burnette",
        "Uzay Emir",
        "Silvia Ronco",
        "Andrew Feig",
        "Richard Weisman",
        "Unidentified speaker",
        "Joshua Brake",
        "Candace Fleischer",
        "bot1",
        "Kristen Marland"
    ],
    "total_speaking_length": 3649,
    "all_data": [
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:00-00:16",
            "transcript": "more discussion. I am sure that there are other topics of discussion that will come up that might fall off that list of key points. Um, maybe Richard who's on on in our room can um make a comment. Are we supposed to put those other ideas into the parking lot or just keep them ourselves or record them somewhere else?",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:00",
            "end_time": "00:16",
            "annotations": [
                {
                    "encourage particpatioin": "Kristen Maitland is encouraging Richard to contribute to the discussion by asking him to make a comment."
                },
                {
                    "ask clarifying question": "Kristen Maitland is asking a clarifying question about where to record ideas that fall outside the list of key points."
                }
            ]
        },
        {
            "speaker": "Richard Weisman",
            "timestamp": "00:17-00:36",
            "transcript": "And either of those things you can do. If you think they're really valuable to put in the parking lot, please do. You can keep them for yourselves. I suggest Josh take some notes on the side, which he can share with people, and then you at the very end of the meeting you added it into the key points uh for the discussion. And just have a lot of fun in the discussion.",
            "speaking_duration": 19,
            "nods_others": 1,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the logo of Research Corporation for Science Advancement. The logo is a blue figure eight with the text \"RESEARCH CORPORATION for SCIENCE ADVANCEMENT\" below it. The screen remains static throughout the segment.",
            "start_time": "00:17",
            "end_time": "00:36",
            "annotations": {
                "assign task": "Richard assigns Josh the task of taking notes and sharing them with the team.",
                "encourage particpatioin": "Richard encourages the team to add valuable ideas to the parking lot or keep them for themselves, promoting active participation in the discussion."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:36-00:43",
            "transcript": "Okay, sounds perfect. Okay, does anyone have any questions before we take our minute to think?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 29.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:36",
            "end_time": "00:43",
            "annotations": [
                {
                    "confirm decision": "Kristen agrees with Richard's suggestions on how to handle additional discussion topics, confirming the decision.",
                    "ask clarifying question": "Kristen asks if anyone has questions before they take a minute to think, seeking clarification."
                }
            ]
        },
        {
            "speaker": "Sixian You",
            "timestamp": "00:43-00:56",
            "transcript": "Uh, I have a quick logistic question. So the slide is uh is called Psi log ABI meeting slides. And then where are we supposed to put our names? Is it slide 16 session one?",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 23.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:43",
            "end_time": "00:56",
            "annotations": [
                {
                    "ask clarifying question": "The speaker is asking a question to clarify where to put their names on the slides, indicating a need for more information."
                }
            ]
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "00:57-01:00",
            "transcript": "I already copied and pasted all of our names in there, so we're good on names.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 33.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "00:57",
            "end_time": "01:00",
            "annotations": {
                "acknowledge contribution": "Josh's statement acknowledges that he has already taken care of adding the names to the slides, addressing Sixian's logistic question."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:00-01:02",
            "transcript": "Okay. It's slide 22.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:00",
            "end_time": "01:02",
            "annotations": {
                "explain or define term or concept": "Kristen is clarifying the location of the slide Sixian was asking about."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "01:03-01:06",
            "transcript": "Uh slide 22. Okay, perfect. Thank you.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:03",
            "end_time": "01:06",
            "annotations": [
                {
                    "confirm decision": "Sixian confirms the location of the slide number, which Kristen previously stated."
                },
                {
                    "express agreement": "Sixian expresses agreement with Kristen's statement about the slide number."
                },
                {
                    "acknowledge contribution": "Sixian acknowledges Kristen's contribution of providing the correct slide number and thanks her."
                }
            ]
        },
        {
            "speaker": "Richard Weisman",
            "timestamp": "01:06-01:13",
            "transcript": "And I'll be jumping in and out through through a few rooms. So if I leave, uh don't worry about it and I'll be quiet the rest of the way.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 14.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the logo of Research Corporation for Science Advancement. The logo is a blue figure eight with the text \"RESEARCH CORPORATION for SCIENCE ADVANCEMENT\" below it. The screen remains static throughout the segment.",
            "start_time": "01:06",
            "end_time": "01:13",
            "annotations": {
                "explain or define term or concept": "Richard is explaining his behavior of moving between different rooms during the meeting, clarifying that his absence shouldn't be a cause for concern.",
                "express enthusiasm": "Richard expresses enthusiasm by saying 'have a lot of fun in the discussion' in the previous turn, encouraging a positive and engaging atmosphere."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:13-01:15",
            "transcript": "Okay. Thank you.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 50.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:13",
            "end_time": "01:15",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges Richard's contribution after he explains his plan to jump in and out of the rooms."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:15-02:30",
            "transcript": "Okay, so I'm going to set a timer for one minute for you each to think about your topic related to uh super resolution methods. We were given two kind of prompt questions, but I think you have other ideas and other questions that you might want to ask. So I'll just we'll have one minute of silence for thinking.",
            "speaking_duration": 75,
            "nods_others": 0,
            "smile_self": 1.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "01:15",
            "end_time": "02:30",
            "annotations": {
                "assign task": "Kristen assigns the task of thinking about their topic related to super resolution methods to each participant.",
                "encourage particpatioin": "Kristen encourages participation by mentioning that participants might have other ideas and questions beyond the provided prompts.",
                "explain or define term or concept": "Kristen explains that the task is to think about topics related to super resolution methods, clarifying the focus of the activity."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "02:31-02:36",
            "transcript": "So both three, I don't I don't have you assigned. I need so I don't know how to put you in.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:31",
            "end_time": "02:36",
            "annotations": {
                "assign task": "The utterance is assigning a task to someone, as bot1 is stating they need to assign someone but doesn't know how."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "02:37-02:40",
            "transcript": "You don't have me, you don't see me in there in the room?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:37",
            "end_time": "02:40",
            "annotations": {
                "ask clarifying question": "The utterance is a question asking for confirmation about whether the speaker is visible in the room, seeking clarification on their presence."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "02:40-02:46",
            "transcript": "I don't see you as an assigned. I don't know why.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:40",
            "end_time": "02:46",
            "annotations": {
                "express frustration": "Bot1 expresses frustration because it cannot assign someone to a room, indicating a problem with the system."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:46-03:12",
            "transcript": "Okay. That is strange. Do you I mean, um so one thing I'll say is that I'll just ask if anyone would want like to start the conversation. Um I'm going to try and keep an eye out on if there is someone that is not contributing and I will call on you at a certain point just to make sure we hear from everyone. Um and I do ask that you be respectful of other people's time and so um if you do feel like you're contributing quite a bit, that's excellent, but maybe make sure that everyone has a chance to speak.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 15.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "02:46",
            "end_time": "03:12",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland asks if anyone would like to start the conversation, encouraging participation.",
                "assign task": "Kristen Maitland states she will keep an eye out for those not contributing and call on them, assigning herself the task of monitoring participation.",
                "express agreement": "Kristen Maitland expresses agreement with the idea that people should be respectful of others' time and ensure everyone has a chance to speak."
            }
        },
        {
            "speaker": "bot1",
            "timestamp": "03:12-03:17",
            "transcript": "Okay, so who would like to get started?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 40.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:12",
            "end_time": "03:17",
            "annotations": {
                "encourage particpatioin": "This utterance is directly inviting someone else to contribute to the discussion, as Kristen Maitland mentioned she would call on people to make sure everyone contributes."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "03:17-04:46",
            "transcript": "I can get started on one of the topics. Uh I really like the second question, how can we mitigate or utilize multiple scattering when we transition this technique to invivo applications? I think there are two ways to think about it. So if we are talking about like traditional super resolution techniques like in optics, uh multiple scattering is the enemy because they scramble your light. So the first way to think about it is how can we gate these multiple scattering? How can we reject them so that we can only get ballistic photons that carry the truly valuable information. And then so I guess one direction along this way is to think how can we more efficiently uh select these ballistic photons. And then a second direction, a second perspective on this is how do we use multiple scattering to get more information? Because these ballistic photons decay exponentially as you go deeper into the tissue. Uh so if we can use the but multiple scattering uh process looks random, but it's deterministic. So if we have physics model that can take advantage of this uh interference and use that to our advantage because with multiple scattering, you can actually get more angles, right? So with that you get more field of view, you get more uh uh resolution. So uh I I think that part is pretty interesting.",
            "speaking_duration": 89,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "03:17",
            "end_time": "04:46",
            "annotations": [
                {
                    "present new idea": "Sixian introduces the idea of mitigating or utilizing multiple scattering when transitioning super-resolution techniques to in-vivo applications, which is a novel concept in the context of the discussion."
                },
                {
                    "expand on existing idea": "Sixian expands on the question of mitigating or utilizing multiple scattering by suggesting two ways to think about it: gating multiple scattering to get ballistic photons and using multiple scattering to get more information."
                },
                {
                    "explain or define term or concept": "Sixian explains that in traditional super-resolution techniques in optics, multiple scattering is the enemy because it scrambles light, clarifying the role of multiple scattering in this context."
                },
                {
                    "express enthusiasm": "Sixian expresses enthusiasm by stating that the idea of using multiple scattering to get more information is 'pretty interesting'."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "04:47-05:07",
            "transcript": "That's great and thank you. And I just realized that we did not introduce ourselves first. So uh Sishan, why why don't you start and introduce yourself? We'll go around, make sure we just it'll be a very brief so your name and institution which we can see, but um a brief uh introduction of your background and what perspective you have on this topic in particular.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 15.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "04:47",
            "end_time": "05:07",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "Kristen acknowledges Sixian's contribution after Sixian shared his ideas on mitigating multiple scattering in super-resolution techniques."
                },
                "assign task": {
                    "Explanation": "Kristen assigns Sixian the task of introducing himself and his background related to the topic, initiating introductions among the participants."
                },
                "encourage particpatioin": {
                    "Explanation": "Kristen encourages Sixian to start the introductions and invites others to follow, ensuring everyone gets a chance to share their background and perspective."
                }
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "05:08-05:26",
            "transcript": "Uh my name is Sishan Yo. I just started at MIT uh three months ago, two months ago. Uh my lab develops optical imaging technologies, especially for microscopy applications. We are interested in using optics and algorithms to solve real world biomedical problems.",
            "speaking_duration": 18,
            "nods_others": 0,
            "smile_self": 11.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:08",
            "end_time": "05:26",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is introducing themself and their lab's focus, which explains their background and perspective on the topic of optical imaging technologies."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:26-05:28",
            "transcript": "Thank you. Uh Dylan.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:26",
            "end_time": "05:28",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges Sishan's contribution after they shared their perspective on super-resolution methods.",
                "encourage particpatioin": "Kristen Maitland is encouraging Dylan to participate in the discussion by calling on them after Sishan introduced themself."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "05:29-06:12",
            "transcript": "I am uh Dylan Burnette. I'm a an associate professor at Vanderbilt University. I just got tenure, so I'm technically now not uh new, although I feel new still. I have new people problems. Um I am a cell biologist by training and I've been using light microscopy for about 20 years now to study everything from neurons to cancer and now I work on heart. So I'm very interested in how the heart grows on a single cell level.",
            "speaking_duration": 43,
            "nods_others": 0,
            "smile_self": 2.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "05:29",
            "end_time": "06:12",
            "annotations": [
                {
                    "explain or define term or concept": "Dylan introduces himself and provides background information about his role, institution, and research interests, which helps the group understand his perspective on the topic."
                }
            ]
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:12-06:12",
            "transcript": "Great.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:12",
            "end_time": "06:12",
            "annotations": {
                "express agreement": "Dylan expresses agreement with the previous turn, which was Kristen saying 'Thank you'."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "06:13-06:13",
            "transcript": "Aseema?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:13",
            "end_time": "06:13",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is inviting Aseema to introduce herself and contribute to the discussion, following the introductions of Sixian and Dylan."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "06:15-06:56",
            "transcript": "Hi, I'm Aseema Mohanty. Um, I recently started as a faculty at Tuffs University in Boston. Um, and I work on uh nanophotonics. Um, so that's like chip scale optics and so um uh we've been kind of working on um optical phase arrays and creating 3D structured light from a chip. Um, and so my kind of perspective on super resolution is is there anything that we can do to kind of, you know, handle some of the limitations of bulk um optics or high NA objectives and miniaturize that to make it kind of feasible for um more portable applications.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 41.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:15",
            "end_time": "06:56",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker explains their field of work as nanophotonics and chip scale optics, providing context for their background."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "06:56-06:57",
            "transcript": "Okay. Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:56",
            "end_time": "06:57",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland acknowledges the previous speaker's contribution, Sishan You, after they introduced themselves and their background."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "06:57-06:57",
            "transcript": "Josh?",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "06:57",
            "end_time": "06:57",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is inviting Josh to introduce himself and share his background and perspective on the topic, as she has done with others."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "07:00-07:54",
            "transcript": "Everybody, my name is Josh Brake. I am an assistant professor in the engineering department at Harvey Mudd College. My training is in engineering and specifically in electrical engineering. I did my PhD work in um biomedical optics, specifically looking at how to use optical wavefront shaping to peer deeper into tissue. And so I really resonated with what we were just talking about about the second option, which I think is the much better one, maybe unbiased, but uh to try to harness the multiply scattered photons and in some sense redeem those to make them make them useful for our for our optical imaging techniques. Uh the last thing I'll say is just that as an engineer, I'm a tool builder by nature and so I'm really looking forward to meeting all of you and hearing about Kristen what you said in the main session really resonated with me too. How can I bring engineering skills to bear to solve solve problems? So thanks.",
            "speaking_duration": 54,
            "nods_others": 0,
            "smile_self": 11.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:00",
            "end_time": "07:54",
            "annotations": [
                {
                    "explain or define term or concept": "Josh introduces himself and his background, explaining his training and research area for the benefit of the group."
                },
                {
                    "express agreement": "Josh expresses agreement with the second option discussed by Sixian, indicating that he resonates with the idea of harnessing multiply scattered photons."
                },
                {
                    "express enthusiasm": "Josh expresses enthusiasm about meeting everyone and contributing his engineering skills to solve problems, showing his excitement for the collaboration."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:54-07:55",
            "transcript": "Great, thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:54",
            "end_time": "07:55",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges the previous speaker's contribution, but does not agree or expand on it."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:55-07:56",
            "transcript": "Uh Luke?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:55",
            "end_time": "07:56",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is inviting Luke to introduce himself and contribute to the discussion, continuing the round-robin introductions."
            }
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "07:57-08:55",
            "transcript": "Um, hi, I'm Luke Mortenson. I'm assistant professor at the University of Georgia. Um, although I will be associate as of July 1st, so I'm kind of in the intermediate space of still feeling new. Um, but um, uh uh my lab is primarily focused on uh multiphoton imaging. Um, so we do um like two photon, we're moving towards like second harmonic, third harmonic generation type stuff. Um, and we're looking at moving to kind of like near IR wavelengths to get um, I guess with 1300, 1700 to kind of like peer deeper into tissue and also some scattering correction approaches um to look at um as how much we can get in there and try to get rid of things that are causing negative interference, etc. And um um I guess our application is looking at bone and muscle regeneration primarily.",
            "speaking_duration": 58,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "07:57",
            "end_time": "08:55",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker explains that their lab is focused on multiphoton imaging, including two-photon, second harmonic, and third harmonic generation, which clarifies the specific techniques they use."
                },
                {
                    "expand on existing idea": "The speaker builds on the topic of super-resolution methods by mentioning their lab's focus on multiphoton imaging and their work with near-IR wavelengths and scattering correction approaches to peer deeper into tissue, adding details about their specific techniques and applications."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:55-08:56",
            "transcript": "Thank you. Matt.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "08:55",
            "end_time": "08:56",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges Luke's introduction before moving on to the next person, Matt."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "09:06-09:54",
            "transcript": "Hi. Uh I'm Matt Lou. Um I'm an assistant professor in electrical and systems engineering at Washu. Uh my group works on um building single molecule imaging techniques for just understanding um chemical and biochemical dynamics in at the nano scale. Uh one of the things that that we really pushed recently is basically leveraging uh signals that are other than just brightness to to understand what's happening at the nano scale. So for us, uh a lot of it is uh fluorescence polarization.",
            "speaking_duration": 48,
            "nods_others": 0,
            "smile_self": 10.0,
            "smile_other": 0.0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "09:06",
            "end_time": "09:54",
            "annotations": [
                {
                    "explain or define term or concept": "Matt Lew is explaining his group's work on single molecule imaging techniques and leveraging signals other than brightness, such as fluorescence polarization, to understand nanoscale chemical and biochemical dynamics."
                }
            ]
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "00:00-00:47",
            "transcript": "I'm Stefan, I'm from the University of Oklahoma. I'm in biomedical engineering. Um, I'm trained as a chemist. Uh, now I'm in my fourth year as a system professor and my research group focuses on nanomedicine, so applying nanotechnology for treatment and diagnosis of cancer specifically and we are interested in understanding um the transport of drug carriers and small molecule drugs through the body and how those drug carriers interact with cell surface. So for us super resolution information is is really the key to understand those transport pathways. Um, and my lab is applying techniques such as expansion microscopy to get a better understanding of those intracellular transport pathways.",
            "speaking_duration": 47,
            "nods_others": 10,
            "smile_self": 10,
            "smile_other": 20,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:00",
            "end_time": "10:47",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker is introducing their background and research interests, which involves defining their area of expertise and the techniques they use, such as expansion microscopy, to understand intracellular transport pathways."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:47-00:52",
            "transcript": "Great, thank you. Um, Uzay, can you tell me how to pronounce your name correctly, please?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:47",
            "end_time": "10:52",
            "annotations": [
                {
                    "acknowledge contribution": "Kristen acknowledges the previous speakers' introductions.",
                    "explaination": "Kristen is acknowledging the previous speakers' introductions."
                },
                {
                    "ask clarifying question": "Kristen asks Uzay how to pronounce their name correctly.",
                    "explaination": "Kristen is asking Uzay how to pronounce their name correctly."
                }
            ]
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:52-00:53",
            "transcript": "Uzay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:52",
            "end_time": "10:53",
            "annotations": {
                "explain or define term or concept": "Uzay is clarifying the pronunciation of his name."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:53-00:54",
            "transcript": "Uzay, thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:53",
            "end_time": "10:54",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges Uzay's participation after he clarified the pronunciation of his name."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:54-02:12",
            "transcript": "Thank you so much. So, um, I'm Uzay and I'm from Purdue University and I'm at the School of Health Sciences as a biomedical engineering. I'm electrical engineer in principle, but I have been doing biomedical stuff since I graduated and that includes all developing new techniques for diagnostic purpose of MRI and the reason I'm interested in super resolution is always try to find the link between the lab resolution to to in vivo or contact animal resolution so microscopic scale. So I always keep an eye on what's happening in the smaller scale higher super resolution and to see what can be translatable to animal. So my research is ranging from cancer to neurological imaging and lipidomics to metabolomics and also cancer and also includes physiological intervention and also bone sodium content and X nuclei and phosphorus all types of imaging but I really like to make the link between the lab to do from bench to bedside actually.",
            "speaking_duration": 78,
            "nods_others": 1,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "10:54",
            "end_time": "12:12",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker explains his interest in super resolution by linking it to translating lab resolution to in vivo animal resolution, connecting microscopic scales to animal studies."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:12-02:13",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "12:12",
            "end_time": "12:13",
            "annotations": {
                "acknowledge contribution": "Kristen Maitland acknowledges the previous speaker's contribution after they finished introducing themselves."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "02:13-02:23",
            "transcript": "Vivian?",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "12:13",
            "end_time": "12:23",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is inviting Vivian to introduce herself and contribute to the discussion, as she has done with others in the group."
            }
        },
        {
            "speaker": "Vivian Qian Lu",
            "timestamp": "02:23-03:11",
            "transcript": "Hello, uh, I'm Vivian Lou. I'm from McGill University. Uh, I'm at the the Institute of parasitology and also McGill Center for viral diseases. I'm trained as a molecular virologist and molecular cell biologist as a PhD student and then in my postdoc, I uh, I joined a biophysical lab where I learned how to do uh single molecule localization microscopy and I study uh virus life cycle using uh super resolution microscope. So I looked at how the virus are entered uh replicated and egress from their host cell.",
            "speaking_duration": 48,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "12:23",
            "end_time": "13:11",
            "annotations": [
                {
                    "explain or define term or concept": "The speaker explains their background and training, including their experience with single molecule localization microscopy and studying virus life cycles using super-resolution microscopy, which provides context for their perspective on the topic."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:11-03:19",
            "transcript": "Great, thank you. And Candace is in our room but she um is on another zoom, so when she gets back in we can um have her introduce herself. So thank you for that um kind of brief introduction that really helps put things in context for us.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "13:11",
            "end_time": "13:19",
            "annotations": {
                "acknowledge contribution": "Kristen acknowledges the introductions made by the participants, showing appreciation for their input.",
                "encourage particpatioin": "Kristen mentions Candace and says they will have her introduce herself when she returns, inviting her to participate."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:19-03:33",
            "transcript": "And maybe if we could just pick up where we left off with the discussion. Josh, did you want to build off of um what you were saying in about using away from uh go ahead.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "13:19",
            "end_time": "13:33",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is explicitly inviting Josh to speak and contribute to the discussion, building off of what he was saying previously."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "03:39-05:00",
            "transcript": "Sure, sure. So I think that um I just see a a game of diminishing returns if we're just trying to get better at gating things out. Um, and so especially now we push to multiphoton two, three, I don't know, can we do four or five? Like at what level does that get so complicated and so expensive that it's not really it's not really useful. And so I I would really like to I think my background is is in more of the second thinking more about the second part of this question, but I think what intrigues me about this room is thinking about the two of these together, especially because super resolution microscopy I think is often speaking as somebody who's not well trained in that area, but seems to me to be very photon start in general. Like you need a lot of light.",
            "speaking_duration": 81,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "13:39",
            "end_time": "15:00",
            "annotations": [
                {
                    "reject idea": "Josh expresses a concern about the approach of 'gating things out' by stating that he sees 'a game of diminishing returns' with this approach, thus rejecting the idea.",
                    "expand on existing idea": "Josh builds on Sixian's initial question about mitigating multiple scattering by discussing the limitations of gating techniques and suggesting an alternative approach of harnessing multiply scattered photons.",
                    "provide supporting evidence": "Josh supports his argument against gating by mentioning the increasing complexity and cost associated with pushing to higher-order multiphoton microscopy, implying it may not be a practical solution."
                }
            ]
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "05:00-05:57",
            "transcript": "Um, and so if you're saying, okay, well, I'm going to throw out all the scattered photons, you're walking a you know, that line is going to get hard to walk pretty quickly. So I I think that I really like the thinking about how how can we maybe take these two together and I'm not I haven't seen too much looking at super resolution combined with thinking deeper into tissue and how to think about scattering. And the last thing I'll say just to uh is I also wonder what the room is for conversations in between let's say minimally invasive types of technology as a stepping stone to getting to the ultimate goal where we just shine some light outside the body and then capture everything outside the body non invasively, but maybe minimally invasive with um, you know, fibers, fiber bundles, uh, these kind of things can be a a nice stepping stone to push things into the into practice because I think with biomedical imaging outside of the like really big success of OCT, there's not so many optical like biomedical optical techniques that have really made a significant um, you know, push into the clinic.",
            "speaking_duration": 57,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "15:00",
            "end_time": "15:57",
            "annotations": [
                {
                    "expand on existing idea": "Josh is building on the previous discussion about mitigating or utilizing multiple scattering, elaborating on the challenges of discarding scattered photons in super-resolution microscopy."
                },
                {
                    "present new idea": "Josh introduces the idea of exploring minimally invasive technologies as a stepping stone to non-invasive imaging, suggesting a practical approach to bridge the gap between current techniques and the ultimate goal of non-invasive imaging."
                }
            ]
        },
        {
            "speaker": "Vivian Qian Lu",
            "timestamp": "05:57-09:17",
            "transcript": "Uh, I I want to add something uh to to uh idea. So she was mentioned about using uh how to uh how to manipulate the scattering interference. So there is something um I was thinking about. Uh, I was doing uh uh super resolution when I was doing super resolution microscope, I always wanted to stabilize the sample so that with a with a long uh long-term imaging for example like 30 minutes, I don't get a great uh sample drift. So one way I was thinking while I was a postdoc is to use the scattering light from the cell. So we take uh we take the scattering light the image using scattering light of the cell at at the beginning of the imaging and after a few minutes we take another one. So by the end like by the end of the imaging we could use those image to align um kind of put to the kind of uh correct the drift. So that's one thing I was thinking about. Uh, but I haven't tapped it. I'm not sure how precisely I can do as my uh uh I claim a 10 nanometer uh uh uh precision. So I'm trying to make sure how I can how precisely I can do that. And uh some thoughts for the first uh question like how can super resolution uh methods can be translated to uh uh organismal applications. Um, I have been thinking about that for the past few years. Um, one thing I found uh uh that could be helpful is maybe lizing the floor for chemistry because right now uh I spend a lot of time on doing uh imaging analysis uh like look at all the localization and how to cluster them and how to figure out the organization of the proteins. But uh at the end of the day I thought if we could use different floor for to map these what I mean is if I put it in a example, see if we have a DNA molecule, they can uh kind of fold into different structure. Like if we wanted to figure out the structure, let's see uh we can use uh maybe the barcoding system like we can since we know the sequence we probably can uh use the barcoding to map the entire sequence, then then we label that the molecule uh ourselves, then we can image that maybe we know we would figure out like uh how they position the spatial. So that's So I think um maybe uh aside from the imaging processing just using AI or deep learning to look at the cluster or organization, maybe uh uh floor for can might be helpful. That was my thought.",
            "speaking_duration": 204,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "15:57",
            "end_time": "19:17",
            "annotations": [
                {
                    "expand on existing idea": "Vivian builds on the idea of manipulating scattering interference, mentioned earlier by Josh, by suggesting using scattering light to stabilize samples during long-term super-resolution imaging to correct for sample drift."
                },
                {
                    "present new idea": "Vivian presents a new idea of using different fluorophores to map molecules and their spatial organization, drawing an analogy to DNA barcoding, to improve super-resolution imaging analysis."
                }
            ]
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "09:18-09:57",
            "transcript": "So I would say that this this this question is well beyond what I think about normally. Um, because we're trying to get to structural resolution and if you do that in an animal, it would be too much data. We don't have big enough computers for that. And so this is a very interesting, you know, concept because when we want to look at an animal, we just cut off a piece of our zebra fish and take that tissue and we call that an animal or an organism.",
            "speaking_duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a presentation slide with the title \"WILHELM LAB Biomedical Nano-Engineering Lab\" and the website URL. The slide also displays the logo of the GALLOGLY COLLEGE OF ENGINEERING STEPHENSON SCHOOL OF BIOMEDICAL ENGINEERING THE UNIVERSITY OF OKLAHOMA.",
            "start_time": "19:18",
            "end_time": "19:57",
            "annotations": [
                {
                    "reject idea": "Dylan expresses that achieving structural resolution in an animal is beyond his normal scope of thinking, implying a rejection of the feasibility of the initial question due to data and computational limitations."
                }
            ]
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "00:00-00:32",
            "transcript": "illumination or single molecule imaging on top of that. And I'm calculating resolution and it's scaring me already and it's a single cell. So do we have any idea what we do with that kind of data if we have super res and like I'm I'm I'm just it's exciting but also scary at the same time.",
            "speaking_duration": 32,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:00",
            "end_time": "20:32",
            "annotations": [
                {
                    "express frustration": "Dylan expresses being scared by the amount of data they would have if they had super resolution, indicating frustration with the potential data overload."
                },
                {
                    "express enthusiasm": "Dylan expresses excitement about the possibilities of super resolution, showing enthusiasm for the potential advancements."
                }
            ]
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:32-01:25",
            "transcript": "Can I uh so similar to your question actually your question is originating from a problem actually going back to whole animal or big organism will be ring a lot of data. Now the question is how from my point of view I'm a microscopic person and even our data is big but uh it's not as complicated as yours uh but it has its own difficulties. How you are seeing all you guys are optical imaging and super resolution compared to myself to make it really translatable to real life or big animal or live animal uh thing. So what is your pathway to bring those techniques to this and considering your concern about the size of the data.",
            "speaking_duration": 53,
            "nods_others": 1,
            "smile_self": 30,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "20:32",
            "end_time": "21:25",
            "annotations": [
                {
                    "ask clarifying question": "The speaker is asking how optical imaging and super-resolution techniques can be translated to real-life or big animal applications, considering the data size concerns raised by Dylan."
                }
            ]
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "01:26-02:35",
            "transcript": "So is it possible to to combine structured light and of scattering at the same time? Is that too complicated? Sorry, I'm not I'm not a physicist, but we are using structured light uh through the line of slide sheet and and and it's the same, you know, basic run of the mill technologies. Um but can you collect scattered light from that sort of information? Because that's already up and running of in many, many labs around the country and world right now. Uh would be able to combine something like the lighter slide sheet which penetrates into tissues pretty decently, let's not say great, but decently. But now it's good as four photo time would. But um um but we uh but that also has already structured information with it. Does that complicate getting scattered light or not? Because that's kind of a fascinating idea uh that I hadn't really thought too much about. And at least three of you had thought a lot about it. So that's pretty cool.",
            "speaking_duration": 69,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "21:26",
            "end_time": "22:35",
            "annotations": {
                "ask clarifying question": "Dylan asks if it's possible to combine structured light and scattering at the same time, seeking clarification on the complexity of this combination.",
                "expand on existing idea": "Dylan builds on the previous discussion about scattering and super-resolution by asking about combining structured light with scattering, referencing their current use of structured light in slide sheet microscopy.",
                "acknowledge contribution": "Dylan acknowledges that at least three other people have thought about the idea of combining structured light and scattering, recognizing their prior input on the topic.",
                "express enthusiasm": "Dylan expresses excitement about the idea of combining structured light and scattering, indicating a positive reaction to the concept."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "02:36-03:03",
            "transcript": "I guess my two cents on this is by de facto as optical engineers, we try to throw out the scattered light. That's the conventional wisdom. We always have done that. And so every optical system you pick up whether it's your iPhone or a microscope is designed to throw that information out. And that's the that I think is the kernel of the revolutionary idea here is like let's remove that constraint and go back to the drawing board and think differently.",
            "speaking_duration": 27,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "22:36",
            "end_time": "23:03",
            "annotations": {
                "explain or define term or concept": "Josh explains that optical engineers conventionally try to eliminate scattered light in optical systems, which is the current standard practice.",
                "present new idea": "Josh introduces the idea of challenging the conventional approach of discarding scattered light and suggests rethinking the design of optical systems to utilize this information instead."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "03:03-04:24",
            "transcript": "Yeah, Josh, I I'd like to to build off of that. So I think you did made a great point about the uh the the sort of the paradigm of of at least microscopy uh and ballistic imaging that we throw away all the scattered light. Then we're kind of forgetting our friends in the diffuse optics regime. So let's think of DOT diffuse optical tomography and people sort of um uh there's there's actually a colleague here at Washu who builds the whole brain uh uh imaging uh device, right? And and looks at uh sort of function uh um by collecting diffuse light off of there. So maybe um maybe a a regime of pushing the resolution there might be helpful. Uh right now it's sort of spatially resolved based upon the average number of scattering events that takes light longer to travel further or or uh uh and and you can sort of resolve some things in depth that way. So maybe that's one way we can think about it. I think maybe another question is um like if we take our existing technologies that can penetrate deep but somehow are deficient in some other axis. So let's just say pet for example, right? The gold standard in in specifically detecting something uh uh within within the body and an organism. Uh is there something that optical imaging if engineered the right way, maybe with the the fancy uh fluorescent based reporters that we saw uh earlier in the keynote. Um maybe there's something that we can do to to to solve a more targeted problem as a as a as a prototype for for for uh for solving the the bigger question that that was posed. Um just a couple ideas there.",
            "speaking_duration": 81,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "23:03",
            "end_time": "24:24",
            "annotations": [
                {
                    "expand on existing idea": "Matt builds on Josh's point about throwing away scattered light by mentioning diffuse optics and diffuse optical tomography (DOT) as a contrasting approach."
                },
                {
                    "present new idea": "Matt introduces the idea of pushing the resolution in the diffuse optics regime and suggests leveraging existing technologies like PET in conjunction with optical imaging to solve targeted problems."
                }
            ]
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "04:24-04:45",
            "transcript": "I'd like to I'd like to kind of jump on that as well. Um I I feel like one thing that I I and this might just be my inexperience with the super resolution field, but like um one thing we don't really talk about much is what and and similar to what Matt was talking about is um what could we kind of learn from, you know, we're kind of used to a a certain type of imaging with an objective with a very high NA, you know, lens and and I feel like that's kind of a bulk of the problem.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 80,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:24",
            "end_time": "24:45",
            "annotations": {
                "expand on existing idea": "Aseema builds on Matt Lew's idea about leveraging insights from other imaging techniques, suggesting that the field should consider what can be learned from different imaging approaches beyond high NA lenses, which she feels is a core issue.",
                "acknowledge contribution": "Aseema acknowledges Matt's contribution by explicitly stating that her point is similar to what Matt was talking about."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "04:45-04:45",
            "transcript": "Yeah.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:45",
            "end_time": "24:45",
            "annotations": {
                "express agreement": "Dylan agrees with a previous statement, indicated by the use of \"Yeah.\""
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "04:45-04:45",
            "transcript": "Yeah, okay.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:45",
            "end_time": "24:45",
            "annotations": {
                "express agreement": "Aseema agrees with Dylan's previous statement, indicated by \"Yeah, okay.\""
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "04:45-06:03",
            "transcript": "So I would say that from because I'm the I'm I'm the uh I'm the holer here not the forger. I don't uh I don't uh I I developed one technique and no one ever used it. So it was called bomb because back in the day anything with single molecules had to have a acronym. Uh and I learned through that that I should not develop techniques. I should just take other people's and Um but I'll say as a as a user and we're pretty advanced users uh that we are pretty much addicted to the high NA lens because it's what's available. It's what's commercially available, it's what we can order. We're not going to build our own lenses. And that is why we use them. There's no one has come up with a better way that I can purchase to do this and it's very limiting because the high NA is usually uh uh for the most of our of our work for super res which is single molecule or structured light. Um and I generally put those in just two categories. I know that some of you are have four categories of super res. Um but when you think about it from that way, it's very limiting as far as Z depth, so how far you can go, so your axial dimension that you can penetrate your sample is limited.",
            "speaking_duration": 78,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "24:45",
            "end_time": "26:03",
            "annotations": [
                {
                    "express humor": "Dylan makes a self-deprecating joke about developing a technique that no one used, adding humor to the conversation."
                },
                {
                    "expand on existing idea": "Dylan expands on Aseema's point about the limitations of high NA lenses, explaining that they are used because they are commercially available and easy to obtain, but they limit Z depth."
                }
            ]
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "06:03-06:03",
            "transcript": "Right.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "26:03",
            "annotations": {
                "express agreement": "Aseema is agreeing with Dylan's previous statement about the limitations of high NA lenses, indicating alignment on the issue."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:03-06:03",
            "transcript": "Yeah.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "26:03",
            "annotations": {
                "express agreement": "Dylan agrees with Aseema's point about the limitations of high NA lenses in super-resolution microscopy, building on the discussion about challenges in penetrating deeper into tissues."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "06:03-06:03",
            "transcript": "So it's.",
            "speaking_duration": 0,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "26:03",
            "annotations": {
                "None": "This utterance is incomplete and does not express a complete thought or idea, so no code applies."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "06:03-07:33",
            "transcript": "I mean, yeah, no, I'm I'm I'm just I'm coming from a different kind of world of of, you know, you know, we everything we do is like little chips and so that you could do like fine resolution here and fine resolution here, you know, what are kind of the limitations um from people who are actually using super resolution um with those objective lenses that that you guys use. Um in terms of I guess field of view and like the amount of power that you need to be able to illuminate an entire section.",
            "speaking_duration": 90,
            "nods_others": 0,
            "smile_self": 70,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "26:03",
            "end_time": "27:33",
            "annotations": {
                "ask clarifying question": "Aseema is asking about the limitations of using objective lenses in super-resolution microscopy, specifically regarding field of view and power requirements, to understand the challenges faced by users of super resolution."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "00:00-00:14",
            "transcript": "you know, light coming out here and creating patterns and but we don't have the I mean, it's it's crazy for me to think about being able to combine that with a microscope, but you know, I think there must be ways.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 86,
            "smile_other": 14,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:00",
            "end_time": "30:14",
            "annotations": {
                "express enthusiasm": "Aseema expresses enthusiasm about the potential of combining their chip-based optics with microscopy, suggesting a belief that there are possible solutions despite the current challenges."
            }
        },
        {
            "speaker": "Andrew Feig",
            "timestamp": "00:15-00:18",
            "transcript": "Dylan, your task is to have the right quarter cell at the right time.",
            "speaking_duration": 3,
            "nods_others": 1,
            "smile_self": 0,
            "smile_other": 33,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:15",
            "end_time": "30:18",
            "annotations": {
                "assign task": "Andrew assigns Dylan the task of having the right quarter cell at the right time, which is a specific responsibility given to Dylan."
            }
        },
        {
            "speaker": "Andrew Feig",
            "timestamp": "00:18-00:20",
            "transcript": "to capture what it is you want to see.",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:18",
            "end_time": "30:20",
            "annotations": {
                "assign task": "This utterance assigns the task of capturing what one wants to see to Dylan, building on the previous statement."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "00:21-00:49",
            "transcript": "Yes, and and and and and and and now with expansion microscopy we were having to do uh what we now refer to as structured illumination as low back imaging. Um, and we had to we do that live, fix that cell and then expand it, find the cell again and then image what is getting down to, you know, we're estimating five to 10 nanometer resolution lateral. So we're really good, but this is all people give me. I I I I I'm I'm I'm I'm I'm wanting for the uh next thing. So that's I I I I think I'm here because I am the user of the next thing, not the inventor of the next thing. So I'm getting excited but I'm also kind of confused at the same time.",
            "speaking_duration": 28,
            "nods_others": 1,
            "smile_self": 50,
            "smile_other": 21,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "30:21",
            "end_time": "30:49",
            "annotations": [
                {
                    "expand on existing idea": "Dylan is building on the previous discussion about super-resolution techniques and their limitations, adding his experience with expansion microscopy and structured illumination."
                },
                {
                    "express frustration": "Dylan expresses frustration with the current limitations of available techniques, stating that he is \"wanting for the next thing\"."
                },
                {
                    "express enthusiasm": "Dylan expresses excitement about the potential of new techniques, stating that he is \"getting excited\"."
                }
            ]
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:01-01:04",
            "transcript": "Yeah, I guess one of the fundamental limitations, at least with fluorescence.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:01",
            "end_time": "31:04",
            "annotations": {
                "present new idea": "Matt is introducing a new idea about the fundamental limitations with fluorescence, which has not been discussed before in this specific context."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:08-01:09",
            "transcript": "just a standard dipole radiation pattern.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:08",
            "end_time": "31:09",
            "annotations": {
                "explain or define term or concept": "Matt Lew is explaining the concept of a standard dipole radiation pattern, which is relevant to the discussion of fluorescence microscopy and its limitations."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:10-01:24",
            "transcript": "So what that will mean is that then the light just goes everywhere. I mean, of course it's zero along the dipole axis, but that's a sine squared kind of fall off. So what that means is you just need a huge collection angle to efficiently collect if you want to do single molecule at least.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:10",
            "end_time": "31:24",
            "annotations": {
                "explain or define term or concept": "Matt Lew is explaining the implications of a standard dipole radiation pattern in fluorescence microscopy, specifically how light is emitted in all directions except along the dipole axis, necessitating a large collection angle for efficient single-molecule imaging, building on the discussion about limitations in fluorescence microscopy."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:24-01:28",
            "transcript": "Uh, because you're just not going to get enough photons to even detect the thing uh without it.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 25,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:24",
            "end_time": "31:28",
            "annotations": {
                "provide supporting evidence": "Matt Lew is providing supporting evidence for the need of a huge collection angle to efficiently collect light, stating that without it, there won't be enough photons to detect the molecule."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:29-01:34",
            "transcript": "Um, in terms of decoupling excitation and emission, there's a lot of interesting light sheet stuff.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:29",
            "end_time": "31:34",
            "annotations": {
                "expand on existing idea": "Matt Lew is building on the previous discussion about limitations in fluorescence microscopy and suggesting light sheet microscopy as a potential solution for decoupling excitation and emission."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:34-01:41",
            "transcript": "It turns out that that's now a mechanical engineering problem because you if you want high NA and two high NA objectives next to each other, it's it's impossible.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:34",
            "end_time": "31:41",
            "annotations": {
                "expand on existing idea": "Matt Lew is building on the previous discussion about the limitations of high NA lenses in super-resolution microscopy, specifically mentioning that achieving high NA with two objectives is a mechanical engineering challenge."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:41-01:50",
            "transcript": "So, um, one of the most cool things that's coming out of uh Calico labs, which is an independent sort of foundation funded thing is is Andrew York's work on remote focusing.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:41",
            "end_time": "31:50",
            "annotations": {
                "present new idea": "Matt Lew introduces Andrew York's work on remote focusing, which hasn't been mentioned before in the conversation."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "01:51-02:13",
            "transcript": "And uh basically doing some interesting optical tricks to get a light sheet scanning in there along with high NA detection and that I think is probably where the sort of classic uh uh innovation like frontier is right now in terms of high resolution and organism and fast. Like that um I've been impressed by that recently.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 14,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "31:51",
            "end_time": "32:13",
            "annotations": {
                "expand on existing idea": "Matt Lew is building on the previous discussion about the limitations of high NA lenses and the need for new approaches by mentioning Andrew York's work on remote focusing as a potential solution.",
                "express enthusiasm": "Matt Lew expresses enthusiasm for Andrew York's work, indicating excitement about its potential for high-resolution, organismal, and fast imaging."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "02:15-02:47",
            "transcript": "Is is there tolerance in the community um for having something that let's say you have a objective lens and then you have something next to it, but it's very tiny, let's say it's, you know, 50 microns thin.",
            "speaking_duration": 32,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:15",
            "end_time": "32:47",
            "annotations": {
                "ask clarifying question": "Aseema is asking a question to understand the community's acceptance of a specific setup involving an objective lens and a small adjacent component, seeking to clarify the feasibility and acceptance of such a design."
            }
        },
        {
            "speaker": "Aseema Mohanty",
            "timestamp": "02:47-02:51",
            "transcript": "Is there tolerance in the community for having something that's some semi, you know, invasive to be able to kind of get some of these light sheet techniques um more portable or, you know, useful for an organism.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:47",
            "end_time": "32:51",
            "annotations": {
                "present new idea": "Aseema is introducing the idea of a semi-invasive approach to make light sheet techniques more portable and useful for organismal studies, which hasn't been explicitly discussed before.",
                "ask clarifying question": "Aseema is asking whether the community would accept a semi-invasive approach to improve light sheet techniques, seeking to understand the community's tolerance for such methods."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "02:52-03:05",
            "transcript": "Yeah, I mean, I think so. Um the at least, you know, if you think about like the head mounted microscopes and things, like building a cranial window in and then having some small thing next next to that's not a big deal.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "32:52",
            "end_time": "33:05",
            "annotations": {
                "express agreement": "Matt Lew agrees with Aseema Mohanty's question about the tolerance in the community for having something that's semi-invasive to get some of these light sheet techniques more portable or useful for an organism, indicating that building a cranial window and having something small next to it is not a big deal."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "03:05-03:16",
            "transcript": "And then a lot of the sort of super stuff right now is still cover slip based, you know, epi fluorescence so you can easily put stuff down at least on on on that epi side.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:05",
            "end_time": "33:16",
            "annotations": {
                "expand on existing idea": "Matt Lew is expanding on the discussion about super-resolution microscopy techniques, specifically mentioning that many current super-resolution methods are cover slip based, which relates to the previous discussion about limitations and potential innovations in the field."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:26-03:33",
            "transcript": "Okay, um, I have lots of ideas on things to talk about, but um, Stefan, how about you? What are what do you have to bring up?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 57,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "33:26",
            "end_time": "33:33",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is explicitly asking Stefan to contribute to the discussion, encouraging his participation."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "03:33-04:14",
            "transcript": "Yeah, so this is an interesting discussion and uh basically I have similar concerns that Dylan mentioned earlier. Uh like with all uh the huge amount of data that you collect, but then actually how would we do this? How do we how will we get a super resolution image of entire mouse, for example, uh uh while the mouse is still alive. So, um this is a really important question and um my group and I we have thought a lot about this and how can we overcome this and how can we find a method that would allow us to to give us something reasonable and the best we came up with is, well, we probably cannot do live imaging.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "33:33",
            "end_time": "34:14",
            "annotations": [
                {
                    "acknowledge contribution": "Stefan acknowledges that the discussion is interesting and expresses similar concerns to Dylan, recognizing Dylan's input.",
                    "ask clarifying question": "Stefan is asking how to get a super resolution image of an entire live mouse, seeking clarification on the practical application of the discussed techniques.",
                    "express frustration": "Stefan expresses frustration about the difficulty of obtaining super-resolution images of a live mouse, highlighting the limitations of current methods."
                }
            ]
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:14-04:27",
            "transcript": "But what we could do is um uh use end points and then make tissues optically transparent, right? So removing all the the scattering.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:14",
            "end_time": "34:27",
            "annotations": {
                "propose decision": "Stefan proposes using end points and making tissues optically transparent to overcome the challenge of obtaining super-resolution images of an entire live mouse, building on the previous discussion about the difficulty of live imaging due to the large amount of data collected."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:27-04:31",
            "transcript": "Uh and then light can penetrate into the tissue.",
            "speaking_duration": 4,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:27",
            "end_time": "34:31",
            "annotations": {
                "expand on existing idea": "Stefan is building on his previous statement about making tissues optically transparent by stating that light can then penetrate into the tissue, further elaborating on the benefits of this approach."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:31-04:41",
            "transcript": "And the interesting thing that we found is that when we do this, we can now actually see um our nanoparticle carriers because they are still there and they scatter light efficiently.",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:31",
            "end_time": "34:41",
            "annotations": {
                "provide supporting evidence": "Stefan is providing evidence based on their findings about seeing nanoparticle carriers when tissues are made optically transparent, supporting the idea of using endpoints and optical clearing techniques."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:41-05:06",
            "transcript": "And now since you remove everything else in the background that will interfere, now you get a pretty clear and crisp view of where your your carriers are. So this was pretty intriguing uh when when we saw this and um it allows you to have volumetric imaging. Um, but now of course you're losing super resolution, right?",
            "speaking_duration": 25,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "34:41",
            "end_time": "35:06",
            "annotations": {
                "provide supporting evidence": "Stefan explains that by making tissues optically transparent, they can get a clear view of their nanoparticle carriers because the background interference is removed, supporting their approach to imaging.",
                "explain or define term or concept": "Stefan explains the concept of making tissues optically transparent to remove scattering, which allows light to penetrate the tissue and provide a clearer view of nanoparticle carriers.",
                "express alternative decision": "Stefan acknowledges that while their method allows for volumetric imaging, it results in a loss of super-resolution, expressing a trade-off in their approach compared to super-resolution techniques."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:06-05:11",
            "transcript": "So then you need to go and expand your samples to get super resolution.",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:06",
            "end_time": "35:11",
            "annotations": {
                "expand on existing idea": "Stefan is building on his previous idea of making tissues optically transparent to see nanoparticle carriers, and now he's adding that expansion microscopy is needed to achieve super-resolution after clearing the tissue."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:11-05:24",
            "transcript": "But then you're only looking at a tiny field of view. So these are all these challenges, but at least for our research, uh what we found is that if we use the right type of nano material that scatters light efficiently.",
            "speaking_duration": 13,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:11",
            "end_time": "35:24",
            "annotations": {
                "expand on existing idea": "Stefan is expanding on his idea of using endpoints and making tissues optically transparent by acknowledging the challenge of having a tiny field of view when using expansion microscopy to get super resolution after clearing the tissue.",
                "provide supporting evidence": "Stefan provides supporting evidence by stating that for their research, using the right type of nanomaterial that scatters light efficiently helps with imaging."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:24-05:36",
            "transcript": "And then we work with uh tissue clearing method and expansion microscopy methods, um we can get somewhere at least um but it's not the the ideal state, but yeah, I would agree that scattering is a big problem.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:24",
            "end_time": "35:36",
            "annotations": [
                {
                    "expand on existing idea": "Stefan is building on his previous idea of using endpoints and making tissues optically transparent to visualize nanoparticle carriers, adding that they then use tissue clearing and expansion microscopy methods to further improve visualization, but acknowledging it's not ideal."
                },
                {
                    "express agreement": "Stefan explicitly agrees that scattering is a big problem, which aligns with the ongoing discussion about challenges in super-resolution microscopy."
                }
            ]
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:36-05:37",
            "transcript": "But scattering can also be.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:36",
            "end_time": "35:37",
            "annotations": {
                "expand on existing idea": "Stefan was discussing challenges in super-resolution imaging of live animals, and how his group uses tissue clearing and expansion microscopy to address them, and this utterance suggests he is about to add more information to the role of scattering."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "05:37-05:40",
            "transcript": "very informative depending how you utilize it.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows the Wilhelm Lab logo, which includes the name of the lab, its focus on Biomedical Nano-Engineering, and a website address. It also displays the logo of the Stephenson School of Biomedical Engineering at the University of Oklahoma.",
            "start_time": "35:37",
            "end_time": "35:40",
            "annotations": {
                "provide supporting evidence": "Stefan is building on the discussion of scattering and suggests that it can be informative, depending on how it is utilized, which provides reasoning to strengthen the idea that scattering is not always a negative factor."
            }
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "06:27-06:36",
            "transcript": "Can someone explain how one would detect the scattered light? How what kind of detectors will we need?",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:27",
            "end_time": "36:36",
            "annotations": {
                "ask clarifying question": "Luke is asking for an explanation on how to detect scattered light, specifically inquiring about the types of detectors needed, showing he needs clarification on this topic."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:36-06:41",
            "transcript": "I just a flat CMOS chip, I bet, right?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:36",
            "end_time": "36:41",
            "annotations": {
                "ask clarifying question": "Dylan is asking if a flat CMOS chip is sufficient to detect scattered light, seeking confirmation or further explanation on the appropriate detector type."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:41-06:43",
            "transcript": "So what kind of detectors are you imagining?",
            "speaking_duration": 2,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:41",
            "end_time": "36:43",
            "annotations": {
                "ask clarifying question": "Dylan is asking for clarification on what kind of detectors Luke is imagining to use for detecting scattered light, following Luke's question about how to detect scattered light."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "06:48-07:02",
            "transcript": "Because I'm I'm a practical guy. I kind of want to imagine what you're going to where where where you're going to capture this with, right? Um is it is is there something that exists or you are you have to invent it?",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "36:48",
            "end_time": "37:02",
            "annotations": {
                "ask clarifying question": "Dylan asks what kind of detectors are being imagined to capture the scattered light, seeking practical details about existing or yet-to-be-invented technology, building on the discussion about detecting scattered light."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:05-07:06",
            "transcript": "So I can jump in if needed.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:05",
            "end_time": "37:06",
            "annotations": {
                "encourage particpatioin": "Kristen offers to contribute to the discussion, encouraging others to participate if needed, following a series of questions about detecting scattered light."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:06-07:27",
            "transcript": "Um, so if you think of um structured illumination and you're capturing that image with a camera and so with the structured illumination, you're illuminating certain areas, your light gets scattered, so you collect light from everywhere.",
            "speaking_duration": 21,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:06",
            "end_time": "37:27",
            "annotations": {
                "explain or define term or concept": "Kristen is explaining the concept of structured illumination and how light is collected in that process, which involves light scattering and collection from all areas."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:27-07:41",
            "transcript": "And then usually you do um there's an algorithm that automatically calculates where that light is coming from and it removes that scattering light. So you're already capturing the scattered light, it's just that you are removing it.",
            "speaking_duration": 14,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:27",
            "end_time": "37:41",
            "annotations": [
                {
                    "explain or define term or concept": "This sentence explains how algorithms are used in structured illumination to calculate the origin of light and remove scattered light, clarifying the process."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "07:41-08:00",
            "transcript": "In confocal, you're using a pin hole to collect that um the light the ballistic photons that you are interested in and you're using that pin hole to block all those other scattered lights um you're it's coming from.",
            "speaking_duration": 19,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "37:41",
            "end_time": "38:00",
            "annotations": {
                "explain or define term or concept": "Kristen is explaining how confocal microscopy uses a pinhole to collect ballistic photons and block scattered light, clarifying the process for the group.",
                "provide supporting evidence": "Kristen is providing details about how confocal microscopy works, supporting the discussion about scattering and super-resolution techniques."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:00-08:16",
            "transcript": "And so if you collect with a camera and you focus if you collect that light from where your pin hole would be, that would be your, you know, from your central focal area, but you could collect the scattered um multi photon light so that you can then collect more of that signal.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:00",
            "end_time": "38:16",
            "annotations": {
                "explain or define term or concept": "Kristen explains how in confocal microscopy, a pinhole is used to collect ballistic photons and block scattered light, but if you collect light from where the pinhole would be, you could collect scattered multi-photon light to gather more signal, clarifying the concept of scattered light collection in microscopy.",
                "expand on existing idea": "Kristen expands on the discussion about detecting scattered light by explaining how structured illumination captures scattered light, which is then removed algorithmically, and how confocal microscopy uses a pinhole to block scattered light, suggesting an alternative approach to collect more signal."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:16-08:22",
            "transcript": "Um, so it just depends a little bit on your imaging strategy and and what the um orientation would be.",
            "speaking_duration": 6,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:16",
            "end_time": "38:22",
            "annotations": {
                "explain or define term or concept": "This utterance explains how the collection of scattered light depends on the imaging strategy and orientation, clarifying the concept of how different imaging techniques handle scattered light."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:22-08:30",
            "transcript": "Yeah, yeah, we try to deconvolve out almost all the what we refer to it as out of focus light in not scattered light, but um.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:22",
            "end_time": "38:30",
            "annotations": {
                "explain or define term or concept": "Dylan is explaining that they try to remove what they call 'out of focus light', which is related to, but not the same as, scattered light, clarifying their image processing approach."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:30-08:33",
            "transcript": "So I'm still kind of confused. How is that going to work?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:30",
            "end_time": "38:33",
            "annotations": {
                "ask clarifying question": "Dylan expresses confusion about how to detect scattered light and asks for clarification on how it would work, building on the previous discussion about detecting scattered light."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:39-08:42",
            "transcript": "on on on on an engine. This is kind of why we're here, right?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:39",
            "end_time": "38:42",
            "annotations": {
                "express enthusiasm": "Dylan expresses enthusiasm about the discussion, suggesting that the confusion and exploration of ideas are the reasons for their gathering.",
                "confirm decision": "Dylan confirms that the purpose of the meeting is to discuss and explore ideas, indicating agreement with the overall goal."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:42-08:49",
            "transcript": "I I I I don't understand how that is going to be a thing that can be developed.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:42",
            "end_time": "38:49",
            "annotations": {
                "express frustration": "Dylan expresses frustration because he doesn't understand how the idea of detecting scattered light can be developed, given the conventional wisdom of throwing it out."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:49-08:56",
            "transcript": "Because if if it was just as simple as I have a CMOS camera and I have very images, I can make them sharp, we would have probably already done that, right?",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:49",
            "end_time": "38:56",
            "annotations": {
                "express skepticism": "Dylan expresses skepticism about the idea of easily sharpening blurry images from a CMOS camera, implying that if it were that simple, it would have already been done, given the prior discussion about detecting and utilizing scattered light."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "08:56-09:03",
            "transcript": "Um and and we do our best that we can by by reassigning uh the out of focus photons into the plane that we're supposed to be.",
            "speaking_duration": 7,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "38:56",
            "end_time": "39:03",
            "annotations": {
                "expand on existing idea": "Dylan is expanding on the existing idea of dealing with scattered light in imaging, mentioning that they try to reassign out-of-focus photons to the correct plane, building upon Kristen's explanation of how structured illumination and confocal microscopy handle scattered light."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "09:03-09:06",
            "transcript": "There's algorithms for that. So we're talking about.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "39:03",
            "end_time": "39:06",
            "annotations": [
                {
                    "expand on existing idea": "Dylan is building on the previous discussion about capturing and processing scattered light, mentioning that algorithms exist to reassign out-of-focus photons, which is related to the idea of utilizing scattered light for imaging."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:00-00:35",
            "transcript": "through your filters, that might be one aspect. Um, so I think um it it would take a big picture look at what are you trying to do, what are is your imaging system or your microscope that you're trying to use and um how is scattering affecting your ability to image what you're trying to see or image at a depth, you know, that maybe you can't reach. Um, and then taking into into consideration your sample that the light is traveling through and how does that influence or impact your ability to image whether it be resolution or depth or field of view.",
            "speaking_duration": 35,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:00",
            "end_time": "40:35",
            "annotations": [
                {
                    "explain or define term or concept": "Kristen is explaining the factors to consider when addressing the problem of scattering, including the imaging system, the sample, and the desired imaging outcome, in response to Dylan's confusion about how to detect scattered light."
                }
            ]
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "00:35-02:05",
            "transcript": "Yeah, maybe to to jump off that and and bridge back to what uh what Sian was talking about at the beginning. Like if we're in the fluorescence and uh some of the light from your floor for gets multiply scattered, there's kind of two ways that we might think of detecting it. One is just waiting long enough because those multiply scattered photons will take longer to get to you. So you you kind of wait long enough and see where they landed and maybe those were your scattered photons. The other thing that I think Josh is really better expert at is um if you change your imaging instrument in some way because that light was determinate that scattering was deterministic, like the cell boundaries that the light scattered off of were at certain some place relative to your imaging system. If you change the instrument a little bit to better leverage those scattering patterns and get more light out now and get more light in, then you have a signature for for for fixing your image in the bit. So the the the the imaging problem becomes harder now because it's no longer uh uh optically engineered perfect objective that does your job for you. Now you've got to reoptimize the imaging system on the fly for your specific sample and then you got to make sure that whatever you thought the scattering was from wherever it was from and whenever it was from like that's actually what you're detecting because it in principle at least with elastically scattered light, there's no way to identify it any other way. Like the photon energy is going to be the same, right? And uh and so yeah.",
            "speaking_duration": 90,
            "nods_others": 2,
            "smile_self": 15,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "40:35",
            "end_time": "42:05",
            "annotations": [
                {
                    "expand on existing idea": "Matt builds upon Kristen's explanation of how scattered light is captured and removed in structured illumination and confocal microscopy, adding two ways to detect multiply scattered light from fluorophores."
                },
                {
                    "explain or define term or concept": "Matt explains that detecting scattered light involves either waiting for multiply scattered photons or changing the imaging instrument to leverage scattering patterns, highlighting the deterministic nature of scattering and the need to reoptimize the imaging system."
                }
            ]
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "02:05-03:40",
            "transcript": "There's also some interesting things with scattering connecting back to our conversation about numerical aperture, which counter, you know, counterintuitively scattering can actually help you because at the fundamental level, high NA is about high spatial frequencies is about high angle illumination and so scattering has a way of creating this for you because of the, you know, in strongly scattering tissue after you, you know, scatter enough, you're at lambda over two. Um, so that I think is something else too that you make your you make your your enemy your friend in some sense by, you know, taking advantage of what's happening there and then maybe you maybe you decouple from the traditional connection with lenses between field of view and working depth and NA and the geometrical piece of lens design, there's only so many parameters you have to to tweak, but if you can think about your lens as a and I think Sian will be, you know, with Laura, she always talks about like your lens is a Laura Waller, your lens is a matrix basically, which I love that like picture thinking about um, you know, and in the wavefront shaping community, we think of like replacing a lens with a cube of salt or something like, you know, cube of sugar or something and just sending light through it and if you know what the you know, the matrix is, mathematically there may be some interesting properties there that you can leverage that may actually help you and not hurt you.",
            "speaking_duration": 95,
            "nods_others": 1,
            "smile_self": 20,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "42:05",
            "end_time": "43:40",
            "annotations": {
                "expand on existing idea": "Josh expands on the idea of using scattering for imaging, building on the previous discussion about numerical aperture and how scattering can be counterintuitively helpful.",
                "provide supporting evidence": "Josh provides supporting evidence by explaining that high NA is about high spatial frequencies and high angle illumination, and scattering can create this, referencing the concept of lambda over two in strongly scattering tissue.",
                "explain or define term or concept": "Josh explains the concept of thinking about a lens as a matrix, referencing Laura Waller's perspective, to illustrate how wavefront shaping can leverage interesting properties of scattering.",
                "express enthusiasm": "Josh expresses enthusiasm by saying there are some interesting things with scattering."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "03:40-04:00",
            "transcript": "That's a great point. Um, I was also doing post in Laura Waller's lab and uh I really like her perspective that uh lens is just a phase mask, right? So whatever whatever point spread function you want in the end, you can somehow engineer the lens you want.",
            "speaking_duration": 20,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "43:40",
            "end_time": "44:00",
            "annotations": {
                "acknowledge contribution": {
                    "Explanation": "The phrase \"That's a great point\" acknowledges Josh's previous contribution about scattering and numerical aperture."
                },
                "expand on existing idea": {
                    "Explanation": "Sian builds on Josh's point about lenses by sharing her experience in Laura Waller's lab and agreeing with the perspective that a lens is just a phase mask that can be engineered to achieve a desired point spread function."
                },
                "express agreement": {
                    "Explanation": "Sian expresses agreement with Josh's point by stating \"That's a great point.\""
                }
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "04:00-05:31",
            "transcript": "And uh back to Dylan's question, that's actually really um uh I think it's also a very good point to start framing off. Um, so to solve the problem, I think we can start from two. Uh one is detection, how can you reassign photons based on different properties, based on different characteristics of photons you capture and then how can you reassign it. And then second way is uh second way, how can you form the beam for for example, for light sheet microscopy, it's very hard to get a nice light sheet after scattering. So how can you use wavefront engineering or scattering compensation to get a nice illumination in the beginning. So you don't worry that much about detection later. Um, my question is um like what is the fundamental limit in either direction. So if we try all these methods and we push our depths like 10% more, is it worth it? Uh, and this applies for both um detection and illumination. Detection, you have photo photon starvation, you have noise issue and for illumination, um no matter how much you compensate, at some point you lose the correlation between photons and you lost uh at one point it's just random walk. So how much more can we push and what is the fundamental challenge in the in the field right now.",
            "speaking_duration": 91,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "44:00",
            "end_time": "45:31",
            "annotations": [
                {
                    "expand on existing idea": "This sentence refers back to Dylan's question and frames it as a good starting point for discussion, building upon the previous conversation.",
                    "present new idea": "The speaker proposes two approaches to solve the problem: improving photon detection and engineering the beam for better illumination, introducing new strategies for addressing the challenge.",
                    "ask clarifying question": "The speaker asks about the fundamental limits of pushing the depth of imaging by 10% with current methods, questioning the worth of such efforts given photon starvation, noise, and loss of photon correlation."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:31-05:36",
            "transcript": "And Luke, can we hear from you as well?",
            "speaking_duration": 5,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:31",
            "end_time": "45:36",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is explicitly inviting Luke to contribute to the discussion, as the group has already heard from several other members."
            }
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "05:36-06:15",
            "transcript": "Um, yeah, sure. So I I think I mean, I think that one of the challenges that I see is is like how much deeper can you go? How much further can you go is a major problem. But I think a a bigger problem that we've noticed is how long does it take you to get there? You know, because you can do a decent job of understanding what's happening to the light and like recreating a focus and then detecting whatever signal you get out.",
            "speaking_duration": 39,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "45:36",
            "end_time": "46:15",
            "annotations": [
                {
                    "expand on existing idea": "This utterance builds upon the previous discussion about the challenges of imaging deeper into tissue, adding the dimension of time as a significant factor, which is a new aspect of the problem."
                }
            ]
        },
        {
            "speaker": "Luke Mortensen",
            "timestamp": "06:15-07:35",
            "transcript": "But you're really going to have to detect for a really long time to get enough photons out and overcome your SNR problems or it's going to take you quite a while to do the correction factor and even you know, current best in class it's pretty, you know, for a whole organism or, you know, whether it's like the whole organism or just a whole organism, in both cases you're looking at problems with, you know, signal and movement and time. And um, you know, those those seem like like major issues that in order to get it from the point of where it requires full um deconstruction of the organism, you know, which is definitely and a useful and insightful approach back to something that's maybe hopefully happening in a dynamic setting, we can understand like how things are are altering with time. Um, you know, sort of like our keynote talk is. I think, you know, trying to bridge those two two spectrum I think is sort of as a as a challenge.",
            "speaking_duration": 80,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "46:15",
            "end_time": "47:35",
            "annotations": [
                {
                    "expand on existing idea": "The speaker is building on the previous discussion about the challenges of imaging deeper into tissue, adding the point that the time required for detection and correction is a significant problem, especially considering signal-to-noise ratio (SNR) and movement."
                },
                {
                    "present new idea": "The speaker introduces the idea of bridging the gap between methods requiring full deconstruction of the organism and dynamic settings to understand how things are altering with time, framing it as a challenge."
                }
            ]
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "07:36-08:33",
            "transcript": "But if you're trying to detect things in multiple dimensions such as you say time, if things are going to take longer to get there, is it possible that you could just use multiple detectors? Because when we when we go and put two cameras on our system, we want them to be par focal basically. We want to them to be in the exact same focal plane. But can you alternate the detectors to detect um things that take longer to get there, just move the camera closer. I mean can I don't know if if with one detector we're going to be able to get to this thing and you and you guys are the physics people, but I can't imagine this is going to be solved with one camera. It's just going to take too darn long to image an organism.",
            "speaking_duration": 57,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "47:36",
            "end_time": "48:33",
            "annotations": [
                {
                    "present new idea": "Dylan suggests using multiple detectors to capture photons that take longer to arrive, addressing the time constraints of deep tissue imaging, which is a novel approach not previously discussed."
                },
                {
                    "ask clarifying question": "Dylan asks if using multiple detectors at different focal planes could address the time constraints of deep tissue imaging, seeking input from the physics experts in the group."
                }
            ]
        },
        {
            "speaker": "Sixian You",
            "timestamp": "08:33-09:31",
            "transcript": "You're definitely not crazy. There is definitely a lot of multi view uh microscopes for all kinds of modalities over there. Uh actually people do it. I I think there are like uh several ways to come about it. One is kind of multi view, so you scan uh different regions at the same time and somehow they end up in different pathways and you can use different cameras to detect it. And for scattering problems or for aberration problems, uh you have this pupil plane where you can also simultaneously uh kind of correct uh different aberrations and scattering for different regions. So there are ways to deal with it, but uh then if you do that, then you are at the danger of even being more photon starved. Um, so it's always a tradeoff. The more multiplex, the the the less photons you have. So.",
            "speaking_duration": 58,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "48:33",
            "end_time": "49:31",
            "annotations": [
                {
                    "express agreement": "The speaker agrees with Dylan that using multiple detectors is a valid idea, indicating agreement with the previous statement."
                },
                {
                    "expand on existing idea": "The speaker expands on Dylan's idea of using multiple detectors by describing multi-view microscopes and how they address scattering and aberration problems, adding details to the initial suggestion."
                },
                {
                    "provide supporting evidence": "The speaker provides supporting evidence for the use of multiple detectors by mentioning the existence of multi-view microscopes and how they are used to correct aberrations and scattering, strengthening the idea with real-world examples."
                },
                {
                    "explain or define term or concept": "The speaker explains the concept of multi-view microscopes and how they work by scanning different regions simultaneously and using different cameras for detection, clarifying the approach for the group."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "09:40-09:52",
            "transcript": "Uh Candace, would you like to introduce yourself? I know that we've been talking without you, but if you'd like to just mention um your area um that you work in and especially related to super resolution and maybe your interest in this area just briefly.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:40",
            "end_time": "49:52",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is inviting Candace to introduce herself and share her perspective, as Candace was previously unavailable."
            }
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "09:52-10:15",
            "transcript": "Yeah, I I really apologize about that. Um, so I'm Candace Fleischer, I'm at Emory University in Atlanta. Um, my",
            "speaking_duration": 23,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "49:52",
            "end_time": "50:15",
            "annotations": [
                {
                    "None": "No code applies to this utterance."
                }
            ]
        },
        {
            "speaker": "Candace Fleischer",
            "timestamp": "00:00-00:29",
            "transcript": "my group primarily focuses on MR spectroscopy and of the brain and you know, we don't do a lot of super resolution in the I I also came from an optical background. So we don't do it in that sense, but maybe Oze, maybe you've already discussed like compressed sensing. I'm not sure if we've gotten that far, but in MR, we do kind of have ways that we refer to as super resolution, but certainly not in the same way. I came I heard multiplexing. So I imagine we're talking about optical imaging.",
            "speaking_duration": 29,
            "nods_others": 4,
            "smile_self": 21,
            "smile_other": 21,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:00",
            "end_time": "50:29",
            "annotations": {
                "explain or define term or concept": "The speaker is explaining that while their group doesn't do super-resolution in the optical sense, they have methods in MR that are referred to as super-resolution, thus defining the term in the context of their work.",
                "acknowledge contribution": "The speaker acknowledges hearing about multiplexing, recognizing a topic discussed earlier in the context of optical imaging.",
                "encourage particpatioin": "The speaker is encouraging Oze to participate by asking if they have already discussed compressed sensing."
            }
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "00:29-01:10",
            "transcript": "No resolution wise we we are not on the same level so far. So I didn't want to intervene any part of the discussion, but I was thinking to introduce to my whether we will be able to use the magnetic properties and you know, to change the optical behavior and make it useful and do multimodality imaging with your approaches. I have been reading and I have been approached a couple of colleagues to use the ultra high field to change the optical properties.",
            "speaking_duration": 41,
            "nods_others": 3,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "50:29",
            "end_time": "51:10",
            "annotations": [
                {
                    "present new idea": "Uzay introduces the idea of using magnetic properties to change optical behavior for multi-modality imaging, which hasn't been discussed before."
                }
            ]
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "01:11-02:23",
            "transcript": "Well, I will definitely say that there's an opportunity for people from different modalities to learn from each other. And so I do think I'm really glad that there are two of you that are in MR in this room because I feel like as you discuss with each other in the next couple days, um if you can talk about um how you approach you know, resolution and improving resolution and some like compressed sensing, you know, which is applied in both fields, but the different approaches, I think sometimes it's hard for them to bridge over those those gaps between fields. And so the more you can talk together about, well, how do you do this or why do you do that or um there's a real opportunity there I think in terms of working together across fields. Um, so I'll just point that out. Um, we have about um 15 minutes left, I believe. Um, yeah. And so uh we'll maybe just talk for another five minutes and then I think we should revisit kind of our key points and and try to narrow those down so that when Josh reports out, we have a a more focused report out.",
            "speaking_duration": 72,
            "nods_others": 4,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "51:11",
            "end_time": "52:23",
            "annotations": [
                {
                    "encourage particpatioin": "Kristen encourages collaboration and knowledge sharing between participants from different modalities, specifically mentioning MR, to bridge gaps between fields and improve resolution approaches."
                },
                {
                    "propose decision": "Kristen proposes to talk for another five minutes and then revisit the key points to narrow them down for Josh's report."
                }
            ]
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "02:24-03:09",
            "transcript": "maybe just oh, I'll throw out one quick one and and maybe it goes nowhere. Um in terms of interesting ways of probing the tissues optically, is there some way that we can engineer photons or maybe even coupled photons so that their probability of scattering is less without let's say not, you know, not even knowing what the tissue looks like. Um I don't know, let's say entangled photons for instance example, right? Uh are there cute little tricks that we could do to uh make them more robust to what classical detection would fail at. Uh you know, maybe it it requires us to to go about that way. Just just a thought.",
            "speaking_duration": 45,
            "nods_others": 2,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "Yes",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "52:24",
            "end_time": "53:09",
            "annotations": {
                "present new idea": "Matt introduces a novel concept of engineering photons to reduce their scattering probability in tissues, which hasn't been discussed before.",
                "expand on existing idea": "Matt builds upon the previous discussion about scattering and detection methods by suggesting a specific approach using engineered photons.",
                "propose decision": "Matt proposes exploring the use of engineered photons to improve tissue probing, suggesting a direction for future investigation."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "03:09-03:55",
            "transcript": "Oh, people are going longer wavelengths to avoid scattering. Uh, so that's one way and I feel like uh the notion you mentioned entangled photons could be very interesting because people are already doing that for telescope and as we know, we are the retarded grandkids from the astronomers as micro says. So maybe maybe that's the I I feel like that could be a very high risk, high reward uh uh notion to do.",
            "speaking_duration": 46,
            "nods_others": 1,
            "smile_self": 15,
            "smile_other": 15,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "53:09",
            "end_time": "53:55",
            "annotations": [
                {
                    "expand on existing idea": "Sixian is expanding on Matt Lew's idea of engineering photons to reduce scattering by mentioning that people are already using longer wavelengths to avoid scattering, building upon the previous discussion about ways to probe tissues optically."
                },
                {
                    "express enthusiasm": "Sixian expresses enthusiasm for the idea of using entangled photons, stating it could be a \"very high risk, high reward\" approach, showing excitement about the potential of this concept."
                }
            ]
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "04:40-05:35",
            "transcript": "So one thing to add to this one, I think for engineering uh is quite intriguing and uh from a nano particle perspective, uh there are materials out there where you can uh tune the lifetime. So maybe it's it's not just the spectral properties but also um like the luminescence lifetime of those materials that that can then be used as as labels um for certain features um of of interest, right? And one example um uh material is called up conversion nano particles that have anti stokes emission um they um typically have luminescence lifetimes in like the millisecond or microsecond range. So that's um orders of magnitude difference to to what you would have with the commercial for so this may also be uh helpful in the end.",
            "speaking_duration": 55,
            "nods_others": 1,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "54:40",
            "end_time": "55:35",
            "annotations": {
                "expand on existing idea": "Stefan is building on Matt's idea of engineering photons by suggesting that nanoparticles with tunable lifetimes could be used as labels, expanding on the discussion of engineering photons to improve tissue penetration.",
                "provide supporting evidence": "Stefan provides an example of upconversion nanoparticles with anti-stokes emission and luminescence lifetimes in the millisecond or microsecond range to support his idea of using materials with tunable lifetimes.",
                "explain or define term or concept": "Stefan explains the concept of upconversion nanoparticles and their anti-stokes emission properties to clarify the type of material he is suggesting."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "05:41-06:03",
            "transcript": "So maybe that's uh that brings up an idea in my head. Um Stefan on on like modulating those like how about magnetic fields to let's say prepare them to be more scattering or less or more up converting or less and that gives us maybe a way of uh controlling them and making them better emitters for deep tissue imaging. I'm not sure.",
            "speaking_duration": 22,
            "nods_others": 1,
            "smile_self": 5,
            "smile_other": 5,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "55:41",
            "end_time": "56:03",
            "annotations": {
                "present new idea": "Matt introduces a novel concept of using magnetic fields to modulate nanoparticles, influencing their scattering or up-conversion properties for improved deep tissue imaging, building on Stefan's mention of nanoparticles with tunable lifetimes.",
                "expand on existing idea": "Matt builds upon Stefan's suggestion of using nanoparticles with tunable lifetimes by proposing the use of magnetic fields to control their scattering or upconverting properties, aiming to enhance their effectiveness as emitters for deep tissue imaging."
            }
        },
        {
            "speaker": "Stefan Wilhelm",
            "timestamp": "06:04-06:26",
            "transcript": "Yeah, absolutely. Like when uh when you mentioned this, I thought immediately about um assembling um uh objects at the nano scale that as a single object do not scatter but when they come together and form an assembly then all of a sudden they scatter light very efficiently. So this definitely something that that we could could work on.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 5,
            "smile_other": 5,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:04",
            "end_time": "56:26",
            "annotations": {
                "expand on existing idea": "This utterance builds upon Matt Lew's idea of using magnetic fields to control nanoparticles, suggesting assembling nanoscale objects that scatter light efficiently when they come together, expanding on the concept of controlling scattering properties.",
                "present new idea": "The idea of assembling nanoscale objects that scatter light efficiently only when they come together is a novel concept not previously discussed in the conversation."
            }
        },
        {
            "speaker": "Silvia Ronco",
            "timestamp": "06:29-06:39",
            "transcript": "Sorry, sorry to interrupt. Do you know where you need to put the main main discussions in the PowerPoint?",
            "speaking_duration": 10,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 10,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "Yes",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:29",
            "end_time": "56:39",
            "annotations": [
                {
                    "ask clarifying question": "Silvia is asking a question to clarify where the main points of the discussion should be placed in the PowerPoint, likely for reporting back to a larger group."
                }
            ]
        },
        {
            "speaker": "Silvia Ronco",
            "timestamp": "06:39-06:40",
            "transcript": "Okay. Good. Thanks.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "56:39",
            "end_time": "56:40",
            "annotations": [
                {
                    "acknowledge contribution": "The speaker acknowledges the information provided by the other person."
                }
            ]
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:00-07:26",
            "transcript": "Okay, so I think we should um try to summarize and come up with our key points, but we had lots of different great ideas. And so I would say if you know, from our discussion, we should use that parking lot to capture some of those as potential um areas that we could probe further in your later discussions and and may, you know, result in in a proposal.",
            "speaking_duration": 26,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:00",
            "end_time": "57:26",
            "annotations": {
                "propose decision": "Kristen suggests summarizing the key points of the discussion, indicating a concrete choice for the group to focus on.",
                "assign task": "Kristen suggests using the parking lot to capture potential areas for further probing, assigning the task of capturing these ideas to the group.",
                "encourage particpatioin": "Kristen encourages the group to use the parking lot to capture ideas for later discussions, inviting them to contribute to future proposals."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:26-07:27",
            "transcript": "Um",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:26",
            "end_time": "57:27",
            "annotations": {
                "None": "No code applies to this utterance."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:27-07:51",
            "transcript": "But at this time, I think we should look at um what we want to report out for our key points.",
            "speaking_duration": 24,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:27",
            "end_time": "57:51",
            "annotations": {
                "propose decision": "Kristen proposes that the group should focus on identifying the key points to report out, shifting the discussion towards summarizing their findings."
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "07:51-08:07",
            "transcript": "So what are what should we try to narrow it down to three topic areas of what we discussed? I think that because it is such a short recording report out time, um I think you want to go with the um the most exciting ideas, not necessarily what we talked about the most.",
            "speaking_duration": 16,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "57:51",
            "end_time": "58:07",
            "annotations": {
                "propose decision": {
                    "Explanation": "Kristen proposes to narrow down the discussion to three topic areas and focus on the most exciting ideas for the report out, given the limited time."
                }
            }
        },
        {
            "speaker": "Kristen Marland",
            "timestamp": "08:07-08:16",
            "transcript": "So maybe but I'm going to leave it up to you to come up with um what we'll cover.",
            "speaking_duration": 9,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:07",
            "end_time": "58:16",
            "annotations": {
                "encourage particpatioin": "Kristen Maitland is encouraging the group to decide on the key points to report out, inviting them to contribute to the decision-making process."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "08:26-09:35",
            "transcript": "I guess one idea that's exciting me is thinking about how multimodal maybe non-traditional use of contrast. So this conversation that Stefan's point that he just brought up about thinking about how do we, you know, maybe something that separated these individual things don't scatter light well, but then due to some kind of biological or chemical change within the organism, they come together and then oops, now they're it's I mean, in some sense it's kind of like, you know, G camp or any other kind of reporter.",
            "speaking_duration": 69,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "58:26",
            "end_time": "59:35",
            "annotations": {
                "present new idea": "Josh introduces the idea of using multimodal, non-traditional contrast mechanisms, drawing inspiration from Stefan's point about nanoparticles that scatter light only when assembled, similar to GCaMP reporters, which is a novel concept in the context of the discussion.",
                "expand on existing idea": "Josh builds upon Stefan's idea of using materials that scatter light efficiently, adding the concept of multimodal contrast and drawing an analogy to GCaMP reporters to enhance the idea.",
                "express enthusiasm": "Josh expresses excitement about the idea of multimodal contrast and its potential applications, indicating his enthusiasm for this direction."
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "09:35-09:57",
            "transcript": "But like new reporters that maybe are ultrasonically or magnetically or some other modality that is deeper penetrating into tissue, you know, using that to modulate those to detect them optically.",
            "speaking_duration": 22,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "59:35",
            "end_time": "59:57",
            "annotations": {
                "present new idea": "This utterance introduces the novel concept of using reporters that are modulated by modalities like ultrasound or magnetism for deeper tissue penetration and optical detection, which hasn't been explicitly discussed before.",
                "expand on existing idea": "This utterance builds upon the previous discussion about multimodal contrast by suggesting new reporters that can be modulated by ultrasound or magnetism for deeper tissue penetration and optical detection.",
                "provide supporting evidence": "The speaker is providing a potential solution to the problem of limited tissue penetration in optical imaging by suggesting the use of reporters modulated by other modalities."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "00:10-00:13",
            "transcript": "Any other ideas we should be reporting out on?",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:10",
            "end_time": "60:13",
            "annotations": {
                "encourage particpatioin": "Kristen is explicitly asking for more ideas from the group, encouraging participation in the discussion."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "00:20-01:33",
            "transcript": "Uh, I think one idea uh that was brought up by a few people was pretty exciting. Uh, the idea of um I can summarize it as adaptive imaging. So I think Josh bring out this idea so first you have low resolution imaging and then you come in with high resolution imaging. So um so uh we can combine with MRI, right? So I was I forgot this person's name, but I was talking to another person in the breakout session that they were developing this low field MRI where they can be portable as a probe, right? So imagine uh you are doing uh clinic session and you have this probe with MRI and you're doing this scanning and then when you have a suspicious area, you heard a beep from the AI algorithms and then you have a needle that comes out that gives you the optical fiber and then insert into do kind of do a real time at a point of procedure diagnosis. Uh, so kind of combine this non-invasive MRI with non with minimal invasive optical cellular resolution imaging.",
            "speaking_duration": 73,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "60:20",
            "end_time": "61:33",
            "annotations": [
                {
                    "expand on existing idea": "Sixian is expanding on the idea of adaptive imaging, which Josh brought up, by suggesting combining low-resolution imaging with high-resolution imaging."
                },
                {
                    "present new idea": "Sixian presents a new idea of combining MRI with optical fiber insertion for real-time diagnosis, building upon the adaptive imaging concept."
                },
                {
                    "express enthusiasm": "Sixian expresses enthusiasm for the idea of adaptive imaging and its potential applications."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "01:37-03:03",
            "transcript": "Yes, so just from my my experience, I guess, that's um one area that in terms of optical imaging that, you know, I've tried to to develop was using actually fluorescence lifetime imaging of in a macroscopic view of tissue and oral cavity. Um and then using um we developed a confocal microscope that also would go into the world cavity and we design our own miniature lens that's about um less than a centimeter in diameter. So it's relatively small, can fit inside. Um and there you're doing kind of that point measurement, but it's with imaging looking at um cell nuclei um that have been identified based on the metabolic changes in the tissue um using the fluorescence lifetime. There's one other group that also uses distortion in the lens so that um on it captures a larger field of view that has a worse resolution, but at the center it has better resolution um but a very limited field of view so that you could use it to kind of guide around um and then you if you see something at the edge of the focus then you move it to the center and you get that higher resolution in the center. So there's just a couple ideas of some and then one thing that I I didn't really hear being brought up but photoacoustic imaging for increased depth um we didn't really discuss but for that kind of multimodality and and using a different type of excitation through your in comparison to your detection.",
            "speaking_duration": 86,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "61:37",
            "end_time": "63:03",
            "annotations": [
                {
                    "expand on existing idea": "Kristen expands on the idea of adaptive imaging, which Sixian brought up, by sharing her experience with fluorescence lifetime imaging and confocal microscopy for oral cavity tissue."
                },
                {
                    "present new idea": "Kristen introduces the idea of using photoacoustic imaging for increased depth and multimodality, which hadn't been discussed previously in the conversation."
                }
            ]
        },
        {
            "speaker": "Uzay Emir",
            "timestamp": "03:04-03:31",
            "transcript": "Yeah, I do think that the photoacoustic is feasible for MRI as well. So I do see great illustration about this kidney and they embedded this photoacoustic and try to induce the ultrasound outside and try to write it up and you can also do the same thing with MRI that might be really interesting way to look at the photoacoustic. We don't have any chance to discuss that.",
            "speaking_duration": 27,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:04",
            "end_time": "63:31",
            "annotations": [
                {
                    "expand on existing idea": "This utterance builds upon the existing discussion of multimodality imaging by suggesting that photoacoustic imaging is feasible for MRI, expanding on the potential combinations of imaging techniques."
                },
                {
                    "express enthusiasm": "The speaker expresses enthusiasm for the idea of combining photoacoustic imaging with MRI, indicating excitement about the potential of this approach."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "03:32-04:13",
            "transcript": "So I do again encourage you to put ideas in the parking lot especially because even though this is a short virtual meeting this week, but um hopefully you will all be back next year and the year after and so if you plan to see now you might come back to it um in the future. Um so I hope this is just the beginning of your discussion together um not necessarily all of you together but um with individuals that you may find other people at the conference that were not in our room that um may be able to help build on some ideas that you're um starting to form.",
            "speaking_duration": 41,
            "nods_others": 0,
            "smile_self": 50,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "63:32",
            "end_time": "64:13",
            "annotations": [
                {
                    "encourage particpatioin": "Kristen Maitland encourages the group to put ideas in the parking lot for future discussions, suggesting they might revisit them in future meetings and collaborate with others at the conference."
                },
                {
                    "express enthusiasm": "Kristen Maitland expresses optimism that this is just the beginning of their discussion and collaboration."
                }
            ]
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "04:13-04:24",
            "transcript": "This is what I have for our slide. I'm not sure what people think about this one if you want to give me any feedback. I was just trying to synthesize what we were just talking about.",
            "speaking_duration": 11,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
            "start_time": "64:13",
            "end_time": "64:24",
            "annotations": {
                "present new idea": {
                    "Explanation": "Josh is presenting the content he has prepared for the slide, which is a new element for the group to consider."
                },
                "encourage particpatioin": {
                    "Explanation": "Josh is asking for feedback from the other participants, inviting them to contribute their thoughts on the slide content."
                }
            }
        },
        {
            "speaker": "Joshua Brake",
            "timestamp": "05:02-05:14",
            "transcript": "I guess the second point is is somewhat related to big the big data. Like all the we had we talked quite a bit about how to deal with the data too. So thinking about how to trade those off.",
            "speaking_duration": 12,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
            "start_time": "65:02",
            "end_time": "65:14",
            "annotations": {
                "expand on existing idea": "Josh is expanding on the previous discussion about key points to report out, adding that the second point is related to big data and how to deal with it, which was also discussed previously.",
                "present new idea": "Josh is presenting a new idea of thinking about how to trade off big data concerns with other aspects of the discussion."
            }
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "05:23-06:01",
            "transcript": "Yeah, and related to that data there we were looking at different um light sheet microscopes from different companies and how they handle the large data size and um just in their software aspect some would um just in how they manage the data so that when you go in you want to look like zoom into an area of interest it doesn't keep that whole large data set so you can kind of have that um just how you approach the data. I think really makes a difference in be able to work with it um because it yeah, it is a lot of a lot of data.",
            "speaking_duration": 38,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "Yes",
            "screenshare_content": "The screen shows a Google Slides presentation titled \"Scialog ABL Meeting Slides\". The current slide is titled \"Room 1.1 - Key points\" and lists three key points related to super-resolution methods: Multi-modal probes, Adaptive imaging, and Co-designing illumination and collection. The slide also lists the participants, facilitator, and reporter for the session.",
            "start_time": "65:23",
            "end_time": "66:01",
            "annotations": {
                "expand on existing idea": "This utterance expands on the previously discussed topic of big data challenges in super-resolution microscopy by providing specific examples of how different light sheet microscopes and their software manage large datasets, building on the conversation about data management.",
                "provide supporting evidence": "The speaker provides supporting evidence by mentioning the observation of different light sheet microscopes from different companies and how they handle the large data size, supporting the idea that data management is a significant challenge.",
                "explain or define term or concept": "The speaker explains the concept of data management in the context of light sheet microscopy, clarifying how different software approaches can impact the ability to work with large datasets, which is relevant to the discussion on big data."
            }
        },
        {
            "speaker": "Matt Lew",
            "timestamp": "07:04-07:12",
            "transcript": "No, I think it went well. Thank you uh Kristen for for facilitating us and getting everyone a chance to speak.",
            "speaking_duration": 8,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "67:04",
            "end_time": "67:12",
            "annotations": [
                {
                    "express agreement": "Matt Lew expresses agreement that the discussion went well."
                },
                {
                    "acknowledge contribution": "Matt Lew acknowledges Kristen's contribution in facilitating the discussion and giving everyone a chance to speak."
                }
            ]
        },
        {
            "speaker": "Sixian You",
            "timestamp": "07:13-08:11",
            "transcript": "Yeah, I really like the we have the questions to guide us and then we kind of each uh each one of us kind of just uh uh branch off that. Um I I think um what I would like better is uh I feel like um so first we can go around introduction for each one and then when we are having this discussion, uh I feel like a lot of people, everybody has really good points that we could build a more fluid and um more coherent coherent conversation instead of one by one. So uh but uh then I guess it's a trade off then maybe we cannot get to hear some people's opinions um maybe. So maybe we could do like first round table uh introduction round table short ideas and then uh more uh just kind of just very casual uh coherent fluid discussions.",
            "speaking_duration": 58,
            "nods_others": 0,
            "smile_self": 10,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "67:13",
            "end_time": "68:11",
            "annotations": [
                {
                    "express agreement": "Sixian expresses agreement with the use of questions to guide the discussion, building on the previous discussion facilitated by Kristen."
                },
                {
                    "offer constructive criticism": "Sixian offers constructive criticism about the discussion format, suggesting a more fluid conversation style to build on the good points made by everyone, aiming to improve future discussions."
                },
                {
                    "propose decision": "Sixian proposes a round table introduction with short ideas followed by casual, coherent discussions, suggesting a concrete change to the meeting structure."
                }
            ]
        },
        {
            "speaker": "Kristen Maitland",
            "timestamp": "08:12-09:55",
            "transcript": "Yes, I do feel that especially in this virtual format that it does feel like okay, it's your turn to talk and there's a little bit less flow. Um I was wondering if it would be better after the introductions that if each person talk like briefly state what they're interested in discussing and you could almost like group them in and say okay, first we're going to talk about this particular direction and then we'll cover this direction. Um so that would be one thought. I think it's hard because of the the topics are relatively broad actually even though you know, in some ways they're specific, but they're relatively broad and you can approach them in different ways and so it's um it's almost hard to put your ideas into, you know, kind of groups. You know, and when I was looking at this topic I was thinking we could talk about new applications for super resolution that are, you know, it's not currently applied to. We could talk about different um advances to the implementation and then um I was also I was glad to see that there were people from MRI in here that if we could um get some information from other fields in imaging that might influence our approaches. Um but I do feel that each person had something different to add that um it might have been hard to kind of narrow down the topics because they are um there's so much to cover. I think. But I hope that you continue to have your discussions with each other in the different um gather rooms or towns or without you get to be in um so you can continue these uh conversations.",
            "speaking_duration": 103,
            "nods_others": 0,
            "smile_self": 20,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Open Palms",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "68:12",
            "end_time": "69:55",
            "annotations": [
                {
                    "express frustration": "Kristen expresses frustration with the virtual format and the lack of flow in the conversation, referencing the feeling that it's 'your turn to talk'.",
                    "present new idea": "Kristen suggests a new format for the discussion where each person briefly states their interests and then the topics are grouped for a more organized conversation."
                }
            ]
        },
        {
            "speaker": "Kristen Macland",
            "timestamp": "00:00-00:06",
            "transcript": "notes and for reporting out for us and we will see you guys later in the conference.",
            "speaking_duration": 6,
            "nods_others": 4,
            "smile_self": 20,
            "smile_other": 80,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:00",
            "end_time": "70:06",
            "annotations": {
                "assign task": "Kristen is assigning the task of reporting out to Josh, as mentioned in the previous utterance.",
                "acknowledge contribution": "Kristen acknowledges the notes taken, recognizing the effort made by someone, likely Josh, without explicitly agreeing or expanding on the content of the notes.",
                "express enthusiasm": "Kristen expresses enthusiasm by saying they will see everyone later in the conference, indicating a positive and encouraging tone."
            }
        },
        {
            "speaker": "Dylan Burnette",
            "timestamp": "00:06-00:07",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 1,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:06",
            "end_time": "70:07",
            "annotations": {
                "acknowledge contribution": "Dylan Burnette is acknowledging the discussion or the facilitation of the meeting, expressing gratitude without necessarily agreeing or expanding on any specific point."
            }
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:07-00:07",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:07",
            "end_time": "70:07",
            "annotations": [
                {
                    "acknowledge contribution": "The speaker is verbally acknowledging the contributions of others in the discussion."
                }
            ]
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:08-00:08",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:08",
            "end_time": "70:08",
            "annotations": [
                {
                    "acknowledge contribution": "The speaker is verbally acknowledging the discussion, expressing gratitude for the contributions made by others."
                }
            ]
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:08-00:09",
            "transcript": "Nice meeting you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:08",
            "end_time": "70:09",
            "annotations": {
                "express enthusiasm": "The speaker expresses a positive sentiment about the meeting, indicating enthusiasm."
            }
        },
        {
            "speaker": "Unidentified speaker",
            "timestamp": "00:09-00:09",
            "transcript": "Thank you.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:09",
            "end_time": "70:09",
            "annotations": {
                "acknowledge contribution": "The speaker is verbally acknowledging the meeting or discussion, but not agreeing or expanding on any specific point."
            }
        },
        {
            "speaker": "Sixian You",
            "timestamp": "00:10-00:11",
            "transcript": "Great to meet everybody.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 100,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "70:10",
            "end_time": "70:11",
            "annotations": {
                "express enthusiasm": "The speaker expresses enthusiasm at the end of the meeting, indicating a positive feeling about the interaction with the other participants."
            }
        },
        {
            "speaker": "Andrew Feig",
            "timestamp": "01:29-01:30",
            "transcript": "Guys.",
            "speaking_duration": 1,
            "nods_others": 0,
            "smile_self": 0,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "None",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "71:29",
            "end_time": "71:30",
            "annotations": [
                {
                    "encourage particpatioin": "This utterance is a simple way to encourage participation from the group, as it is a general call to attention."
                }
            ]
        },
        {
            "speaker": "Shiva Abbaszadeh",
            "timestamp": "01:32-01:35",
            "transcript": "God, my brain felt like as if I have to creak really.",
            "speaking_duration": 3,
            "nods_others": 0,
            "smile_self": 100,
            "smile_other": 0,
            "distracted_others": 0,
            "hand_gesture": "Pointing",
            "interuption": "No",
            "overlap": "No",
            "screenshare": "No",
            "screenshare_content": "None",
            "start_time": "71:32",
            "end_time": "71:35",
            "annotations": {
                "express frustration": "The speaker expresses feeling mentally strained or overwhelmed, indicated by the metaphor of their brain feeling like it's creaking, which suggests a sense of mental fatigue or difficulty processing information after a long meeting."
            }
        }
    ]
}