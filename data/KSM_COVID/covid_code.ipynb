{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in /Users/eveyhuang/Documents/NICO/.venv/lib/python3.12/site-packages (1.2.9)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /Users/eveyhuang/Documents/NICO/.venv/lib/python3.12/site-packages (from pyreadstat) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/eveyhuang/Documents/NICO/.venv/lib/python3.12/site-packages (from pandas>=1.2.0->pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/eveyhuang/Documents/NICO/.venv/lib/python3.12/site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/eveyhuang/Documents/NICO/.venv/lib/python3.12/site-packages (from pandas>=1.2.0->pyreadstat) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/eveyhuang/Documents/NICO/.venv/lib/python3.12/site-packages (from pandas>=1.2.0->pyreadstat) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/eveyhuang/Documents/NICO/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id  Tech  CurrentNegative  PastNegative  \\\n",
      "0  0CD5A01591584DE1940F418669198AEB   1.0              0.5          6.50   \n",
      "1                          1.20E+49   1.0              1.0          3.50   \n",
      "2                             10258   1.0             -1.0          5.00   \n",
      "3                             10408   1.0              0.5          4.00   \n",
      "4                             11293   1.5              0.5          3.75   \n",
      "\n",
      "   Commual  Engage  Defens  Question  PespTak  Simi  VaxImp  BoostImp  \\\n",
      "0      6.0     7.0     1.0       0.5      0.5   1.0     2.5       3.5   \n",
      "1      5.0     4.0     2.0       0.0      1.0   1.0     5.0       2.5   \n",
      "2      4.0     6.0     1.0       0.0      0.5   2.5     7.0       6.0   \n",
      "3      3.0     6.5     1.0       1.0      0.0   0.0     7.0       6.5   \n",
      "4      7.0     7.0     1.0       5.5      3.5   1.5     7.0       6.5   \n",
      "\n",
      "   CogComp  SelfOther  \n",
      "0      3.5       3.00  \n",
      "1      4.5       2.50  \n",
      "2      7.0       4.00  \n",
      "3      5.0       5.00  \n",
      "4      6.5       5.75  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'human_coder.sav'\n",
    "hm_df = pd.read_spss(file_path)\n",
    "\n",
    "print(hm_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   id  Tech  CurrentNegative  PastNegative  \\\n",
      "4                               11293   1.5              0.5          3.75   \n",
      "9                               13717   1.0              0.0          7.00   \n",
      "231  68CDB46365634548A07C5D65711A65B3   1.0             -1.0          2.50   \n",
      "56                              21103   1.0              1.5          3.50   \n",
      "90                              24307   1.0              0.0          0.50   \n",
      "\n",
      "     Commual  Engage  Defens  Question  PespTak  Simi  VaxImp  BoostImp  \\\n",
      "4        7.0     7.0     1.0       5.5      3.5   1.5     7.0       6.5   \n",
      "9        7.0     7.0     1.0       8.5      3.5   0.0     7.0       7.0   \n",
      "231      6.0     7.0     1.0       3.5      3.0   0.0     4.5       3.5   \n",
      "56       7.0     7.0     1.0       1.5      3.0   1.5     7.0       7.0   \n",
      "90       7.0     7.0     1.0       1.0      2.5   6.0     7.0       7.0   \n",
      "\n",
      "     CogComp  SelfOther  \n",
      "4        6.5       5.75  \n",
      "9        6.5       6.00  \n",
      "231      5.5       5.00  \n",
      "56       6.0       6.50  \n",
      "90       6.5       7.00  \n"
     ]
    }
   ],
   "source": [
    "ranked_pt_df = hm_df.sort_values(by='PespTak', ascending=False)\n",
    "print(ranked_pt_df.head())  # Display top rows for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0CD5A01591584DE1940F418669198AEB' '1.20E+49' '10258' '10408' '11293'\n",
      " '11542' '13132' '13258' '13306' '13717' '13867' '14044' '15256' '15418'\n",
      " '15439' '15442' '15472' '15502' '15523' '15547' '15754' '15817' '15823'\n",
      " '15907' '15937' '16114' '16306' '16948' '17668' '17767' '17878'\n",
      " '180F3F79E0514EA8A0A0D2FA682C4294' '18268' '18274' '18277' '18670'\n",
      " '19012' '19324' '19396' '19423' '19993' '19999' '20005' '20041' '20047'\n",
      " '20269' '20344' '20551' '20689' '20809' '20908' '20914' '20950' '20971'\n",
      " '21001' '21007' '21103' '21184' '21193' '21277' '21316' '21337' '21364'\n",
      " '21370' '21436' '21448' '21646' '21652' '21724' '21826' '21832' '21850'\n",
      " '22042' '22054' '22654' '22861' '22876' '22879' '22927' '23311' '23419'\n",
      " '23461' '23719' '23767' '23842' '23863' '23887' '23995' '24268' '24304'\n",
      " '24307' '24394' '24424' '24460' '24676' '24811' '24919'\n",
      " '24BC3A44EAB247DD8A64EE8D7C02D0E5' '26629' '27220' '27490' '27514'\n",
      " '27589' '30259' '3046' '3049' '3082' '3166' '3229' '3283' '3307' '3310'\n",
      " '3322' '33265' '3349' '33661' '3370' '33823' '3406' '34345' '3511'\n",
      " '35233' '3526' '3535' '3553' '35689' '35875' '3643' '36817' '36868'\n",
      " '3688' '3694' '3715' '37261' '37447' '3754' '37558' '37564' '37855'\n",
      " '3811' '38227' '38242' '38647' '3868' '38872' '3901' '39043' '39076'\n",
      " '39184' '39229' '3925' '39280' '39364' '39382' '39385' '39409' '39424'\n",
      " '39637' '3970' '39928' '3A42B40B1AC84DC08935A0F55455F38E'\n",
      " '3B490B5082204B71BA8C946BD4FCC70E' '40084' '40198' '4039' '40561' '40624'\n",
      " '40627' '4102' '41041' '4132' '41392' '41443' '41449' '41734' '41965'\n",
      " '41986' '42223' '4240' '42472' '42532' '42589' '42709' '42712' '4276'\n",
      " '42763' '42772' '4294' '43069' '43174' '43234' '43288' '43396' '43564'\n",
      " '4357' '43582' '43702' '4378' '43792' '43921' '43927' '43948' '43975'\n",
      " '4402' '44038' '44188' '44278' '44287' '4429' '4444' '44500' '4456'\n",
      " '44560' '44626' '4516' '4552' '4588' '4780' '4858' '4981' '5011'\n",
      " '507075A75F704910B84D5123EADAD730' '5338' '5341' '5545' '5749' '5755'\n",
      " '5890' '5CB76BED4B3A4DC586B042B85960FE14'\n",
      " '5FAA82160042458792D27578E79D9C30' '6451'\n",
      " '68CDB46365634548A07C5D65711A65B3' '6DF63FC45D8B4884B57B897C94DB074A'\n",
      " '7123F1A8D2F343B4A62AD8E34A182FEE' '7492' '7633' '7642'\n",
      " '78CFD14BC60E4CD89845ED7BFCCD1A3A' '8.60E+07' '8014'\n",
      " '8781F039E57A430D99F8E2B1ADA9ECC1' '9089405D45634C35A798EC274EA35117'\n",
      " '9421' '9631' '9925' '9970' 'A3BE49A9E92C4E6DBBC9B6EA70CC9AA9'\n",
      " 'A5FA9A6634C74E909A03EF242A9E11CD' 'A7D0D4EB4A18495BB70754AA90E9A72B'\n",
      " 'AEF1CA9F241D49F6BA7BE542C3ADE07D' 'B4C98C85F2CE44B0803EFF51E87FBF73'\n",
      " 'B7D21927472C45B3866D10E6FB320AB8' 'C4303A5F65D041D391BB020BA40D77E6'\n",
      " 'E336C200D5724B1C821874B01A428571' 'E75AABBDA5CC4A219FDBE61855D36359'\n",
      " 'EBD8909E071444E9BAE6D7BEA6636060']\n"
     ]
    }
   ],
   "source": [
    "unique_ids = hm_df['id'].unique()\n",
    "print(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  Tech  CurrentNegative  PastNegative  Commual  Engage  Defens  \\\n",
      "0  0CD5A   1.0              0.5          6.50      6.0     7.0     1.0   \n",
      "1  1.20E   1.0              1.0          3.50      5.0     4.0     2.0   \n",
      "2  10258   1.0             -1.0          5.00      4.0     6.0     1.0   \n",
      "3  10408   1.0              0.5          4.00      3.0     6.5     1.0   \n",
      "4  11293   1.5              0.5          3.75      7.0     7.0     1.0   \n",
      "\n",
      "   Question  PespTak  Simi  VaxImp  BoostImp  CogComp  SelfOther  \n",
      "0       0.5      0.5   1.0     2.5       3.5      3.5       3.00  \n",
      "1       0.0      1.0   1.0     5.0       2.5      4.5       2.50  \n",
      "2       0.0      0.5   2.5     7.0       6.0      7.0       4.00  \n",
      "3       1.0      0.0   0.0     7.0       6.5      5.0       5.00  \n",
      "4       5.5      3.5   1.5     7.0       6.5      6.5       5.75  \n"
     ]
    }
   ],
   "source": [
    "# Create a copy of hm_df\n",
    "hm_df_truncated = hm_df.copy()\n",
    "\n",
    "# Truncate the 'id' column to preserve only the first 5 characters for IDs with length > 5\n",
    "hm_df_truncated['id'] = hm_df_truncated['id'].apply(lambda x: x[:5] if len(x) > 5 else x)\n",
    "\n",
    "print(hm_df_truncated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing key: technology\n",
      "Processing key: cur_neg_affect\n",
      "Processing key: past_neg_affect\n",
      "Processing key: communal_orientation\n",
      "Processing key: engagement\n",
      "Processing key: defensiveness\n",
      "Processing key: questions\n",
      "Processing key: perspective_statements\n",
      "Processing key: similarity_statements\n",
      "Processing key: vaccine_importance\n",
      "Processing key: booster_importance\n",
      "Processing key: cognitive_complexity\n",
      "Processing key: general_notes\n",
      "['1', '1', '3', '5', '6', '1', 3, 0, 0, '-1', '-1', '4', 'The participant is a registered nurse.']\n",
      "{'technology': ['1', 'There were no technical difficulties during the conversation.'], 'cur_neg_affect': ['1', 'The participant did not express any negative affect about the pandemic/masks/vaccine/boosters in the present.'], 'past_neg_affect': ['3', 'The participant expressed some negative affect about the pandemic when recalling the past, such as feeling concerned and scared for those being affected.'], 'communal_orientation': ['5', 'The participant displayed some behaviors and made some statements that reflect a desire for social connectedness with their conversation partner, such as asking questions and listening attentively.'], 'engagement': ['6', 'The participant was engaged in the conversation, throwing themselves into the conversation and genuinely conversing with their partner.'], 'defensiveness': ['1', 'The participant was not at all defensive in justifying their beliefs/perspective.'], 'questions': ['What was your experience like? [00:03:10]', 'Did you get any booster shots as well? [00:12:23]', 'What was your thought process there? [00:12:27]'], 'perspective_statements': [], 'similarity_statements': [], 'vaccine_importance': ['-1', 'The participant did not explicitly state their belief about the importance of vaccines.'], 'booster_importance': ['-1', 'The participant did not explicitly state their belief about the importance of boosters.'], 'cognitive_complexity': ['4', 'The participant demonstrated a moderate amount of cognitive complexity, considering and analyzing different perspectives in the conversation.'], 'general_notes': 'The participant is a registered nurse.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/eveyhuang/Documents/NICO/gemini_code/outputs/NEW_KSM_COVID_videos/output_B4C98/B4C98_Video/B4C98_Video.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    new_row = []\n",
    "    all_keys = data.keys()\n",
    "    for key in all_keys:\n",
    "        print(f\"Processing key: {key}\")\n",
    "        value = data[key]\n",
    "        annotation = value\n",
    "        if key in ['questions', 'perspective_statements', 'similarity_statements']:\n",
    "            annotation = len(value)\n",
    "        elif type(value) is list and len(value) > 0:\n",
    "            # If the value is a list, take the first element\n",
    "            annotation = value[0]\n",
    "        new_row.append(annotation)\n",
    "    print(new_row)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B4C98', '1', '1', '3', '5', '6', '1', 3, 0, 0, 1, 1, '4', 'The participant is a registered nurse.']\n",
      "['180F3', 1, 2, 3, 5, 6, 1, 4, 0, 1, 7, -1, 4, 'The participant is generally positive and open to sharing their experiences.']\n",
      "['8781F', '1', '2', '4', '4', '5', '1', 2, 0, 1, '4', 1, '4', 'The participant had an allergic reaction to the vaccine and is now hesitant to get more boosters.']\n",
      "['12E48', '1', '3', '4', '5', '6', '2', 2, 0, 1, '4', '1', '5', \"The participant is skeptical about the COVID vaccine and boosters, but is respectful of others' opinions.\"]\n",
      "['086E6', '1', '1', '2', '5', '6', '1', 0, 0, 0, '6', '4', '4', 'The participant was very polite and respectful.']\n",
      "['39043', 1, 2, 3, 4, 6, 1, 1, 0, 0, -1, -1, 4, 'The participant seems to have had a relatively positive experience during the pandemic, as they were already working remotely and their family stayed safe.']\n",
      "['6DF63', '1', '1', '2', '4', '5', '1', 2, 0, 0, 1, 1, '4', 'The participant was generally positive and shared their experiences openly.']\n",
      "['A7D0D', '1', '2', '3', '4', '5', '2', 2, 0, 0, '3', '1', '3', 'The participant seems to be against mask mandates and vaccines.']\n",
      "['50707', '1', '1', '2', '4', '5', '1', 1, 0, 0, 1, 1, '3', 'The participant was very friendly and easy to talk to.']\n",
      "['21103', '1', '2', '3', '5', '6', '1', 2, 0, 0, '7', '7', '5', 'The participant is very open and shares her experiences with COVID and the vaccine.']\n",
      "['33823', 1, 2, 3, 5, 6, 1, 2, 0, 0, 7, 7, 5, 'The participant is very talkative and shares a lot of personal information.']\n",
      "['B7D21', '1', '2', '3', '4', '5', '1', 2, 0, 1, '6', '6', '4', 'The participant is open to sharing their experiences and opinions, and seems to have a positive attitude towards vaccines.']\n",
      "['78CFD', 1, 2, 3, 4, 5, 1, 3, 0, 1, 4, 2, 4, 'The participant is a female.']\n",
      "['E75AA', 1, 3, 4, 4, 5, 1, 1, 0, 0, -1, -1, 4, 'The participant E75AA seems to have a negative experience with the vaccine and is now skeptical of it.']\n",
      "['3B490', '1', '1', '2', '4', '5', '1', 2, 0, 0, 1, 1, '4', 'The participant was generally neutral and did not express strong opinions or emotions.']\n",
      "['AEF1C', '1', '2', '6', '5', '6', '2', 2, 0, 0, '1', '1', '5', 'The participant is very open and shares a lot of personal information.']\n",
      "['90894', '1', '2', '3', '4', '5', '1', 2, 0, 1, '4', '3', '4', 'The participant is open and shares her experiences and feelings about COVID and vaccinations.']\n",
      "['5FAA8', '1', '1', '3', '5', '6', '1', 3, 0, 1, '7', '7', '5', 'The participant was very open and shared her experiences in detail. She was also very engaged in the conversation and asked questions to her partner.']\n",
      "['EBD89', '1', '1', '3', '5', '6', '1', 2, 0, 0, '7', '7', '5', 'The participant lost his brother to COVID.']\n",
      "['68CDB', 1, 1, 3, 4, 6, 1, 4, 0, 2, 4, 1, 4, 'The participant is a young woman who lives in Nebraska. She works from home and did not have anyone affected too badly by COVID. She got vaccinated but did not get a booster.']\n",
      "['24BC3', '1', '2', '3', '4', '5', '1', 1, 0, 0, '4', '1', '4', 'The participant is a health officer and has a lot of experience with COVID.']\n",
      "['C4303', '1', '2', '3', '4', '5', '1', 2, 0, 0, 1, 1, '4', 'The participant is open and willing to share her experiences and opinions.']\n",
      "['5CB76', '1', '1', '3', '5', '6', '1', 1, 0, 1, '6', '5', '4', 'The participant was hesitant about the vaccine at first, but got it after seeing Dr. Fauci and Mike Pence get it on TV.']\n",
      "['7123F', '1', '2', '3', '4', '5', '1', 1, 0, 0, 1, 1, '4', 'The participant is identified as 7123F.']\n",
      "['39385', '1', '2', '3', '4', '5', '1', 2, 0, 0, 1, 1, '4', 'The participant seems to be a good listener and is able to share their experiences in a clear and concise manner.']\n",
      "['A5FA9', 1, 2, 3, 4, 6, 1, 2, 0, 0, 4, -1, 4, 'The participant is a healthcare worker and is very knowledgeable about the vaccine.']\n",
      "['3A42B', '1', '1', '3', '5', '5', '1', 1, 0, 0, 1, 1, '4', 'The participant was very open and shared a lot of personal information about their experience with COVID-19.']\n",
      "['0CD5A', '1', '2', '3', '4', '5', '1', 0, 0, 0, '4', '2', '3', 'The participant seems to have a negative view of the vaccine and boosters, but is not strongly opposed to them. He seems to believe that he has natural immunity from having had COVID multiple times.']\n",
      "['E336C', '1', '1', '3', '5', '6', '1', 2, 0, 1, '6', '6', '5', 'The participant was very friendly and open to sharing their experiences.']\n",
      "['A3BE4', 1, 2, 3, 4, 5, 1, 1, 0, 0, 4, 4, 4, \"The participant is generally positive and doesn't express strong opinions about the pandemic or vaccines.\"]\n",
      "      id Tech CurrentNegative PastNegative Commual Engage Defens  Question  \\\n",
      "0  B4C98    1               1            3       5      6      1         3   \n",
      "1  180F3    1               2            3       5      6      1         4   \n",
      "2  8781F    1               2            4       4      5      1         2   \n",
      "3  12E48    1               3            4       5      6      2         2   \n",
      "4  086E6    1               1            2       5      6      1         0   \n",
      "\n",
      "   PespTak  Simi VaxImp BoostImp CogComp  \\\n",
      "0        0     0      1        1       4   \n",
      "1        0     1      7       -1       4   \n",
      "2        0     1      4        1       4   \n",
      "3        0     1      4        1       5   \n",
      "4        0     0      6        4       4   \n",
      "\n",
      "                                           SelfOther  \n",
      "0             The participant is a registered nurse.  \n",
      "1  The participant is generally positive and open...  \n",
      "2  The participant had an allergic reaction to th...  \n",
      "3  The participant is skeptical about the COVID v...  \n",
      "4    The participant was very polite and respectful.  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Create a new DataFrame with the same column names as hm_df\n",
    "new_df = pd.DataFrame(columns=hm_df.columns)\n",
    "\n",
    "# Path to the directory containing subfolders with JSON files\n",
    "base_path = \"/Users/eveyhuang/Documents/NICO/gemini_code/outputs/NEW_KSM_COVID_videos\"\n",
    "\n",
    "# Iterate through each subfolder and JSON file\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON from file {file_path}: {e}\")\n",
    "                new_row = []\n",
    "                # Extract the first 5 characters of the file name as \"id\"\n",
    "                new_row.append(file[:5])\n",
    "                all_keys = data.keys()\n",
    "                for key in all_keys:\n",
    "                    value = data[key]\n",
    "                    annotation = value\n",
    "                    if key in ['questions', 'perspective_statements', 'similarity_statements']:\n",
    "                        annotation = len(value)\n",
    "                    elif key == 'Notes':\n",
    "                        annotation = value\n",
    "                    elif type(value) is list and len(value) > 0:\n",
    "                       # If the value is a list, take the first element\n",
    "                        annotation = value[0]\n",
    "                        if isinstance(annotation, str) and len(annotation) > 1:\n",
    "                            annotation = [int(x) for x in re.findall(r'\\d+', annotation)][0]\n",
    "                    new_row.append(annotation)\n",
    "                print(new_row)\n",
    "                # Append the data as a new row in the DataFrame\n",
    "                new_df.loc[len(new_df)] = new_row\n",
    "\n",
    "print(new_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.rename(columns={'SelfOther': 'Notes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id Tech CurrentNegative PastNegative Commual Engage Defens  Question  \\\n",
      "0   B4C98    1               1            3       5      6      1         3   \n",
      "1   180F3    1               2            3       5      6      1         4   \n",
      "2   8781F    1               2            4       4      5      1         2   \n",
      "3   12E48    1               3            4       5      6      2         2   \n",
      "4   086E6    1               1            2       5      6      1         0   \n",
      "5   39043    1               2            3       4      6      1         1   \n",
      "6   6DF63    1               1            2       4      5      1         2   \n",
      "7   A7D0D    1               2            3       4      5      2         2   \n",
      "8   50707    1               1            2       4      5      1         1   \n",
      "9   21103    1               2            3       5      6      1         2   \n",
      "10  33823    1               2            3       5      6      1         2   \n",
      "11  B7D21    1               2            3       4      5      1         2   \n",
      "12  78CFD    1               2            3       4      5      1         3   \n",
      "13  E75AA    1               3            4       4      5      1         1   \n",
      "14  3B490    1               1            2       4      5      1         2   \n",
      "15  AEF1C    1               2            6       5      6      2         2   \n",
      "16  90894    1               2            3       4      5      1         2   \n",
      "17  5FAA8    1               1            3       5      6      1         3   \n",
      "18  EBD89    1               1            3       5      6      1         2   \n",
      "19  68CDB    1               1            3       4      6      1         4   \n",
      "20  24BC3    1               2            3       4      5      1         1   \n",
      "21  C4303    1               2            3       4      5      1         2   \n",
      "22  5CB76    1               1            3       5      6      1         1   \n",
      "23  7123F    1               2            3       4      5      1         1   \n",
      "24  39385    1               2            3       4      5      1         2   \n",
      "25  A5FA9    1               2            3       4      6      1         2   \n",
      "26  3A42B    1               1            3       5      5      1         1   \n",
      "27  0CD5A    1               2            3       4      5      1         0   \n",
      "28  E336C    1               1            3       5      6      1         2   \n",
      "29  A3BE4    1               2            3       4      5      1         1   \n",
      "\n",
      "    PespTak  Simi VaxImp BoostImp CogComp  \\\n",
      "0         0     0      1        1       4   \n",
      "1         0     1      7       -1       4   \n",
      "2         0     1      4        1       4   \n",
      "3         0     1      4        1       5   \n",
      "4         0     0      6        4       4   \n",
      "5         0     0     -1       -1       4   \n",
      "6         0     0      1        1       4   \n",
      "7         0     0      3        1       3   \n",
      "8         0     0      1        1       3   \n",
      "9         0     0      7        7       5   \n",
      "10        0     0      7        7       5   \n",
      "11        0     1      6        6       4   \n",
      "12        0     1      4        2       4   \n",
      "13        0     0     -1       -1       4   \n",
      "14        0     0      1        1       4   \n",
      "15        0     0      1        1       5   \n",
      "16        0     1      4        3       4   \n",
      "17        0     1      7        7       5   \n",
      "18        0     0      7        7       5   \n",
      "19        0     2      4        1       4   \n",
      "20        0     0      4        1       4   \n",
      "21        0     0      1        1       4   \n",
      "22        0     1      6        5       4   \n",
      "23        0     0      1        1       4   \n",
      "24        0     0      1        1       4   \n",
      "25        0     0      4       -1       4   \n",
      "26        0     0      1        1       4   \n",
      "27        0     0      4        2       3   \n",
      "28        0     1      6        6       5   \n",
      "29        0     0      4        4       4   \n",
      "\n",
      "                                            SelfOther  \n",
      "0              The participant is a registered nurse.  \n",
      "1   The participant is generally positive and open...  \n",
      "2   The participant had an allergic reaction to th...  \n",
      "3   The participant is skeptical about the COVID v...  \n",
      "4     The participant was very polite and respectful.  \n",
      "5   The participant seems to have had a relatively...  \n",
      "6   The participant was generally positive and sha...  \n",
      "7   The participant seems to be against mask manda...  \n",
      "8   The participant was very friendly and easy to ...  \n",
      "9   The participant is very open and shares her ex...  \n",
      "10  The participant is very talkative and shares a...  \n",
      "11  The participant is open to sharing their exper...  \n",
      "12                       The participant is a female.  \n",
      "13  The participant E75AA seems to have a negative...  \n",
      "14  The participant was generally neutral and did ...  \n",
      "15  The participant is very open and shares a lot ...  \n",
      "16  The participant is open and shares her experie...  \n",
      "17  The participant was very open and shared her e...  \n",
      "18         The participant lost his brother to COVID.  \n",
      "19  The participant is a young woman who lives in ...  \n",
      "20  The participant is a health officer and has a ...  \n",
      "21  The participant is open and willing to share h...  \n",
      "22  The participant was hesitant about the vaccine...  \n",
      "23            The participant is identified as 7123F.  \n",
      "24  The participant seems to be a good listener an...  \n",
      "25  The participant is a healthcare worker and is ...  \n",
      "26  The participant was very open and shared a lot...  \n",
      "27  The participant seems to have a negative view ...  \n",
      "28  The participant was very friendly and open to ...  \n",
      "29  The participant is generally positive and does...  \n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  Tech_hm  CurrentNegative_hm  PastNegative_hm  Commual_hm  Engage_hm  \\\n",
      "0  0CD5A      1.0                 0.5              6.5         6.0        7.0   \n",
      "1  180F3      1.0                 0.0              2.5         6.5        7.0   \n",
      "2  21103      1.0                 1.5              3.5         7.0        7.0   \n",
      "3  24BC3      1.0                 1.0              6.5         5.0        7.0   \n",
      "4  33823      1.0                 2.5              5.5         7.0        6.5   \n",
      "\n",
      "   Defens_hm  Question_hm  PespTak_hm  Simi_hm  ...  PastNegative_new  \\\n",
      "0        1.0          0.5         0.5      1.0  ...               3.0   \n",
      "1        1.0          3.5         2.5      2.5  ...               3.0   \n",
      "2        1.0          1.5         3.0      1.5  ...               3.0   \n",
      "3        2.5          0.0         0.5      0.5  ...               3.0   \n",
      "4        1.5          0.0         0.0      0.0  ...               3.0   \n",
      "\n",
      "   Commual_new  Engage_new  Defens_new  Question_new  PespTak_new  Simi_new  \\\n",
      "0          4.0         5.0         1.0           0.0          0.0       0.0   \n",
      "1          5.0         6.0         1.0           4.0          0.0       1.0   \n",
      "2          5.0         6.0         1.0           2.0          0.0       0.0   \n",
      "3          4.0         5.0         1.0           1.0          0.0       0.0   \n",
      "4          5.0         6.0         1.0           2.0          0.0       0.0   \n",
      "\n",
      "   VaxImp_new  BoostImp_new  CogComp_new  \n",
      "0         4.0           2.0          3.0  \n",
      "1         7.0          -1.0          4.0  \n",
      "2         7.0           7.0          5.0  \n",
      "3         4.0           1.0          4.0  \n",
      "4         7.0           7.0          5.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categories:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m merged_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_new\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m merged_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# Calculate Cohen's kappa score for the category\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m         kappa \u001b[38;5;241m=\u001b[39m \u001b[43mcohen_kappa_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcategory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_hm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcategory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_new\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         kappa_scores[category] \u001b[38;5;241m=\u001b[39m kappa\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print the Cohen's kappa scores for each category\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/NICO/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/NICO/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:741\u001b[0m, in \u001b[0;36mcohen_kappa_score\u001b[0;34m(y1, y2, labels, weights, sample_weight)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    668\u001b[0m     {\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my1\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcohen_kappa_score\u001b[39m(y1, y2, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    678\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute Cohen's kappa: a statistic that measures inter-annotator agreement.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m    This function computes Cohen's kappa [1]_, a score that expresses the level\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m    np.float64(0.6875)\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     confusion \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m confusion\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    743\u001b[0m     sum0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(confusion, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/NICO/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/NICO/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:340\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m(np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 340\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/Documents/NICO/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    109\u001b[0m             type_true, type_pred\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "# Ensure both DataFrames have the same IDs and exclude \"Notes\" and \"SelfOther\" columns\n",
    "columns_to_exclude = ['Notes', 'SelfOther']\n",
    "hm_df_filtered = hm_df_truncated.drop(columns=columns_to_exclude, errors='ignore')\n",
    "new_df_filtered = new_df.drop(columns=columns_to_exclude, errors='ignore')\n",
    "\n",
    "# Merge the filtered DataFrames on 'id'\n",
    "merged_df = pd.merge(hm_df_filtered, new_df_filtered, on='id', suffixes=('_hm', '_new'))\n",
    "columns_to_cast = [col for col in merged_df.columns if col != 'id']\n",
    "merged_df[columns_to_cast] = merged_df[columns_to_cast].astype(float)\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  Tech_hm  CurrentNegative_hm  PastNegative_hm  Commual_hm  \\\n",
      "0   0CD5A      1.0                 0.5              6.5         6.0   \n",
      "1   180F3      1.0                 0.0              2.5         6.5   \n",
      "2   21103      1.0                 1.5              3.5         7.0   \n",
      "3   24BC3      1.0                 1.0              6.5         5.0   \n",
      "4   33823      1.0                 2.5              5.5         7.0   \n",
      "5   39043      1.0                 0.5              4.5         5.5   \n",
      "6   39385      1.0                -1.0              4.5         5.5   \n",
      "7   3A42B      1.0                -1.0              6.5         6.0   \n",
      "8   3B490      1.0                 3.0              5.5         6.5   \n",
      "9   50707      1.0                 0.0              3.5         5.0   \n",
      "10  5CB76      1.0                 1.0              6.5         6.5   \n",
      "11  5FAA8      1.0                 1.5              2.0         7.0   \n",
      "12  68CDB      1.0                -1.0              2.5         6.0   \n",
      "13  6DF63      1.0                -1.0              3.5         4.0   \n",
      "14  7123F      1.0                 0.5              5.5         5.0   \n",
      "15  78CFD      1.0                 3.5              6.5         6.0   \n",
      "16  8781F      1.0                 4.5              6.0         5.5   \n",
      "17  90894      1.0                 5.5              6.5         6.0   \n",
      "18  A3BE4      1.0                 1.0              3.0         6.0   \n",
      "19  A5FA9      1.0                 0.5              5.5         6.0   \n",
      "20  A7D0D      1.0                -1.0              4.5         4.5   \n",
      "21  AEF1C      1.0                -1.0              7.0         5.0   \n",
      "22  B4C98      1.0                 1.0              4.5         5.0   \n",
      "23  B7D21      1.0                 3.0              4.0         3.5   \n",
      "24  C4303      1.0                 0.0              6.0         6.0   \n",
      "25  E336C      1.0                 0.0              3.0         7.0   \n",
      "26  E75AA      1.0                 4.5              6.0         5.0   \n",
      "27  EBD89      1.5                -1.0              5.0         4.5   \n",
      "\n",
      "    Engage_hm  Defens_hm  Question_hm  PespTak_hm  Simi_hm  ...  \\\n",
      "0         7.0        1.0          0.5         0.5      1.0  ...   \n",
      "1         7.0        1.0          3.5         2.5      2.5  ...   \n",
      "2         7.0        1.0          1.5         3.0      1.5  ...   \n",
      "3         7.0        2.5          0.0         0.5      0.5  ...   \n",
      "4         6.5        1.5          0.0         0.0      0.0  ...   \n",
      "5         7.0        1.0          0.0         0.5      0.5  ...   \n",
      "6         7.0        1.0          0.0         1.0      1.5  ...   \n",
      "7         7.0        2.5          0.5         0.5      0.5  ...   \n",
      "8         7.0        1.0          3.5         0.0      0.5  ...   \n",
      "9         7.0        2.0          2.0         2.5      1.5  ...   \n",
      "10        7.0        1.0          0.0         2.0      2.5  ...   \n",
      "11        7.0        1.0          5.5         2.5      5.0  ...   \n",
      "12        7.0        1.0          3.5         3.0      0.0  ...   \n",
      "13        6.5        1.0          0.0         0.5      0.5  ...   \n",
      "14        7.0        1.0          0.0         0.0      1.0  ...   \n",
      "15        7.0        1.5          0.5         0.0      0.5  ...   \n",
      "16        7.0        1.5          2.0         1.5      1.0  ...   \n",
      "17        7.0        1.5          0.0         0.0      0.0  ...   \n",
      "18        7.0        1.5          2.5         2.0      1.0  ...   \n",
      "19        7.0        1.0          1.0         1.0      0.5  ...   \n",
      "20        7.0        1.5          1.0         0.5      0.5  ...   \n",
      "21        7.0        3.0          0.0         1.5      0.0  ...   \n",
      "22        7.0        1.0          0.0         1.5      1.0  ...   \n",
      "23        7.0        1.0          2.0         0.0      2.5  ...   \n",
      "24        7.0        2.5          3.0         2.5      0.5  ...   \n",
      "25        7.0        1.0          3.0         1.5      2.5  ...   \n",
      "26        6.5        2.5          0.0         0.0      0.0  ...   \n",
      "27        5.5        1.0          1.0         0.0      0.0  ...   \n",
      "\n",
      "    PastNegative_new  Commual_new  Engage_new  Defens_new  Question_new  \\\n",
      "0                3.0          4.0         5.0         1.0           0.0   \n",
      "1                3.0          5.0         6.0         1.0           4.0   \n",
      "2                3.0          5.0         6.0         1.0           2.0   \n",
      "3                3.0          4.0         5.0         1.0           1.0   \n",
      "4                3.0          5.0         6.0         1.0           2.0   \n",
      "5                3.0          4.0         6.0         1.0           1.0   \n",
      "6                3.0          4.0         5.0         1.0           2.0   \n",
      "7                3.0          5.0         5.0         1.0           1.0   \n",
      "8                2.0          4.0         5.0         1.0           2.0   \n",
      "9                2.0          4.0         5.0         1.0           1.0   \n",
      "10               3.0          5.0         6.0         1.0           1.0   \n",
      "11               3.0          5.0         6.0         1.0           3.0   \n",
      "12               3.0          4.0         6.0         1.0           4.0   \n",
      "13               2.0          4.0         5.0         1.0           2.0   \n",
      "14               3.0          4.0         5.0         1.0           1.0   \n",
      "15               3.0          4.0         5.0         1.0           3.0   \n",
      "16               4.0          4.0         5.0         1.0           2.0   \n",
      "17               3.0          4.0         5.0         1.0           2.0   \n",
      "18               3.0          4.0         5.0         1.0           1.0   \n",
      "19               3.0          4.0         6.0         1.0           2.0   \n",
      "20               3.0          4.0         5.0         2.0           2.0   \n",
      "21               6.0          5.0         6.0         2.0           2.0   \n",
      "22               3.0          5.0         6.0         1.0           3.0   \n",
      "23               3.0          4.0         5.0         1.0           2.0   \n",
      "24               3.0          4.0         5.0         1.0           2.0   \n",
      "25               3.0          5.0         6.0         1.0           2.0   \n",
      "26               4.0          4.0         5.0         1.0           1.0   \n",
      "27               3.0          5.0         6.0         1.0           2.0   \n",
      "\n",
      "    PespTak_new  Simi_new  VaxImp_new  BoostImp_new  CogComp_new  \n",
      "0           0.0       0.0         4.0           2.0          3.0  \n",
      "1           0.0       1.0         7.0          -1.0          4.0  \n",
      "2           0.0       0.0         7.0           7.0          5.0  \n",
      "3           0.0       0.0         4.0           1.0          4.0  \n",
      "4           0.0       0.0         7.0           7.0          5.0  \n",
      "5           0.0       0.0        -1.0          -1.0          4.0  \n",
      "6           0.0       0.0         1.0           1.0          4.0  \n",
      "7           0.0       0.0         1.0           1.0          4.0  \n",
      "8           0.0       0.0         1.0           1.0          4.0  \n",
      "9           0.0       0.0         1.0           1.0          3.0  \n",
      "10          0.0       1.0         6.0           5.0          4.0  \n",
      "11          0.0       1.0         7.0           7.0          5.0  \n",
      "12          0.0       2.0         4.0           1.0          4.0  \n",
      "13          0.0       0.0         1.0           1.0          4.0  \n",
      "14          0.0       0.0         1.0           1.0          4.0  \n",
      "15          0.0       1.0         4.0           2.0          4.0  \n",
      "16          0.0       1.0         4.0           1.0          4.0  \n",
      "17          0.0       1.0         4.0           3.0          4.0  \n",
      "18          0.0       0.0         4.0           4.0          4.0  \n",
      "19          0.0       0.0         4.0          -1.0          4.0  \n",
      "20          0.0       0.0         3.0           1.0          3.0  \n",
      "21          0.0       0.0         1.0           1.0          5.0  \n",
      "22          0.0       0.0         1.0           1.0          4.0  \n",
      "23          0.0       1.0         6.0           6.0          4.0  \n",
      "24          0.0       0.0         1.0           1.0          4.0  \n",
      "25          0.0       1.0         6.0           6.0          5.0  \n",
      "26          0.0       0.0        -1.0          -1.0          4.0  \n",
      "27          0.0       0.0         7.0           7.0          5.0  \n",
      "\n",
      "[28 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     4.0\n",
      "1     7.0\n",
      "2     7.0\n",
      "3     4.0\n",
      "4     7.0\n",
      "5    -1.0\n",
      "6     1.0\n",
      "7     1.0\n",
      "8     1.0\n",
      "9     1.0\n",
      "10    6.0\n",
      "11    7.0\n",
      "12    4.0\n",
      "13    1.0\n",
      "14    1.0\n",
      "15    4.0\n",
      "16    4.0\n",
      "17    4.0\n",
      "18    4.0\n",
      "19    4.0\n",
      "20    3.0\n",
      "21    1.0\n",
      "22    1.0\n",
      "23    6.0\n",
      "24    1.0\n",
      "25    6.0\n",
      "26   -1.0\n",
      "27    7.0\n",
      "Name: VaxImp_new, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['VaxImp_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "16    1\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "22    1\n",
      "23    1\n",
      "24    1\n",
      "25    1\n",
      "26    1\n",
      "27    2\n",
      "Name: Tech_hm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['Tech_hm'].round().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(list(merged_df['Tech_new'].round().astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa for Tech: 0.0\n",
      "Cohen's kappa for CurrentNegative: 0.07999999999999996\n",
      "Cohen's kappa for PastNegative: 0.041825095057034245\n",
      "Cohen's kappa for Commual: 0.022058823529411686\n",
      "Cohen's kappa for Engage: 0.0\n",
      "Cohen's kappa for Defens: 0.17204301075268813\n",
      "Cohen's kappa for Question: 0.25039370078740164\n",
      "Cohen's kappa for PespTak: 0.0\n",
      "Cohen's kappa for Simi: 0.12250712250712248\n",
      "Cohen's kappa for VaxImp: 0.19999999999999996\n",
      "Cohen's kappa for BoostImp: 0.3870402802101576\n",
      "Cohen's kappa for CogComp: 0.02506963788300831\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store Cohen's kappa scores for each category\n",
    "kappa_scores = {}\n",
    "all_labels = list(range(-1, 8)) \n",
    "# Iterate through each category (column) in hm_df excluding 'id'\n",
    "categories = [col for col in hm_df_filtered.columns if col != 'id']\n",
    "for category in categories:\n",
    "    # if f\"{category}_hm\" in merged_df.columns and f\"{category}_new\" in merged_df.columns:\n",
    "    #     # Calculate Cohen's kappa score for the category\n",
    "    #     kappa = cohen_kappa_score(merged_df[f\"{category}_hm\"], merged_df[f\"{category}_new\"])\n",
    "    #     kappa_scores[category] = kappa\n",
    "    \n",
    "    col_hm = f\"{category}_hm\"\n",
    "    col_new = f\"{category}_new\"\n",
    "    \n",
    "    if col_hm in merged_df.columns and col_new in merged_df.columns:\n",
    "        # Drop NaNs\n",
    "        y_true = merged_df[col_hm].round().astype(int)\n",
    "        y_pred = merged_df[col_new].round().astype(int)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred, labels=all_labels, weights='linear')\n",
    "        kappa_scores[category] = kappa\n",
    "# Print the Cohen's kappa scores for each category\n",
    "for category, score in kappa_scores.items():\n",
    "    print(f\"Cohen's kappa for {category}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple agreement score for Tech: 0.9642857142857143\n",
      "Simple agreement score for CurrentNegative: 0.19047619047619047\n",
      "Simple agreement score for PastNegative: 0.07142857142857142\n",
      "Simple agreement score for Commual: 0.17857142857142858\n",
      "Simple agreement score for Engage: 0.07142857142857142\n",
      "Simple agreement score for Defens: 0.6071428571428571\n",
      "Simple agreement score for Question: 0.21428571428571427\n",
      "Simple agreement score for PespTak: 0.5\n",
      "Simple agreement score for Simi: 0.4642857142857143\n",
      "Simple agreement score for VaxImp: 0.38461538461538464\n",
      "Simple agreement score for BoostImp: 0.4166666666666667\n",
      "Simple agreement score for CogComp: 0.32142857142857145\n",
      "Percent agreement: 32.14%\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store Cohen's kappa scores for each category\n",
    "simple_agreement_scores = {}\n",
    "all_labels = list(range(-1, 8)) \n",
    "# Iterate through each category (column) in hm_df excluding 'id'\n",
    "categories = [col for col in hm_df_filtered.columns if col != 'id']\n",
    "for category in categories:\n",
    "    # if f\"{category}_hm\" in merged_df.columns and f\"{category}_new\" in merged_df.columns:\n",
    "    #     # Calculate Cohen's kappa score for the category\n",
    "    #     kappa = cohen_kappa_score(merged_df[f\"{category}_hm\"], merged_df[f\"{category}_new\"])\n",
    "    #     kappa_scores[category] = kappa\n",
    "    \n",
    "    col_hm = f\"{category}_hm\"\n",
    "    col_new = f\"{category}_new\"\n",
    "    \n",
    "    if col_hm in merged_df.columns and col_new in merged_df.columns:\n",
    "        # Drop NaNs\n",
    "        y_true = merged_df[col_hm].round().astype(int)\n",
    "        y_pred = merged_df[col_new].round().astype(int)\n",
    "        valid_pairs = [(a, b) for a, b in zip(y_true, y_pred) if a != -1 and b != -1]\n",
    "        # Count total valid pairs\n",
    "        n_total = len(valid_pairs)\n",
    "\n",
    "        # Count agreements\n",
    "        n_agree = sum(a == b for a, b in valid_pairs)\n",
    "\n",
    "        # Calculate percent agreement\n",
    "        percent_agreement = n_agree / n_total if n_total > 0 else float('nan')\n",
    "\n",
    "        simple_agreement_scores[category] = percent_agreement\n",
    "# Print the Cohen's kappa scores for each category\n",
    "for category, score in simple_agreement_scores.items():\n",
    "    print(f\"Simple agreement score for {category}: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC score for Tech: -9.714451465470118e-17\n",
      "ICC score for CurrentNegative: 0.15351506456241018\n",
      "ICC score for PastNegative: 0.12571428571428586\n",
      "ICC score for Commual: 0.09823182711198457\n",
      "ICC score for Engage: -0.008791208791209162\n",
      "ICC score for Defens: 0.2808716707021793\n",
      "ICC score for Question: 0.4158215010141987\n",
      "ICC score for PespTak: 0.0\n",
      "ICC score for Simi: 0.21140472878998595\n",
      "ICC score for VaxImp: 0.20037231342020664\n",
      "ICC score for BoostImp: 0.5971337579617836\n",
      "ICC score for CogComp: 0.17777777777777803\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store Cohen's kappa scores for each category\n",
    "import pingouin as pg\n",
    "\n",
    "icc_scores = {}\n",
    "all_labels = list(range(-1, 8)) \n",
    "# Iterate through each category (column) in hm_df excluding 'id'\n",
    "categories = [col for col in hm_df_filtered.columns if col != 'id']\n",
    "for category in categories:\n",
    "    # if f\"{category}_hm\" in merged_df.columns and f\"{category}_new\" in merged_df.columns:\n",
    "    #     # Calculate Cohen's kappa score for the category\n",
    "    #     kappa = cohen_kappa_score(merged_df[f\"{category}_hm\"], merged_df[f\"{category}_new\"])\n",
    "    #     kappa_scores[category] = kappa\n",
    "    \n",
    "    col_hm = f\"{category}_hm\"\n",
    "    col_new = f\"{category}_new\"\n",
    "    \n",
    "    if col_hm in merged_df.columns and col_new in merged_df.columns:\n",
    "        # Drop NaNs\n",
    "        coder_1 = merged_df[col_hm].round().astype(int)\n",
    "        coder_2 = merged_df[col_new].round().astype(int)\n",
    "        df = pd.DataFrame({'coder1': coder_1, 'coder2': coder_2})\n",
    "\n",
    "        # Exclude -1s\n",
    "        df = df[(df['coder1'] != -1) & (df['coder2'] != -1)]\n",
    "        # Reshape for pingouin\n",
    "        df_long = df.melt(var_name='rater', value_name='score', ignore_index=False).reset_index()\n",
    "        icc = pg.intraclass_corr(data=df_long, targets='index', raters='rater', ratings='score')\n",
    "       \n",
    "        icc_scores[category] = icc['ICC'].values[1] if not icc.empty else float('nan')\n",
    "\n",
    "# Print the Cohen's kappa scores for each category\n",
    "for category, score in icc_scores.items():\n",
    "    print(f\"ICC score for {category}: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Category  Cohen_Kappa_Score  Simple_Agreement_Score  ICC_Score\n",
      "0              Tech              0.000                   0.964     -0.000\n",
      "1   CurrentNegative              0.080                   0.190      0.154\n",
      "2      PastNegative              0.042                   0.071      0.126\n",
      "3           Commual              0.022                   0.179      0.098\n",
      "4            Engage              0.000                   0.071     -0.009\n",
      "5            Defens              0.172                   0.607      0.281\n",
      "6          Question              0.250                   0.214      0.416\n",
      "7           PespTak              0.000                   0.500      0.000\n",
      "8              Simi              0.123                   0.464      0.211\n",
      "9            VaxImp              0.200                   0.385      0.200\n",
      "10         BoostImp              0.387                   0.417      0.597\n",
      "11          CogComp              0.025                   0.321      0.178\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to display kappa scores and simple agreement scores\n",
    "scores_table = pd.DataFrame({\n",
    "    'Category': kappa_scores.keys(),\n",
    "    'Cohen_Kappa_Score': kappa_scores.values(),\n",
    "    'Simple_Agreement_Score': simple_agreement_scores.values(),\n",
    "    'ICC_Score': icc_scores.values()\n",
    "})\n",
    "\n",
    "print(scores_table.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
