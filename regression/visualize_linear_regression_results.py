#!/usr/bin/env python3
"""
Visualize Regression Results from Excel File

This script loads regression results from the Excel file generated by regression_analysis.py
and creates comprehensive visualizations.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Set style
plt.style.use('default')
sns.set_palette("husl")

def load_regression_results(file_path, sheet_name):
    """
    Load significant regression results from Excel file.
    
    Args:
        file_path: Path to Excel file with regression results
    
    Returns:
        DataFrame with significant regression results only
    """
    
    try:
        # Load the Excel file - only significant results
        df = pd.read_excel(file_path, sheet_name)
        print(f"✅ Loaded {len(df)} SIGNIFICANT regression results from {file_path}")
        print(f"Features: {df['Feature'].nunique()}")
        print(f"Outcomes: {df['Outcome'].nunique()}")
        print(f"All results are significant (p < 0.05)")
        return df
        
    except Exception as e:
        print(f"❌ Error loading file: {e}")
        print("Please ensure 'regression_results.xlsx' exists with 'Significant_Results' sheet")
        return None

def create_r_squared_heatmap(results_df, figsize=(12, 8)):
    """
    Create a heatmap showing R-squared values across features and outcomes.
    """
    
    # Pivot the data for heatmap
    pivot_data = results_df.pivot(index='Feature', columns='Outcome', values='R_Squared')
    
    # Create the heatmap
    fig, ax = plt.subplots(figsize=figsize)
    
    # Use viridis colormap for R-squared
    sns.heatmap(pivot_data, annot=True, fmt='.4f', cmap='viridis', 
                vmin=0, vmax=1, ax=ax, cbar_kws={'label': 'R-squared'})
    
    ax.set_title('R-squared Values by Feature and Outcome', fontsize=16, fontweight='bold')
    ax.set_xlabel('Outcome Variables')
    ax.set_ylabel('Features')
    
    plt.tight_layout()
    return fig

def create_significance_matrix(results_df, figsize=(12, 8)):
    """
    Create a matrix showing significance levels across features and outcomes.
    Since we're only showing significant results, this will show the level of significance.
    """
    
    # Create significance matrix
    significance_matrix = results_df.pivot(index='Feature', columns='Outcome', values='P_Value')
    
    # Convert to significance levels
    sig_levels = significance_matrix.copy()
    sig_levels[sig_levels < 0.001] = 4  # ***
    sig_levels[(sig_levels >= 0.001) & (sig_levels < 0.01)] = 3  # **
    sig_levels[(sig_levels >= 0.01) & (sig_levels < 0.05)] = 2  # *
    sig_levels[(sig_levels >= 0.05) & (sig_levels < 0.1)] = 1  # .
    sig_levels[sig_levels >= 0.1] = 0  # ns
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Create custom colormap for significant results only
    colors = ['lightcoral', 'orange', 'gold', 'lightgreen']  # Removed white since all are significant
    from matplotlib.colors import ListedColormap
    cmap = ListedColormap(colors)
    
    im = ax.imshow(sig_levels.values, cmap=cmap, aspect='auto')
    
    # Add text annotations
    for i in range(len(sig_levels.index)):
        for j in range(len(sig_levels.columns)):
            p_val = significance_matrix.iloc[i, j]
            if p_val < 0.001:
                text = '***'
            elif p_val < 0.01:
                text = '**'
            elif p_val < 0.05:
                text = '*'
            elif p_val < 0.1:
                text = '.'
            else:
                text = 'ns'
            
            ax.text(j, i, text, ha='center', va='center', fontweight='bold', fontsize=12)
    
    ax.set_xticks(range(len(sig_levels.columns)))
    ax.set_xticklabels(sig_levels.columns)
    ax.set_yticks(range(len(sig_levels.index)))
    ax.set_yticklabels(sig_levels.index)
    
    ax.set_title('Significant Results Only\n*** p<0.001, ** p<0.01, * p<0.05', 
                 fontsize=14, fontweight='bold')
    ax.set_xlabel('Outcome Variables')
    ax.set_ylabel('Features')
    
    plt.tight_layout()
    return fig

def create_coefficient_comparison(results_df, figsize=(18, 12)):
    """
    Create a comprehensive comparison of coefficients with confidence intervals.
    """
    
    # Separate by outcome
    outcomes = results_df['Outcome'].unique()
    n_outcomes = len(outcomes)
    
    # Create subplots without shared y-axis to ensure all labels show
    fig, axes = plt.subplots(1, n_outcomes, figsize=figsize, sharey=False)
    if n_outcomes == 1:
        axes = [axes]
    
    for i, outcome in enumerate(outcomes):
        outcome_data = results_df[results_df['Outcome'] == outcome].copy()
        outcome_data = outcome_data.sort_values('Coefficient', ascending=True)
        
        # Create coefficient plot with confidence intervals
        y_pos = range(len(outcome_data))
        
        # Plot confidence intervals
        axes[i].errorbar(outcome_data['Coefficient'], y_pos, 
                       xerr=[outcome_data['Coefficient'] - outcome_data['CI_Lower_95'],
                             outcome_data['CI_Upper_95'] - outcome_data['Coefficient']],
                       fmt='o', capsize=5, capthick=2, markersize=8)
        
        # Color by significance level (all are significant, so show level)
        colors = ['darkgreen' if p < 0.001 else 'green' if p < 0.01 else 'orange' for p in outcome_data['P_Value']]
        for j, (coef, y) in enumerate(zip(outcome_data['Coefficient'], y_pos)):
            axes[i].scatter(coef, y, c=colors[j], s=100, zorder=5)
        
        # Add vertical line at zero
        axes[i].axvline(x=0, color='black', linestyle='--', alpha=0.5)
        
        # Set y-axis labels for each subplot individually
        axes[i].set_yticks(y_pos)
        axes[i].set_yticklabels(outcome_data['Feature'], fontsize=10)
        axes[i].set_xlabel('Coefficient Value')
        axes[i].set_ylabel('Features', fontsize=12, fontweight='bold')
        axes[i].set_title(f'{outcome}\nCoefficients with 95% CI')
        axes[i].grid(True, alpha=0.3)
        
        # Ensure y-axis labels are visible
        axes[i].tick_params(axis='y', labelsize=10)
    
    plt.suptitle('Coefficient Comparison Across Features and Outcomes', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    return fig

def create_r_squared_comparison(results_df, figsize=(12, 8)):
    """
    Create a bar chart comparing R-squared values across features and outcomes, sorted by values.
    """
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Get all unique features and outcomes
    all_features = results_df['Feature'].unique()
    outcomes = results_df['Outcome'].unique()
    colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']
    
    # Calculate maximum R-squared value for each feature across all outcomes for sorting
    feature_max_r2 = {}
    for feature in all_features:
        feature_data = results_df[results_df['Feature'] == feature]
        if len(feature_data) > 0:
            feature_max_r2[feature] = feature_data['R_Squared'].max()
        else:
            feature_max_r2[feature] = 0
    
    # Sort features by their maximum R-squared value (descending)
    sorted_features = sorted(all_features, key=lambda x: feature_max_r2[x], reverse=True)
    
    # Create grouped bar chart
    x = np.arange(len(sorted_features))
    width = 0.35
    
    for i, outcome in enumerate(outcomes):
        outcome_data = results_df[results_df['Outcome'] == outcome]
        
        # Create arrays for this outcome, using sorted features
        r_squared_values = []
        for feature in sorted_features:
            feature_data = outcome_data[outcome_data['Feature'] == feature]
            if len(feature_data) > 0:
                r_squared_values.append(feature_data['R_Squared'].iloc[0])
            else:
                r_squared_values.append(0)  # No data for this feature-outcome combination
        
        bars = ax.bar(x + i * width, r_squared_values, width, 
                     label=outcome, color=colors[i % len(colors)], alpha=0.8)
        
        # Add value labels on bars (only for non-zero values)
        for j, (bar, value) in enumerate(zip(bars, r_squared_values)):
            if value > 0:  # Only label non-zero values
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                       f'{value:.4f}', ha='center', va='bottom', fontsize=9)
    
    ax.set_xlabel('Features')
    ax.set_ylabel('R-squared')
    ax.set_title('R-squared Comparison - Sorted by Maximum R² Value', 
                 fontsize=14, fontweight='bold')
    ax.set_xticks(x + width/2)
    ax.set_xticklabels(sorted_features, rotation=45, ha='right')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def create_coefficient_comparison_barplot(results_df, figsize=(12, 8)):
    """
    Create a bar chart comparing coefficient values across features and outcomes with significance indicators, sorted by values.
    """
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Get all unique features and outcomes
    all_features = results_df['Feature'].unique()
    outcomes = results_df['Outcome'].unique()
    colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']
    
    # Calculate maximum absolute coefficient value for each feature across all outcomes for sorting
    feature_max_coef = {}
    for feature in all_features:
        feature_data = results_df[results_df['Feature'] == feature]
        if len(feature_data) > 0:
            feature_max_coef[feature] = abs(feature_data['Coefficient']).max()
        else:
            feature_max_coef[feature] = 0
    
    # Sort features by their maximum absolute coefficient value (descending)
    sorted_features = sorted(all_features, key=lambda x: feature_max_coef[x], reverse=True)
    
    # Create grouped bar chart
    x = np.arange(len(sorted_features))
    width = 0.35
    
    for i, outcome in enumerate(outcomes):
        outcome_data = results_df[results_df['Outcome'] == outcome]
        
        # Create arrays for this outcome, using sorted features
        coefficient_values = []
        p_values = []
        for feature in sorted_features:
            feature_data = outcome_data[outcome_data['Feature'] == feature]
            if len(feature_data) > 0:
                coefficient_values.append(feature_data['Coefficient'].iloc[0])
                p_values.append(feature_data['P_Value'].iloc[0])
            else:
                coefficient_values.append(0)  # No data for this feature-outcome combination
                p_values.append(1.0)  # Non-significant
        
        bars = ax.bar(x + i * width, coefficient_values, width, 
                     label=outcome, color=colors[i % len(colors)], alpha=0.8)
        
        # Add coefficient values and significance indicators on bars
        for j, (bar, coef, p_val) in enumerate(zip(bars, coefficient_values, p_values)):
            if coef != 0:  # Only label non-zero values
                height = bar.get_height()
                
                # Determine significance level
                if p_val < 0.001:
                    sig_text = '***'
                    sig_color = 'darkgreen'
                elif p_val < 0.01:
                    sig_text = '**'
                    sig_color = 'green'
                elif p_val < 0.05:
                    sig_text = '*'
                    sig_color = 'orange'
                else:
                    sig_text = 'ns'
                    sig_color = 'gray'
                
                # Position text above or below bar based on sign
                if coef >= 0:
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{coef:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
                    # Add significance indicator above the coefficient
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                           sig_text, ha='center', va='bottom', fontsize=10, 
                           fontweight='bold', color=sig_color)
                else:
                    ax.text(bar.get_x() + bar.get_width()/2., height - 0.01,
                           f'{coef:.3f}', ha='center', va='top', fontsize=9, fontweight='bold')
                    # Add significance indicator below the coefficient
                    ax.text(bar.get_x() + bar.get_width()/2., height - 0.05,
                           sig_text, ha='center', va='top', fontsize=10, 
                           fontweight='bold', color=sig_color)
    
    # Add horizontal line at zero
    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3, linewidth=0.5)
    
    ax.set_xlabel('Features')
    ax.set_ylabel('Coefficient Value')
    ax.set_title('Coefficient Comparison - Sorted by Maximum |Coefficient| Value\n*** p<0.001, ** p<0.01, * p<0.05', 
                 fontsize=14, fontweight='bold')
    ax.set_xticks(x + width/2)
    ax.set_xticklabels(sorted_features, rotation=45, ha='right')
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    return fig

def create_p_value_distribution(results_df, figsize=(12, 6)):
    """
    Create visualizations of p-value distributions.
    """
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)
    
    # Histogram of p-values
    ax1.hist(results_df['P_Value'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    ax1.axvline(x=0.05, color='red', linestyle='--', linewidth=2, label='α = 0.05')
    ax1.axvline(x=0.01, color='orange', linestyle='--', linewidth=2, label='α = 0.01')
    ax1.set_xlabel('P-value')
    ax1.set_ylabel('Frequency')
    ax1.set_title('Distribution of P-values')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Q-Q plot for p-values (should be uniform under null)
    from scipy import stats
    stats.probplot(results_df['P_Value'], dist="uniform", plot=ax2)
    ax2.set_title('Q-Q Plot of P-values')
    ax2.grid(True, alpha=0.3)
    
    plt.suptitle('P-value Analysis', fontsize=16, fontweight='bold')
    plt.tight_layout()
    return fig

def create_feature_ranking(results_df, metric='R_Squared', figsize=(12, 8)):
    """
    Create a ranking visualization of features by performance metric.
    """
    
    # Calculate average performance by feature
    feature_performance = results_df.groupby('Feature')[metric].mean().sort_values(ascending=True)
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Create horizontal bar chart
    bars = ax.barh(range(len(feature_performance)), feature_performance.values, 
                   color='steelblue', alpha=0.8)
    
    # Add value labels
    for i, (bar, value) in enumerate(zip(bars, feature_performance.values)):
        ax.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,
               f'{value:.4f}', va='center', fontsize=10)
    
    ax.set_yticks(range(len(feature_performance)))
    ax.set_yticklabels(feature_performance.index)
    ax.set_xlabel(f'Average {metric}')
    ax.set_title(f'Feature Ranking by Average {metric}', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def create_coefficient_barplot_with_ci(results_df, figsize=(12, 8)):
    """
    Create a bar plot with confidence intervals for coefficients, similar to the example provided.
    """
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Sort features by coefficient value for better visualization
    results_sorted = results_df.sort_values('Coefficient', ascending=True)
    
    # Create bar plot
    bars = ax.bar(range(len(results_sorted)), results_sorted['Coefficient'], 
                  color='steelblue', alpha=0.8, capsize=5)
    
    # Add error bars (confidence intervals)
    yerr_lower = results_sorted['Coefficient'] - results_sorted['CI_Lower_95']
    yerr_upper = results_sorted['CI_Upper_95'] - results_sorted['Coefficient']
    
    ax.errorbar(range(len(results_sorted)), results_sorted['Coefficient'], 
                yerr=[yerr_lower, yerr_upper], fmt='none', color='black', capsize=3, capthick=1)
    
    # Add coefficient values as text labels
    for i, (bar, coef) in enumerate(zip(bars, results_sorted['Coefficient'])):
        height = bar.get_height()
        # Position label above or below bar based on sign
        if coef >= 0:
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                   f'b = {coef:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        else:
            ax.text(bar.get_x() + bar.get_width()/2., height - 0.01,
                   f'b = {coef:.3f}', ha='center', va='top', fontsize=10, fontweight='bold')
    
    # Add horizontal line at zero
    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.7, linewidth=1)
    
    # Customize plot
    ax.set_xlabel('Features')
    ax.set_ylabel('Coefficient Value')
    ax.set_title('Coefficient Values with 95% Confidence Intervals', fontsize=16, fontweight='bold')
    ax.set_xticks(range(len(results_sorted)))
    ax.set_xticklabels(results_sorted['Feature'], rotation=45, ha='right')
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    return fig

def create_coefficient_barplot_by_outcome(results_df, figsize=(15, 8)):
    """
    Create separate bar plots with confidence intervals for each outcome.
    """
    
    outcomes = results_df['Outcome'].unique()
    n_outcomes = len(outcomes)
    
    fig, axes = plt.subplots(1, n_outcomes, figsize=figsize, sharey=True)
    if n_outcomes == 1:
        axes = [axes]
    
    for i, outcome in enumerate(outcomes):
        outcome_data = results_df[results_df['Outcome'] == outcome].copy()
        outcome_data = outcome_data.sort_values('Coefficient', ascending=True)
        
        # Create bar plot
        bars = axes[i].bar(range(len(outcome_data)), outcome_data['Coefficient'], 
                          color='steelblue', alpha=0.8, capsize=5)
        
        # Add error bars (confidence intervals)
        yerr_lower = outcome_data['Coefficient'] - outcome_data['CI_Lower_95']
        yerr_upper = outcome_data['CI_Upper_95'] - outcome_data['Coefficient']
        
        axes[i].errorbar(range(len(outcome_data)), outcome_data['Coefficient'], 
                        yerr=[yerr_lower, yerr_upper], fmt='none', color='black', 
                        capsize=3, capthick=1)
        
        # Add coefficient values as text labels
        for j, (bar, coef) in enumerate(zip(bars, outcome_data['Coefficient'])):
            height = bar.get_height()
            # Position label above or below bar based on sign
            if coef >= 0:
                axes[i].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'b = {coef:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
            else:
                axes[i].text(bar.get_x() + bar.get_width()/2., height - 0.01,
                           f'b = {coef:.3f}', ha='center', va='top', fontsize=9, fontweight='bold')
        
        # Add horizontal line at zero
        axes[i].axhline(y=0, color='gray', linestyle='--', alpha=0.7, linewidth=1)
        
        # Customize subplot
        axes[i].set_xlabel('Features')
        axes[i].set_ylabel('Coefficient Value')
        axes[i].set_title(f'{outcome}\nCoefficients with 95% CI', fontsize=14, fontweight='bold')
        axes[i].set_xticks(range(len(outcome_data)))
        axes[i].set_xticklabels(outcome_data['Feature'], rotation=45, ha='right')
        axes[i].grid(True, alpha=0.3, axis='y')
    
    plt.suptitle('Coefficient Values with 95% Confidence Intervals by Outcome', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    return fig



def create_side_by_side_coefficient_comparison(results_df, figsize=(20, 12)):
    """
    Create side-by-side horizontal bar charts for easy comparison of coefficients between outcomes.
    """
    
    outcomes = results_df['Outcome'].unique()
    n_outcomes = len(outcomes)
    
    # Create subplots - one for each outcome (no shared y-axis to ensure all labels show)
    fig, axes = plt.subplots(1, n_outcomes, figsize=figsize, sharey=False)
    if n_outcomes == 1:
        axes = [axes]
    
    # Define colors for each outcome
    outcome_colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']  # Distinct colors for each outcome
    
    for i, outcome in enumerate(outcomes):
        outcome_data = results_df[results_df['Outcome'] == outcome].copy()
        outcome_data = outcome_data.sort_values('Coefficient', ascending=True)
        
        # Create bars with color coding for significance
        bar_colors = []
        for p_val in outcome_data['P_Value']:
            if p_val < 0.001:
                bar_colors.append('darkgreen')
            elif p_val < 0.01:
                bar_colors.append('green')
            elif p_val < 0.05:
                bar_colors.append('orange')
            else:
                bar_colors.append('lightgray')
        
        bars = axes[i].barh(range(len(outcome_data)), outcome_data['Coefficient'], 
                           color=bar_colors, alpha=0.8, edgecolor=outcome_colors[i], 
                           linewidth=2, label=outcome)
        
        # Add coefficient values and significance indicators
        for j, (bar, coef, p_val) in enumerate(zip(bars, outcome_data['Coefficient'], outcome_data['P_Value'])):
            width = bar.get_width()
            
            # Determine significance level
            if p_val < 0.001:
                sig_text = '***'
            elif p_val < 0.01:
                sig_text = '**'
            elif p_val < 0.05:
                sig_text = '*'
            else:
                sig_text = 'ns'
            
            # Position text based on coefficient sign
            if width >= 0:
                axes[i].text(width + 0.01, bar.get_y() + bar.get_height()/2,
                           f'{coef:.3f} {sig_text}', ha='left', va='center', 
                           fontsize=9, fontweight='bold')
            else:
                axes[i].text(width - 0.01, bar.get_y() + bar.get_height()/2,
                           f'{coef:.3f} {sig_text}', ha='right', va='center', 
                           fontsize=9, fontweight='bold')
        
        # Customize subplot
        axes[i].set_xlabel('Coefficient Value (Effect Size)', fontsize=12, fontweight='bold')
        axes[i].set_ylabel('Features', fontsize=12, fontweight='bold')
        axes[i].set_title(f'{outcome}\nCoefficient Comparison with Significance', 
                          fontsize=14, fontweight='bold')
        axes[i].axvline(x=0, color='gray', linestyle='--', alpha=0.7)
        axes[i].grid(True, alpha=0.3, axis='x')
        
        # Set y-axis labels with proper spacing
        axes[i].set_yticks(range(len(outcome_data)))
        axes[i].set_yticklabels(outcome_data['Feature'], fontsize=10)
        
        # Ensure y-axis labels are visible
        axes[i].tick_params(axis='y', labelsize=10)
    
    # Add legend for significance levels
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='darkgreen', label='p < 0.001 (***)'),
        Patch(facecolor='green', label='p < 0.01 (**)'),
        Patch(facecolor='orange', label='p < 0.05 (*)'),
        Patch(facecolor='lightgray', label='p ≥ 0.05 (ns)')
    ]
    axes[0].legend(handles=legend_elements, loc='upper right', fontsize=10)
    
    plt.suptitle('Side-by-Side Coefficient Comparison by Outcome', 
                 fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    return fig

def create_comprehensive_dashboard(results_df, save_path='regression_dashboard.png'):
    """
    Create a comprehensive dashboard with multiple visualizations.
    """
    
    # Create a large figure with subplots
    fig = plt.figure(figsize=(20, 16))
    
    # Define grid layout
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    
    # 1. R-squared heatmap (top left)
    ax1 = fig.add_subplot(gs[0, 0])
    pivot_data = results_df.pivot(index='Feature', columns='Outcome', values='R_Squared')
    sns.heatmap(pivot_data, annot=True, fmt='.4f', cmap='viridis', ax=ax1)
    ax1.set_title('R-squared Heatmap')
    
    # 2. Significance matrix (top middle)
    ax2 = fig.add_subplot(gs[0, 1])
    sig_matrix = results_df.pivot(index='Feature', columns='Outcome', values='P_Value')
    sig_levels = sig_matrix.copy()
    sig_levels[sig_levels < 0.001] = 4  # ***
    sig_levels[(sig_levels >= 0.001) & (sig_levels < 0.01)] = 3  # **
    sig_levels[(sig_levels >= 0.01) & (sig_levels < 0.05)] = 2  # *
    sns.heatmap(sig_levels, annot=True, fmt='.4f', cmap='RdYlGn', ax=ax2)
    ax2.set_title('Significance Levels (All Significant)')
    
    # 3. P-value distribution (top right)
    ax3 = fig.add_subplot(gs[0, 2])
    ax3.hist(results_df['P_Value'], bins=15, alpha=0.7, color='skyblue')
    ax3.axvline(x=0.05, color='red', linestyle='--', linewidth=2)
    ax3.set_title('P-value Distribution')
    ax3.set_xlabel('P-value')
    
    # 4. Coefficient comparison (middle row)
    ax4 = fig.add_subplot(gs[1, :])
    outcomes = results_df['Outcome'].unique()
    all_features = results_df['Feature'].unique()
    x = np.arange(len(all_features))
    width = 0.35
    
    for i, outcome in enumerate(outcomes):
        outcome_data = results_df[results_df['Outcome'] == outcome]
        
        # Create arrays for this outcome, filling missing features with 0
        coefficient_values = []
        for feature in all_features:
            feature_data = outcome_data[outcome_data['Feature'] == feature]
            if len(feature_data) > 0:
                coefficient_values.append(feature_data['Coefficient'].iloc[0])
            else:
                coefficient_values.append(0)  # No data for this feature-outcome combination
        
        ax4.bar(x + i * width, coefficient_values, width, 
               label=outcome, alpha=0.8)
    
    ax4.set_xlabel('Features')
    ax4.set_ylabel('Coefficient Value')
    ax4.set_title('Coefficient Comparison')
    ax4.set_xticks(x + width/2)
    ax4.set_xticklabels(all_features, rotation=45)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. Feature ranking (bottom left)
    ax5 = fig.add_subplot(gs[2, 0])
    feature_avg = results_df.groupby('Feature')['R_Squared'].mean().sort_values()
    ax5.barh(range(len(feature_avg)), feature_avg.values, color='steelblue', alpha=0.8)
    ax5.set_yticks(range(len(feature_avg)))
    ax5.set_yticklabels(feature_avg.index)
    ax5.set_title('Feature Ranking (Avg R²)')
    
    # 6. R-squared vs P-value (bottom middle)
    ax6 = fig.add_subplot(gs[2, 1])
    for outcome in outcomes:
        outcome_data = results_df[results_df['Outcome'] == outcome]
        ax6.scatter(outcome_data['R_Squared'], outcome_data['P_Value'], 
                   label=outcome, alpha=0.7, s=100)
    
    ax6.axhline(y=0.05, color='red', linestyle='--', alpha=0.7)
    ax6.set_xlabel('R-squared')
    ax6.set_ylabel('P-value')
    ax6.set_title('R² vs P-value')
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    # 7. Sample size analysis (bottom right)
    ax7 = fig.add_subplot(gs[2, 2])
    ax7.scatter(results_df['N'], results_df['R_Squared'], 
               c=results_df['P_Value'], cmap='RdYlBu_r', alpha=0.7, s=100)
    ax7.set_xlabel('Sample Size (N)')
    ax7.set_ylabel('R-squared')
    ax7.set_title('Sample Size vs Performance')
    ax7.grid(True, alpha=0.3)
    
    plt.suptitle('Significant Results Analysis Dashboard', 
                 fontsize=20, fontweight='bold', y=0.98)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Dashboard saved to {save_path}")
    
    plt.tight_layout()
    return fig

def create_summary_plots(results_df, save_dir='regression/regression_plots'):
    """
    Create all summary plots and save them.
    """
    
    import os
    os.makedirs(save_dir, exist_ok=True)
    
    print("🎨 Creating regression visualizations...")
    
    # 1. R-squared heatmap
    print("  📊 Creating R-squared heatmap...")
    fig1 = create_r_squared_heatmap(results_df)
    fig1.savefig(f'{save_dir}/r_squared_heatmap.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 2. Significance matrix
    print("  📈 Creating significance matrix...")
    fig2 = create_significance_matrix(results_df)
    fig2.savefig(f'{save_dir}/significance_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 3. Coefficient comparison
    print("  📊 Creating coefficient comparison...")
    fig3 = create_coefficient_comparison(results_df)
    fig3.savefig(f'{save_dir}/coefficient_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 4. R-squared comparison
    print("  📈 Creating R-squared comparison...")
    fig4 = create_r_squared_comparison(results_df)
    fig4.savefig(f'{save_dir}/r_squared_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 4.5. Coefficient comparison barplot
    print("  📊 Creating coefficient comparison barplot...")
    fig4_5 = create_coefficient_comparison_barplot(results_df)
    fig4_5.savefig(f'{save_dir}/coefficient_comparison_barplot.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 5. P-value distribution
    print("  📊 Creating p-value distribution...")
    fig5 = create_p_value_distribution(results_df)
    fig5.savefig(f'{save_dir}/p_value_distribution.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 6. Feature ranking
    print("  📈 Creating feature ranking...")
    fig6 = create_feature_ranking(results_df)
    fig6.savefig(f'{save_dir}/feature_ranking.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 7. Coefficient bar plot with CI
    print("  📊 Creating coefficient bar plot with confidence intervals...")
    fig7 = create_coefficient_barplot_with_ci(results_df)
    fig7.savefig(f'{save_dir}/coefficient_barplot_with_ci.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 8. Coefficient bar plot by outcome
    print("  📊 Creating coefficient bar plot by outcome...")
    fig8 = create_coefficient_barplot_by_outcome(results_df)
    fig8.savefig(f'{save_dir}/coefficient_barplot_by_outcome.png', dpi=300, bbox_inches='tight')
    plt.show()
    

    # 9.5. Side-by-side coefficient comparison
    print("  📊 Creating side-by-side coefficient comparison...")
    fig9_5 = create_side_by_side_coefficient_comparison(results_df)
    fig9_5.savefig(f'{save_dir}/side_by_side_coefficient_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 10. Comprehensive dashboard
    print("  🎯 Creating comprehensive dashboard...")
    fig10 = create_comprehensive_dashboard(results_df, f'{save_dir}/comprehensive_dashboard.png')
    plt.show()
    
    print(f"✅ All plots saved to '{save_dir}' directory!")

def create_summary_report(results_df):
    """
    Create a comprehensive summary report.
    """
    
    print("\n" + "="*80)
    print("📊 SIGNIFICANT RESULTS ANALYSIS SUMMARY REPORT")
    print("="*80)
    
    # Basic statistics
    print(f"\n📈 OVERALL STATISTICS:")
    print("-" * 50)
    print(f"Total significant regressions: {len(results_df)}")
    print(f"Number of features: {results_df['Feature'].nunique()}")
    print(f"Number of outcomes: {results_df['Outcome'].nunique()}")
    print("✅ All results are statistically significant (p < 0.05)")
    
    # Significance analysis
    highly_significant = results_df[results_df['P_Value'] < 0.01]
    very_highly_significant = results_df[results_df['P_Value'] < 0.001]
    
    print(f"\n⭐ SIGNIFICANCE LEVELS:")
    print("-" * 50)
    print(f"Highly significant (p < 0.01): {len(highly_significant)}/{len(results_df)} ({len(highly_significant)/len(results_df)*100:.1f}%)")
    print(f"Very highly significant (p < 0.001): {len(very_highly_significant)}/{len(results_df)} ({len(very_highly_significant)/len(results_df)*100:.1f}%)")
    
    # Performance metrics
    print(f"\n📊 PERFORMANCE METRICS:")
    print("-" * 50)
    print(f"Average R²: {results_df['R_Squared'].mean():.4f}")
    print(f"Median R²: {results_df['R_Squared'].median():.4f}")
    print(f"Max R²: {results_df['R_Squared'].max():.4f}")
    print(f"Min R²: {results_df['R_Squared'].min():.4f}")
    
    # Best performing features
    print(f"\n🔝 TOP PERFORMING FEATURES (by average R²):")
    print("-" * 50)
    best_features = results_df.groupby('Feature')['R_Squared'].mean().sort_values(ascending=False)
    for i, (feature, r2) in enumerate(best_features.head(10).items(), 1):
        print(f"{i:2d}. {feature}: R² = {r2:.4f}")
    
    # Most significant results
    print(f"\n⭐ MOST SIGNIFICANT RESULTS:")
    print("-" * 50)
    top_significant = results_df.sort_values('P_Value').head(10)
    for _, row in top_significant.iterrows():
        significance = "***" if row['P_Value'] < 0.001 else "**" if row['P_Value'] < 0.01 else "*"
        print(f"• {row['Feature']} → {row['Outcome']}: β={row['Coefficient']:.4f}, "
              f"R²={row['R_Squared']:.4f}, p={row['P_Value']:.4f} {significance}")
    
    # Outcome comparison
    print(f"\n📊 OUTCOME COMPARISON:")
    print("-" * 50)
    for outcome in results_df['Outcome'].unique():
        outcome_data = results_df[results_df['Outcome'] == outcome]
        highly_sig_count = len(outcome_data[outcome_data['P_Value'] < 0.01])
        avg_r2 = outcome_data['R_Squared'].mean()
        print(f"{outcome}: {len(outcome_data)} significant results, {highly_sig_count} highly significant, avg R² = {avg_r2:.4f}")
    
    return best_features, results_df

def main():
    """
    Main function to run the visualization analysis for significant results only.
    """
    
    print("🔍 Loading significant regression results from Excel file...")
    
    # Load results
    results_df = load_regression_results(file_path='regression/regression_results_all_data.xlsx', sheet_name='Significant_Results')
    if results_df is None:
        return
    
    # Create visualizations
    create_summary_plots(results_df)
    
    # Create summary report
    best_features, significant_results = create_summary_report(results_df)
    
    print(f"\n✅ Significant results analysis complete! Check the 'regression_plots' directory for all visualizations.")

if __name__ == "__main__":
    main()
